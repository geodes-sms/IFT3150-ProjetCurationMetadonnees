key	project	title	abstract	keywords	authors	venue	doi	references	pages	bibtex	screened_decision	final_decision	mode	inclusion_criteria	exclusion_criteria	reviewer_count	source	year	meta_title	link	publisher	metadata_missing
0	TestNN	A framework for testing robust autonomy of UAS during design and certification	As the number of Uninhabited Airborne Systems (UAS) proliferates in civil applications, industry is increasingly putting pressure on regulation authorities to provide a path for certification and allow UAS integration into regulated airspace. The success of this integration depends on developments in improved UAS reliability and safety, regulations for certification, and technologies for operational performance and safety assessment. This paper focusses on the last topic and describes a framework for quantifying robust autonomy of UAS, which quantifies the system's ability to either continue operating in the presence of faults or safely shut down. Two figures of merit are used to evaluate vehicle performance relative to mission requirements and the consequences of autonomous decision making in motion control and guidance systems. These figures of merit are interpreted within a probabilistic framework, which extends previous work in the literature. The valuation of the figures of merit can be done using stochastic simulation scenarios during both vehicle development and certification stages with different degrees of integration of hardware-in-the-loop simulation technology. The objective of the proposed framework is to aid in decision making about the suitability of a vehicle with respect to safety and reliability relative to mission requirements.	Decision making; Stochastic models; Vehicle performance; Autonomous decision; Control and guidance systems; Hardware in-the-loop simulation; Mission requirements; Operational performance; Probabilistic framework; Reliability and safeties; Stochastic simulations; Integration; Decision making;  Stochastic models;  Vehicle performance;  Autonomous decision;  Control and guidance systems;  Hardware in-the-loop simulation;  Mission requirements;  Operational performance;  Probabilistic framework;  Reliability and safeties;  Stochastic simulations;  Integration	Perez, Tristan; Donaire, Alejandro; de Lamberterie, Pierre; Williams, Brendan	AIAA Infotech at Aerospace Conference and Exhibit 2011	https://www.scopus.com/record/display.uri?eid=2-s2.0-84880791365&origin=resultslist&sort=plf-f&src=s&sid=208f182d599d879d495848333a951eea&sot=b&sdt=b&s=TITLE-ABS-KEY%28a+framework+for+testing+robust+autonomy+of+uas+during+design+and+certification%29&sl=93&sessionSearchId=208f182d599d879d495848333a951eea&relpos=0			"""@CONFERENCE{Perez2011,
    author = ""Perez, Tristan and Donaire, Alejandro and de Lamberterie, Pierre and Williams, Brendan"",
    title = ""A framework for testing robust autonomy of UAS during design and certification"",
    year = ""2011"",
    journal = ""AIAA Infotech at Aerospace Conference and Exhibit 2011"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880791365\&partnerID=40\&md5=67e1d8db066df28bfcdfeab4463af69d"",
    affiliations = ""School of Engineering, University of Newcastle, Callaghan, NSW-2308, Australia; Centre for Complex Dynamic Systems and Control, University of Newcastle, School of Engineering, Callaghan, NSW-2308, Australia; Brisbane Technology Centre, Boeing Research and Technology, QLD-4001, GPO Box 767, Australia"",
    abstract = ""As the number of Uninhabited Airborne Systems (UAS) proliferates in civil applications, industry is increasingly putting pressure on regulation authorities to provide a path for certification and allow UAS integration into regulated airspace. The success of this integration depends on developments in improved UAS reliability and safety, regulations for certification, and technologies for operational performance and safety assessment. This paper focusses on the last topic and describes a framework for quantifying robust autonomy of UAS, which quantifies the system's ability to either continue operating in the presence of faults or safely shut down. Two figures of merit are used to evaluate vehicle performance relative to mission requirements and the consequences of autonomous decision making in motion control and guidance systems. These figures of merit are interpreted within a probabilistic framework, which extends previous work in the literature. The valuation of the figures of merit can be done using stochastic simulation scenarios during both vehicle development and certification stages with different degrees of integration of hardware-in-the-loop simulation technology. The objective of the proposed framework is to aid in decision making about the suitability of a vehicle with respect to safety and reliability relative to mission requirements. (c) 2011 by The University of Newcastle."",
    keywords = ""Decision making; Stochastic models; Vehicle performance; Autonomous decision; Control and guidance systems; Hardware in-the-loop simulation; Mission requirements; Operational performance; Probabilistic framework; Reliability and safeties; Stochastic simulations; Integration"",
    isbn = ""978-160086944-0"",
    language = ""English"",
    abbrev_source_title = ""AIAA Infotech at Aerospace Conf. and Exhib. 2011"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 5; Conference name: AIAA Infotech at Aerospace Conference and Exhibit 2011; Conference date: 29 March 2011 through 31 March 2011; Conference code: 97876""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2011	A framework for testing robust autonomy of UAS during design and certification	https://www.scopus.com/record/display.uri?eid=2-s2.0-84880791365&origin=resultslist&sort=plf-f&src=s&sid=208f182d599d879d495848333a951eea&sot=b&sdt=b&s=TITLE-ABS-KEY%28a+framework+for+testing+robust+autonomy+of+uas+during+design+and+certification%29&sl=93&sessionSearchId=208f182d599d879d495848333a951eea&relpos=0		nan; References; Pages; Publisher
1	TestNN	A PROBABILISTIC APPROACH TO COLLISION RISK ESTIMATION FOR PASSENGER VEHICLES	Active safety and collision avoidance (CA) is a growing field within the automotive industry. The aim of CA systems is to prevent or mitigate collisions by active interventions i.e. warning, braking and steering. For many reasons, such as driver acceptance of the system and legal requirement that the system itself must not cause hazards, the decision making is a crucial part of the system. This paper presents a method for risk estimation on which to base the decision making. We will show how one can form criterions for decision making in terms of probability of collision. This criterion handles the noisy sensor data and process noise (driver behavior) in a natural way, using existing tracking theory. The method is illustrated by simulation results as well as test result from a prototype vehicle. Simulations and tests are examples of a system which performs autonomous braking actuation at imminent collision.	Collision Avoidance;  Collision Mitigation;  Tracking;  Decision Making;  Collision Probability; Collision Avoidance, Collision Mitigation, Tracking, Decision Making, Collision Probability	Jansson, Jonas; Gustafsson, Fredrik	IFAC Proceedings Volumes			223-228	"""@article{JANSSON2002223,
    author = ""Jansson, Jonas and Gustafsson, Fredrik"",
    title = ""A PROBABILISTIC APPROACH TO COLLISION RISK ESTIMATION FOR PASSENGER VEHICLES"",
    journal = ""IFAC Proceedings Volumes"",
    volume = ""35"",
    number = ""1"",
    pages = ""223-228"",
    year = ""2002"",
    note = ""15th IFAC World Congress"",
    issn = ""1474-6670"",
    doi = ""https://doi.org/10.3182/20020721-6-ES-1901.01505"",
    url = ""https://www.sciencedirect.com/science/article/pii/S1474667015399262"",
    keywords = ""Collision Avoidance, Collision Mitigation, Tracking, Decision Making, Collision Probability"",
    abstract = ""Active safety and collision avoidance (CA) is a growing field within the automotive industry. The aim of CA systems is to prevent or mitigate collisions by active interventions i.e. warning, braking and steering. For many reasons, such as driver acceptance of the system and legal requirement that the system itself must not cause hazards, the decision making is a crucial part of the system. This paper presents a method for risk estimation on which to base the decision making. We will show how one can form criterions for decision making in terms of probability of collision. This criterion handles the noisy sensor data and process noise (driver behavior) in a natural way, using existing tracking theory. The method is illustrated by simulation results as well as test result from a prototype vehicle. Simulations and tests are examples of a system which performs autonomous braking actuation at imminent collision.""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Science Direct	2002	A probabilistic approach to collision risk estimation for passenger vehicles		Science Direct	nan; References; Link
2	TestNN	A rational agent controlling an autonomous vehicle: Implementation and formal verification	The development and deployment of Autonomous Vehicles (AVs) on our roads is not only realistic in the near future but can also bring significant benefits. In particular, it can potentially solve several problems relating to vehicles and traffic, for instance: (i) possible reduction of traffic congestion, with the consequence of improved fuel economy and reduced driver inactivity; (ii) possible reduction in the number of accidents, assuming that an AV can minimise the human errors that often cause traffic accidents; and (iii) increased ease of parking, especially when one considers the potential for shared AVs. In order to deploy an AV there are significant steps that must be completed in terms of hardware and software. As expected, software components play a key role in the complex AV system and so, at least for safety, we should assess the correctness of these components. In this paper, we are concerned with the high-level software component(s) responsible for the decisions in an AV. We intend to model an AV capable of navigation; obstacle avoidance; obstacle selection (when a crash is unavoidable) and vehicle recovery, etc, using a rational agent. To achieve this, we have established the following stages. First, the agent plans and actions have been implemented within the GWENDOLEN agent programming language. Second, we have built a simulated automotive environment in the Java language. Third, we have formally specified some of the required agent properties through LTL formulae, which are then formally verified with the AJPF verification tool. Finally, within the MCAPL framework (which comprises all the tools used in previous stages) we have obtained formal verification of our AV agent in terms of its specific behaviours. For example, the agent plans responsible for selecting an obstacle with low potential damage, instead of a higher damage obstacle (when possible) can be formally verified within MCAPL.We must emphasise that the major goal (of our present approach) lies in the formal verification of agent plans, rather than evaluating real-world applications. For this reason we utilised a simple matrix representation concerning the environment used by our agent.	Accidents; Computer software; Formal verification; Fuel economy; Traffic congestion; Vehicles; Agent programming languages; Automotive environment; Autonomous Vehicles; Hardware and software; Matrix representation; Software component; Vehicle recoveries; Verification tools; Autonomous agents; Accidents;  Computer software;  Formal verification;  Fuel economy;  Traffic congestion;  Vehicles;  Agent programming languages;  Automotive environment;  Autonomous Vehicles;  Hardware and software;  Matrix representation;  Software component;  Vehicle recoveries;  Verification tools;  Autonomous agents	Fernandes, Lucas E.R.; Custodio, Vinicius; Alves, Gleifer V.; Fisher, Michael	Electronic Proceedings in Theoretical Computer Science, EPTCS	https://doi.org/10.4204/EPTCS.257.5		35 - 42	"""@CONFERENCE{Fernandes201735,
    author = ""Fernandes, Lucas E.R. and Custodio, Vinicius and Alves, Gleifer V. and Fisher, Michael"",
    editor = ""L., Bulwahn and M., Kamali and S., Linker"",
    title = ""A rational agent controlling an autonomous vehicle: Implementation and formal verification"",
    year = ""2017"",
    journal = ""Electronic Proceedings in Theoretical Computer Science, EPTCS"",
    volume = ""257"",
    pages = ""35 - 42"",
    doi = ""10.4204/EPTCS.257.5"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030101519\&doi=10.4204\%2fEPTCS.257.5\&partnerID=40\&md5=afd12f85812acf2a0c4a00b832fc77ad"",
    affiliations = ""Informatics Department, UTFPR - Federal University of Technology - Parana, Campus Ponta Grossa, Ponta Grossa, Brazil; Department of Computer Science, University of Liverpool, Liverpool, United Kingdom"",
    abstract = ""The development and deployment of Autonomous Vehicles (AVs) on our roads is not only realistic in the near future but can also bring significant benefits. In particular, it can potentially solve several problems relating to vehicles and traffic, for instance: (i) possible reduction of traffic congestion, with the consequence of improved fuel economy and reduced driver inactivity; (ii) possible reduction in the number of accidents, assuming that an AV can minimise the human errors that often cause traffic accidents; and (iii) increased ease of parking, especially when one considers the potential for shared AVs. In order to deploy an AV there are significant steps that must be completed in terms of hardware and software. As expected, software components play a key role in the complex AV system and so, at least for safety, we should assess the correctness of these components. In this paper, we are concerned with the high-level software component(s) responsible for the decisions in an AV. We intend to model an AV capable of navigation; obstacle avoidance; obstacle selection (when a crash is unavoidable) and vehicle recovery, etc, using a rational agent. To achieve this, we have established the following stages. First, the agent plans and actions have been implemented within the GWENDOLEN agent programming language. Second, we have built a simulated automotive environment in the Java language. Third, we have formally specified some of the required agent properties through LTL formulae, which are then formally verified with the AJPF verification tool. Finally, within the MCAPL framework (which comprises all the tools used in previous stages) we have obtained formal verification of our AV agent in terms of its specific behaviours. For example, the agent plans responsible for selecting an obstacle with low potential damage, instead of a higher damage obstacle (when possible) can be formally verified within MCAPL.We must emphasise that the major goal (of our present approach) lies in the formal verification of agent plans, rather than evaluating real-world applications. For this reason we utilised a simple matrix representation concerning the environment used by our agent. (c) 2017 L. Fernandes, V. Custodio, G. Alves \& M. Fisher."",
    keywords = ""Accidents; Computer software; Formal verification; Fuel economy; Traffic congestion; Vehicles; Agent programming languages; Automotive environment; Autonomous Vehicles; Hardware and software; Matrix representation; Software component; Vehicle recoveries; Verification tools; Autonomous agents"",
    correspondence_address = ""L.E.R. Fernandes; Informatics Department, UTFPR - Federal University of Technology - Parana, Campus Ponta Grossa, Ponta Grossa, Brazil; email: lucfer@alunos.utfpr.edu.br"",
    publisher = ""Open Publishing Association"",
    issn = ""20752180"",
    language = ""English"",
    abbrev_source_title = ""Electron. Proc. Theor. Comput. Sci., EPTCS"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 14; Conference name: 1st Workshop on Formal Verification of Autonomous Vehicles, FVAV 2017; Conference date: 19 September 2017; Conference code: 130650; All Open Access, Gold Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2017	A rational agent controlling an autonomous vehicle: Implementation and formal verification	https://www.scopus.com/record/display.uri?eid=2-s2.0-85030101519&origin=resultslist&sort=plf-f&src=s&sid=3a92c64c9ef3ef4a671bc89fb87f0733&sot=b&sdt=b&s=TITLE-ABS-KEY%28a+rational+agent+controlling+an+autonomous+vehicle+implementation+and+formal+verification%29&sl=104&sessionSearchId=3a92c64c9ef3ef4a671bc89fb87f0733&relpos=0	Open Publishing Association	nan; References
3	TestNN	A safety concept for camera based ADAS based on multicore MCU	With the introduction of camera based ADAS systems; there is a need to consider the systems design in terms of functional safety. This is especially so in cases where system image identification results in decision to control the vehicle like in autonomous braking. Firstly, a review of functional safety is followed by a safety analysis of a camera based forward collision warning system. Potential hazards and safety goals will be described. A functional safety concept of the ECU based on multi core MCU is introduced based on image data flow from camera sensor to MCU. Safety mechanisms are introduced at each stage ensuring the correct processed image and decision based on that image. An actual MCU based design that implements these safety mechanisms is also described.	Alarm systems; Cameras; Image processing; Autonomous braking; Forward collision warning system; Functional Safety; Functional safety concepts; Image identification; Potential hazards; Processed images; Safety mechanisms; Microcontrollers; Alarm systems;  Cameras;  Image processing;  Autonomous braking;  Forward collision warning system;  Functional Safety;  Functional safety concepts;  Image identification;  Potential hazards;  Processed images;  Safety mechanisms;  Microcontrollers	Tan, Robert	2014 IEEE International Conference on Vehicular Electronics and Safety, ICVES 2014	https://doi.org/10.1109/ICVES.2014.7063714	"1.B Kaiser, A Ferdowsizadeh and T Neumerkel, ""Integrating Functional Safety and Nominal Performance Requirements for Advanced Driver Assistance Systems"", VDA Automotive SYS Conference, 13./14.06.2013. Google Scholar; 2.BF Wu, CC Kao, YF Li and MY Tsa, ""A Real-Time Embedded Blind Spot Safety Assistance System"", Intl Journal of Vehicular Technology, 2012. CrossRef  Google Scholar; 3.JF Liu, YF Su, MK Ko and PN Yu, ""Development of a Vision-Based Driver Assistance System with Lane Warning and Forward Collision Warning Functions"". CrossRef  Google Scholar; 4.ISO26262 Road Vehicles-Functional Safety. Google Scholar; 5.Aurix TC27Cx 32 bit single chip microcontroller User Manual, V1.5 Infineon Technologies. Google Scholar; 6.AP32224 Aurix Safety Manual V0.7 Infineon Technologies. Google Scholar; 7.AP32233 CIF Application Note. V0.1 Infineon Technologies. Google Scholar; 8.""AP32273 TC297TA ADAS Camera"", Application Note. V1.0 Infineon Technologies. Google Scholar"	1 - 6	"""@CONFERENCE{Tan20141,
    author = ""Tan, Robert"",
    title = ""A safety concept for camera based ADAS based on multicore MCU"",
    year = ""2014"",
    journal = ""2014 IEEE International Conference on Vehicular Electronics and Safety, ICVES 2014"",
    pages = ""1 - 6"",
    doi = ""10.1109/ICVES.2014.7063714"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934284774\&doi=10.1109\%2fICVES.2014.7063714\&partnerID=40\&md5=65782eadc62bcf44540445a927e78eab"",
    affiliations = ""Infineon Technologies Asia Pacific, United States"",
    abstract = ""With the introduction of camera based ADAS systems; there is a need to consider the systems design in terms of functional safety. This is especially so in cases where system image identification results in decision to control the vehicle like in autonomous braking. Firstly, a review of functional safety is followed by a safety analysis of a camera based forward collision warning system. Potential hazards and safety goals will be described. A functional safety concept of the ECU based on multi core MCU is introduced based on image data flow from camera sensor to MCU. Safety mechanisms are introduced at each stage ensuring the correct processed image and decision based on that image. An actual MCU based design that implements these safety mechanisms is also described. (c) 2014 IEEE."",
    keywords = ""Alarm systems; Cameras; Image processing; Autonomous braking; Forward collision warning system; Functional Safety; Functional safety concepts; Image identification; Potential hazards; Processed images; Safety mechanisms; Microcontrollers"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-147991882-9"",
    language = ""English"",
    abbrev_source_title = ""IEEE Int. Conf. Veh. Electron. Saf., ICVES"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: 2014 IEEE International Conference on Vehicular Electronics and Safety, ICVES 2014; Conference date: 16 December 2014 through 17 December 2014; Conference code: 112416""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2014	A Safety Concept for Camera Based ADAS Based on MultiCore MCU	https://www.scopus.com/record/display.uri?eid=2-s2.0-84934284774&origin=resultslist&sort=plf-f&src=s&sid=5dc2c0b4064ec59d2a822434d606e74b&sot=b&sdt=b&s=TITLE-ABS-KEY%28a+safety+concept+for+camera+based+adas+based+on+multicore+mcu%29&sl=76&sessionSearchId=5dc2c0b4064ec59d2a822434d606e74b&relpos=0	Institute of Electrical and Electronics Engineers Inc	
4	TestNN	Accurate neuron resilience prediction for a flexible reliability management in neural network accelerators	Deep neural networks have become a ubiquitous tool for mastering complex classification tasks. Current research focuses on the development of power-efficient and fast neural network hardware accelerators for mobile and embedded devices. However, when used in safety-critical applications, for example autonomously operating vehicles, the reliability of such accelerators becomes a further optimization criterion which can stand in contrast to power-efficiency and latency. Furthermore, ensuring hardware reliability becomes increasingly challenging for shrinking structure widths and rising power densities in the nanometer semiconductor technology era. One solution to this challenge is the exploitation of fault tolerant parts in deep neural networks. In this paper we propose a new method for predicting the error resilience of neurons in deep neural networks and show that this method significantly improves upon existing methods in terms of accuracy as well as interpretability. We evaluate prediction accuracy by simulating hardware faults in networks trained on the CIFAR-10 and ILSVRC image classification benchmarks and protecting neurons according to the resilience estimations. In addition, we demonstrate how our resilience prediction can be used for a flexible trade-off between reliability and efficiency in neural network hardware accelerators.	Economic and social effects; Efficiency; Forecasting; Hardware; Neural networks; Neurons; Reliability; Safety engineering; Semiconductor device manufacture; Classification tasks; Fast neural networks; Hardware reliability; Nanometer semiconductor technologies; Neural network hardware; Optimization criteria; Reliability management; Safety critical applications; Deep neural networks; Economic and social effects;  Efficiency;  Forecasting;  Hardware;  Neural networks;  Neurons;  Reliability;  Safety engineering;  Semiconductor device manufacture;  Classification tasks;  Fast neural networks;  Hardware reliability;  Nanometer semiconductor technologies;  Neural network hardware;  Optimization criteria;  Reliability management;  Safety critical applications;  Deep neural networks	Schorn, Christoph; Guntoro, Andre; Ascheid, Gerd	Proceedings of the 2018 Design, Automation and Test in Europe Conference and Exhibition, DATE 2018	https://doi.org/10.23919/DATE.2018.8342151	"1.Y. LeCun, Y. Bengio and G. Hinton, ""Deep learning"", Nature, vol. 521, no. 7553, pp. 436-444, 2015. CrossRef  Google Scholar; 2.V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra et al., Playing Atari with Deep Reinforcement Learning, 2013. Google Scholar; 3.K. He, X. Zhang, S. Ren and J. Sun, ""Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification"", IEEE International Conference on Computer Vision (ICCV), pp. 1026-1034, 2015. View Article  Google Scholar; 4.D. Silver, A. Huang, C.J. Maddison, A. Guez, L. Sifre, G. van den Driessche et al., ""Mastering the game of Go with deep neural networks and tree search"", Nature, vol. 529, no. 7587, pp. 484-489, 2016. CrossRef  Google Scholar; 5.A. Canziani, A. Paszke and E. Culurciello, An Analysis of Deep Neural Network Models for Practical Applications, 2016. Google Scholar; 6.Road vehicles -- Functional safety, 2011. Google Scholar; 7.J. Henkel, L. Bauer, N. Dutt, P. Gupta, S. Nassif, M. Shafique et al., ""Reliable on-chip systems in the nano-era"", 50th Annual Design Automation Conference, pp. 695-704, 2013. View Article  Google Scholar; 8.R. Aitken, G. Fey, Z.T. Kalbarczyk, F. Reichenbach and M. Sonza Reorda, ""Reliability Analysis Reloaded: How Will We Survive?"", Design Automation  Test in Europe Conference  Exhibition (DATE), pp. 358-367, 2013. View Article  Google Scholar; 9.L.B. Gomez, F. Cappello, L. Carro, N. DeBardeleben, B. Fang, S. Gurumurthi et al., ""GPGPUs: How to combine high computational power with high reliability"", Design Automation  Test in Europe Conference  Exhibition (DATE), 2014. CrossRef  Google Scholar; 10.S. Mittal, ""A Survey of Techniques for Approximate Computing"", ACM Computing Surveys, vol. 48, no. 4, pp. 1-33, 2016. CrossRef  Google Scholar; 11.E.B. Tchernev, R.G. Mulvaney and D.S. Phatak, ""Investigating the Fault Tolerance of Neural Networks"", Neural computation, vol. 17, no. 7, pp. 1646-1664, 2005. View Article  Google Scholar; 12.J.-C. Vialatte and F. Leduc-Primeau, ""A Study of Deep Learning Robustness Against Computation Failures"", Ninth International Conference on Advanced Cognitive Technologies and Applications, 2017. Google Scholar; 13.G. Montavon, S. Lapuschkin, A. Binder, W. Samek and K.-R. Muller, ""Explaining nonlinear classification decisions with deep Taylor decomposition"", Pattern Recognition, vol. 65, pp. 211-222, 2017. CrossRef  Google Scholar; 14.M.D. Zeiler and R. Fergus, Visualizing and Understanding Convolutional Networks, 2013. Google Scholar; 15.K. Simonyan, A. Vedaldi and A. Zisserman, Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, 2014. Google Scholar; 16.R.R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh and D. Batra, Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, 2016. Google Scholar; 17.L.M. Zintgraf, T.S. Cohen, T. Adel and M. Welling, Visualizing Deep Neural Network Decisions: Prediction Difference Analysis, 2017. Google Scholar; 18.S. Venkataramani, A. Ranjan, K. Roy and A. Raghunathan, ""AxNN"", IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED), pp. 27-32, 2014. View Article  Google Scholar; 19.Q. Zhang, T. Wang, Y. Tian, F. Yuan and Q. Xu, ""ApproxANN: An approximate computing framework for artificial neural network"", Design Automation  Test in Europe Conference  Exhibition (DATE), pp. 701-706, 2015. CrossRef  Google Scholar; 20.M.D. Zeiler, M. Ranzato, R. Monga, M. Mao, K. Yang, Q.V. Le et al., ""On rectified linear units for speech processing"", IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP), pp. 3517-3521, 2013. View Article  Google Scholar; 21.J.T. Springenberg, A. Dosovitskiy, T. Brox and M. Riedmiller, Striving for simplicity: The all convolutional net, 2014. Google Scholar; 22.A. Krizhevsky, Learning Multiple Layers of Features from Tiny Images. Google Scholar; 23.K. Simonyan and A. Zisserman, ""Very Deep Convolutional Networks for Large-Scale Image Recognition"", International Conference on Learning Representations (ICLR), 2015. Google Scholar; 24.O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma et al., ""ImageNet Large Scale Visual Recognition Challenge"", International Journal of Computer Vision, vol. 115, no. 3, pp. 211-252, 2015. CrossRef  Google Scholar; 25.F. Chollet et al., Keras, 2015. Google Scholar; 26.Theano: A Python framework for fast computation of mathematical expressions, 2016. Google Scholar"	979 - 984	"""@CONFERENCE{Schorn2018979,
    author = ""Schorn, Christoph and Guntoro, Andre and Ascheid, Gerd"",
    title = ""Accurate neuron resilience prediction for a flexible reliability management in neural network accelerators"",
    year = ""2018"",
    journal = ""Proceedings of the 2018 Design, Automation and Test in Europe Conference and Exhibition, DATE 2018"",
    volume = ""2018-January"",
    pages = ""979 - 984"",
    doi = ""10.23919/DATE.2018.8342151"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048779488\&doi=10.23919\%2fDATE.2018.8342151\&partnerID=40\&md5=6570c2c004d25bbca0a01496acb7c11e"",
    affiliations = ""Institute for Communication Technologies and Embedded Systems, RWTH Aachen University, Germany; Robert Bosch GmbH, Corporate Research, Renningen, Germany"",
    abstract = ""Deep neural networks have become a ubiquitous tool for mastering complex classification tasks. Current research focuses on the development of power-efficient and fast neural network hardware accelerators for mobile and embedded devices. However, when used in safety-critical applications, for example autonomously operating vehicles, the reliability of such accelerators becomes a further optimization criterion which can stand in contrast to power-efficiency and latency. Furthermore, ensuring hardware reliability becomes increasingly challenging for shrinking structure widths and rising power densities in the nanometer semiconductor technology era. One solution to this challenge is the exploitation of fault tolerant parts in deep neural networks. In this paper we propose a new method for predicting the error resilience of neurons in deep neural networks and show that this method significantly improves upon existing methods in terms of accuracy as well as interpretability. We evaluate prediction accuracy by simulating hardware faults in networks trained on the CIFAR-10 and ILSVRC image classification benchmarks and protecting neurons according to the resilience estimations. In addition, we demonstrate how our resilience prediction can be used for a flexible trade-off between reliability and efficiency in neural network hardware accelerators. (c) 2018 EDAA."",
    keywords = ""Economic and social effects; Efficiency; Forecasting; Hardware; Neural networks; Neurons; Reliability; Safety engineering; Semiconductor device manufacture; Classification tasks; Fast neural networks; Hardware reliability; Nanometer semiconductor technologies; Neural network hardware; Optimization criteria; Reliability management; Safety critical applications; Deep neural networks"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-398192631-6"",
    language = ""English"",
    abbrev_source_title = ""Proc. Des., Autom. Test Europe Conf. Exhib., DATE"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 58; Conference name: 2018 Design, Automation and Test in Europe Conference and Exhibition, DATE 2018; Conference date: 19 March 2018 through 23 March 2018; Conference code: 136090""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2018	Accurate neuron resilience prediction for a flexible reliability management in neural network accelerators	https://www.scopus.com/record/display.uri?eid=2-s2.0-85048779488&origin=resultslist&sort=plf-f&src=s&sid=4595e10d4b0e5f0af47911be255ab186&sot=b&sdt=b&s=TITLE-ABS-KEY%28accurate+neuron+resilience+prediction+for+a+flexible+reliability+management+in+neural+network+accelerators%29&sl=121&sessionSearchId=4595e10d4b0e5f0af47911be255ab186&relpos=0	Institute of Electrical and Electronics Engineers Inc	
5	TestNN	Adversarial attacks on computer vision algorithms using natural perturbations	Verifying the correctness of intelligent embedded systems is notoriously difficult due to the use of machine learning algorithms that cannot provide guarantees of deterministic correctness. In this paper, our validation efforts demonstrate that the OpenCV Histogram of Oriented Gradients (HOG) implementation for human detection is susceptible to errors due to both malicious perturbations and naturally occurring fog phenomena. To the best of our knowledge, we are the first to explicitly employ a natural perturbation (like fog) as an adversarial attack using methods from computer graphics. Our experimental results show that computer vision algorithms are susceptible to errors under a small set of naturally occurring perturbations even if they are robust to a majority of such perturbations. Our methods and results may be of interest to the designers, developers and validation teams of intelligent cyber-physical systems such as autonomous cars.	Perturbation methods;Simulated annealing;Machine learning algorithms;Detection algorithms;Computer vision;Support vector machines;Histograms; Perturbation methods; Simulated annealing; Machine learning algorithms; Detection algorithms; Computer vision; Support vector machines; Histograms	Ramanathan, Arvind; Pullum, Laura; Husein, Zubir; Raj, Sunny; Torosdagli, Neslisah; Pattanaik, Sumanta; Jha, Sumit K.	2017 Tenth International Conference on Contemporary Computing (IC3)	https://doi.org/10.1109/IC3.2017.8284294	"1.S. Thrun, ""Toward robotic cars"", Communications of the ACM, vol. 53, no. 4, pp. 99-106, 2010. CrossRef  Google Scholar; 2.C. Mack, ""The multiple lives of moores law"", IEEE Spectrum, vol. 52, no. 4, pp. 31-31, 2015. View Article  Google Scholar; 3.I. L. Markov, ""Limits on fundamental limits to computation"", Nature, vol. 512, no. 7513, pp. 147-154, 2014. CrossRef  Google Scholar; 4.N. Dalal and B. Triggs, ""Histograms of oriented gradients for human detection"", Computer Vision and Pattern Recognition 2005. CVPR 2005. IEEE Computer Society Conference, vol. 1, pp. 886-893, 2005. View Article  Google Scholar; 5.G. Bradski and A. Kaebler, Computer vision with the opencv library, 2008. Google Scholar; 6.C.-R. Hwang, ""Simulated annealing: theory and applications"", Acta Applicandae Mathematicae, vol. 12, no. 1, pp. 108-111, 1988. CrossRef  Google Scholar; 7.I. J. Goodfellow, J. Shlens and C. Szegedy, Explaining and harnessing adversarial examples, 2014. Google Scholar; 8.A. Nguyen, J. Yosinski and J. Clune, ""Deep neural networks are easily fooled: High confidence predictions for unrecognizable images"", 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 427-436, 2015. View Article  Google Scholar; 9.A. Ramanathan, L. L. Pullum, F. Hussain, D. Chakrabarty and S. K. Jha, ""Integrating symbolic and statistical methods for testing intelligent systems: Applications to machine learning and computer vision"", 2016 Design Automation  Test in Europe Conference  Exhibition (DATE), pp. 786-791, 2016. CrossRef  Google Scholar; 10.A. Kurakin, I. Goodfellow and S. Bengio, Adversarial examples in the physical world, 2016. Google Scholar; 11.M. Pacula, Unit-testing statistical software, February 2011,  [online]  Available: http://blog.mpacula.com/2011/02/17/unit-testing-statistical-software/. Google Scholar; 12.R. B. Grosse and D. K. Duvenaud, Testing mcmc code, 2014. Google Scholar; 13.T. Ball, B. Cook, V. Levin and S. K. Rajamani, ""Slam and static driver verifier: Technology transfer of formal methods inside microsoft"", International Conference on Integrated Formal Methods, pp. 1-20, 2004. CrossRef  Google Scholar; 14.L. Fix, ""Fifteen years of formal property verification in intel"" in 25 Years of Model Checking, Springer, pp. 139-144, 2008. CrossRef  Google Scholar; 15.R. Kaivola, R. Ghughal, N. Narasimhan, A. Telfer, J. Whittemore, S. Pandav, A. Slobodova, C. Taylor, V. Frolov, E. Reeber et al., ""Replacing testing with formal verification in intel coretm i7 processor execution engine validation"", International Conference on Computer Aided Verification, pp. 414-429, 2009. CrossRef  Google Scholar; 16.G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock, P. Derrin, D. Elkaduwe, K. Engelhardt, R. Kolanski, M. Norrish et al., ""se14: Formal verification of an os kernel"", Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles, pp. 207-220, 2009. CrossRef  Google Scholar; 17.A. Gupta, ""Formal hardware verification methods: A survey"" in Computer-Aided Verification, Springer, pp. 5-92, 1993. Google Scholar; 18.E. M. Clarke, O. Grumberg and D. Peled, Model checking, MIT press, 1999. Google Scholar; 19.M. Kwiatkowska, G. Norman and D. Parker, ""Stochastic model checking"" in Formal methods for performance evaluation, Springer, pp. 220-270, 2007. CrossRef  Google Scholar; 20.J. R. Burch, E. M. Clarke, K. L. McMillan, D. L. Dill and L.-J. Hwang, ""Symbolic model checking: 10 20 states and beyond"", Logic in Computer Science 1990. LICS'90 Proceedings. Fifth Annual IEEE Symposium on e, pp. 428-439, 1990. View Article  Google Scholar; 21.A. Legay, B. Delahaye and S. Bensalem, ""Statistical model checking: An overview"" in Runtime Verification, Springer, pp. 122-135, 2010. CrossRef  Google Scholar; 22.S. Kirkpatrick, ""Optimization by simulated annealing: Quantitative studies"", Journal of statistical physics, vol. 34, no. 5-6, pp. 975-986, 1984. CrossRef  Google Scholar; 23.E. Aarts, J. Korst and W. Michiels, ""Simulated annealing"" in Search methodologies, Springer, pp. 265-285, 2014. CrossRef  Google Scholar; 24.E. Aarts and J. Korst, Simulated annealing and boltzmann machines, 1988. Google Scholar; 25.R. Mantiuk, K. J. Kim, A. G. Rempel and W. Heidrich, ""Hdr-vdp-2: a calibrated visual metric for visibility and quality predictions in all luminance conditions"", ACM Transactions on Graphics (TOG), vol. 30, no. 4, pp. 40, 2011. CrossRef  Google Scholar; 26.K. Perlin, SIGGRAPH Comput. Graph., vol. 19, no. 3, pp. 287-296, Jul. 1985. CrossRef  Google Scholar; 27.N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. Berkay Celik and A. Swami, Practical black-box attacks against deep learning systems using adversarial examples, 2016. Google Scholar"	1-6	"""@INPROCEEDINGS{8284294,
    author = ""Ramanathan, Arvind and Pullum, Laura and Husein, Zubir and Raj, Sunny and Torosdagli, Neslisah and Pattanaik, Sumanta and Jha, Sumit K."",
    booktitle = ""2017 Tenth International Conference on Contemporary Computing (IC3)"",
    title = ""Adversarial attacks on computer vision algorithms using natural perturbations"",
    year = ""2017"",
    volume = """",
    number = """",
    pages = ""1-6"",
    abstract = ""Verifying the correctness of intelligent embedded systems is notoriously difficult due to the use of machine learning algorithms that cannot provide guarantees of deterministic correctness. In this paper, our validation efforts demonstrate that the OpenCV Histogram of Oriented Gradients (HOG) implementation for human detection is susceptible to errors due to both malicious perturbations and naturally occurring fog phenomena. To the best of our knowledge, we are the first to explicitly employ a natural perturbation (like fog) as an adversarial attack using methods from computer graphics. Our experimental results show that computer vision algorithms are susceptible to errors under a small set of naturally occurring perturbations even if they are robust to a majority of such perturbations. Our methods and results may be of interest to the designers, developers and validation teams of intelligent cyber-physical systems such as autonomous cars."",
    keywords = ""Perturbation methods;Simulated annealing;Machine learning algorithms;Detection algorithms;Computer vision;Support vector machines;Histograms"",
    doi = ""10.1109/IC3.2017.8284294"",
    ISSN = ""2572-6129"",
    month = ""Aug""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	IEEE	2017	Adversarial attacks on computer vision algorithms using natural perturbations	https://doi.org/10.1109/IC3.2017.8284294	IEEE	nan; Link
6	TestNN	Analysis of the Random Direction Mobility Model with a Sense-and-Avoid Protocol	Random mobility models (RMMs) capture the random movement patterns of mobile agents, and have been widely used in the evaluation and design of mobile networks. Existing RMMs (e.g. random walk and random direction) assume every mobile agent to move independently. Unmanned aerial systems (UASs), on the other hand, need to maintain a separation distance for the safety of the airspace, and hence their mobility patterns violate the independent movement assumption of existing RMMs. In this paper, for the first time in the literature per knowledge of authors, we enhance the Random Direction RMM through equipping it with a commonly used decentralized sense and avoid protocol-- sense-and-stop (S&S). We provide analytical results on critical networking statistics such as stationary node distribution and inter-vehicle distance distribution in a two-dimensional (2-D) space using the Markov type of analysis. The analysis and simulation studies lead to interesting insights such as that the commonly used S&S protocol is not effective when the randomness of UAV mobility is high, as it increases the probability for a UAS to stay within the collision distance.	Protocols;Atmospheric modeling;Analytical models;Mathematical model;Two dimensional displays;Collision avoidance;Markov processes; Protocols; Atmospheric modeling; Analytical models; Mathematical model; Two dimensional displays; Collision avoidance; Markov processes	Liu, Mushuang; Wan, Yan; Lewis, Frank L.	2017 IEEE Globecom Workshops (GC Wkshps)	https://doi.org/10.1109/GLOCOMW.2017.8269071	"1.Commercial uav market analysis by product (fixed wing rotary blade nano hybrid) by application (agriculture energy government media and entertainment) and segment forecasts to 2022,  [online]  Available: http://www.grandviewresearch.com/press-release/commercial-drone-market. Google Scholar; 2.Faa news,  [online]  Available: https://www.faa.gov/uas/media/Part_107_Summary.pdf. Google Scholar; 3.J. Yan, Y. Wan, S. Fu, J. Xie, S. Li and K. Lu, ""Received signal strength indicator-based decentralised control for robust long-range aerial networking using directional antennas"", IET Control Theory & Applications, 2017. CrossRef  Google Scholar; 4.J. Chen, J. Xie, Y. Gu, S. Li, S. Fu, Y. Wan, et al., ""Long-range and broadband aerial communication using directional antennas (acda): Design and implementation"", IEEE Transactions on Vehicular Technology, 2017. View Article  Google Scholar; 5.J. Xie, Y. Wan, J.H. Kim, S. Fu and K. Namuduri, ""A survey and analysis of mobility models for airborne networks"", IEEE Communications Surveys & Tutorials, vol. 16, no. 3, pp. 1221-1238, 2014. View Article  Google Scholar; 6.Y. Wan, K. Namuduri, Y. Zhou and S. Fu, ""A smooth-turn mobility model for airborne networks"", IEEE Transactions on Vehicular Technology, vol. 62, no. 7, pp. 3359-3370, 2013. View Article  Google Scholar; 7.Z. Cheng and W.B. Heinzelman, ""Exploring long lifetime routing (llr) in ad hoc networks"", Proceedings of the 7th ACM international symposium on Modeling analysis and simulation of wireless and mobile systems, pp. 203-210, 2004. CrossRef  Google Scholar; 8.G. Lim, K. Shin, S. Lee, H. Yoon and J.S. Ma, ""Link stability and route lifetime in ad-hoc wireless networks"", Parallel Processing Workshops 2002. Proceedings. International Conference on, pp. 116-123, 2002. Google Scholar; 9.P. Nain, D. Towsley, B. Liu and Z. Liu, ""Properties of random direction models"", INFOCOM 2005. 24th Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings IEEE, vol. 3, pp. 1897-1907, 2005. CrossRef  Google Scholar; 10.T. Camp, J. Boleng and V. Davies, ""A survey of mobility models for ad hoc network research"", Wireless Communications and Mobile Computing, vol. 2, no. 5, pp. 483-502, 2002. CrossRef  Google Scholar; 11.J. Xie, Y. Wan, J.H. Kim, S. Fu and K. Namuduri, ""A survey and analysis of mobility models for airborne networks"", IEEE Communications Surveys & Tutorials, vol. 16, no. 3, pp. 1221-1238, 2014. View Article  Google Scholar; 12.A. Van Zanten, ""Cyclic distance-preserving codes on a constant-weight basis"", Discrete applied mathematics, vol. 114, no. 1, pp. 289-294, 2001. CrossRef  Google Scholar"	1-6	"""@INPROCEEDINGS{8269071,
    author = ""Liu, Mushuang and Wan, Yan and Lewis, Frank L."",
    booktitle = ""2017 IEEE Globecom Workshops (GC Wkshps)"",
    title = ""Analysis of the Random Direction Mobility Model with a Sense-and-Avoid Protocol"",
    year = ""2017"",
    volume = """",
    number = """",
    pages = ""1-6"",
    abstract = ""Random mobility models (RMMs) capture the random movement patterns of mobile agents, and have been widely used in the evaluation and design of mobile networks. Existing RMMs (e.g. random walk and random direction) assume every mobile agent to move independently. Unmanned aerial systems (UASs), on the other hand, need to maintain a separation distance for the safety of the airspace, and hence their mobility patterns violate the independent movement assumption of existing RMMs. In this paper, for the first time in the literature per knowledge of authors, we enhance the Random Direction RMM through equipping it with a commonly used decentralized sense and avoid protocol-- sense-and-stop (S\&S). We provide analytical results on critical networking statistics such as stationary node distribution and inter-vehicle distance distribution in a two-dimensional (2-D) space using the Markov type of analysis. The analysis and simulation studies lead to interesting insights such as that the commonly used S\&S protocol is not effective when the randomness of UAV mobility is high, as it increases the probability for a UAS to stay within the collision distance."",
    keywords = ""Protocols;Atmospheric modeling;Analytical models;Mathematical model;Two dimensional displays;Collision avoidance;Markov processes"",
    doi = ""10.1109/GLOCOMW.2017.8269071"",
    ISSN = """",
    month = ""Dec""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	IEEE	2017	Analysis of the Random Direction Mobility Model with a Sense-and-Avoid Protocol	https://doi.org/10.1109/GLOCOMW.2017.8269071	IEEE	nan; Link
7	TestNN	Application of fuzzy logic for safe autonomous subsea IMR operations	Numerous technical and knowledge gaps pose challenges towards implementation of autonomous subsea intervention, maintenance, and repair operations. One such gap is related to development of methods for ensuring subsea asset and operational safety during autonomous subsea interventions. This paper describes a novel approach of using fuzzy logic to develop an asset safety decision support basis in resident underwater vehicles. A fuzzy inference system is developed with remotely operated vehicle envelope and sensor condition as input variables. Fuzzy sets and their respective membership functions are defined. On the basis of existing subsea knowledge in subsea operations, fifteen fuzzy rules are derived. The aggregated conclusions vary for different range values of ROV envelopes and conditions of the sensor system. The initial findings from simulation of the fuzzy inference system show that application of fuzzy logic to subsea intervention operations can be valuable for development of asset safety related aspects, such as for consequence analysis, operational safety, and development of safety philosophies.	Computer circuits; Decision support systems; Fuzzy logic; Fuzzy systems; Membership functions; Philosophical aspects; Reliability; Remotely operated vehicles; Repair; Consequence analysis; Decision supports; Fuzzy inference systems; Input variables; Operational safety; Repair operations; Sub-sea operations; Underwater vehicles; Fuzzy inference; Computer circuits;  Decision support systems;  Fuzzy logic;  Fuzzy systems;  Membership functions;  Philosophical aspects;  Reliability;  Remotely operated vehicles;  Repair;  Consequence analysis;  Decision supports;  Fuzzy inference systems;  Input variables;  Operational safety;  Repair operations;  Sub-sea operations;  Underwater vehicles;  Fuzzy inference	Hegde, J.; Utne, I.B.; Schjolberg, I.; Thorkildsen, B.	Safety and Reliability of Complex Engineered Systems - Proceedings of the 25th European Safety and Reliability Conference, ESREL 2015	https://doi.org/10.1201/b19094-58		415 - 422	"""@CONFERENCE{Hegde2015415,
    author = ""Hegde, J. and Utne, I.B. and Schjolberg, I. and Thorkildsen, B."",
    editor = ""L., Podofillini and B., Sudret and B., Stojadinovic and E., Zio and W., Kroger"",
    title = ""Application of fuzzy logic for safe autonomous subsea IMR operations"",
    year = ""2015"",
    journal = ""Safety and Reliability of Complex Engineered Systems - Proceedings of the 25th European Safety and Reliability Conference, ESREL 2015"",
    pages = ""415 - 422"",
    doi = ""10.1201/b19094-58"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959010981\&doi=10.1201\%2fb19094-58\&partnerID=40\&md5=474ee0be547665f0ae4e162f4f16067e"",
    affiliations = ""Department of Marine Technology, Norwegian University of Science and Technology, Trondheim, Norway; FMC Kongsberg Subsea AS, Kongsberg, Norway"",
    abstract = ""Numerous technical and knowledge gaps pose challenges towards implementation of autonomous subsea intervention, maintenance, and repair operations. One such gap is related to development of methods for ensuring subsea asset and operational safety during autonomous subsea interventions. This paper describes a novel approach of using fuzzy logic to develop an asset safety decision support basis in resident underwater vehicles. A fuzzy inference system is developed with remotely operated vehicle envelope and sensor condition as input variables. Fuzzy sets and their respective membership functions are defined. On the basis of existing subsea knowledge in subsea operations, fifteen fuzzy rules are derived. The aggregated conclusions vary for different range values of ROV envelopes and conditions of the sensor system. The initial findings from simulation of the fuzzy inference system show that application of fuzzy logic to subsea intervention operations can be valuable for development of asset safety related aspects, such as for consequence analysis, operational safety, and development of safety philosophies. (c) 2015 Taylor \& Francis Group, London."",
    keywords = ""Computer circuits; Decision support systems; Fuzzy logic; Fuzzy systems; Membership functions; Philosophical aspects; Reliability; Remotely operated vehicles; Repair; Consequence analysis; Decision supports; Fuzzy inference systems; Input variables; Operational safety; Repair operations; Sub-sea operations; Underwater vehicles; Fuzzy inference"",
    publisher = ""CRC Press/Balkema"",
    isbn = ""978-113802879-1"",
    language = ""English"",
    abbrev_source_title = ""Saf. Reliab. Complex. Eng. syst. - Proc. Eur. Saf. Reliab. Conf."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 7; Conference name: 25th European Safety and Reliability Conference, ESREL 2015; Conference date: 7 September 2015 through 10 September 2015; Conference code: 139809""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2015	Application of fuzzy logic for safe autonomous subsea IMR operations	https://www.scopus.com/record/display.uri?eid=2-s2.0-84959010981&origin=resultslist&sort=plf-f&src=s&sid=94d1380227ebbda0ecb263c00ff389bc&sot=b&sdt=b&s=TITLE-ABS-KEY%28application+of+fuzzy+logic+for+safe+autonomous+subsea+imr+operations%29&sl=83&sessionSearchId=94d1380227ebbda0ecb263c00ff389bc&relpos=0	CRC Press/Balkema	nan; References
8	TestNN	Autonomous intelligent cruise control using both front and back information for tight vehicle following maneuvers	For manual driving, human drivers always look both ahead and behind to make the proper decision for assuring driving safety. It is the purpose of this paper to design an autonomous intelligent cruise control (AICC) which mimics this human driving behavior. The proposed AICC law uses information not only from the immediate predecessor but also from the immediate follower to make the proper control decision. Constant time headway safety policy is used in the design and analysis of AICC law. The individual vehicle stability, and platoon stability in both directions (backward and forward) are guaranteed by the proposed AICC law. In addition, the proposed controller can also be used to operate vehicles with constant spacing safety policy in a platoon. The platoon stability is achieved by the proposed controller (which uses only information from the immediate predecessor and follower) without any preview information from the platoon leader.	Intelligent control;Intelligent vehicles;Remotely operated vehicles;Mobile robots;Vehicle safety;Stability;Automatic control;Humans;Vehicle driving;Springs; Intelligent control; Intelligent vehicles; Remotely operated vehicles; Mobile robots; Vehicle safety; Stability; Automatic control; Humans; Vehicle driving; Springs	Chien, C.C.; Zhang, Youping; Cheng, C.Y.	Proceedings of 1995 American Control Conference - ACC'95	https://doi.org/10.1109/ACC.1995.532085	"1.C. C. Chien and P. Ioannou, ""Automatic vehicle following"", Proc. American Control Conference, pp. 1748-1752, 1992. View Article  Google Scholar; 2.P. Ioannou and C. C. Chien, ""Autonomous intelligent cruise control"", IEEE Transactions on Vehicular Technology, vol. 42, pp. 657-672, Nov. 1993. View Article  Google Scholar; 3.D. Swaroop, J. K. Hedrick, C. C. Chien and P. Ioannou, ""A comparision of spacing and headway control laws for automatically controlled vehicle"", Journal of Vehicle System Dynamics, 1994. CrossRef  Google Scholar; 4.C. C. Chien and P. Ioannou, ""Michael Lai. Entrainment and vehicle following controller design for autonomous intelligent vehicle"", Proc. American Control Conference, pp. 6-10, 1994. View Article  Google Scholar; 5.S. Shladover, Operation of automated guideway transit vehicles in dynamically reconfigured trains and platoons, 1979. Google Scholar; 6.S. Sheikholeslam, Control of a class of interconnected nonlinear dynamical system: the platoon problem, 1991. Google Scholar; 7.S. E. Shiadover, ""Longitudinal control of automotive vehicles in close-formation platoons"", ASME Journal of Dynamic System Measurement and Control, vol. 113, pp. 231-241, 1991. CrossRef  Google Scholar; 8.S. E. Shiadover, C. A. Desoer, J. K. Hedrick, M. Tomizuka, J. Walrand, W. B. Zhang, et al., ""Automatic vehicle control developments in the path program"", IEEE Transactions on Vehicular Technology, vol. 40, pp. 114-130, 1991. View Article  Google Scholar; 9.J. K. Hedrick, D. McMahon, V. Narendran and D. Swaroop, ""Longitudinal vehicle controller design for IVHS systems"", Proc. American Control Conference, pp. 3107-3112, 1991. View Article  Google Scholar; 10.Y. T. Yang and B. H. Tingue. A new control approach for platoon operations during vehicle exit/entry. pre-print, 1993.; 11.C. C. Chien and Y. Zhang. Autonomous intelligent cruise control using both front and back information for tight vehicle following maneuversemac. Preprint, 1994."	3091-3095 vol.5	"""@INPROCEEDINGS{532085,
    author = ""Chien, C.C. and Zhang, Youping and Cheng, C.Y."",
    booktitle = ""Proceedings of 1995 American Control Conference - ACC'95"",
    title = ""Autonomous intelligent cruise control using both front and back information for tight vehicle following maneuvers"",
    year = ""1995"",
    volume = ""5"",
    number = """",
    pages = ""3091-3095 vol.5"",
    abstract = ""For manual driving, human drivers always look both ahead and behind to make the proper decision for assuring driving safety. It is the purpose of this paper to design an autonomous intelligent cruise control (AICC) which mimics this human driving behavior. The proposed AICC law uses information not only from the immediate predecessor but also from the immediate follower to make the proper control decision. Constant time headway safety policy is used in the design and analysis of AICC law. The individual vehicle stability, and platoon stability in both directions (backward and forward) are guaranteed by the proposed AICC law. In addition, the proposed controller can also be used to operate vehicles with constant spacing safety policy in a platoon. The platoon stability is achieved by the proposed controller (which uses only information from the immediate predecessor and follower) without any preview information from the platoon leader."",
    keywords = ""Intelligent control;Intelligent vehicles;Remotely operated vehicles;Mobile robots;Vehicle safety;Stability;Automatic control;Humans;Vehicle driving;Springs"",
    doi = ""10.1109/ACC.1995.532085"",
    ISSN = """",
    month = ""June""
}
"""	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	1995	Autonomous intelligent cruise control using both front and back information for tight vehicle following maneuvers	https://ieeexplore.ieee.org/document/532085	IEEE	
9	TestNN	Automated Information Aggregation for Scaling Scale-Resistant Services	"Machine learning provides techniques to monitor system behavior and predict failures from sensor data. However, such algorithms are ""scale resistant"" $high computational complexity and not parallelizable. The problem then becomes identifying and delivering the relevant subset of the vast amount of sensor data to each monitoring node, despite the lack of explicit ""relevance"" labels. The simplest solution is to deliver only the ""closest"" data items under some distance metric. We demonstrate a better approach using a more sophisticated architecture: a scalable data aggregation and dissemination overlay network uses an influence metric reflecting the relative influence of one node's data on another, to efficiently deliver a mix of raw and aggregated data to the monitoring components, enabling the application of machine learning tools on real-world problems. We term our architecture level of detail after an analogous computer graphics technique"	Condition monitoring;Machine learning;Computerized monitoring;Intelligent sensors;Iterative algorithms;Sensor systems;Machine learning algorithms;Computational complexity;Switches;Military computing; Condition monitoring; Machine learning; Computerized monitoring; Intelligent sensors; Iterative algorithms; Sensor systems; Machine learning algorithms; Computational complexity; Switches; Military computing	Gross, Philip; Kaiser, Gail	Collection of Technical Papers - AIAA Guidance, Navigation, and Control Conference	https://doi.org/10.1109/ASE.2006.18		15-24	"""@INPROCEEDINGS{4019558,
    author = ""Gross, Philip and Kaiser, Gail"",
    booktitle = ""21st IEEE/ACM International Conference on Automated Software Engineering (ASE'06)"",
    title = ""Automated Information Aggregation for Scaling Scale-Resistant Services"",
    year = ""2006"",
    volume = """",
    number = """",
    pages = ""15-24"",
    abstract = {Machine learning provides techniques to monitor system behavior and predict failures from sensor data. However, such algorithms are ""scale resistant"" $high computational complexity and not parallelizable. The problem then becomes identifying and delivering the relevant subset of the vast amount of sensor data to each monitoring node, despite the lack of explicit ""relevance"" labels. The simplest solution is to deliver only the ""closest"" data items under some distance metric. We demonstrate a better approach using a more sophisticated architecture: a scalable data aggregation and dissemination overlay network uses an influence metric reflecting the relative influence of one node's data on another, to efficiently deliver a mix of raw and aggregated data to the monitoring components, enabling the application of machine learning tools on real-world problems. We term our architecture level of detail after an analogous computer graphics technique},
    keywords = ""Condition monitoring;Machine learning;Computerized monitoring;Intelligent sensors;Iterative algorithms;Sensor systems;Machine learning algorithms;Computational complexity;Switches;Military computing"",
    doi = ""10.1109/ASE.2006.18"",
    ISSN = ""1938-4300"",
    month = ""Sep.""
}
"""	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	2004	Autonomous NAS flight control for UAV by fuzzy concept	https://www.scopus.com/record/display.uri?eid=2-s2.0-19644397580&origin=resultslist&sort=plf-f&src=s&sid=f0e672d5f5b8553c1271c14313d80af1&sot=b&sdt=b&s=TITLE-ABS-KEY%28autonomous+nas+flight+control+for+uav+by+fuzzy+concept%29&sl=69&sessionSearchId=f0e672d5f5b8553c1271c14313d80af1&relpos=0		nan; References; Publisher
10	TestNN	Autonomous real-time software \& systems testing	For the Internet of Things (IoT), for safety in automotive, or for data protection, to be legally compliant requires testing the impact of any actions before allowing them to occur. However, system boundaries change at runtime. When adding a new, previously unknown device to an IoT orchestra, or when an autonomous car meets another, or with truck platooning, the original base system expands and needs being tested before it can do decisions with the potential of affecting harm to humans. This paper explains the theory and outlines the implementation approach a framework for autonomous real-time testing of a software-based system while in operation, with an example from IoT.	automated testing;  defects density;  headcombinatory logic;  legal compliance;  metrics for software testing;  real-time testing;  six sigma for software;  testing the internet of things (iot); automated testing, defects density, headcombinatory logic, legal compliance, metrics for software testing, real-time testing, six sigma for software, testing the internet of things (iot)	Fehlmann, Thomas; Kranich, Eberhard	IWSM Mensura '17: Proceedings of the 27th International Workshop on Software Measurement and 12th International Conference on Software Process and Product Measurement	https://doi.org/10.1145/3143434.3143444		54-63	"""@inproceedings{10.1145/3143434.3143444,
    author = ""Fehlmann, Thomas and Kranich, Eberhard"",
    title = ""Autonomous real-time software \\& systems testing"",
    year = ""2017"",
    isbn = ""9781450348539"",
    publisher = ""Association for Computing Machinery"",
    address = ""New York, NY, USA"",
    url = ""https://doi.org/10.1145/3143434.3143444"",
    doi = ""10.1145/3143434.3143444"",
    abstract = ""For the Internet of Things (IoT), for safety in automotive, or for data protection, to be legally compliant requires testing the impact of any actions before allowing them to occur. However, system boundaries change at runtime. When adding a new, previously unknown device to an IoT orchestra, or when an autonomous car meets another, or with truck platooning, the original base system expands and needs being tested before it can do decisions with the potential of affecting harm to humans. This paper explains the theory and outlines the implementation approach a framework for autonomous real-time testing of a software-based system while in operation, with an example from IoT."",
    booktitle = ""Proceedings of the 27th International Workshop on Software Measurement and 12th International Conference on Software Process and Product Measurement"",
    pages = ""54-63"",
    numpages = ""10"",
    keywords = ""automated testing, defects density, headcombinatory logic, legal compliance, metrics for software testing, real-time testing, six sigma for software, testing the internet of things (iot)"",
    location = ""Gothenburg, Sweden"",
    series = ""IWSM Mensura '17""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2017	Autonomous real-time software & systems testing	https://dl.acm.org/doi/10.1145/3143434.3143444	Association for Computing Machinery	nan; References
11	TestNN	Capturing safety requirements to enable effective task allocation between humans and automaton in increasingly autonomous systems	There is a current drive towards enabling the deployment of increasingly autonomous systems in the National Airspace System (NAS). However, shifting the traditional roles and responsibilities between humans and automation for safety critical tasks must be managed carefully, otherwise the current emergent safety properties of the NAS may be disrupted. In this paper, a verification activity to assess the emergent safety properties of a clearly defined, safety critical, operational scenario that possesses tasks that can be fluidly allocated between human and automated agents is conducted. Task allocation role sets were proposed for a human-automation team performing a contingency maneuver in a reduced crew context. A safety critical contingency procedure (engine out on takeoff) was modeled in the Soar cognitive architecture, then translated into the Hybrid Input Output formalism. Verification activities were then performed to determine whether or not the safety properties held over the increasingly autonomous system. The verification activities lead to the development of several key insights regarding the implicit assumptions on agent capability. It subsequently illustrated the usefulness of task annotations associated with specialized requirements (e.g., communication, timing etc.), and demonstrated the feasibility of this approach.	Automation; Automated agents; Autonomous systems; National airspace system; Operational scenario; Safety property; Safety requirements; Soar cognitive architectures; Verification activities; Safety engineering; Automation;  Automated agents;  Autonomous systems;  National airspace system;  Operational scenario;  Safety property;  Safety requirements;  Soar cognitive architectures;  Verification activities;  Safety engineering	Neogi, Natasha A.	16th AIAA Aviation Technology, Integration, and Operations Conference	https://doi.org/10.2514/6.2016-3594			"""@CONFERENCE{Neogi2016,
    author = ""Neogi, Natasha A."",
    title = ""Capturing safety requirements to enable effective task allocation between humans and automaton in increasingly autonomous systems"",
    year = ""2016"",
    journal = ""16th AIAA Aviation Technology, Integration, and Operations Conference"",
    doi = ""10.2514/6.2016-3594"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088771295\&doi=10.2514\%2f6.2016-3594\&partnerID=40\&md5=030db9af785cd1cbeb808707533eb079"",
    affiliations = ""NASA Langley Research Center, Mail Stop 130, Hampton, 23666, VA, United States"",
    abstract = ""There is a current drive towards enabling the deployment of increasingly autonomous systems in the National Airspace System (NAS). However, shifting the traditional roles and responsibilities between humans and automation for safety critical tasks must be managed carefully, otherwise the current emergent safety properties of the NAS may be disrupted. In this paper, a verification activity to assess the emergent safety properties of a clearly defined, safety critical, operational scenario that possesses tasks that can be fluidly allocated between human and automated agents is conducted. Task allocation role sets were proposed for a human-automation team performing a contingency maneuver in a reduced crew context. A safety critical contingency procedure (engine out on takeoff) was modeled in the Soar cognitive architecture, then translated into the Hybrid Input Output formalism. Verification activities were then performed to determine whether or not the safety properties held over the increasingly autonomous system. The verification activities lead to the development of several key insights regarding the implicit assumptions on agent capability. It subsequently illustrated the usefulness of task annotations associated with specialized requirements (e.g., communication, timing etc.), and demonstrated the feasibility of this approach. (c) 2016 American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved."",
    keywords = ""Automation; Automated agents; Autonomous systems; National airspace system; Operational scenario; Safety property; Safety requirements; Soar cognitive architectures; Verification activities; Safety engineering"",
    publisher = ""American Institute of Aeronautics and Astronautics Inc, AIAA"",
    isbn = ""978-162410440-4"",
    language = ""English"",
    abbrev_source_title = ""Aviat. Technol. Integr. Oper. Conf."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 8; Conference name: 16th AIAA Aviation Technology, Integration, and Operations Conference, 2016; Conference date: 13 June 2016 through 17 June 2016; Conference code: 175899; All Open Access, Green Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2016	Capturing safety requirements to enable effective task allocation between humans and automaton in increasingly autonomous systems	https://www.scopus.com/record/display.uri?eid=2-s2.0-85088771295&origin=resultslist&sort=plf-f&src=s&sid=15f6b4df1b827a1e50f1f68ef53f94e0&sot=b&sdt=b&s=TITLE-ABS-KEY%28capturing+safety+requirements+to+enable+effective+task+allocation+between+humans+and+automaton+in+increasingly+autonomous+systems%29&sl=144&sessionSearchId=15f6b4df1b827a1e50f1f68ef53f94e0&relpos=0	American Institute of Aeronautics and Astronautics Inc, AIAA	nan; References; Pages
12	TestNN	Computational methods for the verification of adaptive control systems	"Intelligent and adaptive control systems will significantly challenge current verification and validation (V&V) processes, tools, and methods for flight certification. Although traditional certification practices have produced safe and reliable flight systems, they will not be cost effective for next-generation autonomous unmanned air vehicles (UAVs) due to inherent size and complexity increases from added functionality. Affordable V&V of intelligent control systems is by far the most important challenge in the development of UAVs faced by both commercial and military aerospace industry in the United States. This paper presents a formal modeling framework for a class of adaptive control systems and an associated computational scheme. The class of systems considered include neural network-based flight control systems and vehicle health management systems. This class of systems and indeed all adaptive systems are hybrid systems whose continuum dynamics is nonlinear. Our computational procedure is iterative and each iteration has two sequential steps. The first step is to derive an approximating finite-state automaton whose behaviors contain the behaviors of the hybrid system. The second step is to check if the language accepted by the approximating automaton is empty (emptiness checking). The iterations are terminated if the language accepted is empty; otherwise, the approximation is refined and the iteration is continued. This procedure will never produce an ""error-free"" certificate when the actual system contains errors which is an important requirement in V&Vof safety critical systems."	Aerospace industry; Autonomous agents; Computational complexity; Computational methods; Finite automata; Intelligent agents; Iterative methods; Neural networks; Flight critical software (FCS); Hybrid systems; Reach set; Verification and validation (V &V); Adaptive control systems; Aerospace industry;  Autonomous agents;  Computational complexity;  Computational methods;  Finite automata;  Intelligent agents;  Iterative methods;  Neural networks;  Flight critical software (FCS);  Hybrid systems;  Reach set;  Verification and validation (V &V);  Adaptive control systems	Prasanth, Ravi; Boskovic, Jovan; Mehra, Raman	Proceedings of SPIE - The International Society for Optical Engineering	https://doi.org/10.1117/12.546128	Special issue on hybrid systems(2000)Proc. of IEEE.Cited 256 times.July; http://ase.arc.nasa.gov/andhttp://ic-www.arc.nasa.gov/tech/index.php; Blondel, V.D.,Tsitsiklis, J.N.; Branicky, M.S.,Borkar, V.S.,Mitter, S.K.; Buffington, J.M.,Crum, V.,Krogh, B.,Plaisted, C.,Prasanth, R.,Bose, P.,Johnson, T.; Clarke, E.,Grumberg, O.,Peled, D.(2001)Model Checking.Cited 8036 times.MIT Press; Handelman, D.; Holzmann, G.http://spinroot.com/gerard/; Havelund, K.,Lowry, M.,Penix, J.Formal analysis of a spacecraft controller using SPIN(1998)4th International SPIN Workshop.Cited 22 times.Presented at the Paris, France, November; Henzinger, T.,Kopke, P.,Puri, A.,Varaiya, P.What's decidable about hybrid automata(1995)Proc. Ann. Sym. Theory Computing.Cited 365 times.; Hopcroft, J.,Ullman, J.(1979)Introduction to Automata Theory, Languages and Computation.Cited 10019 times.Addison-Wesley; Lasserre, J.http://www.laas.fr/lasserre/; Narendra, K.S.,Annaswamy, A.M.(1988)Stable Adaptive Systems.Cited 3053 times.Prentice Hall Inc., Englewood Cliffs, New Jersey; Papadimitriou, C.,Steiglitz, K.(1998)Combinatorial Optimization.Cited 417 times.Dover; Parillo, P.,Sturmfels, B.Minimizing polynomial functions(2001)DIMACS Series in Discrete Math. and Theo. Computer Sci..Cited 259 times.; Pecheur, C.(2002)Verification and Validation of Autonomy Software at NASA.Cited 6 times.Preprint; Powers, V.,Reznick, B.(2000)Polynomials That Are Positive on An Interval.Cited 4 times.preprint; Prasanth, R.,Bergstrom, S.,Boskovic, J.D.,Mehra, R.K.; Schmudgen, K.; Shor, N.(1998)Nondifferentiable Optimization and Polynomial Problems.Cited 227 times.Kluwer	264 - 272	"""@CONFERENCE{Prasanth2004264,
    author = ""Prasanth, Ravi and Boskovic, Jovan and Mehra, Raman"",
    title = ""Computational methods for the verification of adaptive control systems"",
    year = ""2004"",
    journal = ""Proceedings of SPIE - The International Society for Optical Engineering"",
    volume = ""5429"",
    pages = ""264 - 272"",
    doi = ""10.1117/12.546128"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-8844276110\&doi=10.1117\%2f12.546128\&partnerID=40\&md5=9db00140853f8fb5efd5f2ba8ae72559"",
    affiliations = ""Scientific Systems Company, Inc., Woburn, MA 01801, 500 West Cummings Park, United States"",
    abstract = {Intelligent and adaptive control systems will significantly challenge current verification and validation (V\&V) processes, tools, and methods for flight certification. Although traditional certification practices have produced safe and reliable flight systems, they will not be cost effective for next-generation autonomous unmanned air vehicles (UAVs) due to inherent size and complexity increases from added functionality. Affordable V\&V of intelligent control systems is by far the most important challenge in the development of UAVs faced by both commercial and military aerospace industry in the United States. This paper presents a formal modeling framework for a class of adaptive control systems and an associated computational scheme. The class of systems considered include neural network-based flight control systems and vehicle health management systems. This class of systems and indeed all adaptive systems are hybrid systems whose continuum dynamics is nonlinear. Our computational procedure is iterative and each iteration has two sequential steps. The first step is to derive an approximating finite-state automaton whose behaviors contain the behaviors of the hybrid system. The second step is to check if the language accepted by the approximating automaton is empty (emptiness checking). The iterations are terminated if the language accepted is empty; otherwise, the approximation is refined and the iteration is continued. This procedure will never produce an ""error-free"" certificate when the actual system contains errors which is an important requirement in V\&Vof safety critical systems.},
    author_keywords = ""Adaptive control systems; Hybrid systems; Reach set; Verification and validation"",
    keywords = ""Aerospace industry; Autonomous agents; Computational complexity; Computational methods; Finite automata; Intelligent agents; Iterative methods; Neural networks; Flight critical software (FCS); Hybrid systems; Reach set; Verification and validation (V \&V); Adaptive control systems"",
    issn = ""0277786X"",
    coden = ""PSISD"",
    language = ""English"",
    abbrev_source_title = ""Proc SPIE Int Soc Opt Eng"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 2; Conference name: Signal Processing, Sensor Fusion, and Target Recognition XIII; Conference date: 12 April 2004 through 14 April 2004; Conference code: 63951""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2004	Computational methods for the verification of adaptive control systems	https://doi.org/10.1117/12.546128		nan; Link; Publisher
13	TestNN	Computer-aided design for safe autonomous vehicles	This paper details the design of an autonomous vehicle CAD toolchain, which captures formal descriptions of driving scenarios in order to develop a safety case for an autonomous vehicle (AV). Rather than focus on a particular component of the AV, like adaptive cruise control, the toolchain models the end-to-end dynamics of the AV in a formal way suitable for testing and verification. First, a domain-specific language capable of describing the scenarios that occur in the day-to-day operation of an AV is defined. The language allows the description and composition of traffic participants (e.g., other vehicles and traffic control devices), and the specification of formal correctness requirements. A scenario described in this language is an executable that can be processed by a specification-guided automated test generator (bug hunting), and by an exhaustive reachability tool. The toolchain allows the user to exploit and integrate the strengths of both testing and reachability, in a way not possible when each is run alone. Finally, given a particular execution of the scenario that violates the requirements, a visualization tool can display this counter-example and generate labeled sensor data. The effectiveness of the approach is demonstrated on three autonomous driving scenarios drawn from a collection of 36 scenarios that account for over 95% of accidents nationwide. These case studies demonstrate robustness-guided verification heuristics to reduce analysis time, counterexample visualization for identifying controller bugs in both the discrete decision logic and low-level analog (continuous) dynamics, and identification of modeling errors (e.g., traffic behaviors) that lead to unrealistic environment behavior.	Roads;Tools;Testing;Robustness;Safety;Trajectory;Autonomous vehicles; Roads; Tools; Testing; Robustness; Safety; Trajectory; Autonomous vehicles	O'Kelly, Matthew; Abbas, Houssam; Mangharam, Rahul	2017 Resilience Week (RWS)	https://doi.org/10.1109/RWEEK.2017.8088654	"1.M. Althoff and J.M. Dolan, ""Reachability computation of low-order models for the safety verification of high-order road vehicle models"", American Control Conference (ACC) 2012, pp. 3559-3566, 2012. CrossRef  Google Scholar; 2.M. Althoff and J.M. Dolan, ""Online verification of automated road vehicles using reachability analysis"", IEEE Transactions on Robotics, vol. 30, no. 4, pp. 903-918, 2014. View Article  Google Scholar; 3.R. Alur, C. Courcoubetis, N. Halbwachs, T.A. Henzinger, P.-H. Ho, X. Nicollin, et al., ""The algorithmic analysis of hybrid systems"", Theoretical Computer Science, vol. 138, no. 1, pp. 3-34, 1995. CrossRef  Google Scholar; 4.Y.S.R. Annapureddy and G.E. Fainekos, ""Ant colonies for temporal logic falsification of hybrid systems"", Proc. of the 36th Annual Conference of IEEE Industrial Electronics, pp. 91-96, 2010. CrossRef  Google Scholar; 5.W. Damm, H.-J. Peter, J. Rakow and B. Westphal, ""Can we build it: formal synthesis of control strategies for cooperative driver assistance systems"", Mathematical Structures in computer Science, vol. 23, no. 04, pp. 676-725, 2013. CrossRef  Google Scholar; 6.G. Fainekos and G. Pappas, ""Robustness of temporal logic specifications for continuous-time signals"", Theoretical Computer Science, vol. 410, no. 42, pp. 4262-4291, September 2009. CrossRef  Google Scholar; 7.E. Gat, ""On three-layer architectures"" in Artificial Intelligence and Mobile Robots, MIT Press, 1998. Google Scholar; 8.D. Hess, M. Althoff and T. Sattel, ""Formal verification of maneuver automata for parameterized motion primitives"", Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1474-1481, 2014. Google Scholar; 9.S. Kong, S. Gao, W. Chen and E.M. Clarke, ""dreach: Delta-reachability analysis for hybrid systems"", Tools and Algorithms for the Construction and Analysis of Systems -- 21st International Conference TACAS 2015, pp. 200-205, 2015. CrossRef  Google Scholar; 10.R. Koymans, ""Specifying real-time properties with metric temporal logic"", Real-Time Systems, vol. 2, no. 4, pp. 255-299, 1990. CrossRef  Google Scholar; 11.S. Linker and M. Hilscher, ""Proof theory of a multi-lane spatial logic"", International Colloquium on Theoretical Aspects of Computing, pp. 231-248, 2013. CrossRef  Google Scholar; 12.S.M. Loos, A. Platzer and L. Nistor, ""Adaptive cruise control: Hybrid distributed and now formally verified"", International Symposium on Formal Methods, pp. 42-56, 2011. CrossRef  Google Scholar; 13.A. Mehra, W.-L. Ma, F. Berg, P. Tabuada, J.W. Grizzle and A.D. Ames, ""Adaptive cruise control: Experimental validation of advanced controllers on scale-model cars"", 2015 American Control Conference (ACC), pp. 1411-1418, 2015. CrossRef  Google Scholar; 14.W.G. Najm, J.D. Smith and M. Yanagisawa, ""Pre-crash scenario typology for crash avoidance research"" in DOT HS, Citeseer, 2007. Google Scholar; 15.Federal automated vehicles policy, September 2016. Google Scholar; 16.M. O'Kelly, H. Abbas, S. Gao, S. Shiraishi, S. Kato and R. Mang-haram, ""Apex: Autonomous vehicle plan verification and execution"", SAE World Congress, vol. 1, Apr 2016. CrossRef  Google Scholar; 17.M. OKelly, H. Abbas and R. Mangharam, ""Computer-aided design for safe autonomous vehicles"", Technical report Scholarly Commons, April 2017. View Article  Google Scholar; 18.B. Paden, S.Z. Yong, D. Yershov and E. Frazzoli, ""A survey of motion planning and control techniques for self-driving urban vehicles"", IEEE Transactions on Intelligent Vehicles, vol. 1, no. 1, pp. 33-55, March 2016. View Article  Google Scholar; 19.T.P. Pavlic, P.A. Sivilotti, A.D. Weide and B.W. Weide, ""Comments on adaptive cruise control: hybrid distributed and now formally verified"", OSU CSE Dept TR22, 2011. Google Scholar; 20.A. Rizaldi and M. Althoff, ""Formalising traffic rules for accountability of autonomous vehicles"", 2015 IEEE 18th International Conference on Intelligent Transportation Systems, pp. 1658-1665, 2015. CrossRef  Google Scholar; 21.O. Stursberg, A. Fehnker, Z. Han and B.H. Krogh, ""Verification of a cruise control system using counterexample-guided search"", Control Engineering Practice, vol. 12, no. 10, pp. 1269-1278, 2004. CrossRef  Google Scholar; 22.C. Urmson, J. Anhalt, D. Bagnell, C. Baker, R. Bittner, M. Clark, J. Dolan, D. Duggins, T. Galatali, C. Geyer et al., ""Autonomous driving in urban environments: Boss and the urban challenge"", Journal of Field Robotics, vol. 25, no. 8, pp. 425-466, 2008. CrossRef  Google Scholar; 23.T. Wongpiromsarn, U. Topcu and R.M. Murray, ""Receding horizon control for temporal logic specifications"", Proceedings of the 13th ACM international conference on Hybrid systems: computation and control, pp. 101-110, 2010. CrossRef  Google Scholar"	90-96	"""@INPROCEEDINGS{8088654,
    author = ""O'Kelly, Matthew and Abbas, Houssam and Mangharam, Rahul"",
    booktitle = ""2017 Resilience Week (RWS)"",
    title = ""Computer-aided design for safe autonomous vehicles"",
    year = ""2017"",
    volume = """",
    number = """",
    pages = ""90-96"",
    abstract = ""This paper details the design of an autonomous vehicle CAD toolchain, which captures formal descriptions of driving scenarios in order to develop a safety case for an autonomous vehicle (AV). Rather than focus on a particular component of the AV, like adaptive cruise control, the toolchain models the end-to-end dynamics of the AV in a formal way suitable for testing and verification. First, a domain-specific language capable of describing the scenarios that occur in the day-to-day operation of an AV is defined. The language allows the description and composition of traffic participants (e.g., other vehicles and traffic control devices), and the specification of formal correctness requirements. A scenario described in this language is an executable that can be processed by a specification-guided automated test generator (bug hunting), and by an exhaustive reachability tool. The toolchain allows the user to exploit and integrate the strengths of both testing and reachability, in a way not possible when each is run alone. Finally, given a particular execution of the scenario that violates the requirements, a visualization tool can display this counter-example and generate labeled sensor data. The effectiveness of the approach is demonstrated on three autonomous driving scenarios drawn from a collection of 36 scenarios that account for over 95\% of accidents nationwide. These case studies demonstrate robustness-guided verification heuristics to reduce analysis time, counterexample visualization for identifying controller bugs in both the discrete decision logic and low-level analog (continuous) dynamics, and identification of modeling errors (e.g., traffic behaviors) that lead to unrealistic environment behavior."",
    keywords = ""Roads;Tools;Testing;Robustness;Safety;Trajectory;Autonomous vehicles"",
    doi = ""10.1109/RWEEK.2017.8088654"",
    ISSN = """",
    month = ""Sep.""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	Computer-aided design for safe autonomous vehicles	https://ieeexplore.ieee.org/document/8088654	IEEE	
14	TestNN	Convoy active safety technologies Warfighter Experiment I	The operational ability to project and sustain forces in distant, anti-access and area denial environments poses new challenges for combatant commanders. One of the new challenges is the ability to conduct sustainment operations at operationally feasible times and places on the battlefield. Combatant commanders require a sustainment system that is agile, versatile, and survivable throughout the range of military operations and across the spectrum of conflict. A key component of conducting responsive, operationally feasible sustainment operations is the ability to conduct sustainment convoys. Sustainment convoys are critical to providing combatant commanders the right support, at the right time and place, and in the right quantities, across the full range of military operations. The ability to conduct sustainment convoys in a variety of hostile environments require force protection measures that address the enemy threat and protect the Soldier. One cost effective, technically feasible method of increasing the force protection for sustainment convoys is the use of robotic follower technology and autonomous navigation. The Convoy Active Safety Technologies (CAST) system is a driver assist, convoy autopilot technology aimed to address these issues. Warfigher Experiment I, held at A.P. Hill, VA in the fall of 2007, tested the utility of this vehicle following technology not only in measures of system integrity and performance vs. manual driving, but also the physiological effects on the operators themselves. This paper will detail the Warfigher Experiment's methodology, analysis, results and conclusions.	Autonomous agents; Collision avoidance; Cost effectiveness; Robotics; Safety engineering; Technology transfer; Convoy active safety technologies; Situational awareness; Military operations; Autonomous agents;  Collision avoidance;  Cost effectiveness;  Robotics;  Safety engineering;  Technology transfer;  Convoy active safety technologies;  Situational awareness;  Military operations	Schoenherr, Edward; Theisen, Bernard L.; Animashaun, Asisat; Davis, James; Day, L.T.C. Christopher	Proceedings of SPIE - The International Society for Optical Engineering	https://doi.org/10.1117/12.780357			"""@CONFERENCE{Schoenherr2008,
    author = ""Schoenherr, Edward and Theisen, Bernard L. and Animashaun, Asisat and Davis, James and Day, L.T.C. Christopher"",
    title = ""Convoy active safety technologies Warfighter Experiment I"",
    year = ""2008"",
    journal = ""Proceedings of SPIE - The International Society for Optical Engineering"",
    volume = ""6962"",
    doi = ""10.1117/12.780357"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-44349149770\&doi=10.1117\%2f12.780357\&partnerID=40\&md5=928492b85ae608792415eac8c7d56d2b"",
    affiliations = ""U.S. Anny Tank Automotive Research, Development, and Engineering Center, Detroit Arsenal, Warren, MI, United States; Army Research Laboratory, Aberdeen Proving Ground, MD, United States; U.S. Army Combined Arms Support Command, Fort Lee, VA, United States"",
    abstract = ""The operational ability to project and sustain forces in distant, anti-access and area denial environments poses new challenges for combatant commanders. One of the new challenges is the ability to conduct sustainment operations at operationally feasible times and places on the battlefield. Combatant commanders require a sustainment system that is agile, versatile, and survivable throughout the range of military operations and across the spectrum of conflict. A key component of conducting responsive, operationally feasible sustainment operations is the ability to conduct sustainment convoys. Sustainment convoys are critical to providing combatant commanders the right support, at the right time and place, and in the right quantities, across the full range of military operations. The ability to conduct sustainment convoys in a variety of hostile environments require force protection measures that address the enemy threat and protect the Soldier. One cost effective, technically feasible method of increasing the force protection for sustainment convoys is the use of robotic follower technology and autonomous navigation. The Convoy Active Safety Technologies (CAST) system is a driver assist, convoy autopilot technology aimed to address these issues. Warfigher Experiment I, held at A.P. Hill, VA in the fall of 2007, tested the utility of this vehicle following technology not only in measures of system integrity and performance vs. manual driving, but also the physiological effects on the operators themselves. This paper will detail the Warfigher Experiment's methodology, analysis, results and conclusions."",
    author_keywords = ""Autonomous; Convoy; Follower; Mobility; Obstacle avoidance; Situational awareness; Sustainment"",
    keywords = ""Autonomous agents; Collision avoidance; Cost effectiveness; Robotics; Safety engineering; Technology transfer; Convoy active safety technologies; Situational awareness; Military operations"",
    correspondence_address = ""E. Schoenherr; U.S. Anny Tank Automotive Research, Development, and Engineering Center, Detroit Arsenal, Warren, MI, United States; email: edward.schoenherr@gmail.com"",
    issn = ""0277786X"",
    isbn = ""978-081947153-6"",
    coden = ""PSISD"",
    language = ""English"",
    abbrev_source_title = ""Proc SPIE Int Soc Opt Eng"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 3; Conference name: Unmanned Systems Technology X; Conference date: 17 March 2008 through 20 March 2008; Conference code: 72124""
}
"""	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	2008	Convoy active safety technologies Warfighter Experiment I	https://www.scopus.com/record/display.uri?eid=2-s2.0-44349149770&origin=resultslist&sort=plf-f&src=s&sid=c2ecafa34e35f6dbc77c0b5b92d11f08&sot=b&sdt=b&s=TITLE-ABS-KEY%28convoy+active+safety+technologies+warfighter+experiment+i%29&sl=72&sessionSearchId=c2ecafa34e35f6dbc77c0b5b92d11f08&relpos=0		nan; References; Pages; Publisher
15	TestNN	Deepxplore: Automated whitebox testing of deep learning systems	Deep learning (DL) systems are increasingly deployed in safety- and security-critical domains such as self-driving cars and malware detection, where the correctness and predictability of a system's behavior for corner case inputs are of great importance. Existing DL testing depends heavily on manually labeled data and therefore often fails to expose erroneous behaviors for rare inputs. We design, implement, and evaluate DeepXplore, the first white-box framework for systematically testing real-world DL systems. First, we introduce neuron coverage for measuring the parts of a DL system exercised by test inputs. Next, we leverage multiple DL systems with similar functionality as cross-referencing oracles to avoid manual checking. Finally, we demonstrate how finding inputs for DL systems that both trigger many differential behaviors and achieve high neuron coverage can be represented as a joint optimization problem and solved efficiently using gradient-based search techniques. DeepXplore efficiently finds thousands of incorrect corner case behaviors (e.g., self-driving cars crashing into guard rails and malware masquerading as benign software) in state-of-the-art DL models with thousands of neurons trained on five popular datasets such as ImageNet and Udacity self-driving challenge data. For all tested DL models, on average, DeepXplore generated one test input demonstrating incorrect behavior within one second while running only on a commodity laptop. We further show that the test inputs generated by DeepXplore can also be used to retrain the corresponding DL model to improve the model's accuracy by up to 3%.	Accidents; Autonomous vehicles; Edge detection; Malware; Neurons; Gradient-based search; Joint optimization; Malware detection; Manual checking; Safety and securities; Self drivings; State of the art; White-box testing; Deep learning; Accidents;  Autonomous vehicles;  Edge detection;  Malware;  Neurons;  Gradient-based search;  Joint optimization;  Malware detection;  Manual checking;  Safety and securities;  Self drivings;  State of the art;  White-box testing;  Deep learning	Pei, Kexin; Cao, Yinzhi; Yang, Junfeng; Jana, Suman	Communications of the ACM	https://doi.org/10.1145/3361566		137 - 145	"""@ARTICLE{Pei2019137,
    author = ""Pei, Kexin and Cao, Yinzhi and Yang, Junfeng and Jana, Suman"",
    title = ""Deepxplore: Automated whitebox testing of deep learning systems"",
    year = ""2019"",
    journal = ""Communications of the ACM"",
    volume = ""62"",
    number = ""11"",
    pages = ""137 - 145"",
    doi = ""10.1145/3361566"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074371403\&doi=10.1145\%2f3361566\&partnerID=40\&md5=8b679b454dd930903c3db35aaa6e4200"",
    affiliations = ""Columbia University, United States; Johns Hopkins University, United States"",
    abstract = ""Deep learning (DL) systems are increasingly deployed in safety- and security-critical domains such as self-driving cars and malware detection, where the correctness and predictability of a system's behavior for corner case inputs are of great importance. Existing DL testing depends heavily on manually labeled data and therefore often fails to expose erroneous behaviors for rare inputs. We design, implement, and evaluate DeepXplore, the first white-box framework for systematically testing real-world DL systems. First, we introduce neuron coverage for measuring the parts of a DL system exercised by test inputs. Next, we leverage multiple DL systems with similar functionality as cross-referencing oracles to avoid manual checking. Finally, we demonstrate how finding inputs for DL systems that both trigger many differential behaviors and achieve high neuron coverage can be represented as a joint optimization problem and solved efficiently using gradient-based search techniques. DeepXplore efficiently finds thousands of incorrect corner case behaviors (e.g., self-driving cars crashing into guard rails and malware masquerading as benign software) in state-of-the-art DL models with thousands of neurons trained on five popular datasets such as ImageNet and Udacity self-driving challenge data. For all tested DL models, on average, DeepXplore generated one test input demonstrating incorrect behavior within one second while running only on a commodity laptop. We further show that the test inputs generated by DeepXplore can also be used to retrain the corresponding DL model to improve the model's accuracy by up to 3\%. (c) 2019 Association for Computing Machinery. All rights reserved."",
    keywords = ""Accidents; Autonomous vehicles; Edge detection; Malware; Neurons; Gradient-based search; Joint optimization; Malware detection; Manual checking; Safety and securities; Self drivings; State of the art; White-box testing; Deep learning"",
    publisher = ""Association for Computing Machinery"",
    issn = ""00010782"",
    coden = ""CACMA"",
    language = ""English"",
    abbrev_source_title = ""Commun ACM"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 90""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	DeepXplore: Automated Whitebox Testing of Deep Learning Systems	https://dl.acm.org/doi/10.1145/3308755.3308767	Association for Computing Machinery	nan; References
16	TestNN	Evaluation and Mitigation of Soft-Errors in Neural Network-Based Object Detection in Three GPU Architectures	In this paper, we evaluate the reliability of the You Only Look Once (YOLO) object detection framework. We have exposed to controlled neutron beams GPUs designed with three different architectures (Kepler, Maxwell, and Pascal) running Darknet, a Convolutional Neural Network for automotive applications, detecting objects in both Caltech and Visual Object Classes data sets. By analyzing the neural network corrupted output, we can distinguish between tolerable errors and critical errors, i.e., errors that could impact on real-time system execution.Additionally, we propose an Algorithm-Based Fault-Tolerance (ABFT) strategy to apply to the matrix multiplication kernels of neural networks able to detect and correct 50% to 60% of radiation induced corruptions. We experimentally validate our hardening solution and compare its efficiency and efficacy with the available ECC.	Errors; Fault tolerance; Graphics processing unit; Interactive computer systems; Network architecture; Neural networks; Object recognition; Program processors; Radiation hardening; Real time systems; Algorithm based fault tolerance; Automotive applications; Convolutional neural network; Detecting objects; Detection framework; Its efficiencies; MAtrix multiplication; Radiation-induced; Object detection; Errors;  Fault tolerance;  Graphics processing unit;  Interactive computer systems;  Network architecture;  Neural networks;  Object recognition;  Program processors;  Radiation hardening;  Real time systems;  Algorithm based fault tolerance;  Automotive applications;  Convolutional neural network;  Detecting objects;  Detection framework;  Its efficiencies;  MAtrix multiplication;  Radiation-induced;  Object detection	Santos, Fernando Fernandes Dos; Draghetti, Lucas; Weigel, Lucas; Carro, Luigi; Navaux, Philippe; Rech, Paolo	Proceedings - 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops, DSN-W 2017	https://doi.org/10.1109/DSN-W.2017.47	"1.B. Van Essen, H. Kim, R. Pearce, K. Boakye and B. Chen, ""Lbann: Livermore big artificial neural network hpc toolkit"", Proceedings of the Workshop on Machine Learning in High-Performance Computing Environments, pp. 5:1-5:6, 2015. CrossRef  Google Scholar; 2.S.U. Amin, K. Agarwal and R. Beg, ""Genetic neural network based data mining in prediction of heart disease using risk factors"", 2013 IEEE Conference on Information Communication Technologies, pp. 1227-1231, April 2013. View Article  Google Scholar; 3.J. Redmon, S.K. Divvala, R.B. Girshick and A. Farhadi, You only look once: Unified real-time object detection, CoRR, 2015,  [online]  Available: http://arxiv.org/abs/1506.02640. Google Scholar; 4.Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, et al., ""Caffe: Convolutional architecture for fast feature embedding"", Proceedings of the 22Nd ACM International Conference on Multimedia, pp. 675-678, 2014. CrossRef  Google Scholar; 5.V.E. Neagoe, A.D. Ciotec and A.P. Brar, ""A concurrent neural network approach to pedestrian detection in thermal imagery"", 2012 9th International Conference on Communications (COMM), pp. 133-136, June 2012. View Article  Google Scholar; 6.Tegra kl techinical reference manual, 2014. Google Scholar; 7.R.R. Lutz, ""Analyzing software requirements errors in safety-critical embedded systems"", Requirements Engineering 1993. Proceedings of IEEE International Symposium, pp. 126-133, Jan 1993. Google Scholar; 8.J.C. Laprie, ""Dependable computing and fault tolerance: Concepts and terminology"", Fault-Tolerant Computing 1995 Highlights from Twenty-Five Years. Twenty-Fifth International Symposium, pp. 2, Jun 1995. View Article  Google Scholar; 9.M. Nicolaidis, ""Time redundancy based soft-error tolerance to rescue nanometer technologies"", VLSI Test Symposium 1999. Proceedings. 17th IEEE, pp. 86-94, 1999. View Article  Google Scholar; 10.R. Baumann, ""Radiation-induced soft errors in advanced semiconductor technologies"", Device and Materials Reliability IEEE Transactions, vol. 5, no. 3, pp. 305-316, Sept 2005. View Article  Google Scholar; 11.P. Rech, C. Aguiar, C. Frost and L. Carro, ""An Efficient and Experimentally Tuned Software-Based Hardening Strategy for Matrix Multiplication on GPUs"", Nuclear Science IEEE Transactions, vol. 60, no. 4, pp. 2797-2804, 2013. View Article  Google Scholar; 12.D. Ciregan, U. Meier and J. Schmidhuber, ""Multi-column deep neural networks for image classification"", 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 3642-3649, June 2012. View Article  Google Scholar; 13.D.C. Ciresan, A. Giusti, L.M. Gambardella and J. Schmidhuber, ""Deep neural networks segment neuronal membranes in electron microscopy images"", Proceedings of the 25th International Conference on Neural Information Processing Systems, pp. 2843-2851, 2012. Google Scholar; 14.C. Szegedy, A. Toshev and D. Erhan, ""Deep neural networks for object detection"", Advances in Neural Information Processing Systems 26, pp. 2553-2561, 2013. Google Scholar; 15.A. Angelova, A. Krizhevsky, V. Vanhoucke, A. Ogale and D. Ferguson, ""Real-time pedestrian detection with deep network cascades"", Proceedings of BMVC 2015, 2015. Google Scholar; 16.P. Luo, Y. Tian, X. Wang and X. Tang, ""Switchable deep network for pedestrian detection"", 2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 899-906, June 2014. View Article  Google Scholar; 17.D. Ribeiro, A. Mateus, J.C. Nascimento and P. Miraldo, A real-time pedestrian detector using deep learning for human-aware navigation, CoRR, 2016,  [online]  Available: http://arxiv.org/abs/1607.04441. Google Scholar; 18.M. Everingham, L. Van Gool, C.K.I. Williams, J. Winn and A. Zisserman, ""The pascal visual object classes (voc) challenge"", International Journal of Computer Vision, vol. 88, no. 2, pp. 303-338, 2010. CrossRef  Google Scholar; 19.D. Oliveira, P. Rech, H. Quinn, T. Fairbanks, L. Monroe, S. Michalak, et al., ""Modern gpus radiation sensitivity evaluation and mitigation through duplication with comparison"", Nuclear Science IEEE Transactions, vol. 61, no. 6, pp. 3115-3122, Dec 2014. View Article  Google Scholar; 20.""JEDEC Standard"", ""Measurement and Reporting of Alpha Particle and Terrestrial Cosmic Ray-Induced Soft Errors in Semiconductor Devices"", Tech. Rep. JESD89A, 2006. Google Scholar; 21.S. Buchner, M. Baze, D. Brown, D. McMorrow and J. Melinger, ""Comparison of error rates in combinational and sequential logic"", Nuclear Science IEEE Transactions, vol. 44, no. 6, pp. 2209-2216, 1997. View Article  Google Scholar; 22.N. Mahatme, T. Jagannathan, L. Massengill, B. Bhuva, S.-J. Wen and R. Wong, ""Comparison of Combinational and Sequential Error Rates for a Deep Submicron Process"", Nuclear Science IEEE Transactions, vol. 58, no. 6, pp. 2719-2725, 2011. View Article  Google Scholar; 23.N. DeBardeleben, S. Blanchard, L. Monroe, P. Romero, D. Grunau, C. Idler, et al., ""GPU Behavior on a Large HPC Cluster"", 6th Workshop on Resiliency in High Performance Computing (Resilience) in Clusters Clouds and Grids in conjunction with the 19th International European Conference on Parallel and Distributed Computing (Euro-Par 2013), August 26-30 2013. Google Scholar; 24.H.J. Wunderlich, C. Braun and S. Halder, ""Efficacy and efficiency of algorithm-based fault-tolerance on gpus"", On-Line Testing Symposium (IOLTS) 2013 IEEE 19th International, pp. 240-243, July 2013. View Article  Google Scholar; 25.L.A.B. Gomez, F. Cappello, L. Carro, N. DeBardeleben, B. Fang, S. Gurumurthi, et al., ""GPGPUs: How to Combine High Computational Power with High Reliability"", 2014 Design Automation and Test in Europe Conference and Exhibition, 2014. View Article  Google Scholar; 26.D.A.G. de Oliveira, L.L. Pilla, T. Santini and P. Rech, ""Evaluation and mitigation of radiation-induced soft errors in graphics processing units"", IEEE Transactions on Computers, vol. 65, no. 3, pp. 791-804, March 2016. View Article  Google Scholar; 27.M. Breuer, S. Gupta and T.M. Mak, ""Defect and error tolerance in the presence of massive numbers of defects"", Design Test of Computers IEEE, vol. 21, no. 3, pp. 216-227, May 2004. View Article  Google Scholar; 28.P. Rech, T. Fairbanks, H. Quinn and L. Carro, ""Threads distribution effects on graphics processing units neutron sensitivity"", Nuclear Science IEEE Transactions, vol. 60, no. 6, pp. 4220-4225, Dec 2013. View Article  Google Scholar; 29.N. Seifert, X. Zhu and L.W. Massengill, ""Impact of scaling on soft-error rates in commercial microprocessors"", Nuclear Science IEEE Transactions, vol. 49, no. 6, pp. 3100-3106, 2002. View Article  Google Scholar; 30.J. Tan, N. Goswami, T. Li and X. Fu, ""Analyzing soft-error vulnerability on GPGPU microarchitecture"", Workload Characterization (IISWC) 2011 IEEE International Symposium, pp. 226-235, Nov 2011. View Article  Google Scholar"	169 - 176	"""@CONFERENCE{Santos2017169,
    author = ""Santos, Fernando Fernandes Dos and Draghetti, Lucas and Weigel, Lucas and Carro, Luigi and Navaux, Philippe and Rech, Paolo"",
    title = ""Evaluation and Mitigation of Soft-Errors in Neural Network-Based Object Detection in Three GPU Architectures"",
    year = ""2017"",
    journal = ""Proceedings - 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops, DSN-W 2017"",
    pages = ""169 - 176"",
    doi = ""10.1109/DSN-W.2017.47"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031755400\&doi=10.1109\%2fDSN-W.2017.47\&partnerID=40\&md5=5c935116899adc89921a3b353c3fd38d"",
    affiliations = ""Instituto de Informatica, Universidade Federal Do Rio Grande Do sul, Porto Alegre, Brazil"",
    abstract = ""In this paper, we evaluate the reliability of the You Only Look Once (YOLO) object detection framework. We have exposed to controlled neutron beams GPUs designed with three different architectures (Kepler, Maxwell, and Pascal) running Darknet, a Convolutional Neural Network for automotive applications, detecting objects in both Caltech and Visual Object Classes data sets. By analyzing the neural network corrupted output, we can distinguish between tolerable errors and critical errors, i.e., errors that could impact on real-time system execution.Additionally, we propose an Algorithm-Based Fault-Tolerance (ABFT) strategy to apply to the matrix multiplication kernels of neural networks able to detect and correct 50\% to 60\% of radiation induced corruptions. We experimentally validate our hardening solution and compare its efficiency and efficacy with the available ECC. (c) 2017 IEEE."",
    keywords = ""Errors; Fault tolerance; Graphics processing unit; Interactive computer systems; Network architecture; Neural networks; Object recognition; Program processors; Radiation hardening; Real time systems; Algorithm based fault tolerance; Automotive applications; Convolutional neural network; Detecting objects; Detection framework; Its efficiencies; MAtrix multiplication; Radiation-induced; Object detection"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153862272-8"",
    language = ""English"",
    abbrev_source_title = ""Proc. - Annu. IEEE/IFIP Int. Conf. Dependable Syst. Networks Workshops, DSN-W"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 59; Conference name: 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops, DSN-W 2017; Conference date: 26 June 2017 through 29 June 2017; Conference code: 130335""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	Evaluation and Mitigation of Soft-Errors in Neural Network-Based Object Detection in Three GPU Architectures	https://www.scopus.com/record/display.uri?eid=2-s2.0-85031755400&origin=resultslist&sort=plf-f&src=s&sid=0f45ba907f39b5ea10e15486a3435b65&sot=b&sdt=b&s=TITLE-ABS-KEY%28evaluation+and+mitigation+of+soft+errors+in+neural+network+based+object+detection+in+three+gpu+architectures%29&sl=123&sessionSearchId=0f45ba907f39b5ea10e15486a3435b65&relpos=0	Institute of Electrical and Electronics Engineers Inc	
17	TestNN	Evaluation of drivers authority in a structured set of driving tasks and decisions: Preliminary results on vehicle simulator study	One of the most challenging factors in the development of autonomous vehicles and advanced driver assistance systems is the imitation of an expert driver system which is the observer and interpreter of the technical system in the related driving scenario. To achieve an expert human-like situational understanding and decision making may be an important feature to fulfill the necessary active safety requirements. In this paper, an exploratory study on a multimodal adaptive driver assistance system is presented. The main goal is to determine the human driver's attention and authority level in a cognitive model and to trigger the timely warnings according to his/her driving intents and driving skills with respect to the possible driving situation and hazard scenarios. In the previous studies, a fairly restrictive vision-based driver assistance system has been deployed to detect lane departure, blind-spot and to monitor following distance, headway time. This vision-based driver assistance system considers the driver's driving performance metric sampled during the longitudinal and lateral vehicle control tasks as well as the processed information about the surrounding traffic environment consisting of the interactions with the other vehicles and the road situations. The presented active safety system models the driving task in a cognitive architecture and assesses the cognition of the human driver by modeling the situation awareness of the driver by using fuzzy sets. Each fuzzy set simply represents the expert driver's perception in both of the longitudinal and lateral traffic. The presented system evaluates the driver's driving skills and attention level by comparing the expert and human driver's reactions suited in a finite set of decision and maneuvering task. In case of hazard analysis, the system triggers timely warnings pointing the driver's attention at the lateral or longitudinal maneuvering tasks depending on the interpreted situation. Introductory experiments are performed with a limited number of participants, the test driving data including the driver's perception and reaction to the surrounding vehicles and traffic situations are collected by the use of a vehicle simulator. And the presented multimodal adaptive driver assistance system is evaluated by the simulator. The preliminary results seem to be promising.	Active safety systems; Automobile simulators; Cognitive systems; Control system synthesis; Fluid mechanics; Fuzzy sets; Hazards; Maneuverability; Systems analysis; Autonomous Vehicles; Cognitive architectures; Driver assistance system; Driving performance; Exploratory studies; Processed information; Situation awareness; Traffic environment; Automobile drivers; Active safety systems;  Automobile simulators;  Cognitive systems;  Control system synthesis;  Fluid mechanics;  Fuzzy sets;  Hazards;  Maneuverability;  Systems analysis;  Autonomous Vehicles;  Cognitive architectures;  Driver assistance system;  Driving performance;  Exploratory studies;  Processed information;  Situation awareness;  Traffic environment;  Automobile drivers	Uluer, Pinar; Gocmenoglu, Can; Acarman, Tankut	ASME 2012 11th Biennial Conference on Engineering Systems Design and Analysis, ESDA 2012	https://doi.org/10.1115/ESDA2012-82675	Acarman, T.,Pan, Y.,Ozguner, U.; Bellet, T.,Tattegrain-Veste, H.A framework for representing driving knowledge(1999)International Journal of Cognitive Ergonomics,3(1),pp. 37-49.Cited 24 times.; Liu, Y.,Feyen, R.,Tsimhoni, O.; Bi, L.-Z.,Liu, Y.-L.; Bi, L.,Shang, J.,Gan, G.,Liu, Y.; Ciardelli, L.,Bixio, L.,Regazzoni, C.S.; Yuksel, E.,Acarman, T.; Endsley, M.R.; Cayir, B.,Acarman, T.	803 - 811	"""@CONFERENCE{Uluer2012803,
    author = ""Uluer, Pinar and Gocmenoglu, Can and Acarman, Tankut"",
    title = ""Evaluation of drivers authority in a structured set of driving tasks and decisions: Preliminary results on vehicle simulator study"",
    year = ""2012"",
    journal = ""ASME 2012 11th Biennial Conference on Engineering Systems Design and Analysis, ESDA 2012"",
    volume = ""2"",
    pages = ""803 - 811"",
    doi = ""10.1115/ESDA2012-82675"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883892834\&doi=10.1115\%2fESDA2012-82675\&partnerID=40\&md5=de6337a976edd5c03a53ecc03d951d97"",
    affiliations = ""Galatasaray University, Computer Engineering Department, Istanbul, Turkey"",
    abstract = ""One of the most challenging factors in the development of autonomous vehicles and advanced driver assistance systems is the imitation of an expert driver system which is the observer and interpreter of the technical system in the related driving scenario. To achieve an expert human-like situational understanding and decision making may be an important feature to fulfill the necessary active safety requirements. In this paper, an exploratory study on a multimodal adaptive driver assistance system is presented. The main goal is to determine the human driver's attention and authority level in a cognitive model and to trigger the timely warnings according to his/her driving intents and driving skills with respect to the possible driving situation and hazard scenarios. In the previous studies, a fairly restrictive vision-based driver assistance system has been deployed to detect lane departure, blind-spot and to monitor following distance, headway time. This vision-based driver assistance system considers the driver's driving performance metric sampled during the longitudinal and lateral vehicle control tasks as well as the processed information about the surrounding traffic environment consisting of the interactions with the other vehicles and the road situations. The presented active safety system models the driving task in a cognitive architecture and assesses the cognition of the human driver by modeling the situation awareness of the driver by using fuzzy sets. Each fuzzy set simply represents the expert driver's perception in both of the longitudinal and lateral traffic. The presented system evaluates the driver's driving skills and attention level by comparing the expert and human driver's reactions suited in a finite set of decision and maneuvering task. In case of hazard analysis, the system triggers timely warnings pointing the driver's attention at the lateral or longitudinal maneuvering tasks depending on the interpreted situation. Introductory experiments are performed with a limited number of participants, the test driving data including the driver's perception and reaction to the surrounding vehicles and traffic situations are collected by the use of a vehicle simulator. And the presented multimodal adaptive driver assistance system is evaluated by the simulator. The preliminary results seem to be promising. Copyright (c) 2012 by ASME."",
    keywords = ""Active safety systems; Automobile simulators; Cognitive systems; Control system synthesis; Fluid mechanics; Fuzzy sets; Hazards; Maneuverability; Systems analysis; Autonomous Vehicles; Cognitive architectures; Driver assistance system; Driving performance; Exploratory studies; Processed information; Situation awareness; Traffic environment; Automobile drivers"",
    isbn = ""978-079184485-4"",
    language = ""English"",
    abbrev_source_title = ""ASME Bienn. Conf. Eng. Syst. Des. Anal., ESDA"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 0; Conference name: ASME 2012 11th Biennial Conference on Engineering Systems Design and Analysis, ESDA 2012; Conference date: 2 July 2012 through 4 July 2012; Conference code: 99242""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2012	Evaluation of drivers authority in a structured set of driving tasks and decisions: Preliminary results on vehicle simulator study	https://www.scopus.com/record/display.uri?eid=2-s2.0-84883892834&origin=resultslist&sort=plf-f&src=s&sid=64668a6f670944c65a0888916cf01d71&sot=b&sdt=b&s=TITLE-ABS-KEY%28evaluation+of+drivers+authority+in+a+structured+set+of+driving+tasks+and+decisions+preliminary+results+on+vehicle+simulator+study%29&sl=144&sessionSearchId=64668a6f670944c65a0888916cf01d71&relpos=0		nan; Publisher
18	TestNN	Guaranteed safe online learning via reachability: Tracking a ground target using a quadrotor	While machine learning techniques have become popular tools in the design of autonomous systems, the asymptotic nature of their performance guarantees means that they should not be used in scenarios in which safety and robustness are critical for success. By pairing machine learning algorithms with rigorous safety analyses, such as Hamilton-Jacobi-Isaacs (HJI) reachability, this limitation can be overcome. Guaranteed Safe Online Learning via Reachability (GSOLR) is a framework which combines HJI reachability with general machine learning techniques, allowing for the design of robotic systems which demonstrate both high performance and guaranteed safety. In this paper we show how the GSOLR framework can be applied to a target tracking problem, in which an observing quadrotor helicopter must keep a target ground vehicle with unknown (but bounded) dynamics inside its field of view at all times, while simultaneously attempting to build a motion model of the target. The resulting algorithm was implemented on board the Stanford Testbed of Autonomous Rotorcraft for Multi-Agent Control, and was compared to a naive safety-only algorithm and a learning-only algorithm. Experimental results illustrate the success of the GSOLR algorithm, even under scenarios in which the machine learning algorithm performed poorly (and would otherwise lead to unsafe actions), thus demonstrating the power of this technique.	Aircraft detection; E-learning; Learning systems; Multi agent systems; Online systems; Robotics; Autonomous rotorcrafts; Autonomous systems; Hamilton-Jacobi-Isaacs; Machine learning techniques; Multiagent control; Performance guarantees; Quadrotor helicopter; Safety analysis; Learning algorithms; Aircraft detection;  E-learning;  Learning systems;  Multi agent systems;  Online systems;  Robotics;  Autonomous rotorcrafts;  Autonomous systems;  Hamilton-Jacobi-Isaacs;  Machine learning techniques;  Multiagent control;  Performance guarantees;  Quadrotor helicopter;  Safety analysis;  Learning algorithms	Gillula, Jeremy H.; Tomlin, Claire J.	Proceedings - IEEE International Conference on Robotics and Automation	https://doi.org/10.1109/ICRA.2012.6225136	"1.P. Abbeel, A. Coates, and M. Quigley, ""An application of reinforcement learning to aerobatic helicopter flight,"" in Advances in Neural Information Processing Systems 19. MIT Press, 2007. CrossRef  Google Scholar; 2.M. Kalakrishnan, J. Buchli, P. Pastor, M. Mistry, and S. Schaal, ""Fast, robust quadruped locomotion over challenging terrain,"" in Proc. of the IEEE International Conference on Robotics and Automation (ICRA), Anchorage, AK, May 2010, pp. 2665-2670. View Article  Google Scholar; 3.H. Dahlkamp, A. Kaehler, D. Stavens, S. Thrun, and G. Bradski, ""Self-supervised monocular road detection in desert terrain,"" in Proc. of Robotics: Science and Systems (RSS), Philadelphia, PA, 2006. CrossRef  Google Scholar; 4.C. J. Geyer, ""On the asymptotics of constrained M-estimation,"" The Annals of Statistics, vol. 22, no. 4, pp. 1993-2010, 1994. CrossRef  Google Scholar; 5.K. Knight and W. Fu, ""Asymptotics for lasso-type estimators,"" The Annals of Statistics, vol. 28, no. 5, pp. 1356-1378, 2000. CrossRef  Google Scholar; 6.J. W. Roberts, I. R. Manchester, and R. Tedrake, ""Feedback Controller Parameterizations for Reinforcement Learning,"" in IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL), 2011. View Article  Google Scholar; 7.A. Teichman and S. Thrun, ""Tracking-based semi-supervised learning,"" in Proc. of Robotics: Science and Systems (RSS), Los Angeles, CA, June 2011. CrossRef  Google Scholar; 8.I. M. Mitchell, A. M. Bayen, and C. J. Tomlin, ""A time-dependent Hamilton-Jacobi formulation of reachable sets for continuous dynamic games,"" IEEE Transactions on Automatic Control, vol. 50, no. 7, pp. 947-957, July 2005. View Article  Google Scholar; 9.J. H. Gillula and C. J. Tomlin, ""Guaranteed Safe Online Learning of a Bounded System,"" in Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), San Francisco, CA, Sept. 2011. View Article  Google Scholar; 10.C. Claudel, A. Hofleitner, N. Mignerey, and A. M. Bayen, ""Guaranteed bounds on highway travel times using probe and fixed data,"" in 88th Transportation Research Board Annual Meeting, Washington, D.C., 2009. Google Scholar; 11.A. Aswani, H. Gonzalez, S. S. Sastry, and C. J. Tomlin, ""Provably Safe and Robust Learning-Based Model Predictive Control,"" ArXiv e-prints, 2011. Google Scholar; 12.J. Ding, J. H. Gillula, H. Huang, M. P. Vitus, W. Zhang, and C. J. Tomlin, ""Hybrid Systems in Robotics: Toward Reachability-Based Controller Design,"" IEEE Robotics  Automation Magazine (RAM), no. September, 2011. Google Scholar; 13.I. M. Mitchell, ""A Toolbox of Level Set Methods,"" http://people.cs. ubc.ca/mitchell/ToolboxLS/index.html, 2009. Google Scholar; 14.G. M. Hoffmann and C. J. Tomlin, ""Decentralized cooperative collision avoidance for acceleration constrained vehicles,"" in Proc. of the IEEE Conference on Decision and Control (CDC). Cancun, Mexico: Ieee, 2008, pp. 4357-4363. View Article  Google Scholar; 15.W. Hoburg and R. Tedrake, ""System identification of post stall aerodynamics for UAV perching,"" in Proc. of the AIAA Infotech@Aerospace Conference. American Institute of Aeronautics and Astronautics, Reston VA, Apr. 2009. CrossRef  Google Scholar; 16.G. M. Hoffmann and C. J. Tomlin, ""Mobile sensor network control using mutual information methods and particle filters,"" IEEE Transactions on Automatic Control, vol. 55, no. 1, pp. 32-47, 2010. View Article  Google Scholar; 17.T. M. Cover and J. A. Thomas, Elements of Information Theory. John Wiley  Sons, 1991. CrossRef  Google Scholar; 18.""AscTec Pelican - Ascending Technologies,"" http://www.asctec. de/asctec-pelican-3/. Google Scholar; 19.P. Bouffard, ""starmac-ros-pkg,"" http://www.ros.org/wiki/ starmac-ros-pkg, 2011. Google Scholar; 20.M. Quigley, B. Gerkey, K. Conley, J. Faust, T. Foote, J. Leibs, E. Berger, R. Wheeler, and A. Y. Ng, ""ROS : an open-source Robot Operating System,"" http://ai.stanford.edu/~ang/papers/icraoss09-ROS.pdf, 2009. Google Scholar; 21.""MobileRobots Pioneer 3-AT (P3AT) research robot platform,"" http: //www.mobilerobots.com/researchrobots/researchrobots/P3AT.aspx. Google Scholar; 22.D. Feil-Seifer, ""p2os,"" http://www.ros.org/wiki/p2os. Google Scholar; 23.N. Michael, ""ipc-bridge,"" https://alliance.seas.upenn.edu/ ~meam620/wiki/index.php?n=Roslab.IpcBridge, 2011. Google Scholar; 24.M. Kearns and S. Singh, ""Near-optimal reinforcement learning in polynomial time,"" Machine Learning, vol. 49, no. 2, pp. 209-232, Apr. 2002. Google Scholar"	2723 - 2730	"""@CONFERENCE{Gillula20122723,
    author = ""Gillula, Jeremy H. and Tomlin, Claire J."",
    title = ""Guaranteed safe online learning via reachability: Tracking a ground target using a quadrotor"",
    year = ""2012"",
    journal = ""Proceedings - IEEE International Conference on Robotics and Automation"",
    pages = ""2723 - 2730"",
    doi = ""10.1109/ICRA.2012.6225136"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864441922\&doi=10.1109\%2fICRA.2012.6225136\&partnerID=40\&md5=dd36cc0c299b0731245592321a6090a2"",
    affiliations = ""Computer Science Department, Stanford University, Stanford, CA 94305-4035, United States; Department of Electrical Engineering and Computer Sciences, UC Berkeley, Berkeley, CA 94720-1770, United States"",
    abstract = ""While machine learning techniques have become popular tools in the design of autonomous systems, the asymptotic nature of their performance guarantees means that they should not be used in scenarios in which safety and robustness are critical for success. By pairing machine learning algorithms with rigorous safety analyses, such as Hamilton-Jacobi-Isaacs (HJI) reachability, this limitation can be overcome. Guaranteed Safe Online Learning via Reachability (GSOLR) is a framework which combines HJI reachability with general machine learning techniques, allowing for the design of robotic systems which demonstrate both high performance and guaranteed safety. In this paper we show how the GSOLR framework can be applied to a target tracking problem, in which an observing quadrotor helicopter must keep a target ground vehicle with unknown (but bounded) dynamics inside its field of view at all times, while simultaneously attempting to build a motion model of the target. The resulting algorithm was implemented on board the Stanford Testbed of Autonomous Rotorcraft for Multi-Agent Control, and was compared to a naive safety-only algorithm and a learning-only algorithm. Experimental results illustrate the success of the GSOLR algorithm, even under scenarios in which the machine learning algorithm performed poorly (and would otherwise lead to unsafe actions), thus demonstrating the power of this technique. (c) 2012 IEEE."",
    keywords = ""Aircraft detection; E-learning; Learning systems; Multi agent systems; Online systems; Robotics; Autonomous rotorcrafts; Autonomous systems; Hamilton-Jacobi-Isaacs; Machine learning techniques; Multiagent control; Performance guarantees; Quadrotor helicopter; Safety analysis; Learning algorithms"",
    correspondence_address = ""J.H. Gillula; Computer Science Department, Stanford University, Stanford, CA 94305-4035, United States; email: jgillula@cs.stanford.edu"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""10504729"",
    isbn = ""978-146731403-9"",
    coden = ""PIIAE"",
    language = ""English"",
    abbrev_source_title = ""Proc IEEE Int Conf Rob Autom"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 68; Conference name: 2012 IEEE International Conference on Robotics and Automation, ICRA 2012; Conference date: 14 May 2012 through 18 May 2012; Conference code: 115022""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2012	Guaranteed safe online learning via reachability: tracking a ground target using a quadrotor	https://www.scopus.com/record/display.uri?eid=2-s2.0-84864441922&origin=resultslist&sort=plf-f&src=s&sid=e49c984e378c932e52a6caa866cf2a55&sot=b&sdt=b&s=TITLE-ABS-KEY%28guaranteed+safe+online+learning+via+reachability+tracking+a+ground+target+using+a+quadrotor%29&sl=106&sessionSearchId=e49c984e378c932e52a6caa866cf2a55&relpos=0	Institute of Electrical and Electronics Engineers Inc	
19	TestNN	Integrating virtual agents to allow safe, complex testing of autonomous unmanned vehicles	DISTRIBUTION STATEMENT A; APPROVAL FOR PUBLIC RELEASE DISTRIBUTION IS UNLIMITED. A gap currently exists in the industry's ability to carry out safe, rigorous testing of autonomous unmanned vehicles (AUVs). In 2013, the Test Resource Management Center (TRMC) initiated an effort to design an infrastructure for carrying out complex and safe tests of AUVs under the Safe Testing of Autonomy in Complex Environments (TACE) program. The TACE infrastructure watches over the system under test's (SUT) autonomous decisions to assure that the SUT does not violate safety constraints during a test. TACE also provides complex, interactive, stimulation to the SUT autonomy necessary to assess SUT performance. To reduce cost and help increase safety during a test, the stimulation of the autonomy must often be synthetic, such as simulating other vehicles in the same test as the SUT. Additionally, a vendor may wish to test live autonomous systems interacting with simulated cooperative systems, allowing autonomous cooperative behavior to be tested without the risk and expense of having a larger number of SUTs. This paper will detail the software written to simulate autonomous agents, including communications between live and virtual autonomous agents. TRMC's Test and Training Enabling Architecture (TENA) was used to handle the networking layer, while the Naval Air Systems Command's (NAVAIR) Joint Integrated Mission Model (JIMM) was used to simulate the battlespace environment and maintain ground truth. The Johns Hopkins University Applied Physics Laboratory (JHUAPL)-developed Autonomy Tool Kit (ATK) was used as the autonomy engine driving both the live SUT and the virtual cooperative agents.	Ability testing; Autonomous underwater vehicles; Behavioral research; Integration testing; Interoperability; Microwave circuits; Network layers; Safety engineering; Software agents; Software testing; Supersonic aerodynamics; Unmanned aerial vehicles (UAV); Unmanned vehicles; Vehicles; Autonomy; Hard-ware-in-the-loop; Mission models; Safe testings; TACE; Virtual agent; Autonomous agents; Ability testing;  Autonomous underwater vehicles;  Behavioral research;  Integration testing;  Interoperability;  Microwave circuits;  Network layers;  Safety engineering;  Software agents;  Software testing;  Supersonic aerodynamics;  Unmanned aerial vehicles (UAV);  Unmanned vehicles;  Vehicles;  Autonomy;  Hard-ware-in-the-loop;  Mission models;  Safe testings;  TACE;  Virtual agent;  Autonomous agents	John, Brendan A.	2015 Fall Simulation Interoperability Workshop, SIW 2015	https://www.scopus.com/record/display.uri?eid=2-s2.0-84964054299&origin=resultslist&sort=plf-f&src=s&sid=311873e766cd4d7005089bf4ba7bddf2&sot=b&sdt=b&s=TITLE-ABS-KEY%28integrating+virtual+agents+to+allow+safe+complex+testing+of+autonomous+unmanned+vehicles%29&sl=103&sessionSearchId=311873e766cd4d7005089bf4ba7bddf2&relpos=0			"""@CONFERENCE{John2015,
    author = ""John, Brendan A."",
    title = ""Integrating virtual agents to allow safe, complex testing of autonomous unmanned vehicles"",
    year = ""2015"",
    journal = ""2015 Fall Simulation Interoperability Workshop, SIW 2015"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964054299\&partnerID=40\&md5=476e20cdf98d6819103711a7d20c757a"",
    affiliations = ""Johns Hopkins University, Applied Physics Laboratory, 11100 Johns Hopkins Rd, Laurel, 20723, MD, United States"",
    abstract = ""DISTRIBUTION STATEMENT A; APPROVAL FOR PUBLIC RELEASE DISTRIBUTION IS UNLIMITED. A gap currently exists in the industry's ability to carry out safe, rigorous testing of autonomous unmanned vehicles (AUVs). In 2013, the Test Resource Management Center (TRMC) initiated an effort to design an infrastructure for carrying out complex and safe tests of AUVs under the Safe Testing of Autonomy in Complex Environments (TACE) program. The TACE infrastructure watches over the system under test's (SUT) autonomous decisions to assure that the SUT does not violate safety constraints during a test. TACE also provides complex, interactive, stimulation to the SUT autonomy necessary to assess SUT performance. To reduce cost and help increase safety during a test, the stimulation of the autonomy must often be synthetic, such as simulating other vehicles in the same test as the SUT. Additionally, a vendor may wish to test live autonomous systems interacting with simulated cooperative systems, allowing autonomous cooperative behavior to be tested without the risk and expense of having a larger number of SUTs. This paper will detail the software written to simulate autonomous agents, including communications between live and virtual autonomous agents. TRMC's Test and Training Enabling Architecture (TENA) was used to handle the networking layer, while the Naval Air Systems Command's (NAVAIR) Joint Integrated Mission Model (JIMM) was used to simulate the battlespace environment and maintain ground truth. The Johns Hopkins University Applied Physics Laboratory (JHUAPL)-developed Autonomy Tool Kit (ATK) was used as the autonomy engine driving both the live SUT and the virtual cooperative agents. (c) Copyright 2015, SISO, Inc."",
    author_keywords = ""Autonomy; Hardware in the Loop; Mission Modeling; Safe Testing; TACE; Unmanned Aerial Vehicles; Virtual Agents"",
    keywords = ""Ability testing; Autonomous underwater vehicles; Behavioral research; Integration testing; Interoperability; Microwave circuits; Network layers; Safety engineering; Software agents; Software testing; Supersonic aerodynamics; Unmanned aerial vehicles (UAV); Unmanned vehicles; Vehicles; Autonomy; Hard-ware-in-the-loop; Mission models; Safe testings; TACE; Virtual agent; Autonomous agents"",
    correspondence_address = ""B.A. John; Johns Hopkins University, Applied Physics Laboratory, Laurel, 11100 Johns Hopkins Rd, 20723, United States; email: brendan.john@jhuapl.edu"",
    publisher = ""SISO - Simulation Interoperability Standards Organization"",
    language = ""English"",
    abbrev_source_title = ""Fall Simul. Interoper. Workshop, SIW"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 0; Conference name: 2015 Fall Simulation Interoperability Workshop, SIW 2015; Conference date: 31 August 2015 through 4 September 2015; Conference code: 118772""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2015	Integrating virtual agents to allow safe, complex testing of autonomous unmanned vehicles	https://www.scopus.com/record/display.uri?eid=2-s2.0-84964054299&origin=resultslist&sort=plf-f&src=s&sid=311873e766cd4d7005089bf4ba7bddf2&sot=b&sdt=b&s=TITLE-ABS-KEY%28integrating+virtual+agents+to+allow+safe+complex+testing+of+autonomous+unmanned+vehicles%29&sl=103&sessionSearchId=311873e766cd4d7005089bf4ba7bddf2&relpos=0	SISO - Simulation Interoperability Standards Organization	nan; References; Pages
20	TestNN	Intelligent sensor attack detection and identification for automotive cyber-physical systems	This paper addresses the problem of detection and identification of the sensor attacks when most sensors are attacked. Sensors can play a key role to improve safety and convenience in automotive Cyber-Physical Systems (CPS). A dramatic increase in connectivity and openness of the automotive CPS brings high security risks. If multiple and heterogeneous sensors equipped for braking and steering provides false sensing information for their controllers under deception attacks, it might cause catastrophic situations during driving. If the existing machine learning approaches are applied for sensor attacks while the majority of sensors is attacked, it cannot guarantee to identify deceptions as cyber-physical attacks. To address this problem, we propose an intelligent sensor attack detection and identification method based on Deep Neural Network (DNN) techniques, called deep learning, without a prior knowledge about the deception attacks modifying sensing data in time. We investigate an autonomous vehicle with Inertial Measurement Unit (IMU) and wheel encoder sensors under conditions of uncertainty and nonlinearity during driving. We firstly identify all possible attacks category on the sensors of it, choose what model to use and then systematically design its architecture on which the performance of deep learning highly depends. We train and then validate the proposed method's performance on real measurement data obtained from an unmanned ground vehicle. Finally, we show analytically the superiority of our method in terms of accuracy, precision, and computation time, including the worst situation where two among three sensors are simultaneously attacked.	Cybersecurity; Deep neural networks; Embedded systems; Intelligent control; Intelligent systems; Intelligent vehicle highway systems; Uncertainty analysis; Attack detection; Automotive cybe-physical system; Automotives; Cybe-physical systems; Cyber-physical systems; Detection and identifications; Gated recurrent unit; Heterogeneous sensors; Intelligent sensors; Performance; Cyber Physical System; Cybersecurity;  Deep neural networks;  Embedded systems;  Intelligent control;  Intelligent systems;  Intelligent vehicle highway systems;  Uncertainty analysis;  Attack detection;  Automotive cybe-physical system;  Automotives;  Cybe-physical systems;  Cyber-physical systems;  Detection and identifications;  Gated recurrent unit;  Heterogeneous sensors;  Intelligent sensors;  Performance;  Cyber Physical System	Shin, Jongho; Baek, Youngmi; Eun, Yongsoon; Son, Sang Hyuk	2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017 - Proceedings	https://doi.org/10.1109/SSCI.2017.8280915	"1.Jianhua Shi et al., ""A survey of cyber-physical systems"", Wireless Communications and Signal Processing (WCSP) 2011 International Conference on, 2011. View Article  Google Scholar; 2.Robert Mitchell and Ing-Ray Chen, ""A survey of intrusion detection techniques for cyber-physical systems"", ACM Computing Surveys (CSUR), vol. 46, no. 4, pp. 55, 2014. CrossRef  Google Scholar; 3.Alvaro A. Cardenas et al., ""Attacks against process control systems: risk assessment detection and response"", Proceedings of the 6th ACM symposium on information computer and communications security, 2011. CrossRef  Google Scholar; 4.MA Perez Del Pino et al., ""Towards self-organizing maps based Computational Intelligent System for denial of Service Attacks Detection"", 2010 IEEE 14th International Conference on Intelligent Engineering Systems, 2010. View Article  Google Scholar; 5.Siddharth Sridhar, Adam Hahn and Manimaran Govindarasu, ""Cyber-physical system security for the electric power grid"", Proceedings of the IEEE, vol. 100, no. 1, pp. 210-224, 2012. View Article  Google Scholar; 6.Yilin Mo et al., ""Cyber-physical security of a smart grid infrastructure"", Proceedings of the IEEE, vol. 100, no. 1, pp. 195-209, 2012. View Article  Google Scholar; 7.Cheolhyeon Kwon, Weiyi Liu and Inseok Hwang, ""Security analysis for cyber-physical systems against stealthy deception attacks"", 2013 American Control Conference, 2013. View Article  Google Scholar; 8.Nicola Bezzo et al., ""Attack resilient state estimation for autonomous robotic systems"", 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems, 2014. View Article  Google Scholar; 9.Rolf Isermann, Fault-diagnosis systems: an introduction from fault detection to fault tolerance, Springer Science  Business Media, 2006. Google Scholar; 10.Minsu Jo et al., ""Adaptive Transient Fault Model for Sensor Attack Detection"", Cyber-Physical Systems Networks and Applications (CPSNA) 2016 IEEE 4th International Conference on, 2016. View Article  Google Scholar; 11.Andrew J. Kerns et al., ""Unmanned aircraft capture and control via GPS spoofing"", Journal of Field Robotics, vol. 31, no. 4, pp. 617-636, 2014. CrossRef  Google Scholar; 12.Daniel P. Shepard et al., ""Evaluation of smart grid and civilian UAV vulnerability to GPS spoofing attacks"", Proceedings of the ION GNSS Meeting, vol. 3, 2012. Google Scholar; 13.Karl Koscher et al., ""Experimental security analysis of a modern automobile"", 2010 IEEE Symposium on Security and Privacy, 2010. View Article  Google Scholar; 14.Aviva Hope Rutkin, ""spoofers use fake GPS signals to knock a yacht off course"", MIT Technology Review (2013). Google Scholar; 15.Hamza Fawzi, Paulo Tabuada and Suhas Diggavi, ""Security for control systems under sensor and actuator attacks"", 2012 IEEE 51st IEEE Conference on Decision and Control (CDC), 2012. View Article  Google Scholar; 16.Giedre Sabaliauskaite and Aditya P. Mathur, ""Intelligent checkers to improve attack detection in cyber physical systems"", Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC) 2013 International Conference on, 2013. View Article  Google Scholar; 17.Saurabh Amin, Alvaro A. Cardenas and S. Shankar Sastry, ""Safe and secure networked control systems under denial-of-service attacks"", International Workshop on Hybrid Systems: Computation and control, 2009. CrossRef  Google Scholar; 18.Youmin Zhang and Jin Jiang, ""Bibliographical review on reconfigurable fault-tolerant control systems"", Annual reviews in control, vol. 32, no. 2, pp. 229-252, 2008. CrossRef  Google Scholar; 19.Zhiwei Gao, Carlo Cecati and Steven X. Ding, ""A survey of fault diagnosis and fault-tolerant techniques-Part I: Fault diagnosis with model-based and signal-based approaches"", IEEE Transactions on Industrial Electronics, vol. 62, no. 6, pp. 3757-3767, 2015. View Article  Google Scholar; 20.Rolf Isermann and Peter Balle, ""Trends in the application of model-based fault detection and diagnosis of technical processes"", Control engineering practice, vol. 5, no. 5, pp. 709-719, 1997. CrossRef  Google Scholar; 21.Saurabh Amin et al., ""Cyber security of water SCADA systems-Part II: Attack detection using enhanced hydrodynamic models"", IEEE Transactions on Control Systems Technology, vol. 21, no. 5, pp. 1679-1693, 2013. View Article  Google Scholar; 22.Ihab Samy, Ian Postlethwaite and Da-Wei Gu, ""Detection and accommodation of sensor faults in UAVs-a comparison of NN and EKF based approaches"", Decision and Control (CDC) 2010 49th IEEE Conference on, 2010. View Article  Google Scholar; 23.Venkat Venkatasubramanian et al., ""A review of process fault detection and diagnosis: Part III: Process history based methods"", Computers  chemical engineering, vol. 27, no. 3, pp. 327-346, 2003. CrossRef  Google Scholar; 24.Pedro Santos et al., ""An SVM-based solution for fault detection in wind turbines"", Sensors, vol. 15, no. 3, pp. 5627-5648, 2015. CrossRef  Google Scholar; 25.Achmad Widodo and Bo-Suk Yang, ""Support vector machine in machine condition monitoring and fault diagnosis"", Mechanical systems and signal processing, vol. 21, no. 6, pp. 2560-2574, 2007. CrossRef  Google Scholar; 26.L.J. Cao et al., ""A comparison of PCA KPCA and ICA for dimensionality reduction in support vector machine"", Neurocomputing, vol. 55, no. 1, pp. 321-336, 2003. CrossRef  Google Scholar; 27.Jinane Harmouche, Claude Delpha and Demba Diallo, ""Incipient fault detection and diagnosis based on Kullback-Leibler divergence using principal component analysis: Part II"", Signal Processing, vol. 109, pp. 334-344, 2015. CrossRef  Google Scholar; 28.Qing Wang et al., ""A sensor network modeling and fault detection method for large wind farms by using neural networks"", Control  Automation (ICCA) 11th IEEE International Conference on, 2014. View Article  Google Scholar; 29.Paul J. Werbos, ""Backpropagation through time: what it does and how to do it"", Proceedings of the IEEE, vol. 78, no. 10, pp. 1550-1560, 1990. View Article  Google Scholar; 30.Yoshua Bengio, Patrice Simard and Paolo Frasconi, ""Learning long-term dependencies with gradient descent is difficult"", IEEE transactions on neural networks, vol. 5, no. 2, pp. 157-166, 1994. View Article  Google Scholar"	1 - 8	"""@CONFERENCE{Shin20171,
    author = ""Shin, Jongho and Baek, Youngmi and Eun, Yongsoon and Son, Sang Hyuk"",
    title = ""Intelligent sensor attack detection and identification for automotive cyber-physical systems"",
    year = ""2017"",
    journal = ""2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017 - Proceedings"",
    volume = ""2018-January"",
    pages = ""1 - 8"",
    doi = ""10.1109/SSCI.2017.8280915"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046095781\&doi=10.1109\%2fSSCI.2017.8280915\&partnerID=40\&md5=f87d334210e368e9056ab8cf748dc05a"",
    affiliations = ""Department of Information and Communication Engineering, DGIST, Daegu, South Korea"",
    abstract = ""This paper addresses the problem of detection and identification of the sensor attacks when most sensors are attacked. Sensors can play a key role to improve safety and convenience in automotive Cyber-Physical Systems (CPS). A dramatic increase in connectivity and openness of the automotive CPS brings high security risks. If multiple and heterogeneous sensors equipped for braking and steering provides false sensing information for their controllers under deception attacks, it might cause catastrophic situations during driving. If the existing machine learning approaches are applied for sensor attacks while the majority of sensors is attacked, it cannot guarantee to identify deceptions as cyber-physical attacks. To address this problem, we propose an intelligent sensor attack detection and identification method based on Deep Neural Network (DNN) techniques, called deep learning, without a prior knowledge about the deception attacks modifying sensing data in time. We investigate an autonomous vehicle with Inertial Measurement Unit (IMU) and wheel encoder sensors under conditions of uncertainty and nonlinearity during driving. We firstly identify all possible attacks category on the sensors of it, choose what model to use and then systematically design its architecture on which the performance of deep learning highly depends. We train and then validate the proposed method's performance on real measurement data obtained from an unmanned ground vehicle. Finally, we show analytically the superiority of our method in terms of accuracy, precision, and computation time, including the worst situation where two among three sensors are simultaneously attacked. (c) 2017 IEEE."",
    author_keywords = ""Attack detection; Automotive cyber-physical systems; Gated Recurrent Unit; Heterogeneous sensors; Long Short-Term Memory"",
    keywords = ""Cybersecurity; Deep neural networks; Embedded systems; Intelligent control; Intelligent systems; Intelligent vehicle highway systems; Uncertainty analysis; Attack detection; Automotive cybe-physical system; Automotives; Cybe-physical systems; Cyber-physical systems; Detection and identifications; Gated recurrent unit; Heterogeneous sensors; Intelligent sensors; Performance; Cyber Physical System"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153862725-9"",
    language = ""English"",
    abbrev_source_title = ""IEEE Symp. Ser. Comput. Intell., SSCI - Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 28; Conference name: 2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017; Conference date: 27 November 2017 through 1 December 2017; Conference code: 134337""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2018	Intelligent sensor attack detection and identification for automotive cyber-physical systems	https://www.scopus.com/record/display.uri?eid=2-s2.0-85046095781&origin=resultslist&sort=plf-f&src=s&sid=ff4332e39f7cd92cb46884309de2e9c4&sot=b&sdt=b&s=TITLE-ABS-KEY%28intelligent+sensor+attack+detection+and+identification+for+automotive+cyber+physical+systems%29&sl=107&sessionSearchId=ff4332e39f7cd92cb46884309de2e9c4&relpos=0	Institute of Electrical and Electronics Engineers Inc	
21	TestNN	Introducing ASIL inspired dynamic tactical safety decision framework for automated vehicles	Existing automotive Hazard Analysis and Risk Assessment (HARA) process as discussed by the international standard ISO 26262 is static in nature. While the standard describes a systematic process to incorporate functional safety in the development process of Electrical & Electronic (E/E) systems, it fails to address the needs of Advanced Driver Assistance Systems (ADAS) and Automated Driving (AD) systems. In order to ensure the safety of ADAS and AD systems, it is important to incorporate the changing nature of interactions between the system and the environment, in the safety analysis process for ADAS and AD systems. In this paper, the authors argue the need for a dynamic approach for automotive safety analysis by adapting the tactical safety for ADAS and AD systems depending on the real-time operational capability and real-time ASIL (Automotive Safety Integrity Level) rating of a situation, and discuss a framework for this process. The novelty and therefore contribution of this paper lies in the proposed ASIL inspired dynamic tactical safety framework, which evaluates the severity, controllability and exposure ratings in real-time based on the real time values of the various vehicle and environment parameters. These ratings are used to assign a real-time ASIL value which is used to determine the tactical decisions in order to lower the ASIL value in real-time by altering the functional (operational) capability of the system. Furthermore, the framework is explained with the help of a case study based on a combined Adaptive Cruise Control (ACC) and Autonomous Emergency Braking (AEB) system.	Adaptive control systems; Adaptive cruise control; Advanced driver assistance systems; Automobile drivers; Hazards; Real time systems; Risk analysis; Vehicle safety; Automated driving systems; Automotive safety integrity levels; Hazard analyse and risk assessment; Hazard risks; Hazards analysis; ISO 26262; Real- time; Risks assessments; Tactical decisions; Tacticals; Risk assessment; Adaptive control systems;  Adaptive cruise control;  Advanced driver assistance systems;  Automobile drivers;  Hazards;  Real time systems;  Risk analysis;  Vehicle safety;  Automated driving systems;  Automotive safety integrity levels;  Hazard analyse and risk assessment;  Hazard risks;  Hazards analysis;  ISO 26262;  Real- time;  Risks assessments;  Tactical decisions;  Tacticals;  Risk assessment	Khastgir, Siddartha; Sivencrona, Hakan; Dhadyalla, Gunwant; Billing, Peter; Birrell, Stewart; Jennings, Paul	IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC	https://doi.org/10.1109/ITSC.2017.8317868	"1.S. Singh, Critical reasons for crashes investigated in the National Motor Vehicle Crash Causation Survey. (Traffic Safety Facts Crash Stats. Report No. DOT HS 812 115), 2015. Google Scholar; 2.J. Carbaugh, D. N. Godbole and R. Sengupta, ""Safety and capacity analysis of automated and manual highway systems"", Transp. Res. Part C Emerg. Technol., vol. 6, no. 1-2, pp. 69-99, 1998. CrossRef  Google Scholar; 3.R. Johansson and J. Nilsson, ""The Need for an Environment Perception Block to Address all ASIL Levels Simultaneously"", Proc. of the IEEE Intelligent Vehicles Symposium (IV), 2016. CrossRef  Google Scholar; 4.S. Khastgir, S. Birrell, G. Dhadyalla and P. Jennings, ""Identifying a Gap in Existing Validation Methodologies for Intelligent Automotive Systems: Introducing the 3xD Simulator"", Proc. of the IEEE Intelligent Vehicles Symposium (IV), pp. 648-653, 2015. CrossRef  Google Scholar; 5.J. A. Michon, ""A critical view of driver behavior models: what do we know what should we do?"" in Human behavior and traffic safety, Plenum Press, pp. 485-520, 1985. CrossRef  Google Scholar; 6.V. Villa, N. Paltrinieri, F. Khan and V. Cozzani, ""Towards dynamic risk analysis: A review of the risk assessment approach and its limitations in the chemical process industry"", Saf. Sci., vol. 89, pp. 77-93, 2016. CrossRef  Google Scholar; 7.The Buncefield Incident 11 December 2005: The final report of the Major Incident Investigation Board, 2008. Google Scholar; 8.H. Pasman and G. Reniers, ""Past present and future of Quantitative Risk Assessment (QRA) and the incentive it obtained from Land-Use Planning (LUP)"", J. Loss Prev. Process Ind., vol. 28, pp. 2-9, 2014. CrossRef  Google Scholar; 9.E. Fadier and C. De La Garza, ""Safety design: Towards a new philosophy"", Saf. Sci., vol. 44, no. 1, pp. 55-73, 2006. CrossRef  Google Scholar; 10.N. Paltrinieri, F. Khan and V. Cozzani, ""Coupling of advanced techniques for dynamic risk management"", J. Risk Res., vol. 18, no. 7, pp. 910-930, 2015. CrossRef  Google Scholar; 11.G. D. Creedy, ""Quantitative risk assessment: How realistic are those frequency assumptions?"", J. Loss Prev. Process Ind., vol. 24, no. 3, pp. 203-207, 2011. CrossRef  Google Scholar; 12.M. Kalantamia, F. Khan and K. Hawboldt, ""Dynamic risk assessment using failure assessment and Bayesian theory"", J. Loss Prev. Process Ind., vol. 22, no. 5, pp. 600-606, 2009. CrossRef  Google Scholar; 13.A. Falck, E. Skramstad and M. Berg, ""Use of QRA for decision support in the design of an offshore oil production installation"", J. Hazard. Mater., vol. 71, no. 1-3, pp. 179-192, 2000. CrossRef  Google Scholar; 14.M. Yang, F. Khan and P. Amyotte, ""Operational risk assessment: A case of the Bhopal disaster"", Process Saf. Environ. Prot., vol. 97, pp. 70-79, 2015. CrossRef  Google Scholar; 15.M. Kalantamia, F. Khan and K. Hawboldt, ""Modelling of BP Texas City refinery accident using dynamic risk assessment approach"", Process Saf. Environ. Prot., vol. 88, no. 3, pp. 191-199, 2010. CrossRef  Google Scholar; 16.N. Paltrinieri and G. Scarponi, ""Addressing Dynamic Risk in the Petroleum Industry by Means of Innovative Analysis Solutions"", Chem. Eng. Trans., vol. 36, pp. 451-456, 2014. Google Scholar; 17.N. Khakzad, F. Khan and P. Amyotte, ""Dynamic risk analysis using bow-tie approach"", Reliab. Eng. Syst. Saf., vol. 104, pp. 36-44, 2012. CrossRef  Google Scholar; 18.N. Paltrinieri, A. Tugnoli, J. Buston, M. Wardman and V. Cozzani, ""Dynamic Procedure for Atypical Scenarios Identification (DyPASI): A new systematic HAZID tool"", J. Loss Prev. Process Ind., vol. 26, no. 4, pp. 683-695, 2013. CrossRef  Google Scholar; 19.Road vehicles - Functional safety (ISO 26262), 2011. Google Scholar; 20.P. E. Labeau, C. Smidts and S. Swaminathan, ""Dynamic reliability: Towards an integrated platform for probabilistic risk assessment"", Reliab. Eng. Syst. Saf., vol. 68, no. 3, pp. 219-254, 2000. CrossRef  Google Scholar; 21.S. Swaminathan, ""The Event Sequence Diagram framework for dynamic Probabilistic Risk Assessment"", Reliab. Eng. Syst. Saf., vol. 63, no. 1, pp. 73-90, 1999. CrossRef  Google Scholar; 22.H. Boudali and J. B. Dugan, ""A discrete-time Bayesian network reliability modeling and analysis framework"", Reliab. Eng. Syst. Saf., vol. 87, no. 3, pp. 337-349, 2005. CrossRef  Google Scholar; 23.R. Ferdous, F. Khan, R. Sadiq, P. Amyotte and B. Veitch, ""Analyzing system safety and risks under uncertainty using a bow-tie diagram: An innovative approach"", Process Saf. Environ. Prot., vol. 91, no. 1-2, pp. 1-18, 2013. CrossRef  Google Scholar; 24.M. Abimbola, F. Khan and N. Khakzad, ""Dynamic safety risk analysis of offshore drilling"", J. Loss Prev. process Ind., vol. 30, no. 1, pp. 74-85, 2014. CrossRef  Google Scholar; 25.S. Rathnayaka, F. Khan and P. Amayotte, ""Accident modeling and risk assessment framework for safety critical decision-making: application to deepwater drilling operation"", J. Risk Reliab., vol. 227, no. 1, pp. 86-105, 2013. CrossRef  Google Scholar; 26.F. Khan, S. J. Hashemi, N. Paltrinieri, P. Amyotte, V. Cozzani and G. Reniers, ""Dynamic risk management: a contemporary approach to process safety management"", Curr. Opin. Chem. Eng., vol. 14, pp. 9-17, 2016. CrossRef  Google Scholar; 27.N. Paltrinieri, F. Khan, P. Amyotte and V. Cozzani, ""Dynamic approach to risk management: Application to the Hoeganaes metal dust accidents"", Process Saf. Environ. Prot., vol. 92, no. 6, pp. 669-679, 2013. CrossRef  Google Scholar; 28.S. Khastgir, S. Birrell, G. Dhadyalla, H. Sivencrona and P. Jennings, ""Towards increased reliability by objectification of Hazard Analysis and Risk Assessment (HARA) of automated automotive systems"", Saf. Sci., 2017. CrossRef  Google Scholar; 29.H. Yu, C.- W. Lin and B. Kim, ""Automotive Software Certification: Current Status and Challenges"", SAE Int. J. Passeng. Cars - Electron. Electr. Syst., vol. 9, no. 1, pp. 2016-01-0050, 2016. CrossRef  Google Scholar; 30.R. Johansson and J. Nilsson, ""Disarming the Trolley Problem - Why Self-driving Cars do not Need to Choose Whom to Kill"", Proc. of the Workshop Critical Automotive applications: Robustness & Safety, 2016. Google Scholar"	1 - 6	"""@CONFERENCE{Khastgir20171,
    author = ""Khastgir, Siddartha and Sivencrona, Hakan and Dhadyalla, Gunwant and Billing, Peter and Birrell, Stewart and Jennings, Paul"",
    title = ""Introducing ASIL inspired dynamic tactical safety decision framework for automated vehicles"",
    year = ""2017"",
    journal = ""IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC"",
    volume = ""2018-March"",
    pages = ""1 - 6"",
    doi = ""10.1109/ITSC.2017.8317868"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046261765\&doi=10.1109\%2fITSC.2017.8317868\&partnerID=40\&md5=95943814807438cbe7f8afe9498c3e48"",
    affiliations = ""WMG, University of Warwick Coventry, United Kingdom; Qamcom Research and Technology AB, Goteborg, Sweden"",
    abstract = ""Existing automotive Hazard Analysis and Risk Assessment (HARA) process as discussed by the international standard ISO 26262 is static in nature. While the standard describes a systematic process to incorporate functional safety in the development process of Electrical \& Electronic (E/E) systems, it fails to address the needs of Advanced Driver Assistance Systems (ADAS) and Automated Driving (AD) systems. In order to ensure the safety of ADAS and AD systems, it is important to incorporate the changing nature of interactions between the system and the environment, in the safety analysis process for ADAS and AD systems. In this paper, the authors argue the need for a dynamic approach for automotive safety analysis by adapting the tactical safety for ADAS and AD systems depending on the real-time operational capability and real-time ASIL (Automotive Safety Integrity Level) rating of a situation, and discuss a framework for this process. The novelty and therefore contribution of this paper lies in the proposed ASIL inspired dynamic tactical safety framework, which evaluates the severity, controllability and exposure ratings in real-time based on the real time values of the various vehicle and environment parameters. These ratings are used to assign a real-time ASIL value which is used to determine the tactical decisions in order to lower the ASIL value in real-time by altering the functional (operational) capability of the system. Furthermore, the framework is explained with the help of a case study based on a combined Adaptive Cruise Control (ACC) and Autonomous Emergency Braking (AEB) system. (c) 2017 IEEE."",
    author_keywords = ""HARA; Hazards; ISO 26262; Tactical decisions"",
    keywords = ""Adaptive control systems; Adaptive cruise control; Advanced driver assistance systems; Automobile drivers; Hazards; Real time systems; Risk analysis; Vehicle safety; Automated driving systems; Automotive safety integrity levels; Hazard analyse and risk assessment; Hazard risks; Hazards analysis; ISO 26262; Real- time; Risks assessments; Tactical decisions; Tacticals; Risk assessment"",
    correspondence_address = ""S. Khastgir; WMG, University of Warwick Coventry, United Kingdom; email: S.Khastgir@warwick.ac.uk"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153861525-6"",
    language = ""English"",
    abbrev_source_title = ""IEEE Conf Intell Transport Syst Proc ITSC"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 14; Conference name: 20th IEEE International Conference on Intelligent Transportation Systems, ITSC 2017; Conference date: 16 October 2017 through 19 October 2017; Conference code: 135272; All Open Access, Green Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2018	Introducing ASIL inspired dynamic tactical safety decision framework for automated vehicles	https://www.scopus.com/record/display.uri?eid=2-s2.0-85046261765&origin=resultslist&sort=plf-f&src=s&sid=55a6c4c432435de6c7344c2ab9be966e&sot=b&sdt=b&s=TITLE-ABS-KEY%28introducing+asil+inspired+dynamic+tactical+safety+decision+framework+for+automated+vehicles%29&sl=106&sessionSearchId=55a6c4c432435de6c7344c2ab9be966e&relpos=0	Institute of Electrical and Electronics Engineers Inc	
22	TestNN	Introspective perception: Learning to predict failures in vision systems	As robots aspire for long-term autonomous operations in complex dynamic environments, the ability to reliably take mission-critical decisions in ambiguous situations becomes critical. This motivates the need to build systems that have situational awareness to assess how qualified they are at that moment to make a decision. We call this self-evaluating capability as introspection. In this paper, we take a small step in this direction and propose a generic framework for introspective behavior in perception systems. Our goal is to learn a model to reliably predict failures in a given system, with respect to a task, directly from input sensor data. We present this in the context of vision-based autonomous MAV flight in outdoor natural environments, and show that it effectively handles uncertain situations.	Computer vision; Robots; Autonomous operations; Complex dynamics; Generic frameworks; Mission-critical decisions; Natural environments; Perception systems; Situational awareness; Vision systems; Intelligent robots; Computer vision;  Robots;  Autonomous operations;  Complex dynamics;  Generic frameworks;  Mission-critical decisions;  Natural environments;  Perception systems;  Situational awareness;  Vision systems;  Intelligent robots	Daftry, Shreyansh; Zeng, Sam; Bagnell, J. Andrew; Hebert, Martial	IEEE International Conference on Intelligent Robots and Systems	https://doi.org/10.1109/IROS.2016.7759279		1743 - 1750	"""@CONFERENCE{Daftry20161743,
    author = ""Daftry, Shreyansh and Zeng, Sam and Bagnell, J. Andrew and Hebert, Martial"",
    title = ""Introspective perception: Learning to predict failures in vision systems"",
    year = ""2016"",
    journal = ""IEEE International Conference on Intelligent Robots and Systems"",
    volume = ""2016-November"",
    pages = ""1743 - 1750"",
    doi = ""10.1109/IROS.2016.7759279"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006345776\&doi=10.1109\%2fIROS.2016.7759279\&partnerID=40\&md5=2054a57ed46dbdd1b91e488a8455c514"",
    affiliations = ""Robotics Institute, Carnegie Mellon University, Pittsburgh, 15213, PA, United States"",
    abstract = ""As robots aspire for long-term autonomous operations in complex dynamic environments, the ability to reliably take mission-critical decisions in ambiguous situations becomes critical. This motivates the need to build systems that have situational awareness to assess how qualified they are at that moment to make a decision. We call this self-evaluating capability as introspection. In this paper, we take a small step in this direction and propose a generic framework for introspective behavior in perception systems. Our goal is to learn a model to reliably predict failures in a given system, with respect to a task, directly from input sensor data. We present this in the context of vision-based autonomous MAV flight in outdoor natural environments, and show that it effectively handles uncertain situations. (c) 2016 IEEE."",
    keywords = ""Computer vision; Robots; Autonomous operations; Complex dynamics; Generic frameworks; Mission-critical decisions; Natural environments; Perception systems; Situational awareness; Vision systems; Intelligent robots"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""21530858"",
    isbn = ""978-150903762-9"",
    coden = ""85RBA"",
    language = ""English"",
    abbrev_source_title = ""IEEE Int Conf Intell Rob Syst"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 56; Conference name: 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2016; Conference date: 9 October 2016 through 14 October 2016; Conference code: 125056; All Open Access, Green Open Access""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2016	Introspective perception: Learning to predict failures in vision systems	https://www.scopus.com/record/display.uri?eid=2-s2.0-85006345776&origin=resultslist&sort=plf-f&src=s&sid=061f27eca83067e646c7039b0015bdee&sot=b&sdt=b&s=TITLE-ABS-KEY%28introspective+perception+learning+to+predict+failures+in+vision+systems%29&sl=86&sessionSearchId=061f27eca83067e646c7039b0015bdee&relpos=0	Institute of Electrical and Electronics Engineers Inc	nan; References
23	TestNN	Is Deep Learning Safe for Robot Vision? Adversarial Examples Against the iCub Humanoid	Deep neural networks have been widely adopted in recent years, exhibiting impressive performances in several application domains. It has however been shown that they can be fooled by adversarial examples, i.e., images altered by a barely-perceivable adversarial noise, carefully crafted to mislead classification. In this work, we aim to evaluate the extent to which robot-vision systems embodying deep-learning algorithms are vulnerable to adversarial examples, and propose a computationally efficient countermeasure to mitigate this threat, based on rejecting classification of anomalous inputs. We then provide a clearer understanding of the safety properties of deep networks through an intuitive empirical analysis, showing that the mapping learned by such networks essentially violates the smoothness assumption of learning algorithms. We finally discuss the main limitations of this work, including the creation of real-world adversarial examples, and sketch promising research directions.	Computer vision; Deep neural networks; Computationally efficient; Empirical analysis; Real-world; Robot vision systems; Safety property; Learning algorithms; Computer vision;  Deep neural networks;  Computationally efficient;  Empirical analysis;  Real-world;  Robot vision systems;  Safety property;  Learning algorithms	Melis, Marco; Demontis, Ambra; Biggio, Battista; Brown, Gavin; Fumera, Giorgio; Roli, Fabio	Proceedings - 2017 IEEE International Conference on Computer Vision Workshops, ICCVW 2017	https://doi.org/10.1109/ICCVW.2017.94	"1.M. Barreno, B. Nelson, A. Joseph and J. Tygar, ""The security of machine learning"", Mach. Learn., vol. 81, pp. 121-148, 2010. CrossRef  Google Scholar; 2.A. Bendale and T. E. Boult, ""Towards open set deep networks"", Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, pp. 1563-1572, 2016. View Article  Google Scholar; 3.B. Biggio, I. Corona, Z.-M. He, P. P. K. Chan, G. Giacinto, D. S. Yeung, et al., ""One-and-a-half-class multiple classifier systems for secure learning against evasion attacks at test time"" in Multiple Classifier Systems, Springer International Publishing, vol. 9132, pp. 168-180, 2015. CrossRef  Google Scholar; 4.B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Srndic, P. Laskov, G. Giacinto, F. Roli et al., ""Evasion attacks against machine learning at test time"" in ECML PKDD Part III, Berlin Heidelberg:Springer, vol. 8190, pp. 387-402, 2013. CrossRef  Google Scholar; 5.B. Biggio, G. Fumera and F. Roli, ""Security evaluation of pattern classifiers under attack"", IEEE Trans. Knowl. and Data Eng., vol. 26, no. 4, pp. 984-996, April 2014. View Article  Google Scholar; 6.B. Biggio, B. Nelson and P. Laskov, ""Poisoning attacks against support vector machines"" in 29th Intl Conf. on Machine Learning, Omnipress, pp. 1807-1814, 2012. Google Scholar; 7.N. Cristianini, ""Intelligence reinvented"", New Scientist, vol. 232, no. 3097, pp. 37-41, 2016. CrossRef  Google Scholar; 8.A. Demontis, P. Russu, B. Biggio, G. Fumera, F. Roli et al., ""On security and sparsity of linear classifiers for adversarial settings"" in Joint IAPR Intl Workshop on Structural Syntactic and Statistical Patt. Rec., Cham:Springer International Publishing, vol. 10029, pp. 322-332, 2016. CrossRef  Google Scholar; 9.R. Feinman, R. R. Curtin, S. Shintre and A. B. Gardner, Detecting adversarial samples from artifacts, 2017. Google Scholar; 10.I. J. Goodfellow, J. Shlens and C. Szegedy, ""Explaining and harnessing adversarial examples"", International Conf. on Learning Representations, 2015. Google Scholar; 11.G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-R. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath et al., ""Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups"", IEEE Signal Processing Magazine, vol. 29, no. 6, pp. 82-97, 2012. View Article  Google Scholar; 12.L. Huang, A. D. Joseph, B. Nelson, B. Rubinstein and J. D. Tygar, ""Adversarial machine learning"", 4th ACM Workshop on Artificial Intelligence and Security (AISec 2011), pp. 43-57, 2011. CrossRef  Google Scholar; 13.A. Krizhevsky, I. Sutskever and G. E. Hinton, ""Imagenet classification with deep convolutional neural networks"" in Advances in Neural Information Processing Systems, Curran Associates, Inc., vol. 25, pp. 1097-1105, 2012. CrossRef  Google Scholar; 14.A. Kurakin, I. Goodfellow and S. Bengio, Adversarial examples in the physical world, 2016. Google Scholar; 15.X. Li and F. Li, ""Adversarial examples detection in deep networks with convolutional filter statistics"", CoRR abs/1612.07767, 2016. Google Scholar; 16.Y. Luo, X. Boix, G. Roig, T. Poggio and Q. Zhao, Foveation-based mechanisms alleviate adversarial examples, 2015. Google Scholar; 17.A. Mahendran and A. Vedaldi, ""Understanding deep image representations by inverting them"", IEEE Conf Computer Vision and Patt. Rec., pp. 5188-5196, 2015. View Article  Google Scholar; 18.G. Metta, G. Sandini, D. Vernon, L. Natale and F. Nori, ""The iCub humanoid robot: an open platform for research in embodied cognition"", Proc. of the 8th workshop on performance metrics for intelligent systems, pp. 50-56, 2008. CrossRef  Google Scholar; 19.S.-M. Moosavi-Dezfooli, A. Fawzi and P. Frossard, ""Deep-fool: a simple and accurate method to fool deep neural networks"", Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, pp. 2574-2582, 2016. Google Scholar; 20.N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik and A. Swami, ""The limitations of deep learning in adversarial settings"", 1st IEEE European Symp. Sec.  Privacy, pp. 372-387, 2016. View Article  Google Scholar; 21.G. Pasquale, C. Ciliberto, F. Odone, L. Rosasco, L. Natale and I. dei Sistemi, ""Teaching iCub to recognize objects using deep convolutional neural networks"", MLIS@ ICML, pp. 21-25, 2015. Google Scholar; 22.P. Russu, A. Demontis, B. Biggio, G. Fumera and F. Roli, ""Secure kernel machines against evasion attacks"", 9th AISec, pp. 59-69, 2016. CrossRef  Google Scholar; 23.W. Scheirer, L. Jain and T. Boult, ""Probability models for open set recognition"", IEEE Trans. Patt. An. Mach. In tell., vol. 36, no. 11, pp. 2317-2324, 2014. View Article  Google Scholar; 24.M. Sharif, S. Bhagavatula, L. Bauer and M. K. Reiter, ""Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition"", Conf. Computer and Comm. Sec., pp. 1528-1540, 2016. CrossRef  Google Scholar; 25.C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, et al., ""Intriguing properties of neural networks"", ICLR, 2014. Google Scholar; 26.T. Tanay and L. Griffin, A boundary tilting persepective on the phenomenon of adversarial examples, 2016. Google Scholar; 27.Y. Tang, ""Deep learning using support vector machines"", ICML Workshop on Representational Learning, vol. arXiv:1306.0239, 2013. Google Scholar; 28.N. Srndic and P. Laskov, ""Practical evasion of a learning-based classifier: A case study"", IEEE Symp. Sec.  Privacy, pp. 197-211, 2014. View Article  Google Scholar; 29.H. Xu, C. Caramanis and S. Mannor, ""Robustness and regularization of support vector machines"", JMLR, vol. 10, pp. 1485-1510, July 2009. Google Scholar; 30.M. D. Zeiler and R. Fergus, ""Visualizing and understanding convolutional networks"", ECCV, pp. 818-833, 2014. CrossRef  Google Scholar"	751 - 759	"""@CONFERENCE{Melis2017751,
    author = ""Melis, Marco and Demontis, Ambra and Biggio, Battista and Brown, Gavin and Fumera, Giorgio and Roli, Fabio"",
    title = ""Is Deep Learning Safe for Robot Vision? Adversarial Examples Against the iCub Humanoid"",
    year = ""2017"",
    journal = ""Proceedings - 2017 IEEE International Conference on Computer Vision Workshops, ICCVW 2017"",
    volume = ""2018-January"",
    pages = ""751 - 759"",
    doi = ""10.1109/ICCVW.2017.94"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046297726\&doi=10.1109\%2fICCVW.2017.94\&partnerID=40\&md5=d3daf5b7ac861edde196b1c71ff85756"",
    affiliations = ""Department of Electrical and Electronic Engineering, University of Cagliari, Italy; Pluribus One, Italy; School of Computer Science, University of Manchester, United Kingdom"",
    abstract = ""Deep neural networks have been widely adopted in recent years, exhibiting impressive performances in several application domains. It has however been shown that they can be fooled by adversarial examples, i.e., images altered by a barely-perceivable adversarial noise, carefully crafted to mislead classification. In this work, we aim to evaluate the extent to which robot-vision systems embodying deep-learning algorithms are vulnerable to adversarial examples, and propose a computationally efficient countermeasure to mitigate this threat, based on rejecting classification of anomalous inputs. We then provide a clearer understanding of the safety properties of deep networks through an intuitive empirical analysis, showing that the mapping learned by such networks essentially violates the smoothness assumption of learning algorithms. We finally discuss the main limitations of this work, including the creation of real-world adversarial examples, and sketch promising research directions. (c) 2017 IEEE."",
    keywords = ""Computer vision; Deep neural networks; Computationally efficient; Empirical analysis; Real-world; Robot vision systems; Safety property; Learning algorithms"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153861034-3"",
    language = ""English"",
    abbrev_source_title = ""Proc. - IEEE Int. Conf. Comput. Vis. Workshops, ICCVW"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 59; Conference name: 16th IEEE International Conference on Computer Vision Workshops, ICCVW 2017; Conference date: 22 October 2017 through 29 October 2017; Conference code: 134301; All Open Access, Green Open Access""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	Is Deep Learning Safe for Robot Vision? Adversarial Examples Against the iCub Humanoid	https://www.scopus.com/record/display.uri?eid=2-s2.0-85046297726&origin=resultslist&sort=plf-f&src=s&sid=57ef2bfff3c1152448bc69f1446eed79&sot=b&sdt=b&s=TITLE-ABS-KEY%28is+deep+learning+safe+for+robot+vision+adversarial+examples+against+the+icub+humanoid%29&sl=100&sessionSearchId=57ef2bfff3c1152448bc69f1446eed79&relpos=0	Institute of Electrical and Electronics Engineers Inc	
24	TestNN	Machine learning and deep neural network - Artificial intelligence core for lab and real-world test and validation for ADAS and autonomous vehicles: AI for efficient and quality test and validation	Autonomous vehicles are now the future of automobile industry. Human drivers can be completely taken out of the loop through the implementation of safe and intelligent autonomous vehicles. Although we can say that HW and SW development continues to play a large role in the automotive industry, test and validation of these systems is a must. The ability to test these vehicles thoroughly and efficiently will ensure their proper and flawless operation. When a large number of people with heterogeneous knowledge and skills try to develop an autonomous vehicle together, it is important to use a sensible engineering process. State of the art techniques for such development include Waterfall, Agile & V-model, where test & validation (T&V) process is an integral part of such a development cycle. This paper will propose a new methodology using machine learning & deep neural network (AI-core) for lab & real-world T&V for ADAS (Advanced driver assistance system) and autonomous vehicles. The methodology will initially connect T&V of individual systems in each level of development and that of complete system efficiently, by using the proposed phase methodology, in which autonomous driving functions are grouped under categories, special T&V processes are carried on simulation as well as in HIL systems. The complete transition towards AI in the field of T&V will be a sequence of steps. Initially the AI-core is fed with available test scenarios, boundary conditions for the test cases and scenarios, and examples, the AI-core will conduct virtual tests on simulation environment using available test scenarios and further generates new test cases and scenarios for efficient and precise tests. These test cases and scenarios are meant to cover all available cases and concentrate on the area where bugs or failures occur. The complete surrounding environment in the simulation is also controlled by the AI-core which means that the system can attain endless/all-possible combinations of the surrounding environment which is necessary. Results of the tests are sorted and stored, critical and important tests are again repeated in the real-world environment using automated cars with other real subsystems to depict the surrounding environment, which are all controlled by the AI-core, and meanwhile the AI-core is always in the loop and learning from each and every executed test case and its results/outcomes. The main goal is to achieve efficient and high quality test and validation of systems for automated driving, which can save precious time in the development process. As a future scope of this methodology, we can step-up to make most parts of test and validation completely autonomous.	Advanced driver assistance systems; Automotive industry; Autonomous vehicles; Deep neural networks; Verification; Virtual reality; Advanced driver assistance system system; AI-core; Autonomous Vehicles; Efficient; High quality; Machine-learning; Simulation; Test and validation; Test scenario; Test validation; Automobile drivers; Advanced driver assistance systems;  Automotive industry;  Autonomous vehicles;  Deep neural networks;  Verification;  Virtual reality;  Advanced driver assistance system system;  AI-core;  Autonomous Vehicles;  Efficient;  High quality;  Machine-learning;  Simulation;  Test and validation;  Test scenario;  Test validation;  Automobile drivers	Vishnukumar, Harsha Jakkanahalli; Butting, Bjorn; Muller, Christian; Sax, Eric	2017 Intelligent Systems Conference, IntelliSys 2017	https://doi.org/10.1109/IntelliSys.2017.8324372	"1.Daniel Liden, ""What Is a Driverless Car?"", WiseGeek, October 2013. Google Scholar; 2.Automated driving levels of driving automation are defined in new SAE international standard J3016. Google Scholar; 3.""European Roadmap Smart Systems for Automated Driving"", European Technology Platform on Smart Systems Integration (EPoSS), 2015. Google Scholar; 4.Z. Wentao, M. Jun, H. Jiangbi and Q. Laiyun, ""Vehicle detection in driving simulation using extreme learning machine"", Neurocomputing, vol. 128, pp. 160-165, 03 2014. Google Scholar; 5.J. Ziegler, P. Bender, H. Lategahn, M. Schreiber, T. Strauss, T. Dang, et al., ""Kartengestutztes Fahren auf der Bertha-Benz-Route von Mannheim nach Pforzheim"", FAS 2014 Walting, 2014. Google Scholar; 6.P. Koopman and M. Wagner, Challenges in Autonomous Vehicle T&V, CM-University; Edge Case Research LLC. Google Scholar; 7.Automatisiertes Testen Eingebetteter Systeme in der Automobilindustrie, ISBN 978-3-446-41635-2. Google Scholar; 8.""ISO 26262-3:2011"", Road vehicles Functional Safety Part 3, Nov. 2011. Google Scholar; 9.J. Kramer, layer model to abstract functions of complex intervening DAS. Google Scholar; 10.N. Storey, Safety-Critical Computer Systems, Essex, U.K.:Addison Wesley Longman Ltd., 1996. Google Scholar; 11.F. Mosnier and J. Bortolazzi, ""Prototyping car-embedded applications"" in Advances in Information Technologies: The Business Challenge, Amsterdam, The Netherlands:IOS Press, pp. 744-751, 1997. Google Scholar; 12.O. Gietelink, J. Ploeg, B. De Schutter and M. Verhaegen, ""Development of ADAS with vehicle HiL simulations"", Vehicle System Dynamics, vol. 44, no. 7, pp. 569-590, July 2006. CrossRef  Google Scholar; 13.Press Release 105/2016: Karlsruhe to Pioneer Autonomous Driving. Google Scholar; 14.Development of a test target for AEB systems Volker Sandner ADAC Germany Paper Number 13-0406. Google Scholar; 15.D. Gohring, M. Wang, M. Schnurmacher and T. Ganjineh, Radar/Lidar Sensor Fusion for Car-Following on Highways, IFI, Freie Universitat Berlin. CrossRef  Google Scholar; 16.A. Teichman and S. Thrun, Practical object recognition in autonomous driving and beyond, Stanford University Computer Science Department. View Article  Google Scholar; 17.Is 'data labeling' the new blue-collar job of the AI era? - By Hope Reese, March 2016. Google Scholar; 18.Bruce A. Draper and J. Ross Beveridge, Efficient Label Collection for Unlabeled Image Datasets Maggie Wigness. Google Scholar; 19.Big Data & self-driving cars: New studies from ITF, May 2015. Google Scholar; 20.Autonomous Cars Self-Driving the New Auto Industry Paradigm morgan stanley blue paper, November 2013. Google Scholar; 21.Proceedings of 2nd OpenSCENARIO meeting, June 29th, 2016. Google Scholar; 22.Insight Automotive Advanced Driver Assistance Systems in HiL Tests in the Frame with Direct Image Injection, February 2014. Google Scholar; 23.Harsha Jakkanahalli Vishnukumar, C. Muller, B. Butting, R. Magnus, S. Werner and E. Sax, ""Methodology to efficiently connect lab and real-world validation for autonomous vehicles"", 6TH AUTOTEST TECHNICAL CONFERENCE, 26-27 OCTOBER 2016. Google Scholar; 24.J. Bach, K. Bauer, M. Holzapfel, M. Hillenbrand and Eric Sax, Control based driving assistant functions' test using recorded in field data. Google Scholar; 25.A book on ""AI understanding human speech"" by Russell & Norvig edition, 2009. Google Scholar; 26.Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep learning references: Ovid and Martin 2004; Sparkes 1996; Tandy, 1997. Google Scholar"	714 - 721	"""@CONFERENCE{Vishnukumar2017714,
    author = ""Vishnukumar, Harsha Jakkanahalli and Butting, Bjorn and Muller, Christian and Sax, Eric"",
    title = ""Machine learning and deep neural network - Artificial intelligence core for lab and real-world test and validation for ADAS and autonomous vehicles: AI for efficient and quality test and validation"",
    year = ""2017"",
    journal = ""2017 Intelligent Systems Conference, IntelliSys 2017"",
    volume = ""2018-January"",
    pages = ""714 - 721"",
    doi = ""10.1109/IntelliSys.2017.8324372"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051091232\&doi=10.1109\%2fIntelliSys.2017.8324372\&partnerID=40\&md5=5e1900c49e38ecc92460e1f3dfa9d681"",
    affiliations = ""Department of Measurement and Test Technology, MBtech Group GmbH and Co. KGaA, Sindelfingen, Germany; Manager Test and Measurement Systems, MBtech Group GmbH and Co. KGaA, Sindelfingen, Germany; Direct. Measurement and Test Technology, MBtech Group GmbH and Co. KGaA, Sindelfingen, Germany; Institut fur Technik der Informationsverarbeitung (ITIV), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany"",
    abstract = ""Autonomous vehicles are now the future of automobile industry. Human drivers can be completely taken out of the loop through the implementation of safe and intelligent autonomous vehicles. Although we can say that HW and SW development continues to play a large role in the automotive industry, test and validation of these systems is a must. The ability to test these vehicles thoroughly and efficiently will ensure their proper and flawless operation. When a large number of people with heterogeneous knowledge and skills try to develop an autonomous vehicle together, it is important to use a sensible engineering process. State of the art techniques for such development include Waterfall, Agile \& V-model, where test \& validation (T\&V) process is an integral part of such a development cycle. This paper will propose a new methodology using machine learning \& deep neural network (AI-core) for lab \& real-world T\&V for ADAS (Advanced driver assistance system) and autonomous vehicles. The methodology will initially connect T\&V of individual systems in each level of development and that of complete system efficiently, by using the proposed phase methodology, in which autonomous driving functions are grouped under categories, special T\&V processes are carried on simulation as well as in HIL systems. The complete transition towards AI in the field of T\&V will be a sequence of steps. Initially the AI-core is fed with available test scenarios, boundary conditions for the test cases and scenarios, and examples, the AI-core will conduct virtual tests on simulation environment using available test scenarios and further generates new test cases and scenarios for efficient and precise tests. These test cases and scenarios are meant to cover all available cases and concentrate on the area where bugs or failures occur. The complete surrounding environment in the simulation is also controlled by the AI-core which means that the system can attain endless/all-possible combinations of the surrounding environment which is necessary. Results of the tests are sorted and stored, critical and important tests are again repeated in the real-world environment using automated cars with other real subsystems to depict the surrounding environment, which are all controlled by the AI-core, and meanwhile the AI-core is always in the loop and learning from each and every executed test case and its results/outcomes. The main goal is to achieve efficient and high quality test and validation of systems for automated driving, which can save precious time in the development process. As a future scope of this methodology, we can step-up to make most parts of test and validation completely autonomous. (c) 2017 IEEE."",
    author_keywords = ""ADAS systems; AI-core; Artificial Intelligence; Autonomous Vehicles; Efficient; High quality; Machine Learning; Simulation; Test and Validation"",
    keywords = ""Advanced driver assistance systems; Automotive industry; Autonomous vehicles; Deep neural networks; Verification; Virtual reality; Advanced driver assistance system system; AI-core; Autonomous Vehicles; Efficient; High quality; Machine-learning; Simulation; Test and validation; Test scenario; Test validation; Automobile drivers"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-150906435-9"",
    language = ""English"",
    abbrev_source_title = ""Intell. Syst. Conf., IntelliSys"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 73; Conference name: 2017 Intelligent Systems Conference, IntelliSys 2017; Conference date: 7 September 2017 through 8 September 2017; Conference code: 135475""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	Machine learning and deep neural network - artificial intelligence core for lab and real-world test and validation for ADAS and autonomous vehicles: AI for efficient and quality test and validation	https://www.scopus.com/record/display.uri?eid=2-s2.0-85051091232&origin=resultslist&sort=plf-f&src=s&sid=33ab5e135f0fda6d257470afe383e6b4&sot=b&sdt=b&s=TITLE-ABS-KEY%28machine+learning+and+deep+neural+network+artificial+intelligence+core+for+lab+and+real+world+test+and+validation+for+adas+and+autonomous+vehicles+ai+for+efficient+and+quality+test+and+validation%29&sl=209&sessionSearchId=33ab5e135f0fda6d257470afe383e6b4&relpos=0	Institute of Electrical and Electronics Engineers Inc	
25	TestNN	MAR-CPS: Measurable augmented reality for prototyping Cyber-Physical systems	Cyber-Physical Systems (CPSs) refer to engineering platforms that rely on the inte- gration of physical systems with control, computation, and communication technologies. Autonomous vehicles are instances of CPSs that are rapidly growing with applications in many domains. Due to the integration of physical systems with computational sens- ing, planning, and learning in CPSs, hardware-in-the-loop experiments are an essential step for transitioning from simulations to real-world experiments. This paper proposes an architecture for rapid prototyping of CPSs that has been developed in the Aerospace Controls Laboratory at the Massachusetts Institute of Technology. This system, referred to as MAR-CPS (Measurable Augmented Reality for Prototyping Cyber-Physical Systems), includes physical vehicles and sensors, a motion capture technology, a projection system, and a communication network. The role of the projection system is to augment a physical laboratory space with 1) autonomous vehicles' beliefs and 2) a simulated mission environ- ment, which in turn will be measured by physical sensors on the vehicles. The main focus of this method is on rapid design of planning, perception, and learning algorithms for au- tonomous single-agent or multi-agent systems. Moreover, the proposed architecture allows researchers to project a simulated counterpart of outdoor environments in a controlled, indoor space, which can be crucial when testing in outdoor environments is disfavored due to safety, regulatory, or monetary concerns. We discuss the issues related to the design and implementation of MAR-CPS and demonstrate its real-time behavior in a variety of problems in autonomy, such as motion planning, multi-robot coordination, and learning spatio-temporal fields.	Augmented reality; Autonomous vehicles; Cyber Physical System; Embedded systems; Laboratories; Learning algorithms; Learning systems; Machine design; Motion planning; Multi agent systems; Network architecture; Projection systems; Robot programming; Safety testing; Communication technologies; Cyber physical systems (CPSs); Design and implementations; Hard-ware-in-the-loop; Massachusetts Institute of Technology; Multi-robot coordination; Proposed architectures; Real world experiment; Vehicle to vehicle communications; Augmented reality;  Autonomous vehicles;  Cyber Physical System;  Embedded systems;  Laboratories;  Learning algorithms;  Learning systems;  Machine design;  Motion planning;  Multi agent systems;  Network architecture;  Projection systems;  Robot programming;  Safety testing;  Communication technologies;  Cyber physical systems (CPSs);  Design and implementations;  Hard-ware-in-the-loop;  Massachusetts Institute of Technology;  Multi-robot coordination;  Proposed architectures;  Real world experiment;  Vehicle to vehicle communications	Omidshafiei, Shayegan; Agha-Mohammadi, Ali-Akbar; Chen, Yu Fan; Kemal Ure, N.; How, Jonathan P.; Vian, John; Surati, Rajeev	AIAA Infotech at Aerospace	https://doi.org/10.2514/6.2015-0643	(2014)Faa: Coa: Frequently asked questions.Cited 39 times.Onlinehttps://www.faa.gov/about/office:org/headquarters_offices/ato/service:units/systemops/aaim/organizations/uas/coa/faq/; How, J.P.,Bethke, B.,Frank, A.,Dale, D.,Vian, J.; Cruz, D.,Mcclintock, J.,Perteet, B.,Orqueda, O.A.A.,Cao, Y.,Fierro, R.; Hoffmann, G.,Rajnarayan, D.G.,Waslander, S.L.,Dostal, D.,Jang, J.S.,Tomlin, C.J.; Johnson, E.N.,Schrage, D.P.; John Koo, T.Vanderbilt embedded computing platform for autonomous vehicles (vecpav)Available athttp://www.vuse.vanderbilt.edu/kootj/Projects/VECPAV/,July2006; Ulusoy, A.,Marrazzo, M.,Oikonomopoulos, K.,Hunter, R.,Belta, C.; Ghiringhelli, F.,Guzzi, J.,Di Caro, G.A.,Caglioti, V.,Gambardella, L.M.,Giusti, A.; Leutert, F.,Herrmann, C.,Schilling, K.; Oculus, V.R.(2014)Oculus vr, Onlinehttp://www.oculus.com; Daily, M.,Cho, Y.,Martin, K.,Payton, D.; (2008)Motion capture systems from Vicon.Cited 3 times.Onlinehttp://www.vicon.com; Quigley, M.,Conley, K.,Gerkey, B.,Faust, J.,Foote, T.,Leibs, J.,Wheeler, R.,(...),Ng, A.Y.ROS: An open-source robot operating system(2009)ICRA Workshop on Open Source Software,3.Cited 7563 times.; (2014)Onlinehttp://www.scalabledisplay.com; Berger, C.,Rumpe, B.Engineering autonomous driving software(2014)CoRR, abs/1409,p. 6579.; Agha-Mohammadi, A.-A.,Ure, N.K.,How, J.P.,Vian, J.; Kemal Ure, N.,Omidshafiei, S.,Lopez, T.B.,Agha-Mohammadi, A.A.,How, J.P.,Vian, J.Heterogeneous Multiagent Learning with Applications to Forest Fire Management(2015)In IEEE International Conference on Robotics and Automation (ICRA)Submitted; Chen, Y.F.,Ure, N.K.,Chowdhary, G.,How, J.P.,Vian, J.; Agha-mohammadi, A.-A.,Chakravorty, S.,Amato, N.M.; Ferguson, S.,Luders, B.,Grande, R.C.,How, J.P.Real-time predictive modeling and robust avoidance of pedestrians with uncertain, changing intentionsProceedings of the Workshop on the Algorithmic Foundations of Robotics,p. 2014.Cited 8 times.Istanbul, Turkey, August		"""@CONFERENCE{Omidshafiei2015,
    author = ""Omidshafiei, Shayegan and Agha-Mohammadi, Ali-Akbar and Chen, Yu Fan and Kemal Ure, N. and How, Jonathan P. and Vian, John and Surati, Rajeev"",
    title = ""MAR-CPS: Measurable augmented reality for prototyping Cyber-Physical systems"",
    year = ""2015"",
    journal = ""AIAA Infotech at Aerospace"",
    doi = ""10.2514/6.2015-0643"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088358215\&doi=10.2514\%2f6.2015-0643\&partnerID=40\&md5=a15856d2ee857ed713bd94c214634903"",
    affiliations = ""xute of Technology, Cambridge, 02139, MA, United States; Department of Aeronautics and Astronautics, MIT, Cambridge, 02139, MA, United States; The Boeing Company, Seattle, 98124, WA, United States; Boeing Research and Technology, Seattle, 98124, WA, United States; Scalable Display Technologies, Cambridge, 02139, MA, United States; Scalable Display Technologies, 585 Massachusetts Avenue, 4th Floor, Cambridge, 02139-2499, MA, United States"",
    abstract = ""Cyber-Physical Systems (CPSs) refer to engineering platforms that rely on the inte- gration of physical systems with control, computation, and communication technologies. Autonomous vehicles are instances of CPSs that are rapidly growing with applications in many domains. Due to the integration of physical systems with computational sens- ing, planning, and learning in CPSs, hardware-in-the-loop experiments are an essential step for transitioning from simulations to real-world experiments. This paper proposes an architecture for rapid prototyping of CPSs that has been developed in the Aerospace Controls Laboratory at the Massachusetts Institute of Technology. This system, referred to as MAR-CPS (Measurable Augmented Reality for Prototyping Cyber-Physical Systems), includes physical vehicles and sensors, a motion capture technology, a projection system, and a communication network. The role of the projection system is to augment a physical laboratory space with 1) autonomous vehicles' beliefs and 2) a simulated mission environ- ment, which in turn will be measured by physical sensors on the vehicles. The main focus of this method is on rapid design of planning, perception, and learning algorithms for au- tonomous single-agent or multi-agent systems. Moreover, the proposed architecture allows researchers to project a simulated counterpart of outdoor environments in a controlled, indoor space, which can be crucial when testing in outdoor environments is disfavored due to safety, regulatory, or monetary concerns. We discuss the issues related to the design and implementation of MAR-CPS and demonstrate its real-time behavior in a variety of problems in autonomy, such as motion planning, multi-robot coordination, and learning spatio-temporal fields. (c) 2015, American Institute of Aeronautics and Astronautics Inc. All rights received."",
    keywords = ""Augmented reality; Autonomous vehicles; Cyber Physical System; Embedded systems; Laboratories; Learning algorithms; Learning systems; Machine design; Motion planning; Multi agent systems; Network architecture; Projection systems; Robot programming; Safety testing; Communication technologies; Cyber physical systems (CPSs); Design and implementations; Hard-ware-in-the-loop; Massachusetts Institute of Technology; Multi-robot coordination; Proposed architectures; Real world experiment; Vehicle to vehicle communications"",
    publisher = ""American Institute of Aeronautics and Astronautics Inc."",
    isbn = ""978-162410338-4"",
    language = ""English"",
    abbrev_source_title = ""AIAA Infotech Aerosp."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 15; Conference name: AIAA Infotech @ Aerospace 2015; Conference date: 5 January 2015 through 9 January 2015; Conference code: 112879; All Open Access, Green Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2015	MAR-CPS: Measurable Augmented Reality for Prototyping Cyber-Physical Systems	https://doi.org/10.2514/6.2015-0643	American Institute of Aeronautics and Astronautics Inc	nan; Pages; Link
26	TestNN	Extending service model to build an effective service composition framework for cyber-physical systems	Cyber-Physical Systems (CPSs) are combinations of physical entities controlled by software systems to accomplish specified tasks under stringent real-time and physical entity constraints. As more and more physical entities are equipped with embedded computers, they are becoming more and more intelligent. However, the problem of effectively composing the services provided by cyber and physical entities to achieve specific goals still remains a challenge. Traditional service-oriented models and composition techniques are insufficient for CPS. In this paper, we present a novel Physical-Entity (PE) service-oriented model to address the problem, including the concepts of PE-ontology and PE-SOA specifications. Based on the model, we develop a two-level compositional reasoning approach, which divides the process into abstract and physical levels to expedite the composition process. With the assistance of the PE-ontology and PE-SOA, abstract level reasoning is performed by hiding the physical level details. This separation greatly reduces the search space for both levels through a divide-and-conquer technique. The model and the composition approach are illustrated using a simplified emergency response case study system.	Service oriented architecture;Physics computing;Knowledge engineering;Sensor fusion;Intelligent sensors;Concrete;Computer science;Control systems;Software systems;Real time systems;Cyber-physical systems;service-oriented architecture;service composition;AI planning techniques; Service oriented architecture; Physics computing; Knowledge engineering; Sensor fusion; Intelligent sensors; Concrete; Computer science; Control systems; Software systems; Real time systems; Cyber-physical systems; service-oriented architecture; service composition; AI planning techniques	Huang, J.; Bastani, F.; Yen, I.-L.; Dong, J.; Zhang, W.; Wang, F.-J.; Hsu, H.-J.	Reliability, Risk and Safety: Back to the Future	https://doi.org/10.1109/SOCA.2009.5410453		1-8	"""@INPROCEEDINGS{5410453,
    author = ""Huang, J. and Bastani, F. and Yen, I.-L. and Dong, J. and Zhang, W. and Wang, F.-J. and Hsu, H.-J."",
    booktitle = ""2009 IEEE International Conference on Service-Oriented Computing and Applications (SOCA)"",
    title = ""Extending service model to build an effective service composition framework for cyber-physical systems"",
    year = ""2009"",
    volume = """",
    number = """",
    pages = ""1-8"",
    abstract = ""Cyber-Physical Systems (CPSs) are combinations of physical entities controlled by software systems to accomplish specified tasks under stringent real-time and physical entity constraints. As more and more physical entities are equipped with embedded computers, they are becoming more and more intelligent. However, the problem of effectively composing the services provided by cyber and physical entities to achieve specific goals still remains a challenge. Traditional service-oriented models and composition techniques are insufficient for CPS. In this paper, we present a novel Physical-Entity (PE) service-oriented model to address the problem, including the concepts of PE-ontology and PE-SOA specifications. Based on the model, we develop a two-level compositional reasoning approach, which divides the process into abstract and physical levels to expedite the composition process. With the assistance of the PE-ontology and PE-SOA, abstract level reasoning is performed by hiding the physical level details. This separation greatly reduces the search space for both levels through a divide-and-conquer technique. The model and the composition approach are illustrated using a simplified emergency response case study system."",
    keywords = ""Service oriented architecture;Physics computing;Knowledge engineering;Sensor fusion;Intelligent sensors;Concrete;Computer science;Control systems;Software systems;Real time systems;Cyber-physical systems;service-oriented architecture;service composition;AI planning techniques"",
    doi = ""10.1109/SOCA.2009.5410453"",
    ISSN = ""2163-2871"",
    month = ""Jan""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2010	Mission reconfiguration based on real-time system reliability assessment	https://doi.org/10.1109/SOCA.2009.5410453		nan; References; Link; Publisher
27	TestNN	Mitigating catastrophic failure at intersections of autonomous vehicles	"Fully autonomous vehicles promise enormous gains in safety, efficiency, and economy. Before such gains can be realized, safety and reliability concerns must be addressed. We have previously introduced a system for managing such vehicles at intersections that is capable of handling more vehicles and causing fewer delays than traffic lights and stop signs [2], While the system is safe under normal operating conditions, we have not discussed the possibility or implications of unforeseen mechanical failures. Because the system orchestrates such precarious ""close calls"" the tolerance for such errors is small. In this paper, we introduce safety features of the system designed to deal with these types of failures, and perform a basic failure mode analysis, demonstrating that without these features, the system is unsuitable for deployment due to a propensity for catastrophic failure modes."	Autonomous agents; Failure modes; Intelligent systems; Safe handling; Traffic signs; Autonomous Vehicles; Catastrophic failures; Failure mode analysis; Fully-autonomous vehicles; Intelligent transportation systems; Intersection control; Mechanical failures; Normal operating conditions; Multi agent systems; Autonomous agents;  Failure modes;  Intelligent systems;  Safe handling;  Traffic signs;  Autonomous Vehicles;  Catastrophic failures;  Failure mode analysis;  Fully-autonomous vehicles;  Intelligent transportation systems;  Intersection control;  Mechanical failures;  Normal operating conditions;  Multi agent systems	Dresner, Kurt; Stone, Peter	Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS	https://doi.org/10.5555/1402821.1402881		1361 - 1364	"""@CONFERENCE{Dresner20081361,
    author = ""Dresner, Kurt and Stone, Peter"",
    title = ""Mitigating catastrophic failure at intersections of autonomous vehicles"",
    year = ""2008"",
    journal = ""Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS"",
    volume = ""3"",
    pages = ""1361 - 1364"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899895199\&partnerID=40\&md5=8dfa67a3deb79e0795cfdad1637e15cc"",
    affiliations = ""University of Texas at Austin, Department of Computer Sciences, Austin, TX 78712, United States"",
    abstract = {Fully autonomous vehicles promise enormous gains in safety, efficiency, and economy. Before such gains can be realized, safety and reliability concerns must be addressed. We have previously introduced a system for managing such vehicles at intersections that is capable of handling more vehicles and causing fewer delays than traffic lights and stop signs [2], While the system is safe under normal operating conditions, we have not discussed the possibility or implications of unforeseen mechanical failures. Because the system orchestrates such precarious ""close calls"" the tolerance for such errors is small. In this paper, we introduce safety features of the system designed to deal with these types of failures, and perform a basic failure mode analysis, demonstrating that without these features, the system is unsuitable for deployment due to a propensity for catastrophic failure modes. Copyright (c) 2008, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.},
    author_keywords = ""Autonomous vehicles; Intelligent transportation systems; Intersection control; Multiagent systems"",
    keywords = ""Autonomous agents; Failure modes; Intelligent systems; Safe handling; Traffic signs; Autonomous Vehicles; Catastrophic failures; Failure mode analysis; Fully-autonomous vehicles; Intelligent transportation systems; Intersection control; Mechanical failures; Normal operating conditions; Multi agent systems"",
    publisher = ""International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)"",
    issn = ""15488403"",
    isbn = ""978-160560470-1"",
    language = ""English"",
    abbrev_source_title = ""Proc. Int. Joint Conf. Auton. Agents Multiagent Syst., AAMAS"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 18; Conference name: 7th International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS 2008; Conference date: 12 May 2008 through 16 May 2008; Conference code: 105064""
}
"""	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	2008	Mitigating catastrophic failure at intersections of autonomous vehicles	https://www.scopus.com/record/display.uri?eid=2-s2.0-84899895199&origin=resultslist&sort=plf-f&src=s&sid=a76a649f0989481b245c999e53bd8196&sot=b&sdt=b&s=TITLE-ABS-KEY%28mitigating+catastrophic+failure+at+intersections+of+autonomous+vehicles%29&sl=86&sessionSearchId=a76a649f0989481b245c999e53bd8196&relpos=0	International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)	nan; References
28	TestNN	Modeling risk perception for mars rover supervisory control: Before and after wheel damage	The perception of risk can dramatically influence the human selection of semi-autonomous system control strategies, particularly in safety-critical systems like unmanned vehicle operation. Thus, the ability to understand the components of risk perception can be extremely valuable in developing either operational strategies or decision support technologies. To this end, this paper analyzes the differences in human supervisory control of Mars Science Laboratory rover operation before and after the discovery of wheel damage. This paper identifies four operational factors sensitive to risk perception changes including rover distance traveled, utilization frequency of the autonomous driving capability (AutoNav), terrain risk weighting, and changes in high-level mission planning. A resulting Rover Risk Perception Model illustrates how these operational factors relate to increased perception of risk. Based on these results, we propose aiding risk perception mitigation strategies such that risk can be appropriately anchored. Such strategies can include a change in system design including adding technology and decision support tools, or changing the training of operators who use the system.	Decision support systems; Martian surface analysis; Personnel training; Remotely operated vehicles; Systems analysis; Wheels; Decision support tools; Human supervisory control; Mars science laboratory; Mitigation strategy; Operational strategies; Safety critical systems; Semi-autonomous systems; Supervisory control; Risk perception; Decision support systems;  Martian surface analysis;  Personnel training;  Remotely operated vehicles;  Systems analysis;  Wheels;  Decision support tools;  Human supervisory control;  Mars science laboratory;  Mitigation strategy;  Operational strategies;  Safety critical systems;  Semi-autonomous systems;  Supervisory control;  Risk perception	Stimpson, Alex J.; Tucker, Matthew B.; Ono, Masahiro; Steffy, Amanda; Cummings, Mary L.	IEEE Aerospace Conference Proceedings	https://doi.org/10.1109/AERO.2017.7943871	"1.Mars Science Laboratory/Curosity Fact Sheet. Google Scholar; 2.C. Debarati, A. Mishkin, A. Allbaugh, Z. Cox, S. Lee, G Tan-Wang et al., ""The Mars Science Laboratory Supratactical Process"", SpaceOps 2014 Conference, 2014. Google Scholar; 3.A. Mann, ""The Photo-Geeks Guide to Curiosity Rovers 17 Cameras"", Wired Magazine, 07 2012,  [online]  Available: https://www.wired.com/2012/08/curiosity-mars-rover-camerasl. Google Scholar; 4.Eyes and Other Senses,  [online]  Available: http://mars.nasa.gov/msl/mission/rover/eyesandother/. Google Scholar; 5.M. Bajracharya, M. Maimone and D. Helmick, ""Autonomy for Mars Rovers: Past Present and Future"", IEEE Computer, vol. 41, pp. 44-50, 2008. View Article  Google Scholar; 6.J. Biesiadecki and M. Maimone, ""The Mars Exploration Rover Surface Mobility Flight Software: Driving Ambition"", the IEEE Aerospace Conference, 2006. View Article  Google Scholar; 7.M. Operators, MSL Operators In MSL Planning Environment, 2016. Google Scholar; 8.Wheels and Legs,  [online]  Available: http://mars.nasa.gov/msl/mission/rover/wheelslegs/. Google Scholar; 9.E. Lakdawalla, Curosity wheel damage: The problem and solutions, The Planetary Society, vol. 2016, 2014. Google Scholar; 10.NASA Mars Rover Curosity: Mission Updates. Google Scholar; 11.T. S. Group, ""Curosity Wheel Issues and Solutions: A Conversation with JPLs Jim Erickson"", Space Safety Magazine, 02 2014. Google Scholar; 12.M. Operators, MSL Operators Outside Planning Environment, 2016. Google Scholar; 13.G. Webster, NASAs Mars Curosity Debuts Autonomous Navigation, Jet Propulsion Laboratory, 2013. Google Scholar; 14.J. Paur, ""Can Killer Drones Land On Carriers Like Human Top Gun?"", Wired, 2009. Google Scholar; 15.M. Ono, B. Williams and L. Blackmore, ""Probabilistic Planning for Continuous Dynamic Systems under Bounded Risk"", Journal of Artificial Intelligence Research, vol. 46, pp. 511-577, 2013. CrossRef  Google Scholar; 16.N. Carr, ""All Can Be Lost: The Risk of Putting Our Knowledge in the Hands of Machines"", The Atlantic, 2013. Google Scholar"		"""@CONFERENCE{Stimpson2017,
    author = ""Stimpson, Alex J. and Tucker, Matthew B. and Ono, Masahiro and Steffy, Amanda and Cummings, Mary L."",
    title = ""Modeling risk perception for mars rover supervisory control: Before and after wheel damage"",
    year = ""2017"",
    journal = ""IEEE Aerospace Conference Proceedings"",
    doi = ""10.1109/AERO.2017.7943871"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021191452\&doi=10.1109\%2fAERO.2017.7943871\&partnerID=40\&md5=c8131000db7959851d9d24eac97eb2f0"",
    affiliations = ""Humans and Autonomy Lab., 144 Hudson Hall, Durham, 27708, NC, United States; NASA Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Drive, Pasadena, 91109, CA, United States"",
    abstract = ""The perception of risk can dramatically influence the human selection of semi-autonomous system control strategies, particularly in safety-critical systems like unmanned vehicle operation. Thus, the ability to understand the components of risk perception can be extremely valuable in developing either operational strategies or decision support technologies. To this end, this paper analyzes the differences in human supervisory control of Mars Science Laboratory rover operation before and after the discovery of wheel damage. This paper identifies four operational factors sensitive to risk perception changes including rover distance traveled, utilization frequency of the autonomous driving capability (AutoNav), terrain risk weighting, and changes in high-level mission planning. A resulting Rover Risk Perception Model illustrates how these operational factors relate to increased perception of risk. Based on these results, we propose aiding risk perception mitigation strategies such that risk can be appropriately anchored. Such strategies can include a change in system design including adding technology and decision support tools, or changing the training of operators who use the system. (c) 2017 IEEE."",
    keywords = ""Decision support systems; Martian surface analysis; Personnel training; Remotely operated vehicles; Systems analysis; Wheels; Decision support tools; Human supervisory control; Mars science laboratory; Mitigation strategy; Operational strategies; Safety critical systems; Semi-autonomous systems; Supervisory control; Risk perception"",
    publisher = ""IEEE Computer Society"",
    issn = ""1095323X"",
    isbn = ""978-150901613-6"",
    language = ""English"",
    abbrev_source_title = ""IEEE Aerosp. Conf. Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 8; Conference name: 2017 IEEE Aerospace Conference, AERO 2017; Conference date: 4 March 2017 through 11 March 2017; Conference code: 128213""
}
"""	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	2017	Modeling risk perception for mars rover supervisory control: Before and after wheel damage	https://www.scopus.com/record/display.uri?eid=2-s2.0-85021191452&origin=resultslist&sort=plf-f&src=s&sid=2e22c7a2b5db053071052ca155ee2fa2&sot=b&sdt=b&s=TITLE-ABS-KEY%28modeling+risk+perception+for+mars+rover+supervisory+control+before+and+after+wheel+damage%29&sl=104&sessionSearchId=2e22c7a2b5db053071052ca155ee2fa2&relpos=0	IEEE Computer Society	nan; Pages
29	TestNN	On the Robustness of a Neural Network	With the development of neural networks based machine learning and their usage in mission critical applications, voices are rising against the black box aspect of neural networks as it becomes crucial to understand their limits and capabilities. With the rise of neuromorphic hardware, it is even more critical to understand how a neural network, as a distributed system, tolerates the failures of its computing nodes, neurons, and its communication channels, synapses. Experimentally assessing the robustness of neural networks involves the quixotic venture of testing all the possible failures, on all the possible inputs, which ultimately hits a combinatorial explosion for the first, and the impossibility to gather all the possible inputs for the second.In this paper, we prove an upper bound on the expected error of the output when a subset of neurons crashes. This bound involves dependencies on the network parameters that can be seen as being too pessimistic in the average case. It involves a polynomial dependency on the Lipschitz coefficient of the neurons' activation function, and an exponential dependency on the depth of the layer where a failure occurs. We back up our theoretical results with experiments illustrating the extent to which our prediction matches the dependencies between the network parameters and robustness. Our results show that the robustness of neural networks to the average crash can be estimated without the need to neither test the network on all failure configurations, nor access the training set used to train the network, both of which are practically impossible requirements.	Neurons;Biological neural networks;Robustness;Computer crashes;Hardware;Neuromorphics;Computational modeling;Neural Networks;Neuromorphic computing;Fault Tolerance;Robustness;Machine Learning;Distributed Systems;Adversarial Machine Learning; Neurons; Biological neural networks; Robustness; Computer crashes; Hardware; Neuromorphics; Computational modeling; Neural Networks; Neuromorphic computing; Fault Tolerance; Robustness; Machine Learning; Distributed Systems; Adversarial Machine Learning	El Mhamdi, El Mahdi; Guerraoui, Rachid; Rouault, Sebastien	2017 IEEE 36th Symposium on Reliable Distributed Systems (SRDS)	https://doi.org/10.1109/SRDS.2017.21		84-93	"""@INPROCEEDINGS{8069071,
    author = ""El Mhamdi, El Mahdi and Guerraoui, Rachid and Rouault, Sebastien"",
    booktitle = ""2017 IEEE 36th Symposium on Reliable Distributed Systems (SRDS)"",
    title = ""On the Robustness of a Neural Network"",
    year = ""2017"",
    volume = """",
    number = """",
    pages = ""84-93"",
    abstract = ""With the development of neural networks based machine learning and their usage in mission critical applications, voices are rising against the black box aspect of neural networks as it becomes crucial to understand their limits and capabilities. With the rise of neuromorphic hardware, it is even more critical to understand how a neural network, as a distributed system, tolerates the failures of its computing nodes, neurons, and its communication channels, synapses. Experimentally assessing the robustness of neural networks involves the quixotic venture of testing all the possible failures, on all the possible inputs, which ultimately hits a combinatorial explosion for the first, and the impossibility to gather all the possible inputs for the second.In this paper, we prove an upper bound on the expected error of the output when a subset of neurons crashes. This bound involves dependencies on the network parameters that can be seen as being too pessimistic in the average case. It involves a polynomial dependency on the Lipschitz coefficient of the neurons' activation function, and an exponential dependency on the depth of the layer where a failure occurs. We back up our theoretical results with experiments illustrating the extent to which our prediction matches the dependencies between the network parameters and robustness. Our results show that the robustness of neural networks to the average crash can be estimated without the need to neither test the network on all failure configurations, nor access the training set used to train the network, both of which are practically impossible requirements."",
    keywords = ""Neurons;Biological neural networks;Robustness;Computer crashes;Hardware;Neuromorphics;Computational modeling;Neural Networks;Neuromorphic computing;Fault Tolerance;Robustness;Machine Learning;Distributed Systems;Adversarial Machine Learning"",
    doi = ""10.1109/SRDS.2017.21"",
    ISSN = """",
    month = ""Sep.""
}
"""	Included	Included	new_screen			1	IEEE	2017	On the Robustness of a Neural Network	https://doi.org/10.1109/SRDS.2017.21	IEEE	nan; References; Link
30	TestNN	Preemptive detection of unsafe motion liable for hazard	Establishing a safety standard for autonomous vehicles operating in open and dynamic environment is a challenge. As collisions are inevitable in over-constrained situations, we focus on deciding the liability for a hazard. Our insight is that hazards caused by malfunctions of autonomous vehicles result from loss of functional integrity. Design defects may leave it unnoticed, or the real-world may make integrity- preserving motion infeasible. Guarantee of functional integrity in an observable way at run-time is indispensable for revealing defects by using formal root-cause analysis, and for supporting safety claims by dismissing unreasonable doubts about design defects. From a practitical standpoint, we attempt to formalize a verification problem that consists of a novel criterion for determining liability for hazard, a safety claim comprised of confirmed observable states, and assumptions underlying the safety claim. We propose a run-time scheme of monitoring events that may lead to violations of the assumptions and a precursor to root-causes leading to loss of functional integrity and consequent hazards. We formulate a means of preemptively detecting unsafe motions liable to be hazardous as satisfiability problem within the framework of an adversarial motion planning subject to assumptions on maneuverability of movers. A numerical study shows that the run-time scheme using non-linear programming (NLP) encoding is viable in a real-world setting.	Computer games; Deep learning; Defects; Embedded systems; Hazards; Knowledge based systems; Maneuverability; Motion analysis; Motion planning; Nonlinear programming; Operations research; Autonomous Vehicles; Dynamic environments; Functional integrities; Over-constrained; Real world setting; Root cause analysis; Satisfiability problems; Verification problems; Problem solving; Computer games;  Deep learning;  Defects;  Embedded systems;  Hazards;  Knowledge based systems;  Maneuverability;  Motion analysis;  Motion planning;  Nonlinear programming;  Operations research;  Autonomous Vehicles;  Dynamic environments;  Functional integrities;  Over-constrained;  Real world setting;  Root cause analysis;  Satisfiability problems;  Verification problems;  Problem solving	Nishi, Masataka	AAAI Workshop - Technical Report	https://www.scopus.com/record/display.uri?eid=2-s2.0-85046083868&origin=resultslist&sort=plf-f&src=s&sid=697616317dd751385c2eaae4e470e2a9&sot=b&sdt=b&s=TITLE-ABS-KEY%28preemptive+detection+of+unsafe+motion+liable+for+hazard%29&sl=70&sessionSearchId=697616317dd751385c2eaae4e470e2a9&relpos=0		153 - 160	"""@CONFERENCE{Nishi2017153,
    author = ""Nishi, Masataka"",
    title = ""Preemptive detection of unsafe motion liable for hazard"",
    year = ""2017"",
    journal = ""AAAI Workshop - Technical Report"",
    volume = ""WS-17-01 - WS-17-15"",
    pages = ""153 - 160"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046083868\&partnerID=40\&md5=d892239482e2ab70b6931e5059667bac"",
    affiliations = ""Hitachi Research Laboratory, Hitachi Ltd., Japan"",
    abstract = ""Establishing a safety standard for autonomous vehicles operating in open and dynamic environment is a challenge. As collisions are inevitable in over-constrained situations, we focus on deciding the liability for a hazard. Our insight is that hazards caused by malfunctions of autonomous vehicles result from loss of functional integrity. Design defects may leave it unnoticed, or the real-world may make integrity- preserving motion infeasible. Guarantee of functional integrity in an observable way at run-time is indispensable for revealing defects by using formal root-cause analysis, and for supporting safety claims by dismissing unreasonable doubts about design defects. From a practitical standpoint, we attempt to formalize a verification problem that consists of a novel criterion for determining liability for hazard, a safety claim comprised of confirmed observable states, and assumptions underlying the safety claim. We propose a run-time scheme of monitoring events that may lead to violations of the assumptions and a precursor to root-causes leading to loss of functional integrity and consequent hazards. We formulate a means of preemptively detecting unsafe motions liable to be hazardous as satisfiability problem within the framework of an adversarial motion planning subject to assumptions on maneuverability of movers. A numerical study shows that the run-time scheme using non-linear programming (NLP) encoding is viable in a real-world setting. (c) Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."",
    keywords = ""Computer games; Deep learning; Defects; Embedded systems; Hazards; Knowledge based systems; Maneuverability; Motion analysis; Motion planning; Nonlinear programming; Operations research; Autonomous Vehicles; Dynamic environments; Functional integrities; Over-constrained; Real world setting; Root cause analysis; Satisfiability problems; Verification problems; Problem solving"",
    correspondence_address = ""M. Nishi; Hitachi Research Laboratory, Hitachi Ltd., Japan; email: masataka.nishi.en@hitachi.com"",
    publisher = ""AI Access Foundation"",
    isbn = ""978-157735786-5"",
    language = ""English"",
    abbrev_source_title = ""AAAI Workshop Tech. Rep."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: 31st AAAI Conference on Artificial Intelligence, AAAI 2017; Conference date: 4 February 2017 through 5 February 2017; Conference code: 135573""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2017	Preemptive detection of unsafe motion liable for hazard	https://www.scopus.com/record/display.uri?eid=2-s2.0-85046083868&origin=resultslist&sort=plf-f&src=s&sid=697616317dd751385c2eaae4e470e2a9&sot=b&sdt=b&s=TITLE-ABS-KEY%28preemptive+detection+of+unsafe+motion+liable+for+hazard%29&sl=70&sessionSearchId=697616317dd751385c2eaae4e470e2a9&relpos=0	AI Access Foundation	nan; References
31	TestNN	Reasoning About Risk in Agent's Deliberation Process: A Jadex Implementation	Autonomous agents and multi-agent systems have been proved to be useful in several safety-critical applications. However, in current agent architectures (particularly BDI architectures) the deliberation process does not include any form of risk analysis. In this paper, we propose guidelines to implement Tropos Goal-Risk reasoning. Our proposal aims at introducing risk reasoning in the deliberation process of a BDI agent so that the overall set of possible plans is evaluated with respect to risk. When the level of risk results too high, agents can consider and introduce additional plans, called treatments, that produce an overall reduction of the risk. Side effects of treatments are also considered as part of the model. To make the discussion more concrete, we illustrate the proposal with a case study on the Unmanned Aerial Vehicle agent.	Multiagent System; Unmanned Aerial Vehicle; Autonomous Agent; Reasoning Mechanism; Agent Platform	Yudistira Asnar; Paolo Giorgini; Nicola Zannone	International Workshop on Agent-Oriented Software Engineering	https://doi.org/10.1007/978-3-540-79488-2_9		118-131		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Springer Link	2008	Reasoning about risk in agent's deliberation process: a Jadex implementation	https://doi.org/10.1007/978-3-540-79488-2_9	Springer, Berlin, Heidelberg	nan; References; Year; Bibtex; Link
32	TestNN	Reluplex: An efficient smt solver for verifying deep neural networks	Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully prove properties of networks that are an order of magnitude larger than the largest networks verified using existing methods.	Aircraft accidents; Computer aided analysis; Linear programming; Safety engineering; Activation functions; Airborne collision avoidance systems; Counter examples; Real-world problem; Safety critical systems; Simplex methods; Simplifying assumptions; Unmanned aircrafts; Deep neural networks; Aircraft accidents;  Computer aided analysis;  Linear programming;  Safety engineering;  Activation functions;  Airborne collision avoidance systems;  Counter examples;  Real-world problem;  Safety critical systems;  Simplex methods;  Simplifying assumptions;  Unmanned aircrafts;  Deep neural networks	Katz, Guy; Barrett, Clark; Dill, David L.; Julian, Kyle; Kochenderfer, Mykel J.	Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)	https://doi.org/10.1007/978-3-319-63387-9_5		97 - 117	"""@ARTICLE{Katz201797,
    author = ""Katz, Guy and Barrett, Clark and Dill, David L. and Julian, Kyle and Kochenderfer, Mykel J."",
    editor = ""V., Kuncak and R., Majumdar"",
    title = ""Reluplex: An efficient smt solver for verifying deep neural networks"",
    year = ""2017"",
    journal = ""Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"",
    volume = ""10426 LNCS"",
    pages = ""97 - 117"",
    doi = ""10.1007/978-3-319-63387-9\_5"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026742103\&doi=10.1007\%2f978-3-319-63387-9\_5\&partnerID=40\&md5=9dc7582088aa6f998ebc7f22fd957068"",
    affiliations = ""Stanford University, Stanford, United States"",
    abstract = ""Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully prove properties of networks that are an order of magnitude larger than the largest networks verified using existing methods. (c) Springer International Publishing AG 2017."",
    keywords = ""Aircraft accidents; Computer aided analysis; Linear programming; Safety engineering; Activation functions; Airborne collision avoidance systems; Counter examples; Real-world problem; Safety critical systems; Simplex methods; Simplifying assumptions; Unmanned aircrafts; Deep neural networks"",
    correspondence_address = ""G. Katz; Stanford University, Stanford, United States; email: guyk@stanford.edu"",
    publisher = ""Springer Verlag"",
    issn = ""03029743"",
    isbn = ""978-331963386-2"",
    language = ""English"",
    abbrev_source_title = ""Lect. Notes Comput. Sci."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1003; Conference name: 29th International Conference on Computer Aided Verification, CAV 2017; Conference date: 24 July 2017 through 28 July 2017; Conference code: 195249; All Open Access, Green Open Access""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	Reluplex: An efficient SMT solver for verifying deep neural networks	https://www.scopus.com/record/display.uri?eid=2-s2.0-85026742103&origin=resultslist&sort=plf-f&src=s&sid=c24998195b51b8f0c137c2876e0a7cd6&sot=b&sdt=b&s=TITLE-ABS-KEY%28reluplex+an+efficient+smt+solver+for+verifying+deep+neural+networks%29&sl=82&sessionSearchId=c24998195b51b8f0c137c2876e0a7cd6&relpos=0	Springer Verlag	nan; References
33	TestNN	Runtime Analysis with R2U2: A Tool Exhibition Report	We present R2U2 (Realizable, Responsive, Unobtrusive Unit), a hardware-supported tool and framework for the continuous monitoring of safety-critical and embedded cyber-physical systems. With the widespread advent of autonomous systems such as Unmanned Aerial Systems (UAS), satellites, rovers, and cars, real-time, on-board decision making requires unobtrusive monitoring of properties for safety, performance, security, and system health. R2U2 models combine past-time and future-time Metric Temporal Logic, ``mission time'' Linear Temporal Logic, probabilistic reasoning with Bayesian Networks, and model-based prognostics.	Metric Temporal Logic (MTL); Software Health Management; Flight Software; Unmanned Aerial Systems (UAS); Model Ru	Schumann, Johann; Moosbrugger, Patrick; Rozier, Kristin Y.	International Conference on Runtime Verification	https://doi.org/10.1007/978-3-319-46982-9_35		504--509	"""@InProceedings{10.1007/978-3-319-46982-9_35,
    author = ""Schumann, Johann and Moosbrugger, Patrick and Rozier, Kristin Y."",
    editor = ""Falcone, Yli{\`e}s and S{\'a}nchez, C{\'e}sar"",
    title = ""Runtime Analysis with R2U2: A Tool Exhibition Report"",
    booktitle = ""Runtime Verification"",
    year = ""2016"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""504--509"",
    abstract = ""We present R2U2 (Realizable, Responsive, Unobtrusive Unit), a hardware-supported tool and framework for the continuous monitoring of safety-critical and embedded cyber-physical systems. With the widespread advent of autonomous systems such as Unmanned Aerial Systems (UAS), satellites, rovers, and cars, real-time, on-board decision making requires unobtrusive monitoring of properties for safety, performance, security, and system health. R2U2 models combine past-time and future-time Metric Temporal Logic, ``mission time'' Linear Temporal Logic, probabilistic reasoning with Bayesian Networks, and model-based prognostics."",
    isbn = ""978-3-319-46982-9""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Springer Link	2016	Runtime Analysis with R2U2: A Tool Exhibition Report	https://doi.org/10.1007/978-3-319-46982-9_35	Springer International Publishing	nan; References; Link
34	TestNN	Safety analysis of Autonomous Ground Vehicle optical systems: Bayesian belief networks approach	Autonomous Ground Vehicles (AGV) require diverse sensor systems to support the navigation and sense-and-avoid tasks. Two of these systems are discussed in the paper: dual camera-based computer vision (CV) and laser-based detection and ranging (LIDAR). Reliable operation of these optical systems is critical to safety since potential faults or failures could result in mishaps leading to loss of life and property. The paper identifies basic hazards and, using fault tree analysis, the causes and effects of these hazards as related to LIDAR and CV systems. A Bayesian Belief Network approach (BN) supported by automated tool is subsequently used to obtain quantitative probabilistic estimation of system safety.	Laser radar;Hazards;Navigation;Vehicles;Cameras;Cognition; Laser radar; Hazards; Navigation; Vehicles; Cameras; Cognition	Reyes Duran, Daniel; Robinson, Elliot; Kornecki, Andrew J.; Zalewski, Janusz	2013 Federated Conference on Computer Science and Information Systems	https://ieeexplore.ieee.org/document/6644203	"1.D. Coombs, K. Murphy, A. Lacaze, A. and S. Legowik, ""Driving autonomously offroad up to 35 km/h"". Proceedings of the IEEE Intelligent Vehicles Symposium, Dearborn, Michigan. 2000. View Article  Google Scholar; 2.T.H. Hong, M.O. Shneier, C. Rasmussen and T. Chang, ""Road detection and tracking for autonomous mobile robots"". SPIE 16th Annual International Symposium on Aerospace/Defense Sensing, Simulation, and Controls, Orlando, Florida. 2002. Google Scholar; 3.C. Rasmussen, ""Combining laser range, color, and texture cues for autonomous road following"", IEEE International Conference on Robotics and Automation, Washington, DC. 2002. View Article  Google Scholar; 4.J.A. Bornstein and C.M. Shoemaker, ""Army ground robotics research program"", Unmanned Ground Vehicle Technology V, Orlando, Florida. SPIE Proceedings Series, Volume 5083, pp. 303-310, 2003. CrossRef  Google Scholar; 5.C. Urmson, Navigation regimes for off-road driving, Technical Report No. CMU-RI-TR-05-23. Pittsburgh, PA: Carnegie Mellon University, Robotics Institute, 2005. Google Scholar; 6.W. Vesely et al., Fault Tree Handbook with Aerospace Applications, NASA Office of Safety and Mission Assurance, August 2002. Google Scholar; 7.L. Portinale, ""Bayesian Belief Networks in Reliability"", Tutorial Notes, 2012 Annual Reliability and Maintainability Symposium, Reno, NV, URL: http://www.xcdsystem.com/rams2012/cdrom/tutorials/ 09a.pdf Google Scholar; 8.N.E. Fenton and M. Neil, Risk Assessment and Decision Analysis with Bayesian Networks, CRC Press, ISBN: 9781439809105, 2012. Google Scholar; 9.F.V. Jensen and T.D. Nielsen, Bayesian Networks and Decision Graphs. Second Edition, Springer-Verlag, 2007. CrossRef  Google Scholar; 10.Netica Software Package. Norsys Software Corp., Vancouver, BC. URL: http://www.norsys.com/netica.html. Google Scholar; 11.R. Chalupa, Failure Modes, Effects and Diagnostics Analysis. Report No. 06-11-25-R001, Rosemount Corp., Eden Prairie, Minn. 2007. Google Scholar"	1419-1425	"""@INPROCEEDINGS{6644203,
    author = ""Reyes Duran, Daniel and Robinson, Elliot and Kornecki, Andrew J. and Zalewski, Janusz"",
    booktitle = ""2013 Federated Conference on Computer Science and Information Systems"",
    title = ""Safety analysis of Autonomous Ground Vehicle optical systems: Bayesian belief networks approach"",
    year = ""2013"",
    volume = """",
    number = """",
    pages = ""1419-1425"",
    abstract = ""Autonomous Ground Vehicles (AGV) require diverse sensor systems to support the navigation and sense-and-avoid tasks. Two of these systems are discussed in the paper: dual camera-based computer vision (CV) and laser-based detection and ranging (LIDAR). Reliable operation of these optical systems is critical to safety since potential faults or failures could result in mishaps leading to loss of life and property. The paper identifies basic hazards and, using fault tree analysis, the causes and effects of these hazards as related to LIDAR and CV systems. A Bayesian Belief Network approach (BN) supported by automated tool is subsequently used to obtain quantitative probabilistic estimation of system safety."",
    keywords = ""Laser radar;Hazards;Navigation;Vehicles;Cameras;Cognition"",
    doi = """",
    ISSN = """",
    month = ""Sep.""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2013	Safety analysis of Autonomous Ground Vehicle optical systems: Bayesian belief networks approach	https://ieeexplore.ieee.org/document/6644203	IEEE	
35	TestNN	Safety verification of autonomous vehicles for coordinated evasive maneuvers	The verification of evasive maneuvers for autonomous vehicles driving with constant velocity is considered. Modeling uncertainties, uncertain measurements, and disturbances can cause substantial deviations from an initially planned evasive maneuver. From this follows that the maneuver, which is safe under perfect conditions, might become unsafe. In this work, the possible set of deviations is computed with methods from reachability analysis, which allows to verify evasive maneuvers under consideration of the mentioned uncertainties. Since the presented approach has a short response time, it can be applied for real time safety decisions. The methods are presented for a numerical example where two autonomous cars plan a coordinated evasive maneuver in order to prevent a collision with a wrong-way driver.	Intelligent vehicle highway systems; Numerical methods; Uncertainty analysis; Autonomous car; Autonomous Vehicles; Constant velocities; Modeling uncertainties; Numerical example; Reachability analysis; Real time; Safety verification; Short response time; Uncertain measurements; Vehicles; Intelligent vehicle highway systems;  Numerical methods;  Uncertainty analysis;  Autonomous car;  Autonomous Vehicles;  Constant velocities;  Modeling uncertainties;  Numerical example;  Reachability analysis;  Real time;  Safety verification;  Short response time;  Uncertain measurements;  Vehicles	Althoff, Matthias; Althoff, Daniel; Wollherr, Dirk; Buss, Martin	IEEE Intelligent Vehicles Symposium, Proceedings	https://doi.org/10.1109/IVS.2010.5548121	"1.C. Stiller, G. Farber and S. Kammel, ""Cooperative cognitive automobiles"", Proc. of the IEEE Intelligent Vehicles Symposium, pp. 215-220, 2007. View Article  Google Scholar; 2.M. Vendittelli, J.-P. Laumond and C. Nissoux, ""Obstacle distance for car-like robots"", IEEE Transactions on Robotics and Automation, vol. 15, pp. 678-691, 1999. View Article  Google Scholar; 3.J. van den Berg, ""Path planning in dynamic environments"", 2007. Google Scholar; 4.C. Schmidt, F. Oechsle and W. Branz, ""Research on trajectory planning in emergency situations with multiple objects"", Proc. of the IEEE Intelligent Transportation Systems Conference, pp. 988-992, 2006. View Article  Google Scholar; 5.C. F. Chung, T. Furukawa and A. H. Goktogan, ""Coordinated control for capturing a highly maneuverable evader using forward reachable sets"", Proc. of the IEEE International Conference on Robotics and Automation, pp. 1336-1341, 2006. View Article  Google Scholar; 6.J.-Y. Wang and M. Tomizuka, ""Reachability analysis of hybrid lateral control problem for automated heavy-duty vehicles"", Proc. of the American Control Conference, pp. 1-6, 2001. View Article  Google Scholar; 7.A. Girard and G. J. Pappas, ""Verification using simulation"" in Hybrid Systems: Computation and Control, Springer, pp. 272-286, 2006. CrossRef  Google Scholar; 8.A. Donze and O. Maler, ""Systematic simulations using sensitivity analysis"" in Hybrid Systems: Computation and Control, Springer, pp. 174-189, 2007. CrossRef  Google Scholar; 9.J. Kapinski, B. H. Krogh, O. Maler and O. Stursberg, ""On systematic simulation of open continuous systems"" in Hybrid Systems: Computation and Control, Springer, pp. 283-297, 2003. CrossRef  Google Scholar; 10.J. Lygeros, D. N. Godbole and S. Sastry, ""A verified hybrid controller for automated vehicles"", Proc. of the 35th Conference on Decision and Control, pp. 2289-2294, 1996. View Article  Google Scholar; 11.R. Horowitz and P. Varaiya, ""Control design of an automated highway system"", Proceedings of the IEEE, vol. 88, pp. 913-925, 2000. View Article  Google Scholar; 12.C. Livadas, J. Lygeros and N. A. Lynch, ""High-level modeling and analysis of the traffic alert and collision avoidance system (tcas)"", Proceedings of the IEEE, vol. 88, pp. 926-948, 2000. View Article  Google Scholar; 13.C. Tomlin, I. Mitchell and R. Ghosh, ""Safety verification of conflict resolution maneuvers"", IEEE Transactions in Intelligent Transportation Systems, vol. 2, pp. 110-120, 2001. View Article  Google Scholar; 14.A. Platzer and E. M. Clarke, ""Formal verification of curved flight collision avoidance maneuvers: A case study"", Proc. of the 16th International Symposium on Formal Methods, pp. 547-562, 2009. CrossRef  Google Scholar; 15.A. Platzer and J.-D. Quesel, ""European train control system: A case study in formal verification"", Formal Methods and Software Engineering: 11th International Conference on Formal Engineering Methods, vol. 5885, pp. 246-265, 2009. CrossRef  Google Scholar; 16.W. Damm, A. Mikschl, J. Oehlerking, E.-R. Olderog, J. Pang, A. Platzer, et al., ""Automating verification of cooperation control and design in traffic applications"" in Formal Methods and Hybrid Real-Time Systems, Springer, pp. 115-169, 2007. CrossRef  Google Scholar; 17.E. Asarin, T. Dang, G. Frehse, A. Girard, C. Le Guernic and O. Maler, ""Recent progress in continuous and hybrid reach reachability analysis"", Proc. of the 2006 IEEE Conference on Computer Aided Control Systems Design, pp. 1582-1587, 2006. View Article  Google Scholar; 18.A. Eidehall and L. Peters Petersson, ""Statistical threat assessment for general road scenes using Monte Carlo sampling"", IEEE Transactions on Intelligent Transportation Systems, vol. 9, pp. 137-147, 2008. View Article  Google Scholar; 19.M. Althoff, O. Stursberg and M. Buss, ""Model-based probabilistic collision detection in autonomous driving"", IEEE Transactions on Intelligent Transportation Systems, vol. 10, pp. 299-310, 2009. View Article  Google Scholar; 20.J. Guldner, W. Sienel, H.-S. Tan, J. Ackermann, S. Patwardhan and T. Bunte, ""Robust automatic steering control for look-down reference systems with front and rear sensors"", IEEE Transactions on Control Systems Technology, vol. 7, pp. 2-11, 1999. View Article  Google Scholar; 21.J. I. Hernandez and C. Y. Kuo, ""Lateral control of higher order nonlinear vehicle model in emergency maneuvers using absolute positioning gps and magnetic markers"", IEEE Transactions on Vehicular Technology, vol. 53, pp. 372-384, 2004. View Article  Google Scholar; 22.D. Smith, R. Benton and J. Starkey, ""Nonlinear-gain-optimised controller development and evaluation for automated emergency vehicle steering"", International Journal of Vehicle Design, vol. 24, pp. 79-99, 2000. CrossRef  Google Scholar; 23.G. Indiveri, A. Nuchter and K. Lingemann, ""High speed differential drive mobile robot path following control with bounded wheel speed commands"", Proc. of the IEEE International Conference on Robotics and Automation, pp. 2202-2207, 2007. View Article  Google Scholar; 24.M. Durali, G. A. Javid and A. Kasaiezadeh, ""Collision avoidance maneuver for an autonomous vehicle"", Proc. of the 9th International Workshop on Advanced Motion Control, pp. 249-254, 2006. View Article  Google Scholar; 25.M. Althoff, O. Stursberg and M. Buss, ""Reachability analysis of nonlinear systems with uncertain parameters using conservative linearization"", Proc. of the 47th IEEE Conference on Decision and Control, pp. 4042-4048, 2008. View Article  Google Scholar; 26.G. Lafferriere, G. J. Pappas and S. Yovine, ""Symbolic reachability computation for families of linear vector fields"", Symbolic Computation, vol. 32, pp. 231-253, 2001. CrossRef  Google Scholar; 27.A. Girard, ""Reachability of uncertain linear systems using zonotopes"" in Hybrid Systems: Computation and Control, Springer, pp. 291-305, 2005. CrossRef  Google Scholar; 28.A. Chutinan and B. H. Krogh, ""Computational techniques for hybrid system verification"", IEEE Transactions on Automatic Control, vol. 48, no. 1, pp. 64-75, 2003. View Article  Google Scholar; 29.O. Stursberg and B. H. Krogh, ""Efficient representation and computation of reachable sets for hybrid systems"" in Hybrid Systems: Computation and Control, Springer, pp. 482-497, 2003. Google Scholar; 30.M. Althoff, O. Stursberg and M. Buss, ""Reachability analysis of linear systems with uncertain parameters and inputs"", Proc. of the 46th IEEE Conference on Decision and Control, pp. 726-732, 2007. View Article  Google Scholar"	1078 - 1083	"""@CONFERENCE{Althoff20101078,
    author = ""Althoff, Matthias and Althoff, Daniel and Wollherr, Dirk and Buss, Martin"",
    title = ""Safety verification of autonomous vehicles for coordinated evasive maneuvers"",
    year = ""2010"",
    journal = ""IEEE Intelligent Vehicles Symposium, Proceedings"",
    pages = ""1078 - 1083"",
    doi = ""10.1109/IVS.2010.5548121"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956510770\&doi=10.1109\%2fIVS.2010.5548121\&partnerID=40\&md5=34d6e272a2766882b7dbc47c37247d96"",
    affiliations = ""Institute of Automatic Control Engineering (LSR), Technische Universitat Munchen, 80290 Munchen, Germany"",
    abstract = ""The verification of evasive maneuvers for autonomous vehicles driving with constant velocity is considered. Modeling uncertainties, uncertain measurements, and disturbances can cause substantial deviations from an initially planned evasive maneuver. From this follows that the maneuver, which is safe under perfect conditions, might become unsafe. In this work, the possible set of deviations is computed with methods from reachability analysis, which allows to verify evasive maneuvers under consideration of the mentioned uncertainties. Since the presented approach has a short response time, it can be applied for real time safety decisions. The methods are presented for a numerical example where two autonomous cars plan a coordinated evasive maneuver in order to prevent a collision with a wrong-way driver. (c)2010 IEEE."",
    keywords = ""Intelligent vehicle highway systems; Numerical methods; Uncertainty analysis; Autonomous car; Autonomous Vehicles; Constant velocities; Modeling uncertainties; Numerical example; Reachability analysis; Real time; Safety verification; Short response time; Uncertain measurements; Vehicles"",
    correspondence_address = ""M. Althoff; Institute of Automatic Control Engineering (LSR), Technische Universitat Munchen, 80290 Munchen, Germany; email: althoff@tum.de"",
    isbn = ""978-142447866-8"",
    language = ""English"",
    abbrev_source_title = ""IEEE Intell Veh Symp Proc"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 53; Conference name: 2010 IEEE Intelligent Vehicles Symposium, IV 2010; Conference date: 21 June 2010 through 24 June 2010; Conference code: 81688; All Open Access, Green Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2010	Safety Verification of Autonomous Vehicles for Coordinated Evasive Maneuvers	https://www.scopus.com/record/display.uri?eid=2-s2.0-77956510770&origin=resultslist&sort=plf-f&src=s&sid=2c6becc9c13b634ce1b7b72592747647&sot=b&sdt=b&s=TITLE-ABS-KEY%28safety+verification+of+autonomous+vehicles+for+coordinated+evasive+maneuvers%29&sl=91&sessionSearchId=2c6becc9c13b634ce1b7b72592747647&relpos=0	IEEE	
36	TestNN	STPA-based hazard analysis of a complex UAV system in take-off	The ATRC-UAV system is a multifunction system with close subsystem component interactions. Considering its complexity, component hardware failures are no longer the only reason for flight testing accidents, and a comprehensive approach is needed for hazard analysis. Systems-Theoretic Process Analysis (STPA) is a novel technique based on systems theory rather than traditional reliability theories. It addresses safety of complex systems as a control problem rather than a failure problem. In this paper, we adopt STPA on a subscale Unmanned Aerial Vehicle (UAV) system take-off hazard analysis and the potential feasibility of STPA for complex UAV system is demonstrated. Unsafe control actions during take-off and their relevant control flaws are identified and safety constrains at different levels are specified. In addition to component failures, we discover that component interactions and flawed human decision making might also lead to violation of safety constrains by using STPA.	Accidents; Decision making; Large scale systems; Reliability analysis; Reliability theory; Unmanned aerial vehicles (UAV); Accident models; Component failures; Component interaction; Hardware failures; Hazard analysis; Human decision making; Multifunction systems; Unmanned aerial vehicle systems; Hazards; Accidents;  Decision making;  Large scale systems;  Reliability analysis;  Reliability theory;  Unmanned aerial vehicles (UAV);  Accident models;  Component failures;  Component interaction;  Hardware failures;  Hazard analysis;  Human decision making;  Multifunction systems;  Unmanned aerial vehicle systems;  Hazards	Chen, Jieyu; Zhang, Shuguang; Lu, Yi; Tang, Peng	ICTIS 2015 - 3rd International Conference on Transportation Information and Safety, Proceedings	https://doi.org/10.1109/ICTIS.2015.7232133	"1.Y. Lu, S. G. Zhang and X. Q. Li, ""A hazard analysis based approach to improve the landing safety of a BWB remotely operated vehicle"", vol. 25, no. 6, pp. 846-853, 2012. Google Scholar; 2.N. Leveson, ""A new accident model for engineering safer systems"", Saf. Sci, vol. 42, no. 4, pp. 237-270, 2004. CrossRef  Google Scholar; 3.L. Gong, S. G. Zhang, X. F. Liu and T. Qiu, ""Research on hazard identification of turbo-fan engin digital control systems based on functional hazard analysis"", Acta Aeronautica et Astronautica Sinica, vol. 32, no. 12, pp. 2194-2203, 2011. Google Scholar; 4.J. P. Sawyer, ""Fault tree analysis of mechanical system"", Micro electron and Reliability, vol. 54, no. 4, pp. 653-667, 1994. CrossRef  Google Scholar; 5.SAE ARP 4761 Guideline and Methods for Conducting the Safety Assessment Process on Civil Airborne Systems and Equipment, 1996. Google Scholar; 6.J. Reason, Human Error, Cambridge, UK:Cambridge University Press, 1990. CrossRef  Google Scholar; 7.J. Reason, Managing the Risks of Organizational Accidents, Hampshire, England:Ashgate Publishers, 1997. Google Scholar; 8.F. H. Hawkins and H. W. Orlady, Human factors in flight, Ashgate Publishing Company, 1993. Google Scholar; 9.Y. Lu, S. G. Zhang, P. Tang and L. Gong, ""STAMP-based safety control approach for flight testing of a low-cost unmanned subscale blended-wing-body demonstrator"", Saf. Sci, vol. 74, pp. 102-113, 2015. CrossRef  Google Scholar; 10.N. Leveson, ""System Safety Engineering: Back to the Future (tentative title)"" in Unpublished Draft Aeronautics and Astronautics Department, Cambridge, MA:Massachusetts Institute of Technology, 2002. Google Scholar; 11.C. H. Feming, M. Spencer, J Thomas, N. Leveson and C Wilkinson, ""Safety assurance in NextGen and complex transportation systems"", Saf. Sci, vol. 55, no. 3, pp. 173-187, 2013. CrossRef  Google Scholar; 12.T. Ishimatsu, N. Leveson, J. Thomas, M. Katahira, Y. Miyamoto and H. Nakao, ""Modeling and hazard analysis using STPA"", Proceedings of the 4th IAASS Conference Making Safety Matter, vol. SP-680, 2010. Google Scholar"	774 - 779	"""@CONFERENCE{Chen2015774,
    author = ""Chen, Jieyu and Zhang, Shuguang and Lu, Yi and Tang, Peng"",
    title = ""STPA-based hazard analysis of a complex UAV system in take-off"",
    year = ""2015"",
    journal = ""ICTIS 2015 - 3rd International Conference on Transportation Information and Safety, Proceedings"",
    pages = ""774 - 779"",
    doi = ""10.1109/ICTIS.2015.7232133"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960091468\&doi=10.1109\%2fICTIS.2015.7232133\&partnerID=40\&md5=929660a1c32f0609155def6582d44f2b"",
    affiliations = ""School of Transportation Science and Engineering, Airworthiness Technologies Research Center, Beihang University, Beijing, 100191, China; School of Energy and Power Engineering, Beijing Key Laboratory of Aircraft/Engine, Beihang University, Beijing, 100191, China"",
    abstract = ""The ATRC-UAV system is a multifunction system with close subsystem component interactions. Considering its complexity, component hardware failures are no longer the only reason for flight testing accidents, and a comprehensive approach is needed for hazard analysis. Systems-Theoretic Process Analysis (STPA) is a novel technique based on systems theory rather than traditional reliability theories. It addresses safety of complex systems as a control problem rather than a failure problem. In this paper, we adopt STPA on a subscale Unmanned Aerial Vehicle (UAV) system take-off hazard analysis and the potential feasibility of STPA for complex UAV system is demonstrated. Unsafe control actions during take-off and their relevant control flaws are identified and safety constrains at different levels are specified. In addition to component failures, we discover that component interactions and flawed human decision making might also lead to violation of safety constrains by using STPA. (c) 2015 IEEE."",
    author_keywords = ""accident model; complex system; hazard analysis; STAMP/STPA; UAV"",
    keywords = ""Accidents; Decision making; Large scale systems; Reliability analysis; Reliability theory; Unmanned aerial vehicles (UAV); Accident models; Component failures; Component interaction; Hardware failures; Hazard analysis; Human decision making; Multifunction systems; Unmanned aerial vehicle systems; Hazards"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-147998694-1"",
    language = ""English"",
    abbrev_source_title = ""ICTIS - Int. Conf. Transp. Inf. Saf., Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 15; Conference name: 3rd International Conference on Transportation Information and Safety, ICTIS 2015; Conference date: 25 June 2015 through 28 June 2015; Conference code: 117960""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2015	STPA-based hazard analysis of a complex UAV system in take-off	https://www.scopus.com/record/display.uri?eid=2-s2.0-84960091468&origin=resultslist&sort=plf-f&src=s&sid=3a1124f76d35e81123b509230fa0342c&sot=b&sdt=b&s=TITLE-ABS-KEY%28stpa+based+hazard+analysis+of+a+complex+uav+system+in+take+off%29&sl=77&sessionSearchId=3a1124f76d35e81123b509230fa0342c&relpos=0	Institute of Electrical and Electronics Engineers Inc	
37	TestNN	System safety surveillance and control system concept for autonomous or semi-autonomous systems fall-back layer realization	Autonomous and semi-autonomous aerial systems (AES) are often needed to perform tasks in complex and dynamic environments, especially in search and rescue applications. The safe navigation assurance as well as safety assurance of AES are open research issues. This paper investigates modeling of fallback layer for AES assurance. To realize given advanced requirement the System Safety Surveillance and Control (SSSC) system concept is introduced. To fulfill safety requirements also for software developments formal requirements are formulated, to be realized with the formal modeling technique Strictly Formalized Situation-Operator-Modeling (sf-SOM). Fall-back system integration into AES can achieve system safety by separated safety consideration and emergency behavior integration and realization. Universally concept design permits the fall-back layer realization also for other applications. This in turn allows the first proof of concept of sf-SOM based SSSC system for fall-back layer realization using an experimental example. Here a Threetank system is used to show the successful fall-back layer realization and the concept transferability to the introduced AES example.	Antennas; Manipulators; Motion planning; Multi agent systems; Networked control systems; Robot applications; Robot programming; Robots; Robustness (control systems); Traffic control; Vibrations (mechanical); Behavior integration; Dynamic environments; Safety considerations; Safety requirements; Search-and-rescue applications; Semi-autonomous systems; System integration; Three-Tank-System; Advanced vehicle control systems; Antennas;  Manipulators;  Motion planning;  Multi agent systems;  Networked control systems;  Robot applications;  Robot programming;  Robots;  Robustness (control systems);  Traffic control;  Vibrations (mechanical);  Behavior integration;  Dynamic environments;  Safety considerations;  Safety requirements;  Search-and-rescue applications;  Semi-autonomous systems;  System integration;  Three-Tank-System;  Advanced vehicle control systems	Hagele, Georg; Soffker, Dirk	ASME 2016 Dynamic Systems and Control Conference, DSCC 2016	https://doi.org/10.1115/DSCC2016-9718			"""@CONFERENCE{Hagele2016,
    author = ""Hagele, Georg and Soffker, Dirk"",
    title = ""System safety surveillance and control system concept for autonomous or semi-autonomous systems fall-back layer realization"",
    year = ""2016"",
    journal = ""ASME 2016 Dynamic Systems and Control Conference, DSCC 2016"",
    volume = ""2"",
    doi = ""10.1115/DSCC2016-9718"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015635348\&doi=10.1115\%2fDSCC2016-9718\&partnerID=40\&md5=fb34966efec337afbfee65ef62cf146e"",
    affiliations = ""Department of Dynamics and Control, University of Duisburg-Essen, Germany"",
    abstract = ""Autonomous and semi-autonomous aerial systems (AES) are often needed to perform tasks in complex and dynamic environments, especially in search and rescue applications. The safe navigation assurance as well as safety assurance of AES are open research issues. This paper investigates modeling of fallback layer for AES assurance. To realize given advanced requirement the System Safety Surveillance and Control (SSSC) system concept is introduced. To fulfill safety requirements also for software developments formal requirements are formulated, to be realized with the formal modeling technique Strictly Formalized Situation-Operator-Modeling (sf-SOM). Fall-back system integration into AES can achieve system safety by separated safety consideration and emergency behavior integration and realization. Universally concept design permits the fall-back layer realization also for other applications. This in turn allows the first proof of concept of sf-SOM based SSSC system for fall-back layer realization using an experimental example. Here a Threetank system is used to show the successful fall-back layer realization and the concept transferability to the introduced AES example. Copyright (c) 2016 by ASME."",
    keywords = ""Antennas; Manipulators; Motion planning; Multi agent systems; Networked control systems; Robot applications; Robot programming; Robots; Robustness (control systems); Traffic control; Vibrations (mechanical); Behavior integration; Dynamic environments; Safety considerations; Safety requirements; Search-and-rescue applications; Semi-autonomous systems; System integration; Three-Tank-System; Advanced vehicle control systems"",
    publisher = ""American Society of Mechanical Engineers"",
    isbn = ""978-079185070-1"",
    language = ""English"",
    abbrev_source_title = ""ASME Dyn. Syst. Control Conf., DSCC"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 3; Conference name: ASME 2016 Dynamic Systems and Control Conference, DSCC 2016; Conference date: 12 October 2016 through 14 October 2016; Conference code: 126470""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2016	System safety surveillance and control system concept for autonomous or semi-autonomous systems fall-back layer realization	https://doi.org/10.1115/DSCC2016-9718	American Society of Mechanical Engineers	nan; References; Pages; Link
38	TestNN	The human should be part of the control loop?	"The capabilities of autonomy have grown to encompass new application spaces that until recently were considered exclusive to humans. In the past, automation has focused on applications where it was preferable to completely replace the human. Today, though, we have the opportunity to leverage the complementary strengths of both human and autonomy technologies to maximize performance and limit risk, and the human should therefore remain ""in"" or ""on"" the loop. To adequately assess when and how to accomplish this, it requires us to assess not only the capabilities, but the risks and the ethical questions; coupled to this are the issues with degradation of performance in specific instances (for instance, recovery from failure) that may require a human to remain the sole control authority. This paper investigates the contributors to success/failure in current human-autonomy integration frameworks, and proposes guidelines for safe and resilient use of humans and autonomy with regard to performance, consequence, and the stability of human-machine switching. Key to our proposed approach are (i) the relative error rate between the human and autonomy and (ii) the consequence of possible events."	Decision making;Automation;Switches;Sensors;Man-machine systems;Service robots;human-autonomy integration;human-machine interaction;shared control;switched control; Decision making; Automation; Switches; Sensors; Man-machine systems; Service robots; human-autonomy integration; human-machine interaction; shared control; switched control	Nothwang, William D.; McCourt, Michael J.; Robinson, Ryan M.; Burden, Samuel A.; Curtis, J. Willard	2016 Resilience Week (RWS)	https://doi.org/10.1109/RWEEK.2016.7573336	"1.D. E. Nye, America s Assembly Line, MIT Press, 2013. Google Scholar; 2.F. W. Meredith, ""The modern autopilot"", Aeronautical Journal, 1949. Google Scholar; 3.A. Wolman, ""Industrial water supply from processed sewage treatment plant effluent at Baltimore Md"", Sewage Works Journal, vol. 20, no. 1, pp. 15-21, 1948. Google Scholar; 4.Y. Harrison and J. A. Horne, ""The impact of sleep deprivation on decision making: a review"", Journal of Experimental Psychology, vol. 6, no. 3, pp. 236-249, 2000. CrossRef  Google Scholar; 5.B. Donmez, C. Neheme and M. L. Cummings, ""Modeling workload impact in multiple unnmanned vehicle supervisory control"", IEEE Transactions on Systems Man and Cybernetics, vol. 40, no. 6, pp. 1180-1190, 2010. View Article  Google Scholar; 6.R. Parasuraman and D. Manzey, ""Complacency and bias in human use of automation: an attentional integration"", Human Factors: The Journal of the Human Factors and Ergonomics Society, vol. 52, no. 3, pp. 381-410, 2010. CrossRef  Google Scholar; 7.P. Scharre and M. Horowitz, ""An introduction to autonomy in weapon systems"", Center for New American Security, 2015. Google Scholar; 8.L. Onnasch, C. D. Wickens, H. Li and D. Manzey, ""Human performance consequences of stages and levels of automation: an integrated meta-analysis"", Human Factors: The Journal of the Human Factors and Ergonomics Society, vol. 56, no. 3, pp. 476-488, May 2014. CrossRef  Google Scholar; 9.M. Pilling, ""Issues regarding the future application of autonomous systems to command and control (C2)"", Defense Science and Technology Organisation Australian Department of Defense DSTO-TR-3112, 2015. Google Scholar; 10.A. R. Lanfranco, A. E. Castellanos, J. P. Desai and W. C. Meyers, ""Robotic surgery a current perspective"", Annals of surgery, vol. 239, no. 1, pp. 14-21, 2004. CrossRef  Google Scholar; 11.M. A. Talamini, S. Chapman, S. Horgan and W. S. Melvin, ""A prospective analysis of 211 robotic-assisted surgical procedures"", Surg Endosc, vol. 17, pp. 1521-1524, 2003. CrossRef  Google Scholar; 12.A. M. Okamura, ""Methods for haptic feedback in teleoperated robot-assisted surgery"", Industrial Robot, vol. 31, no. 6, pp. 499-508, 2004. CrossRef  Google Scholar; 13.H. Ding, J. Heyn, B. Matthias and H. Staab, ""Structured collaborative behavior of industrial robots in mixed human-robot environments"", IEEE International Conference on Automation Science, pp. 1101-1106, 2013. View Article  Google Scholar; 14.A. M. Zanchettin, N. M. Ceriani, P. Rocco, H. Ding and B. Matthias, ""Safety in human-robot collaborative manufacturing environments: metrics and control"", IEEE Trans. on Automation Science and Engineeriing, vol. 13, no. 2, pp. 882-893, April 2016. View Article  Google Scholar; 15.K. Wagner, ""Facebooks virtual assistant 'M' is super smart. Its also probably a human"", Recode, Nov. 2015,  [online]  Available: http://www.recode.net/2015/11/3/11620286/facebooks-virtual-assistant-m-is-super-smart-its-also-probably-a-human. Google Scholar; 16.""Collaborative Operations in Denied Environment (CODE)"",  [online]  Available: http://www.darpa.mil/program/collaborative-operations-in-denied-environment. Google Scholar; 17.K. He, X. Zhang, S. Ren and J. Sun, ""Delving deep into rectifiers: surpassing human-level performance on ImageNet classification"", IEEE International Conference on Computer Vision, pp. 1026-1034, Feb. 2015. View Article  Google Scholar; 18.S. Ioffe and C. Szegedy, ""Batch normalization: accelerating deep network training by reducing internal covariate shift"", International Conference on Machine Learning, pp. 448-456, 2015. Google Scholar; 19.V. Mnih, K. Kavukcuoglu, D. Silver, A.A. Rusu, J. Veness, M. G. Bellemare, A. Graves et al., ""Human-level control through deep reinforcement learning"", Nature, vol. 518, no. 7540, pp. 529-533, 2015. CrossRef  Google Scholar; 20.D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van den Driessche, J. Schrittwieser et al., ""Mastering the game of Go with deep neural networks and tree search"", Nature, vol. 529, no. 7587, pp. 484-489, 2016. CrossRef  Google Scholar; 21.C. Moyer, ""How Googles AlphaGo beat a Go world champion"", The Atlantic, March 2016,  [online]  Available: http://www.theatlantic.com/technology/archive/2016/03/theinvisibleopponent/475611/. Google Scholar; 22.P. M. Fitts, ""Human Engineering for an effective air-navigation and traffic-control system"" in , Washington, DC:National Research Council, 1951. Google Scholar; 23.B. Kantowitz and R. Sorkin, ""Allocation of functions"" in Handbook of Human Factors, New York:Wiley, pp. 365-369. Google Scholar; 24.J.-M. Hoc, ""Towards a cognitive approach to human-machine cooperation in dynamic situations"", Int. J. Human-Computer Studies, vol. 54, pp. 509-540, 2001. CrossRef  Google Scholar; 25.J. M. Bradshaw, V. Dignum, C. Jonker and M. Sierhuis, ""Human-agent-robot teamwork"", IEEE Intelligent Systems, vol. 27, no. 2, pp. 8-13, 2012. View Article  Google Scholar; 26.M. Johnson, J. M. Bradshaw, P. J. Feltovich, C. M. Jonker, M. B. van Riemsdijk and M. Sierhuis, ""Coactive design: designing support for interdependence in joint activity"", Journal of Human-Robot Interaction, vol. 3, no. 1, pp. 43-69, 2014. CrossRef  Google Scholar; 27.R. M. Robinson, D. Scobee, S. A. Burden and S. S. Sastry, ""Dynamic inverse models in human-cyber-physical systems"", SPIE Conference on Defense and Commercial Sensing, April 2016. Google Scholar; 28.M. Korber, W. Schneider and M. Zimmerman, ""Vigilance boredom proneness and detection time of a malfunction in partially automated driving"", IEEE Collaboration Technologies and Systems, pp. 70-76, 2015. View Article  Google Scholar; 29.R. J. Jagacinski and J. M. Flach, Control Theory for Humans: Quantiitative Approaches to Modeling Performance, CRC Press, 2003. Google Scholar; 30.J. Wise, ""What really happened aboard Air France 447"", Popular Mechanics, Dec. 2011,  [online]  Available: http://www.popularmechanics.com/flight/a3115/what-really-happened-aboard-air-france-447-6611877/. Google Scholar"	214-220	"""@INPROCEEDINGS{7573336,
    author = ""Nothwang, William D. and McCourt, Michael J. and Robinson, Ryan M. and Burden, Samuel A. and Curtis, J. Willard"",
    booktitle = ""2016 Resilience Week (RWS)"",
    title = ""The human should be part of the control loop?"",
    year = ""2016"",
    volume = """",
    number = """",
    pages = ""214-220"",
    abstract = ""The capabilities of autonomy have grown to encompass new application spaces that until recently were considered exclusive to humans. In the past, automation has focused on applications where it was preferable to completely replace the human. Today, though, we have the opportunity to leverage the complementary strengths of both human and autonomy technologies to maximize performance and limit risk, and the human should therefore remain ""in"" or ""on"" the loop. To adequately assess when and how to accomplish this, it requires us to assess not only the capabilities, but the risks and the ethical questions; coupled to this are the issues with degradation of performance in specific instances (for instance, recovery from failure) that may require a human to remain the sole control authority. This paper investigates the contributors to success/failure in current human-autonomy integration frameworks, and proposes guidelines for safe and resilient use of humans and autonomy with regard to performance, consequence, and the stability of human-machine switching. Key to our proposed approach are (i) the relative error rate between the human and autonomy and (ii) the consequence of possible events."",
    keywords = ""Decision making;Automation;Switches;Sensors;Man-machine systems;Service robots;human-autonomy integration;human-machine interaction;shared control;switched control"",
    doi = ""10.1109/RWEEK.2016.7573336"",
    ISSN = """",
    month = ""Aug""
}
"""	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	2016	The human should be part of the control loop?	https://ieeexplore.ieee.org/document/7573336	IEEE	
39	TestNN	The Robustly-Safe Automated Driving System for Enhanced Active Safety	Road safety is one of the major concerns for automated vehicles. In order for these vehicles to interact safely and efficiently with the other road participants, the behavior of the automated vehicles should be carefully designed. Liu and Tomizuka proposed the Robustly-safe Automated Driving system (ROAD) which prevents or minimizes occurrences of collisions of the automated vehicle with other road participants while maintaining efficiency. In this paper, a set of design principles are elaborated as an extension of the previous work, including robust perception and cognition algorithms for environment monitoring and high level decision making and low level control algorithms for safe maneuvering of the automated vehicle. The autonomous driving problem in mixed traffic is posed as a stochastic optimization problem, which is solved by 1) behavior classification and trajectory prediction of other road participants, and 2) a unique parallel planner architecture which addresses the efficiency goal in the long term and the safety goal in the short term separately. Moreover, a python-based high fidelity simulation system is developed and extensive simulations are performed to evaluate the effectiveness of the proposed algorithm, where both high level decision making and low level vehicle regulation are considered. Two typical scenarios are studied, driving on freeway and driving in unstructured environments such as parking lots. In the simulation, multiple moving agents representing surrounding vehicles and pedestrians are added to the environment, some of which are controlled by human subjects in order to test the real time response of the automated vehicle.	Automation; Computer software; Decision making; Efficiency; Motor transportation; Optimization; Roads and streets; Automated driving systems; Behavior classification; Environment monitoring; High-fidelity simulation systems; Perception and cognition; Stochastic optimization problems; Trajectory prediction; Unstructured environments; Maneuverability; Automation;  Computer software;  Decision making;  Efficiency;  Motor transportation;  Optimization;  Roads and streets;  Automated driving systems;  Behavior classification;  Environment monitoring;  High-fidelity simulation systems;  Perception and cognition;  Stochastic optimization problems;  Trajectory prediction;  Unstructured environments;  Maneuverability	Liu, Changliu; Chen, Jianyu; Nguyen, Trong-Duy; Tomizuka, Masayoshi	SAE Technical Papers	https://doi.org/10.4271/2017-01-1406			"""@ARTICLE{Liu2017,
    author = ""Liu, Changliu and Chen, Jianyu and Nguyen, Trong-Duy and Tomizuka, Masayoshi"",
    title = ""The Robustly-Safe Automated Driving System for Enhanced Active Safety"",
    year = ""2017"",
    journal = ""SAE Technical Papers"",
    volume = ""2017-March"",
    number = ""March"",
    doi = ""10.4271/2017-01-1406"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018385891\&doi=10.4271\%2f2017-01-1406\&partnerID=40\&md5=e6c5b3667f5191203491243f70f91399"",
    affiliations = ""University of California, Berkeley, United States; DENSO International America Inc., United States"",
    abstract = ""Road safety is one of the major concerns for automated vehicles. In order for these vehicles to interact safely and efficiently with the other road participants, the behavior of the automated vehicles should be carefully designed. Liu and Tomizuka proposed the Robustly-safe Automated Driving system (ROAD) which prevents or minimizes occurrences of collisions of the automated vehicle with other road participants while maintaining efficiency. In this paper, a set of design principles are elaborated as an extension of the previous work, including robust perception and cognition algorithms for environment monitoring and high level decision making and low level control algorithms for safe maneuvering of the automated vehicle. The autonomous driving problem in mixed traffic is posed as a stochastic optimization problem, which is solved by 1) behavior classification and trajectory prediction of other road participants, and 2) a unique parallel planner architecture which addresses the efficiency goal in the long term and the safety goal in the short term separately. Moreover, a python-based high fidelity simulation system is developed and extensive simulations are performed to evaluate the effectiveness of the proposed algorithm, where both high level decision making and low level vehicle regulation are considered. Two typical scenarios are studied, driving on freeway and driving in unstructured environments such as parking lots. In the simulation, multiple moving agents representing surrounding vehicles and pedestrians are added to the environment, some of which are controlled by human subjects in order to test the real time response of the automated vehicle. (c) 2017 SAE International."",
    keywords = ""Automation; Computer software; Decision making; Efficiency; Motor transportation; Optimization; Roads and streets; Automated driving systems; Behavior classification; Environment monitoring; High-fidelity simulation systems; Perception and cognition; Stochastic optimization problems; Trajectory prediction; Unstructured environments; Maneuverability"",
    publisher = ""SAE International"",
    issn = ""01487191"",
    language = ""English"",
    abbrev_source_title = ""SAE Techni. Paper."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 5; Conference name: SAE World Congress Experience, WCX 2017; Conference date: 4 April 2017 through 6 April 2017; Conference code: 127407""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2017	The Robustly-Safe Automated Driving System for Enhanced Active Safety	https://www.scopus.com/record/display.uri?eid=2-s2.0-85018385891&origin=resultslist&sort=plf-f&src=s&sid=93ccc33920098b86169bf355737ef7a8&sot=b&sdt=b&s=TITLE-ABS-KEY%28the+robustly+safe+automated+driving+system+for+enhanced+active+safety%29&sl=84&sessionSearchId=93ccc33920098b86169bf355737ef7a8&relpos=0	SAE International	nan; References; Pages
40	TestNN	The role of situation awareness in assuring safety of autonomous vehicles	Assuring safety of autonomous vehicles operating in an open environment requires reliable situation awareness, action planning and prediction of actions of other vehicles and objects. Factors that also have to be considered are certainty and completeness of available information and trust in information sources and other entities. The paper discusses the problem of autonomous vehicle safety assurance and proposes dynamic situation assessment to cope with the problem of environment dynamics and incomplete and uncertain situation knowledge. The approach is presented for a simple example of a simulated autonomous vehicle. The situation awareness model and autonomous vehicle control system architecture is presented. The problems of justifying system safety are discussed.	Autonomous agents; Computer architecture; Computer simulation; Information analysis; Problem solving; Unmanned vehicles; Autonomous vehicle control system architecture; Autonomous vehicles; Safety assurance; Simulated autonomous vehicles; Accident prevention; Autonomous agents;  Computer architecture;  Computer simulation;  Information analysis;  Problem solving;  Unmanned vehicles;  Autonomous vehicle control system architecture;  Autonomous vehicles;  Safety assurance;  Simulated autonomous vehicles;  Accident prevention	Wardzinski, Andrzej	Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)	https://www.scopus.com/record/display.uri?eid=2-s2.0-33750994641&origin=resultslist&sort=plf-f&src=s&sid=c9c24ac7bea321bf6a58abbda2eafeca&sot=b&sdt=b&s=TITLE-ABS-KEY%28the+role+of+situation+awareness+in+assuring+safety+of+autonomous+vehicles%29&sl=88&sessionSearchId=c9c24ac7bea321bf6a58abbda2eafeca&relpos=0		205 - 218	"""@ARTICLE{Wardzinski2006205,
    author = ""Wardzinski, Andrzej"",
    title = ""The role of situation awareness in assuring safety of autonomous vehicles"",
    year = ""2006"",
    journal = ""Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"",
    volume = ""4166 LNCS"",
    pages = ""205 - 218"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750994641\&partnerID=40\&md5=c979dec7bbc3efac765f12443bc4dd9d"",
    affiliations = ""PROKOM Software SA, 81-321 Gdynia, Podolska 21, Poland"",
    abstract = ""Assuring safety of autonomous vehicles operating in an open environment requires reliable situation awareness, action planning and prediction of actions of other vehicles and objects. Factors that also have to be considered are certainty and completeness of available information and trust in information sources and other entities. The paper discusses the problem of autonomous vehicle safety assurance and proposes dynamic situation assessment to cope with the problem of environment dynamics and incomplete and uncertain situation knowledge. The approach is presented for a simple example of a simulated autonomous vehicle. The situation awareness model and autonomous vehicle control system architecture is presented. The problems of justifying system safety are discussed. (c) Springer-Verlag Berlin Heidelberg 2006."",
    keywords = ""Autonomous agents; Computer architecture; Computer simulation; Information analysis; Problem solving; Unmanned vehicles; Autonomous vehicle control system architecture; Autonomous vehicles; Safety assurance; Simulated autonomous vehicles; Accident prevention"",
    correspondence_address = ""A. Wardzinski; PROKOM Software SA, 81-321 Gdynia, Podolska 21, Poland; email: wardzinskia@prokom.pl"",
    publisher = ""Springer Verlag"",
    issn = ""03029743"",
    isbn = ""3540457623; 978-354045762-6"",
    language = ""English"",
    abbrev_source_title = ""Lect. Notes Comput. Sci."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 16; Conference name: 25th International Conference on Computer Safety, Reliability, and Security, SAFECOMP 2006; Conference date: 27 September 2006 through 29 September 2006; Conference code: 68507""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	Scopus Signed In	2006	The role of situation awareness in assuring safety of autonomous vehicles	https://www.scopus.com/record/display.uri?eid=2-s2.0-33750994641&origin=resultslist&sort=plf-f&src=s&sid=c9c24ac7bea321bf6a58abbda2eafeca&sot=b&sdt=b&s=TITLE-ABS-KEY%28the+role+of+situation+awareness+in+assuring+safety+of+autonomous+vehicles%29&sl=88&sessionSearchId=c9c24ac7bea321bf6a58abbda2eafeca&relpos=0	Springer Verlag	nan; References
41	TestNN	Towards Evaluating the Robustness of Neural Networks			Carlini, N. and D. Wagner	2017 IEEE Symposium on Security and Privacy (SP)					Included	Included	new_screen			1		2017				
42	TestNN	Trust Bit: Reward-based intelligent vehicle commination using blockchain paper	The Intelligent vehicle is experiencing revolutionary growth in research and industry, but it still suffers from a lot of security vulnerabilities. Traditional security methods are incapable of providing secure IV, mainly in terms of communication. In IV communication, major issues are trust and data accuracy of received and broadcasted reliable data in the communication channel. Blockchain technology works for the cryptocurrency, Bitcoin which has been recently used to build trust and reliability in peer-to-peer networks with similar topologies to IV Communication world. IV to IV, communicate in a decentralized manner within communication networks. In this paper, we have proposed, Trust Bit (TB) for IV communication among IVs using Blockchain technology. Our proposed trust bit provides surety for each IVs broadcasted data, to be secure and reliable in every particular networks. Our Trust Bit is a symbol of trustworthiness of vehicles behavior, and vehicles legal and illegal action. Our proposal also includes a reward system, which can exchange some TB among IVs, during successful communication. For the data management of this trust bit, we have used blockchain technology in the vehicular cloud, which can store all Trust bit details and can be accessed by IV anywhere and anytime. Our proposal provides secure and reliable information. We evaluate our proposal with the help of IV communication on intersection use case which analyzes a variety of trustworthiness between IVs during communication.	Blockchain; Communication; Distributed computer systems; Electronic money; Indium compounds; Industrial research; Information management; Intelligent vehicle highway systems; Internet of things; Peer to peer networks; Vehicles; Data accuracy; Illegal actions; Reward systems; Security; Security methods; Security vulnerabilities; Use-case; Vehicular clouds; Network security; Blockchain;  Communication;  Distributed computer systems;  Electronic money;  Indium compounds;  Industrial research;  Information management;  Intelligent vehicle highway systems;  Internet of things;  Peer to peer networks;  Vehicles;  Data accuracy;  Illegal actions;  Reward systems;  Security;  Security methods;  Security vulnerabilities;  Use-case;  Vehicular clouds;  Network security	Singh, Madhusudan; Kim, Shiho	IEEE World Forum on Internet of Things, WF-IoT 2018 - Proceedings	https://doi.org/10.1109/WF-IoT.2018.8355227	"1.D. Singh, M. Singh, I. Singh and H. J. Lee, ""Secure and reliable cloud networks for smart transportation services"", 2015 17th International Conference on Advanced Communication Technology (ICACT) Seoul, pp. 358-362, 2015. View Article  Google Scholar; 2.G. Yan and S. Olariu, ""A probabilistic analysis of link duration in vehicular adhoc networks"", IEEE Transaction Intelligent. Transportation Syst., vol. 12, no. 4, pp. 1227-1236, Dec. 2011. View Article  Google Scholar; 3.C. Wang, Q. Wang, K. Ren and W. Lou, ""Privacy-preserving public auditing for data storage security in cloud computing"", Proc. IEEE INFOCOM San Diego CA, pp. 1-9, 2010. CrossRef  Google Scholar; 4.S. Olariu, M. Eltoweissy and M. Younis, ""Toward autonomous vehicu lar clouds"", ICST Trans. Mobile Communication Computers, vol. 11, no. 7-9, pp. 1-11, Jul.-Sep. 2011. CrossRef  Google Scholar; 5.M. Singh, D. Singh and A. Jara, ""Secure cloud networks for connected & automated vehicles"", 2015 International Conference on Connected Vehicles and Expo (ICCVE), pp. 330-335, 2015. CrossRef  Google Scholar; 6.Satoshi Nakomoto, Bitcoin: A Peer-to-Peer Electronic Cash System BITCOIN. ORG, vol. 3, no. 3, 2009. Google Scholar; 7.Madhusudan Singh and Shiho Kim, ""Blockchain based Intelligent Vehicle Data Sharing Framework"" in arXiv preprint arXiv:1708.09721, Sept. 2017. Google Scholar; 8.Yong Yuan and Fei-Yue Wang, ""Towards Blockchain-based Intelligent Transportation Systems"", 2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC) Windsor Oceanico Hotel Rio de Janerio Brazil, Nov. 1-4, 2016. CrossRef  Google Scholar; 9.Benjamin Leiding, Parisa Memarmoshrefi and Dieter Hogrefe, ""2016. Self-managed and blockchain-based vehicular ad-hoc networks"", Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct (UbiComp '16), pp. 137-140. Google Scholar; 10.Dorri Ali, Steger Marco, Salil S. Kanhere and Raja Jurdak, ""Blockchain: A distributed solution to automotive security and privacy"", eprint arXiv: 1704.00073, March 2017. Google Scholar; 11.Sean Rowan, Michael Clear, Meriel Huggard and Ciaran Mc Goldrick, ""Securing vehicle to vehicle data sharing using blockchain through visible light and acoustic side-channels"", eprint arXiv: 1704.02553, April 2017. Google Scholar"	62 - 67	"""@CONFERENCE{Singh201862,
    author = ""Singh, Madhusudan and Kim, Shiho"",
    title = ""Trust Bit: Reward-based intelligent vehicle commination using blockchain paper"",
    year = ""2018"",
    journal = ""IEEE World Forum on Internet of Things, WF-IoT 2018 - Proceedings"",
    volume = ""2018-January"",
    pages = ""62 - 67"",
    doi = ""10.1109/WF-IoT.2018.8355227"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050387319\&doi=10.1109\%2fWF-IoT.2018.8355227\&partnerID=40\&md5=da2bb6f8945e81a20166e755fcdc908c"",
    affiliations = ""Yonsei Institute of Convergence Technology, Yonsei University, Songdo, South Korea; School of Integrated Technology, Yonsei University, Seoul, South Korea"",
    abstract = ""The Intelligent vehicle is experiencing revolutionary growth in research and industry, but it still suffers from a lot of security vulnerabilities. Traditional security methods are incapable of providing secure IV, mainly in terms of communication. In IV communication, major issues are trust and data accuracy of received and broadcasted reliable data in the communication channel. Blockchain technology works for the cryptocurrency, Bitcoin which has been recently used to build trust and reliability in peer-to-peer networks with similar topologies to IV Communication world. IV to IV, communicate in a decentralized manner within communication networks. In this paper, we have proposed, Trust Bit (TB) for IV communication among IVs using Blockchain technology. Our proposed trust bit provides surety for each IVs broadcasted data, to be secure and reliable in every particular networks. Our Trust Bit is a symbol of trustworthiness of vehicles behavior, and vehicles legal and illegal action. Our proposal also includes a reward system, which can exchange some TB among IVs, during successful communication. For the data management of this trust bit, we have used blockchain technology in the vehicular cloud, which can store all Trust bit details and can be accessed by IV anywhere and anytime. Our proposal provides secure and reliable information. We evaluate our proposal with the help of IV communication on intersection use case which analyzes a variety of trustworthiness between IVs during communication. (c) 2018 IEEE."",
    author_keywords = ""Blockchain Technology; Communication; Intelligent Vehicles; Security"",
    keywords = ""Blockchain; Communication; Distributed computer systems; Electronic money; Indium compounds; Industrial research; Information management; Intelligent vehicle highway systems; Internet of things; Peer to peer networks; Vehicles; Data accuracy; Illegal actions; Reward systems; Security; Security methods; Security vulnerabilities; Use-case; Vehicular clouds; Network security"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-146739944-9"",
    language = ""English"",
    abbrev_source_title = ""IEEE World Forum Internet Things, WF-IoT - Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 70; Conference name: 4th IEEE World Forum on Internet of Things, WF-IoT 2018; Conference date: 5 February 2018 through 8 February 2018; Conference code: 136296""
}
"""	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	2018	Trust Bit: Reward-based intelligent vehicle commination using blockchain paper	https://www.scopus.com/record/display.uri?eid=2-s2.0-85050387319&origin=resultslist&sort=plf-f&src=s&sid=39d40c04c6fdae371899d88752510a4c&sot=b&sdt=b&s=TITLE-ABS-KEY%28trust+bit+reward+based+intelligent+vehicle+commination+using+blockchain+paper%29&sl=92&sessionSearchId=39d40c04c6fdae371899d88752510a4c&relpos=0	Institute of Electrical and Electronics Engineers Inc	
43	TestNN	Trusted machine learning: Model repair and data repair for probabilistic models	When machine learning algorithms are used in life-critical or mission-critical applications (e.g., self driving cars, cyber security, surgical robotics), it is important to ensure that they provide some high-level correctness guarantees. We introduce a paradigm called Trusted Machine Learning (TML) with the goal of making learning techniques more trustworthy. We outline methods that show how symbolic analysis (specifically parametric model checking) can be used to learn the dynamical model of a system where the learned model satisfies correctness requirements specified in the form of temporal logic properties (e.g., safety, liveness). When a learned model does not satisfy the desired guarantees, we try two approaches: (1) Model Repair, wherein we modify a learned model directly, and (2) Data Repair, wherein we modify the data so that re-learning from the modified data will result in a trusted model. Model Repair tries to make the minimal changes to the trained model while satisfying the properties, whereas Data Repair tries to make the minimal changes to the dataset used to train the model for ensuring satisfaction of the properties. We show how the Model Repair and Data Repair problems can be solved for the case of probabilistic models, specifically Discrete-Time Markov Chains (DTMC) or Markov Decision Processes (MDP), when the desired properties are expressed in Probabilistic Computation Tree Logic (PCTL). Specifically, we outline how the parameter learning problem in the probabilistic Markov models under temporal logic constraints can be equivalently expressed as a non-linear optimization with non-linear rational constraints, by performing symbolic transformations using a parametric model checker. We illustrate the approach on two case studies: A controller for automobile lane changing, and query router for a wireless sensor network.	Automobile safety devices; Computer circuits; Computer games; Deep learning; Knowledge based systems; Learning algorithms; Linear transformations; Markov processes; Mathematical transformations; Model checking; Nonlinear programming; Operations research; Repair; Temporal logic; Trees (mathematics); Wireless sensor networks; Discrete time Markov chains; Markov Decision Processes; Mission critical applications; Non-linear optimization; Parametric model checking; Probabilistic computation tree logic (PCTL); Probabilistic models; Temporal logic properties; Problem solving; Automobile safety devices;  Computer circuits;  Computer games;  Deep learning;  Knowledge based systems;  Learning algorithms;  Linear transformations;  Markov processes;  Mathematical transformations;  Model checking;  Nonlinear programming;  Operations research;  Repair;  Temporal logic;  Trees (mathematics);  Wireless sensor networks;  Discrete time Markov chains;  Markov Decision Processes;  Mission critical applications;  Non-linear optimization;  Parametric model checking;  Probabilistic computation tree logic (PCTL);  Probabilistic models;  Temporal logic properties;  Problem solving	Ghosh, Shalini; Lincoln, Patrick; Tiwari, Ashish; Zhu, Xiaojin	AAAI Workshop - Technical Report			909 - 916	"""@CONFERENCE{Ghosh2017909,
    author = ""Ghosh, Shalini and Lincoln, Patrick and Tiwari, Ashish and Zhu, Xiaojin"",
    title = ""Trusted machine learning: Model repair and data repair for probabilistic models"",
    year = ""2017"",
    journal = ""AAAI Workshop - Technical Report"",
    volume = ""WS-17-01 - WS-17-15"",
    pages = ""909 - 916"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046076595\&partnerID=40\&md5=85fef797f658f51285a2c6baf69ce3e0"",
    abstract = ""When machine learning algorithms are used in life-critical or mission-critical applications (e.g., self driving cars, cyber security, surgical robotics), it is important to ensure that they provide some high-level correctness guarantees. We introduce a paradigm called Trusted Machine Learning (TML) with the goal of making learning techniques more trustworthy. We outline methods that show how symbolic analysis (specifically parametric model checking) can be used to learn the dynamical model of a system where the learned model satisfies correctness requirements specified in the form of temporal logic properties (e.g., safety, liveness). When a learned model does not satisfy the desired guarantees, we try two approaches: (1) Model Repair, wherein we modify a learned model directly, and (2) Data Repair, wherein we modify the data so that re-learning from the modified data will result in a trusted model. Model Repair tries to make the minimal changes to the trained model while satisfying the properties, whereas Data Repair tries to make the minimal changes to the dataset used to train the model for ensuring satisfaction of the properties. We show how the Model Repair and Data Repair problems can be solved for the case of probabilistic models, specifically Discrete-Time Markov Chains (DTMC) or Markov Decision Processes (MDP), when the desired properties are expressed in Probabilistic Computation Tree Logic (PCTL). Specifically, we outline how the parameter learning problem in the probabilistic Markov models under temporal logic constraints can be equivalently expressed as a non-linear optimization with non-linear rational constraints, by performing symbolic transformations using a parametric model checker. We illustrate the approach on two case studies: A controller for automobile lane changing, and query router for a wireless sensor network. (c) 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."",
    keywords = ""Automobile safety devices; Computer circuits; Computer games; Deep learning; Knowledge based systems; Learning algorithms; Linear transformations; Markov processes; Mathematical transformations; Model checking; Nonlinear programming; Operations research; Repair; Temporal logic; Trees (mathematics); Wireless sensor networks; Discrete time Markov chains; Markov Decision Processes; Mission critical applications; Non-linear optimization; Parametric model checking; Probabilistic computation tree logic (PCTL); Probabilistic models; Temporal logic properties; Problem solving"",
    publisher = ""AI Access Foundation"",
    isbn = ""978-157735786-5"",
    language = ""English"",
    abbrev_source_title = ""AAAI Workshop Tech. Rep."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 5; Conference name: 31st AAAI Conference on Artificial Intelligence, AAAI 2017; Conference date: 4 February 2017 through 5 February 2017; Conference code: 135573""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2017	Trusted machine learning: Model repair and data repair for probabilistic models		AI Access Foundation	nan; References; DOI; Link
44	TestNN	Understanding error propagation in deep learning neural network (DNN) accelerators and applications	Deep learning neural networks (DNNs) have been successful in solving a wide range of machine learning problems. Specialized hardware accelerators have been proposed to accelerate the execution of DNN algorithms for high-performance and energy efficiency. Recently, they have been deployed in datacenters (potentially for business-critical or industrial applications) and safety-critical systems such as self-driving cars. Soft errors caused by high-energy particles have been increasing in hardware systems, and these can lead to catastrophic failures in DNN systems. Traditional methods for building resilient systems, e.g., Triple Modular Redundancy (TMR), are agnostic of the DNN algorithm and the DNN accelerator's architecture. Hence, these traditional resilience approaches incur high overheads, which makes them challenging to deploy. In this paper, we experimentally evaluate the resilience characteristics of DNN systems (i.e., DNN software running on specialized accelerators). We find that the error resilience of a DNN system depends on the data types, values, data reuses, and types of layers in the design. Based on our observations, we propose two efficient protection techniques for DNN systems.	soft error;  silent data corruption;  reliability;  deep learning; soft error, silent data corruption, reliability, deep learning	Li, Guanpeng; Hari, Siva Kumar Sastry; Sullivan, Michael; Tsai, Timothy; Pattabiraman, Karthik; Emer, Joel; Keckler, Stephen W.	SC '17: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis	https://doi.org/10.1145/3126908.3126964		1-12	"""@inproceedings{10.1145/3126908.3126964,
    author = ""Li, Guanpeng and Hari, Siva Kumar Sastry and Sullivan, Michael and Tsai, Timothy and Pattabiraman, Karthik and Emer, Joel and Keckler, Stephen W."",
    title = ""Understanding error propagation in deep learning neural network (DNN) accelerators and applications"",
    year = ""2017"",
    isbn = ""9781450351140"",
    publisher = ""Association for Computing Machinery"",
    address = ""New York, NY, USA"",
    url = ""https://doi.org/10.1145/3126908.3126964"",
    doi = ""10.1145/3126908.3126964"",
    abstract = ""Deep learning neural networks (DNNs) have been successful in solving a wide range of machine learning problems. Specialized hardware accelerators have been proposed to accelerate the execution of DNN algorithms for high-performance and energy efficiency. Recently, they have been deployed in datacenters (potentially for business-critical or industrial applications) and safety-critical systems such as self-driving cars. Soft errors caused by high-energy particles have been increasing in hardware systems, and these can lead to catastrophic failures in DNN systems. Traditional methods for building resilient systems, e.g., Triple Modular Redundancy (TMR), are agnostic of the DNN algorithm and the DNN accelerator's architecture. Hence, these traditional resilience approaches incur high overheads, which makes them challenging to deploy. In this paper, we experimentally evaluate the resilience characteristics of DNN systems (i.e., DNN software running on specialized accelerators). We find that the error resilience of a DNN system depends on the data types, values, data reuses, and types of layers in the design. Based on our observations, we propose two efficient protection techniques for DNN systems."",
    booktitle = ""Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis"",
    articleno = ""8"",
    numpages = ""12"",
    keywords = ""soft error, silent data corruption, reliability, deep learning"",
    location = ""Denver, Colorado"",
    series = ""SC '17""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	Understanding error propagation in deep learning neural network (DNN) accelerators and applications.	https://dl.acm.org/doi/10.1145/3126908.3126964	Association for Computing Machinery	nan; References
45	TestNN	Verification Methodology for Fully Autonomous Heavy Vehicles	The introduction of fully autonomous vehicles posesa number of concerns regarding the safety and dependability ofvehicle operation. Best practice standards within the automotiveindustry rely on the driver operating the vehicle. With thetransition away from manual control, an increased emphasishas to be placed on verification during the vehicle developmentstages. The work presented within this paper aims to establisha framework for the various verification activities performedduring development, and their impact on the safety of the vehicle, as well as a set of guidelines for verification of the decision makingprocess of autonomous vehicles.	Crashworthiness; Decision making; Formal verification; Intelligent vehicle highway systems; Mathematical models; Safety testing; Software testing; Vehicles; Autonomous Vehicles; Fully-autonomous vehicles; Road vehicles; Safety and dependability; System testing; Vehicle safety; Verification activities; Verification methodology; Verification; Crashworthiness;  Decision making;  Formal verification;  Intelligent vehicle highway systems;  Mathematical models;  Safety testing;  Software testing;  Vehicles;  Autonomous Vehicles;  Fully-autonomous vehicles;  Road vehicles;  Safety and dependability;  System testing;  Vehicle safety;  Verification activities;  Verification methodology;  Verification	Gustavsson, Joakim	Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation, ICST 2016	https://doi.org/10.1109/ICST.2016.42	"1.""Road vehicles - Functional safety - Part 2: Management of functional safety"", ISO Std. Rev.26262-2:2011, 2011. Google Scholar; 2.A. C. Rao, R. McMurran and R. P. Jones, ""A critical analysis of model-based formal verification efforts within the automotive industry"", SAE Int. J. Passeng. Cars Electron. Electr. Syst., vol. 1, pp. 77-83, 04 2008. CrossRef  Google Scholar; 3.H. Felbinger, ""Test suite quality assessment using model inference techniques"", Software Testing Verification and Validation (ICST) 2015 IEEE 8th International Conference on, pp. 1-2, April 2015. View Article  Google Scholar; 4.A. Porter, H. Siy and L. Votta, ""A review of software inspections"" in Software Process volume 42 of Advances in Computers, Academic Press, pp. 2074-2, 1996. CrossRef  Google Scholar; 5.D. M. Stavens, ""Learning to drive: Perception for autonomous cars"", May 2011,  [online]  Available: https://searchworks.stanford.edu/view/9238350. Google Scholar; 6.J. Westman and M. Nyberg, ""Contracts for Specifying and Structuring Requirements on Cyber-Physical Systems"", Cyber-Physical Systems, pp. 307-341, Oct. 2015. CrossRef  Google Scholar; 7.J. M. Cobleigh, G. S. Avrunin and L. A. Clarke, ""Breaking up is hard to do"", ACM Transactions on Software Engineering and Methodology, vol. 17, no. 2, pp. 1-52, Apr. 2008. CrossRef  Google Scholar; 8.M. Fisher, L. Dennis and M. Webster, ""Verifying autonomous systems"", Communications of the ACM, vol. 56, no. 9, pp. 84-93, Sep. 2013. CrossRef  Google Scholar"	381 - 382	"""@CONFERENCE{Gustavsson2016381,
    author = ""Gustavsson, Joakim"",
    title = ""Verification Methodology for Fully Autonomous Heavy Vehicles"",
    year = ""2016"",
    journal = ""Proceedings - 2016 IEEE International Conference on Software Testing, Verification and Validation, ICST 2016"",
    pages = ""381 - 382"",
    doi = ""10.1109/ICST.2016.42"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983371297\&doi=10.1109\%2fICST.2016.42\&partnerID=40\&md5=10d3bbe1c872db6bbde871c383304e48"",
    affiliations = ""Department of Mechatronics, KTH Royal Institute of Technology, Stockholm, Sweden"",
    abstract = ""The introduction of fully autonomous vehicles posesa number of concerns regarding the safety and dependability ofvehicle operation. Best practice standards within the automotiveindustry rely on the driver operating the vehicle. With thetransition away from manual control, an increased emphasishas to be placed on verification during the vehicle developmentstages. The work presented within this paper aims to establisha framework for the various verification activities performedduring development, and their impact on the safety of the vehicle, as well as a set of guidelines for verification of the decision makingprocess of autonomous vehicles. (c) 2016 IEEE."",
    author_keywords = ""Formal verification; Intelligent vehicles; Mathematical model; Road vehicles; System testing; Vehicle safety"",
    keywords = ""Crashworthiness; Decision making; Formal verification; Intelligent vehicle highway systems; Mathematical models; Safety testing; Software testing; Vehicles; Autonomous Vehicles; Fully-autonomous vehicles; Road vehicles; Safety and dependability; System testing; Vehicle safety; Verification activities; Verification methodology; Verification"",
    correspondence_address = ""J. Gustavsson; Department of Mechatronics, KTH Royal Institute of Technology, Stockholm, Sweden; email: joagusta@kth.se"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-150901826-0"",
    language = ""English"",
    abbrev_source_title = ""Proc. - IEEE Int. Conf. Softw. Test., Verification Valid., ICST"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: 9th IEEE International Conference on Software Testing, Verification and Validation, ICST 2016; Conference date: 10 April 2016 through 15 April 2016; Conference code: 122841""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	Scopus Signed In	2016	Verification Methodology for Fully Autonomous Heavy Vehicles	https://www.scopus.com/record/display.uri?eid=2-s2.0-84983371297&origin=resultslist&sort=plf-f&src=s&sid=c9c663b7ecfc007a8e3f9de7e391b9e8&sot=b&sdt=b&s=TITLE-ABS-KEY%28verification+methodology+for+fully+autonomous+heavy+vehicles%29&sl=75&sessionSearchId=c9c663b7ecfc007a8e3f9de7e391b9e8&relpos=0	Institute of Electrical and Electronics Engineers Inc	
46	TestNN	Verification of safety for autonomous unmanned ground vehicles	The existing tools for hardware and software reliability and safety engineering do not supply sufficient solutions regarding AI (Artificial Intelligent) adaptive and learning algorithms, which are being used in autonomous robotics and massively rely on designer experience and include methods such as Heuristic, Rules based decision, Fuzzy Logic, Neural Networks, and Genetic Algorithms, Bayes Networks, etc. Since it is obvious that only this kind of algorithms can deal with the complexity and the uncertainty of the real world environment, suitable safety validation methodology is required. In this paper we present the limitation of the existing reliability and safety engineering tools in dealing with autonomous systems and propose a novel methodology based on statistical testing in simulated environment.	Safety;Vehicles;Robots;Artificial intelligence;Algorithm design and analysis;Software;Testing;Performance Testing of Autonomy by Simulation;Robot Autonomy;Robot Autonomy Safety Verification;Safety Verification for Autonomy;Standardization for Robot Autonomy Safety;Unmanned Ground Vehicle; Safety; Vehicles; Robots; Artificial intelligence; Algorithm design and analysis; Software; Testing; Performance Testing of Autonomy by Simulation; Robot Autonomy; Robot Autonomy Safety Verification; Safety Verification for Autonomy; Standardization for Robot Autonomy Safety; Unmanned Ground Vehicle	Meltz, Daniel; Guterman, Hugo	2014 IEEE 28th Convention of Electrical & Electronics Engineers in Israel (IEEEI)	https://doi.org/10.1109/EEEI.2014.7005895		1-5	"""@INPROCEEDINGS{7005895,
    author = ""Meltz, Daniel and Guterman, Hugo"",
    booktitle = ""2014 IEEE 28th Convention of Electrical \& Electronics Engineers in Israel (IEEEI)"",
    title = ""Verification of safety for autonomous unmanned ground vehicles"",
    year = ""2014"",
    volume = """",
    number = """",
    pages = ""1-5"",
    abstract = ""The existing tools for hardware and software reliability and safety engineering do not supply sufficient solutions regarding AI (Artificial Intelligent) adaptive and learning algorithms, which are being used in autonomous robotics and massively rely on designer experience and include methods such as Heuristic, Rules based decision, Fuzzy Logic, Neural Networks, and Genetic Algorithms, Bayes Networks, etc. Since it is obvious that only this kind of algorithms can deal with the complexity and the uncertainty of the real world environment, suitable safety validation methodology is required. In this paper we present the limitation of the existing reliability and safety engineering tools in dealing with autonomous systems and propose a novel methodology based on statistical testing in simulated environment."",
    keywords = ""Safety;Vehicles;Robots;Artificial intelligence;Algorithm design and analysis;Software;Testing;Performance Testing of Autonomy by Simulation;Robot Autonomy;Robot Autonomy Safety Verification;Safety Verification for Autonomy;Standardization for Robot Autonomy Safety;Unmanned Ground Vehicle"",
    doi = ""10.1109/EEEI.2014.7005895"",
    ISSN = """",
    month = ""Dec""
}
"""	Excluded	Excluded	new_screen		Exclusion: low quality-lack sufficient information	1	IEEE	2014	Verification of safety for autonomous unmanned ground vehicles	https://doi.org/10.1109/EEEI.2014.7005895	IEEE	nan; References; Link
47	TestNN	Work-in-progress: Testing autonomous cyber-physical systems using fuzzing features from convolutional neural networks	Autonomous cyber-physical systems rely on modern machine learning methods such as deep neural networks to control their interactions with the physical world. Testing of such intelligent cyberphysical systems is a challenge due to the huge state space associated with high-resolution visual sensory inputs. We demonstrate how fuzzing the input using patterns obtained from the convolutional flters of an unrelated convolutional neural network can be used to test computer vision algorithms implemented in intelligent cyber-physical systems. Our method discovers interesting counterexamples to a pedestrian detection algorithm implemented in the popular OpenCV library. Our approach also unearths counterexamples to the correct behavior of an autonomous car similar to NVIDIA's end-to-end self-driving deep neural net running on the Udacity open-source simulator.	Convolution; Cyber Physical System; Embedded software; Embedded systems; Learning systems; Neural networks; Open source software; Computer vision algorithms; Convolutional neural network; Cyber physical systems (CPSs); High resolution; Modern machines; Pedestrian detection; Visual sensory; Work in progress; Deep neural networks; Convolution;  Cyber Physical System;  Embedded software;  Embedded systems;  Learning systems;  Neural networks;  Open source software;  Computer vision algorithms;  Convolutional neural network;  Cyber physical systems (CPSs);  High resolution;  Modern machines;  Pedestrian detection;  Visual sensory;  Work in progress;  Deep neural networks	Raj, Sunny; Jha, Sumit Kumar; Ramanathan, Arvind; Pullum, Laura L.	Proceedings of the 13th ACM International Conference on Embedded Software 2017 Companion, EMSOFT 2017	https://doi.org/10.1145/3125503.3125568	1.Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang et al., End to end learning for self-driving cars., 2016. Google Scholar; 2.Bhaskar Kumar Ghosh and Pranab Kumar Sen, Handbook of sequential analysis, CRC Press, 1991. Google Scholar; 3.Jordan Golson, Driver in fatal Tesla Autopilot crash had seven seconds to take action, 2016,  [online]  Available: https://www.theverge.com/2017/1/19/14326604/tesla-autopilot-crash-driver-seven-seconds-inattentive-nhtsa. Google Scholar; 4.Ian J Goodfellow, Jonathon Shlens and Christian Szegedy, Explaining and harnessing adversarial examples, 2014. Google Scholar; 5.Ryan Randazzo, Here's what happened in Uber's self-driving car crash., 2017,  [online]  Available: https://www.usatoday.com/story/news/nation-now/2017/03/30/self-driving-uber-crash-police-report/99814322/. Google Scholar		"""@CONFERENCE{Raj2017,
    author = ""Raj, Sunny and Jha, Sumit Kumar and Ramanathan, Arvind and Pullum, Laura L."",
    title = ""Work-in-progress: Testing autonomous cyber-physical systems using fuzzing features from convolutional neural networks"",
    year = ""2017"",
    journal = ""Proceedings of the 13th ACM International Conference on Embedded Software 2017 Companion, EMSOFT 2017"",
    doi = ""10.1145/3125503.3125568"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034850699\&doi=10.1145\%2f3125503.3125568\&partnerID=40\&md5=d8731a242990b5e245d8fb028ed23508"",
    affiliations = ""Computer Science Department, University of Central Florida, Orlando, FL, United States; Computational Science and Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN, United States"",
    abstract = ""Autonomous cyber-physical systems rely on modern machine learning methods such as deep neural networks to control their interactions with the physical world. Testing of such intelligent cyberphysical systems is a challenge due to the huge state space associated with high-resolution visual sensory inputs. We demonstrate how fuzzing the input using patterns obtained from the convolutional flters of an unrelated convolutional neural network can be used to test computer vision algorithms implemented in intelligent cyber-physical systems. Our method discovers interesting counterexamples to a pedestrian detection algorithm implemented in the popular OpenCV library. Our approach also unearths counterexamples to the correct behavior of an autonomous car similar to NVIDIA's end-to-end self-driving deep neural net running on the Udacity open-source simulator. (c) 2017 Copyright held by the owner/author(s)."",
    keywords = ""Convolution; Cyber Physical System; Embedded software; Embedded systems; Learning systems; Neural networks; Open source software; Computer vision algorithms; Convolutional neural network; Cyber physical systems (CPSs); High resolution; Modern machines; Pedestrian detection; Visual sensory; Work in progress; Deep neural networks"",
    publisher = ""Association for Computing Machinery, Inc"",
    isbn = ""978-145035186-7"",
    language = ""English"",
    abbrev_source_title = ""Proc. ACM Int. Conf. Embed. Softw. Companion, EMSOFT"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 5; Conference name: 13th ACM International Conference on Embedded Software, EMSOFT 2017; Conference date: 15 October 2017 through 20 October 2017; Conference code: 131251; All Open Access, Green Open Access""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	Work-in-progress: testing autonomous cyber-physical systems using fuzzing features from convolutional neural networks	https://www.scopus.com/record/display.uri?eid=2-s2.0-85034850699&origin=resultslist&sort=plf-f&src=s&sid=b5ed42402358b4a72da1c57e1896f992&sot=b&sdt=b&s=TITLE-ABS-KEY%28work+in+progress+testing+autonomous+cyber+physical+systems+using+fuzzing+features+from+convolutional+neural+networks%29&sl=131&sessionSearchId=b5ed42402358b4a72da1c57e1896f992&relpos=0	Association for Computing Machinery, Inc	nan; Pages
48	TestNN	A cognitive agent aboard remotely piloted aircraft systems: Development, evaluation, and certification issues	In future air traffic scenarios, remotely piloted aircraft systems are likely to play an increasingly important role. A major use case and subject of research is loss of command and control data link. Therefore, a novel engineering solution is described, which makes use of knowledge-based information processing methods for the implementation of higher cognitive functions in an artificial agent. This agent shall be integrated aboard the airborne vehicle and shall work in a cooperative relationship with the human pilot on the ground for his or her support. With the provision of functional redundancy in flight guidance and mission management related decision-making the overall system safety shall be improved. The article captures the whole development process of the agent including concept, requirements definition, system design, implementation and evaluation. The interactions between the human and the cognitive agent are discussed and the necessity to augment the conventional human-machine interface is deduced. A scenario-based usability study with a group of pilots in addition to real flight tests to evaluate the developed system is described. In addition, considerations on certifiability of such an artificial cognitive associate system are presented.	Command and control systems; Decision making; Fighter aircraft; Human computer interaction; Intelligent agents; Knowledge based systems; Man machine systems; Redundancy; Remote control; Unmanned aerial vehicles (UAV); Cognitive agents; Cooperative relationships; Engineering solutions; Human machine interaction; Human Machine Interface; Pilot assistance; Remotely piloted aircraft; Requirements definition; Cognitive systems; Command and control systems;  Decision making;  Fighter aircraft;  Human computer interaction;  Intelligent agents;  Knowledge based systems;  Man machine systems;  Redundancy;  Remote control;  Unmanned aerial vehicles (UAV);  Cognitive agents;  Cooperative relationships;  Engineering solutions;  Human machine interaction;  Human Machine Interface;  Pilot assistance;  Remotely piloted aircraft;  Requirements definition;  Cognitive systems	Wohler, Marcus; Schulte, Axel	Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering	https://doi.org/10.1177/0954410015613115		1694 - 1704	"""@ARTICLE{Wohler20161694,
    author = ""Wohler, Marcus and Schulte, Axel"",
    title = ""A cognitive agent aboard remotely piloted aircraft systems: Development, evaluation, and certification issues"",
    year = ""2016"",
    journal = ""Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering"",
    volume = ""230"",
    number = ""9"",
    pages = ""1694 - 1704"",
    doi = ""10.1177/0954410015613115"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979049900\&doi=10.1177\%2f0954410015613115\&partnerID=40\&md5=d60629545fb087855fa0dcd105b4eaa8"",
    affiliations = ""Institute of Flight Systems, Aerospace Engineering Department, Bundeswehr University, Munich, Neubiberg, 85577, Germany"",
    abstract = ""In future air traffic scenarios, remotely piloted aircraft systems are likely to play an increasingly important role. A major use case and subject of research is loss of command and control data link. Therefore, a novel engineering solution is described, which makes use of knowledge-based information processing methods for the implementation of higher cognitive functions in an artificial agent. This agent shall be integrated aboard the airborne vehicle and shall work in a cooperative relationship with the human pilot on the ground for his or her support. With the provision of functional redundancy in flight guidance and mission management related decision-making the overall system safety shall be improved. The article captures the whole development process of the agent including concept, requirements definition, system design, implementation and evaluation. The interactions between the human and the cognitive agent are discussed and the necessity to augment the conventional human-machine interface is deduced. A scenario-based usability study with a group of pilots in addition to real flight tests to evaluate the developed system is described. In addition, considerations on certifiability of such an artificial cognitive associate system are presented. (c) Institution of Mechanical Engineers."",
    author_keywords = ""Cognitive agent; human-machine interaction; pilot assistance; redundancy; remotely piloted aircraft systems"",
    keywords = ""Command and control systems; Decision making; Fighter aircraft; Human computer interaction; Intelligent agents; Knowledge based systems; Man machine systems; Redundancy; Remote control; Unmanned aerial vehicles (UAV); Cognitive agents; Cooperative relationships; Engineering solutions; Human machine interaction; Human Machine Interface; Pilot assistance; Remotely piloted aircraft; Requirements definition; Cognitive systems"",
    correspondence_address = ""A. Schulte; Institute of Flight Systems, Aerospace Engineering Department, Bundeswehr University, Munich, Neubiberg, 85577, Germany; email: axel.schulte@unibw.de"",
    publisher = ""SAGE Publications Ltd"",
    issn = ""09544100"",
    coden = ""PMGEE"",
    language = ""English"",
    abbrev_source_title = ""Proc. Inst. Mech. Eng. Part G J. Aerosp. Eng."",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 0""
}
"""	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	2016	A cognitive agent aboard remotely piloted aircraft systems: development, evaluation, and certification issues	https://www.scopus.com/record/display.uri?eid=2-s2.0-84979049900&origin=resultslist&sort=plf-f&src=s&sid=8fc1ca532130ccd1c3d2775c8b6dd88e&sot=b&sdt=b&s=TITLE-ABS-KEY%28a+cognitive+agent+aboard+remotely+piloted+aircraft+systems+development+evaluation+and+certification+issues%29&sl=121&sessionSearchId=8fc1ca532130ccd1c3d2775c8b6dd88e&relpos=0	SAGE Publications Ltd	nan; References
49	TestNN	A Motion Certification Concept to Evaluate Operational Safety and Optimizing Operating Parameters at Runtime	For technical systems, which perform highly automated or so-called autonomous actions, there exist a large demand to evaluate their operational safety in a uniform way at runtime based on the combination of environmental threats and the conditions of subordinated system modules. To guarantee a safe motion based on autonomous decisions we have introduced a universal and transparent certification process which not only takes functional aspects like environment detection and collision avoidance techniques into account but especially identifies the associated system condition itself as a key aspect for the determination of operational safety and for an automated optimization of operating parameters. Similar to a feedback loop possible constraints for environment perception of sensor components or the ability of actuator components to interact with their environment have to be taken into account to introduce a generalized safetyevaluation for the entire system. Therefore, a model is derived to evaluate the operational safety for the autonomous driving robot RAVON from TU Kaiserslautern based on an integrated behavior-based control (IB2C).		Sebastian Muller; Peter Liggesmeyer	International Conference on Computer Safety, Reliability, and Security	https://doi.org/10.1007/978-3-319-24249-1_14		156-166		Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Springer Link	2015	A motion certification concept to evaluate operational safety and optimizing operating parameters at runtime	https://doi.org/10.1007/978-3-319-24249-1_14	Springer, Cham	nan; Keywords; References; Year; Bibtex; Link
50	TestNN	Advances in Vision-Based Lane Detection: Algorithms, Integration, Assessment, and Perspectives on ACP-Based Parallel Vision	Lane detection is a fundamental aspect of most current advanced driver assistance systems U+0028 ADASs U+0029. A large number of existing results focus on the study of vision-based lane detection methods due to the extensive knowledge background and the low-cost of camera devices. In this paper, previous vision-based lane detection studies are reviewed in terms of three aspects, which are lane detection algorithms, integration, and evaluation methods. Next, considering the inevitable limitations that exist in the camera-based lane detection system, the system integration methodologies for constructing more robust detection systems are reviewed and analyzed. The integration methods are further divided into three levels, namely, algorithm, system, and sensor. Algorithm level combines different lane detection algorithms while system level integrates other object detection systems to comprehensively detect lane positions. Sensor level uses multi-modal sensors to build a robust lane recognition system. In view of the complexity of evaluating the detection system, and the lack of common evaluation procedure and uniform metrics in past studies, the existing evaluation methods and metrics are analyzed and classified to propose a better evaluation of the lane detection system. Next, a comparison of representative studies is performed. Finally, a discussion on the limitations of current lane detection systems and the future developing trends toward an Artificial Society, Computational experiment-based parallel lane detection framework is proposed.	Automobile drivers; Benchmarking; Cameras; Object detection; Signal detection; Acp theories; Artificial societies; Computational experiment; Lane detection; Object detection systems; Parallel vision; performance evaluation; System integration; Advanced driver assistance systems; Automobile drivers;  Benchmarking;  Cameras;  Object detection;  Signal detection;  Acp theories;  Artificial societies;  Computational experiment;  Lane detection;  Object detection systems;  Parallel vision;  performance evaluation;  System integration;  Advanced driver assistance systems	Xing, Yang; Lv, Chen; Chen, Long; Wang, Huaji; Wang, Hong; Cao, Dongpu; Velenis, Efstathios; Wang, Fei-Yue	IEEE/CAA Journal of Automatica Sinica	https://doi.org/10.1109/JAS.2018.7511063		645 - 661	"""@ARTICLE{Xing2018645,
    author = ""Xing, Yang and Lv, Chen and Chen, Long and Wang, Huaji and Wang, Hong and Cao, Dongpu and Velenis, Efstathios and Wang, Fei-Yue"",
    title = ""Advances in Vision-Based Lane Detection: Algorithms, Integration, Assessment, and Perspectives on ACP-Based Parallel Vision"",
    year = ""2018"",
    journal = ""IEEE/CAA Journal of Automatica Sinica"",
    volume = ""5"",
    number = ""3"",
    pages = ""645 - 661"",
    doi = ""10.1109/JAS.2018.7511063"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045300346\&doi=10.1109\%2fJAS.2018.7511063\&partnerID=40\&md5=9c0328fd71b91b8c7a5f0f33fe36e891"",
    affiliations = ""Advanced Vehicle Engineering Centre, Cranfield University, Bedford, MK43 0AL, United Kingdom; Vehicle Intelligence Pioneers Ltd, Qingdao, 266000, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, 510275, China; Mechanical and Mechatronics Engineering, University of Waterloo, 200 University Avenue West Waterloo, N2L 3G1, ON, Canada; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China"",
    abstract = ""Lane detection is a fundamental aspect of most current advanced driver assistance systems U+0028 ADASs U+0029. A large number of existing results focus on the study of vision-based lane detection methods due to the extensive knowledge background and the low-cost of camera devices. In this paper, previous vision-based lane detection studies are reviewed in terms of three aspects, which are lane detection algorithms, integration, and evaluation methods. Next, considering the inevitable limitations that exist in the camera-based lane detection system, the system integration methodologies for constructing more robust detection systems are reviewed and analyzed. The integration methods are further divided into three levels, namely, algorithm, system, and sensor. Algorithm level combines different lane detection algorithms while system level integrates other object detection systems to comprehensively detect lane positions. Sensor level uses multi-modal sensors to build a robust lane recognition system. In view of the complexity of evaluating the detection system, and the lack of common evaluation procedure and uniform metrics in past studies, the existing evaluation methods and metrics are analyzed and classified to propose a better evaluation of the lane detection system. Next, a comparison of representative studies is performed. Finally, a discussion on the limitations of current lane detection systems and the future developing trends toward an Artificial Society, Computational experiment-based parallel lane detection framework is proposed. (c) 2014 Chinese Association of Automation."",
    author_keywords = ""ACP theory; Advanced driver assistance systems (ADASs); benchmark; lane detection; parallel vision; performance evaluation"",
    keywords = ""Automobile drivers; Benchmarking; Cameras; Object detection; Signal detection; Acp theories; Artificial societies; Computational experiment; Lane detection; Object detection systems; Parallel vision; performance evaluation; System integration; Advanced driver assistance systems"",
    correspondence_address = ""D. Cao; Mechanical and Mechatronics Engineering, University of Waterloo, 200 University Avenue West Waterloo, N2L 3G1, Canada; email: d.cao@cranfield.ac.uk"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""23299266"",
    language = ""English"",
    abbrev_source_title = ""IEEE CAA J. Autom. Sin."",
    type = ""Review"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 136; All Open Access, Bronze Open Access, Green Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: review paper	1	Scopus Signed In	2018	Advances in Vision-Based Lane Detection: Algorithms, Integration, Assessment, and Perspectives on ACP-Based Parallel Vision	https://www.scopus.com/record/display.uri?eid=2-s2.0-85045300346&origin=resultslist&sort=plf-f&src=s&sid=f388e10a623841eea65ff996aadd3d7f&sot=b&sdt=b&s=TITLE-ABS-KEY%28advances+in+vision+based+lane+detection+algorithms+integration+assessment+and+perspectives+on+acp+based+parallel+vision%29&sl=134&sessionSearchId=f388e10a623841eea65ff996aadd3d7f&relpos=0	Institute of Electrical and Electronics Engineers Inc	nan; References
51	TestNN	An efficient phased mission reliability analysis for autonomous vehicles	Autonomous systems are becoming more commonly used, especially in hazardous situations. Such systems are expected to make their own decisions about future actions when some capabilities degrade due to failures of their subsystems. Such decisions are made without human input, therefore they need to be well-informed in a short time when the situation is analysed and future consequences of the failure are estimated. The future planning of the mission should take account of the likelihood of mission failure. The reliability analysis for autonomous systems can be performed using the methodologies developed for phased mission analysis, where the causes of failure for each phase in the mission can be expressed by fault trees. Unmanned autonomous vehicles (UAVs) are of a particular interest in the aeronautical industry, where it is a long term ambition to operate them routinely in civil airspace. Safety is the main requirement for the UAV operation and the calculation of failure probability of each phase and the overall mission is the topic of this paper. When components or subsystems fail or environmental conditions throughout the mission change, these changes can affect the future mission. The new proposed methodology takes into account the available diagnostics data and is used to predict future capabilities of the UAV in real time. Since this methodology is based on the efficient BDD method, the quickly provided advice can be used in making decisions. When failures occur appropriate actions are required in order to preserve safety of the autonomous vehicle. The overall decision making strategy for autonomous vehicles is explained in this paper. Some limitations of the methodology are discussed and further improvements are presented based on experimental results.	Binary decision diagrams; Decision making; Failure analysis; Reliability analysis; Remotely operated vehicles; Unmanned aerial vehicles (UAV); Vehicles; Autonomous system; Autonomous systems; Autonomous Vehicles; Civil airspace; Decision-making strategies; Environmental conditions; Failure Probability; Fault-trees; Future mission; Future planning; Long term; Making decision; Phased mission; Real time; Unmanned autonomous vehicles; Quality assurance; Binary decision diagrams;  Decision making;  Failure analysis;  Reliability analysis;  Remotely operated vehicles;  Unmanned aerial vehicles (UAV);  Vehicles;  Autonomous system;  Autonomous systems;  Autonomous Vehicles;  Civil airspace;  Decision-making strategies;  Environmental conditions;  Failure Probability;  Fault-trees;  Future mission;  Future planning;  Long term;  Making decision;  Phased mission;  Real time;  Unmanned autonomous vehicles;  Quality assurance	Remenyte-Prescott, R.; Andrews, J.D.; Chung, P.W.H.	Reliability Engineering and System Safety	https://doi.org/10.1016/j.ress.2009.10.002		226 - 235	"""@ARTICLE{Remenyte-Prescott2010226,
    author = ""Remenyte-Prescott, R. and Andrews, J.D. and Chung, P.W.H."",
    title = ""An efficient phased mission reliability analysis for autonomous vehicles"",
    year = ""2010"",
    journal = ""Reliability Engineering and System Safety"",
    volume = ""95"",
    number = ""3"",
    pages = ""226 - 235"",
    doi = ""10.1016/j.ress.2009.10.002"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-73649107872\&doi=10.1016\%2fj.ress.2009.10.002\&partnerID=40\&md5=a928899598a3420e9f0e763b3edb6bc5"",
    affiliations = ""Nottingham Transportation Engineering Centre, Faculty of Engineering, University of Nottingham, Nottingham, NG7 2RD England, United Kingdom; Department of Computer Science, Loughborough University, Loughborough, LE11 3TU England, United Kingdom"",
    abstract = ""Autonomous systems are becoming more commonly used, especially in hazardous situations. Such systems are expected to make their own decisions about future actions when some capabilities degrade due to failures of their subsystems. Such decisions are made without human input, therefore they need to be well-informed in a short time when the situation is analysed and future consequences of the failure are estimated. The future planning of the mission should take account of the likelihood of mission failure. The reliability analysis for autonomous systems can be performed using the methodologies developed for phased mission analysis, where the causes of failure for each phase in the mission can be expressed by fault trees. Unmanned autonomous vehicles (UAVs) are of a particular interest in the aeronautical industry, where it is a long term ambition to operate them routinely in civil airspace. Safety is the main requirement for the UAV operation and the calculation of failure probability of each phase and the overall mission is the topic of this paper. When components or subsystems fail or environmental conditions throughout the mission change, these changes can affect the future mission. The new proposed methodology takes into account the available diagnostics data and is used to predict future capabilities of the UAV in real time. Since this methodology is based on the efficient BDD method, the quickly provided advice can be used in making decisions. When failures occur appropriate actions are required in order to preserve safety of the autonomous vehicle. The overall decision making strategy for autonomous vehicles is explained in this paper. Some limitations of the methodology are discussed and further improvements are presented based on experimental results. (c) 2009 Elsevier Ltd. All rights reserved."",
    author_keywords = ""Autonomous system; Binary decision diagram; Fault tree; Phased mission; Reliability"",
    keywords = ""Binary decision diagrams; Decision making; Failure analysis; Reliability analysis; Remotely operated vehicles; Unmanned aerial vehicles (UAV); Vehicles; Autonomous system; Autonomous systems; Autonomous Vehicles; Civil airspace; Decision-making strategies; Environmental conditions; Failure Probability; Fault-trees; Future mission; Future planning; Long term; Making decision; Phased mission; Real time; Unmanned autonomous vehicles; Quality assurance"",
    correspondence_address = ""R. Remenyte-Prescott; Nottingham Transportation Engineering Centre, Faculty of Engineering, University of Nottingham, Nottingham, NG7 2RD England, United Kingdom; email: R.Remenyte-Prescott@nottingham.ac.uk"",
    issn = ""09518320"",
    coden = ""RESSE"",
    language = ""English"",
    abbrev_source_title = ""Reliab Eng Syst Saf"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 55; All Open Access, Green Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2010	An efficient phased mission reliability analysis for autonomous vehicles	https://www.scopus.com/record/display.uri?eid=2-s2.0-73649107872&origin=resultslist&sort=plf-f&src=s&sid=16a0ce3b206661df9fa833a4ec5f76f4&sot=b&sdt=b&s=TITLE-ABS-KEY%28an+efficient+phased+mission+reliability+analysis+for+autonomous+vehicles%29&sl=87&sessionSearchId=16a0ce3b206661df9fa833a4ec5f76f4&relpos=0		nan; References; Publisher
52	TestNN	Autonomous cognition and recovery controller design of UAV spiral	Aiming at dealing with the spiral recovery puzzle of aerial vehicles, we put forward an autonomous spiral cognition and recovery control method of the unmanned aerial vehicle(UAV). First of all, the safety control framework of unmanned aerial vehicles(UAV) based on flight state-cognition is built and the autonomous spiral cognition and recovery controller is designed. Then, the spiral factors are analyzed and the spiral state is recognized by using intuitive fuzzy statistic adjudging and decision-making algorithm according to timing flight variables information afforded by airborne sensors. Finally, the control scheduling of state variables is considered, and nonlinear dynamic inversion control laws are designed, which accomplish the guidance and control of the UAV spiral. Simulation results and their analysis suggest that, compared with the existing strategies, the proposed control method can decrease the time needed for spiral recovery evidently and meanwhile has good dynamic response characteristics.	Air navigation; Aircraft control; Aneroid altimeters; Angle of attack; Angular velocity; Computer control systems; Computer simulation; Computer system recovery; Control; Control surfaces; Control theory; Damping; Data fusion; Decision making; Degrees of freedom (mechanics); Design; Drag coefficient; Dynamic response; Efficiency; Electronic guidance systems; Errors; Fixed wings; Flight control systems; Flight dynamics; Flight simulators; Free flight; Frequency bands; Global positioning system; Inertial navigation systems; Measurements; Navigation systems; Probability; Real time control; Real time systems; Recovery; Safety engineering; Scheduling; Sensors; Statistics; Time series; Tracking (position); Unmanned aerial vehicles (UAV); Vehicles; Velocity; Cognition; Control laws; Flight state; Nonlinear dynamic inversion; Safety controls; Spiral statistic adjudging; Controllers; Air navigation;  Aircraft control;  Aneroid altimeters;  Angle of attack;  Angular velocity;  Computer control systems;  Computer simulation;  Computer system recovery;  Control;  Control surfaces;  Control theory;  Damping;  Data fusion;  Decision making;  Degrees of freedom (mechanics);  Design;  Drag coefficient;  Dynamic response;  Efficiency;  Electronic guidance systems;  Errors;  Fixed wings;  Flight control systems;  Flight dynamics;  Flight simulators;  Free flight;  Frequency bands;  Global positioning system;  Inertial navigation systems;  Measurements;  Navigation systems;  Probability;  Real time control;  Real time systems;  Recovery;  Safety engineering;  Scheduling;  Sensors;  Statistics;  Time series;  Tracking (position);  Unmanned aerial vehicles (UAV);  Vehicles;  Velocity;  Cognition;  Control laws;  Flight state;  Nonlinear dynamic inversion;  Safety controls;  Spiral statistic adjudging;  Controllers	Huang, Hanqiao; Zhao, Xin; Zhou, Huan; Wang, Zutong	Xibei Gongye Daxue Xuebao/Journal of Northwestern Polytechnical University	https://www.scopus.com/record/display.uri?eid=2-s2.0-84954213963&origin=resultslist&sort=plf-f&src=s&sid=e318f778ebd70c029be2f9b1966b1c83&sot=b&sdt=b&s=TITLE-ABS-KEY%28autonomous+cognition+and+recovery+controller+design+of+uav+spiral%29&sl=80&sessionSearchId=e318f778ebd70c029be2f9b1966b1c83&relpos=0		879 - 886	"""@ARTICLE{Huang2015879,
    author = ""Huang, Hanqiao and Zhao, Xin and Zhou, Huan and Wang, Zutong"",
    title = ""Autonomous cognition and recovery controller design of UAV spiral"",
    year = ""2015"",
    journal = ""Xibei Gongye Daxue Xuebao/Journal of Northwestern Polytechnical University"",
    volume = ""33"",
    number = ""6"",
    pages = ""879 - 886"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954213963\&partnerID=40\&md5=936bb8b273f4cca1068d53267c6b6283"",
    affiliations = ""Aeronautics and Astronautics Engineering College, Air Force Engineering University, Xi'an, 710038, China; Northwestern Polytechnic University, Xi'an, 710038, China"",
    abstract = ""Aiming at dealing with the spiral recovery puzzle of aerial vehicles, we put forward an autonomous spiral cognition and recovery control method of the unmanned aerial vehicle(UAV). First of all, the safety control framework of unmanned aerial vehicles(UAV) based on flight state-cognition is built and the autonomous spiral cognition and recovery controller is designed. Then, the spiral factors are analyzed and the spiral state is recognized by using intuitive fuzzy statistic adjudging and decision-making algorithm according to timing flight variables information afforded by airborne sensors. Finally, the control scheduling of state variables is considered, and nonlinear dynamic inversion control laws are designed, which accomplish the guidance and control of the UAV spiral. Simulation results and their analysis suggest that, compared with the existing strategies, the proposed control method can decrease the time needed for spiral recovery evidently and meanwhile has good dynamic response characteristics. (c) 2015, Northwestern Polytechnical University. All right reserved."",
    author_keywords = ""Aneroid altimeters; Angle of attack; Angular velocity; Cognition; Computer simulation; Control; Control law; Control scheduling; Control surfaces; Controllers; Damping; Data fusion; Decision making; Degrees of freedom(mechanics); Design; Drag coefficient; Dynamic response; Efficiency; Electronic guidance systems; Errors; Fixed wings; Flight control systems; Flight state; Frequency bands; Global positioning system; Inertial navigation systems; Measurements; Nonlinear dynamic inversion(NDI); Probability; Real time control; Recovery; Safety control; Safety engineering; Scheduling; Sensors; Spiral statistic adjudging; Statistics; Time series; Unmanned aerial vehicles(UAV); Velocity"",
    keywords = ""Air navigation; Aircraft control; Aneroid altimeters; Angle of attack; Angular velocity; Computer control systems; Computer simulation; Computer system recovery; Control; Control surfaces; Control theory; Damping; Data fusion; Decision making; Degrees of freedom (mechanics); Design; Drag coefficient; Dynamic response; Efficiency; Electronic guidance systems; Errors; Fixed wings; Flight control systems; Flight dynamics; Flight simulators; Free flight; Frequency bands; Global positioning system; Inertial navigation systems; Measurements; Navigation systems; Probability; Real time control; Real time systems; Recovery; Safety engineering; Scheduling; Sensors; Statistics; Time series; Tracking (position); Unmanned aerial vehicles (UAV); Vehicles; Velocity; Cognition; Control laws; Flight state; Nonlinear dynamic inversion; Safety controls; Spiral statistic adjudging; Controllers"",
    publisher = ""Northwestern Polytechnical University"",
    issn = ""10002758"",
    coden = ""XGDUE"",
    language = ""Chinese"",
    abbrev_source_title = ""Xibei Gongye Daxue Xuebao"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 0""
}
"""	Excluded	Excluded	new_screen		Exclusion: not written in English	1	Scopus Signed In	2015	Autonomous cognition and recovery controller design of UAV spiral	https://www.scopus.com/record/display.uri?eid=2-s2.0-84954213963&origin=resultslist&sort=plf-f&src=s&sid=e318f778ebd70c029be2f9b1966b1c83&sot=b&sdt=b&s=TITLE-ABS-KEY%28autonomous+cognition+and+recovery+controller+design+of+uav+spiral%29&sl=80&sessionSearchId=e318f778ebd70c029be2f9b1966b1c83&relpos=0	Northwestern Polytechnical University	nan; References
53	TestNN	Cloud-Based Cyber-Physical Intrusion Detection for Vehicles Using Deep Learning	Detection of cyber attacks against vehicles is of growing interest. As vehicles typically afford limited processing resources, proposed solutions are rule-based or lightweight machine learning techniques. We argue that this limitation can be lifted with computational offloading commonly used for resource-constrained mobile devices. The increased processing resources available in this manner allow access to more advanced techniques. Using as case study a small four-wheel robotic land vehicle, we demonstrate the practicality and benefits of offloading the continuous task of intrusion detection that is based on deep learning. This approach achieves high accuracy much more consistently than with standard machine learning techniques and is not limited to a single type of attack or the in-vehicle CAN bus as previous work. As input, it uses data captured in real-time that relate to both cyber and physical processes, which it feeds as time series data to a neural network architecture. We use both a deep multilayer perceptron and recurrent neural network architecture, with the latter benefitting from a long-short term memory hidden layer, which proves very useful for learning the temporal context of different attacks. We employ denial of service, command injection and malware as examples of cyber attacks that are meaningful for a robotic vehicle. The practicality of computation offloading depends on the resources afforded onboard and remotely, and the reliability of the communication means between them. Using detection latency as the criterion, we have developed a mathematical model to determine when computation offloading is beneficial given parameters related to the operation of the network and the processing demands of the deep learning model. The more reliable the network and the greater the processing demands, the greater the reduction in detection latency achieved through offloading.	Robot sensing systems;Intrusion detection;Monitoring;Aircraft;Machine learning;Intrusion detection;machine learning;autonomous vehicles; Robot sensing systems; Intrusion detection; Monitoring; Aircraft; Machine learning; Intrusion detection; machine learning; autonomous vehicles	Loukas, George; Vuong, Tuan; Heartfield, Ryan; Sakellari, Georgia; Yoon, Yongpil; Gan, Diane	IEEE Access	https://doi.org/10.1109/ACCESS.2017.2782159		3491-3508	"""@ARTICLE{8171725,
    author = ""Loukas, George and Vuong, Tuan and Heartfield, Ryan and Sakellari, Georgia and Yoon, Yongpil and Gan, Diane"",
    journal = ""IEEE Access"",
    title = ""Cloud-Based Cyber-Physical Intrusion Detection for Vehicles Using Deep Learning"",
    year = ""2018"",
    volume = ""6"",
    number = """",
    pages = ""3491-3508"",
    abstract = ""Detection of cyber attacks against vehicles is of growing interest. As vehicles typically afford limited processing resources, proposed solutions are rule-based or lightweight machine learning techniques. We argue that this limitation can be lifted with computational offloading commonly used for resource-constrained mobile devices. The increased processing resources available in this manner allow access to more advanced techniques. Using as case study a small four-wheel robotic land vehicle, we demonstrate the practicality and benefits of offloading the continuous task of intrusion detection that is based on deep learning. This approach achieves high accuracy much more consistently than with standard machine learning techniques and is not limited to a single type of attack or the in-vehicle CAN bus as previous work. As input, it uses data captured in real-time that relate to both cyber and physical processes, which it feeds as time series data to a neural network architecture. We use both a deep multilayer perceptron and recurrent neural network architecture, with the latter benefitting from a long-short term memory hidden layer, which proves very useful for learning the temporal context of different attacks. We employ denial of service, command injection and malware as examples of cyber attacks that are meaningful for a robotic vehicle. The practicality of computation offloading depends on the resources afforded onboard and remotely, and the reliability of the communication means between them. Using detection latency as the criterion, we have developed a mathematical model to determine when computation offloading is beneficial given parameters related to the operation of the network and the processing demands of the deep learning model. The more reliable the network and the greater the processing demands, the greater the reduction in detection latency achieved through offloading."",
    keywords = ""Robot sensing systems;Intrusion detection;Monitoring;Aircraft;Machine learning;Intrusion detection;machine learning;autonomous vehicles"",
    doi = ""10.1109/ACCESS.2017.2782159"",
    ISSN = ""2169-3536"",
    month = """"
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	IEEE	2018	Cloud-Based Cyber-Physical Intrusion Detection for Vehicles Using Deep Learning	https://doi.org/10.1109/ACCESS.2017.2782159	IEEE	nan; References; Link
54	TestNN	DeepTest: Automated testing of deep-neural-network-driven autonomous cars	Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.	Accidents; Automatic test pattern generation; Automobile manufacture; Autonomous vehicles; Deep learning; Digital storage; Information dissemination; Neural networks; Rain; Software engineering; Tellurium compounds; Testing; Automatically generated; Driving conditions; Human intervention; Lighting conditions; Potentially fatal; Real world accidents; Systematic testing; Testing technique; Deep neural networks; Accidents;  Automatic test pattern generation;  Automobile manufacture;  Autonomous vehicles;  Deep learning;  Digital storage;  Information dissemination;  Neural networks;  Rain;  Software engineering;  Tellurium compounds;  Testing;  Automatically generated;  Driving conditions;  Human intervention;  Lighting conditions;  Potentially fatal;  Real world accidents;  Systematic testing;  Testing technique;  Deep neural networks	Jana, Suman; Tian, Yuchi; Pei, Kexin; Ray, Baishakhi	Proceedings - International Conference on Software Engineering	https://doi.org/10.1145/3180155.3180220		303-314	"""@CONFERENCE{Jana2018,
    author = ""Jana, Suman and Tian, Yuchi and Pei, Kexin and Ray, Baishakhi"",
    title = ""DeepTest: Automated testing of deep-neural-network-driven autonomous cars"",
    year = ""2018"",
    journal = ""Proceedings - International Conference on Software Engineering"",
    volume = ""2018-May"",
    doi = ""10.1145/3180155.3180220"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069772253\&doi=10.1145\%2f3180155.3180220\&partnerID=40\&md5=bd81c43f9e437a21d2524b38678cb67f"",
    affiliations = ""Columbia University, United States; University of Virginia, United States"",
    abstract = ""Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge. (c) 2018 Association for Computing Machinery."",
    author_keywords = ""Autonomous vehicle; Deep learning; Deep neural networks; Neuron coverage; Self-driving cars; Testing"",
    keywords = ""Accidents; Automatic test pattern generation; Automobile manufacture; Autonomous vehicles; Deep learning; Digital storage; Information dissemination; Neural networks; Rain; Software engineering; Tellurium compounds; Testing; Automatically generated; Driving conditions; Human intervention; Lighting conditions; Potentially fatal; Real world accidents; Systematic testing; Testing technique; Deep neural networks"",
    publisher = ""IEEE Computer Society"",
    issn = ""02705257"",
    isbn = ""978-145035663-3"",
    coden = ""PCSED"",
    language = ""English"",
    abbrev_source_title = ""Proc Int Conf Software Eng"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 882; Conference name: 40th International Conference on Software Engineering, ICSE 2018; Conference date: 27 May 2018 through 3 June 2018; Conference code: 137142; All Open Access, Bronze Open Access""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	DeepTest: Automated testing of deep-neural-network-driven autonomous cars	https://www.scopus.com/record/display.uri?eid=2-s2.0-85069772253&origin=resultslist&sort=plf-f&src=s&sid=1fbf40ceb6f60b02ebbf39a06a61b367&sot=b&sdt=b&s=TITLE-ABS-KEY%28deeptest+automated+testing+of+deep+neural+network+driven+autonomous+cars%29&sl=87&sessionSearchId=1fbf40ceb6f60b02ebbf39a06a61b367&relpos=0	IEEE Computer Society	nan; References
55	TestNN	Distilling a neural network into a soft decision tree	Deep neural networks have proved to be a very e ective way to perform classification tasks. They excel when the input data is high dimensional, the relationship between the input and the output is complicated, and the number of labeled training examples is large [Szegedy et al., 2015, Wu et al., 2016, Jozefowicz et al., 2016, Graves et al., 2013]. But it is hard to explain why a learned network makes a particular classification decision on a particular test case. This is due to their reliance on distributed hierarchical representations. If we could take the knowledge acquired by the neural net and express the same knowledge in a model that relies on hierarchical decisions instead, explaining a particular decision would be much easier. We describe a way of using a trained neural net to create a type of soft decision tree that generalizes better than one learned directly from the training data.	Decision trees; Deep neural networks; Trees (mathematics); Classification decision; Classification tasks; Hierarchical decisions; Hierarchical representation; High-dimensional; Soft decision; Training data; Training example; Neural networks; Decision trees;  Deep neural networks;  Trees (mathematics);  Classification decision;  Classification tasks;  Hierarchical decisions;  Hierarchical representation;  High-dimensional;  Soft decision;  Training data;  Training example;  Neural networks	Frosst, Nicholas; Hinton, Geo rey	CEUR Workshop Proceedings	https://www.scopus.com/record/display.uri?eid=2-s2.0-85045439769&origin=resultslist&sort=plf-f&src=s&sid=7ede30158a89625a2d0e731fe899257a&sot=b&sdt=b&s=TITLE%28Distilling+a+Neural+Network+Into+a+Soft+Decision+Tree%29&sl=60&sessionSearchId=7ede30158a89625a2d0e731fe899257a&relpos=0			"""@CONFERENCE{Frosst2018,
    author = ""Frosst, Nicholas and Hinton, Geo rey"",
    editor = ""O., Kutz and T.R., Besold"",
    title = ""Distilling a neural network into a soft decision tree"",
    year = ""2018"",
    journal = ""CEUR Workshop Proceedings"",
    volume = ""2071"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045439769\&partnerID=40\&md5=d68db18b132ae555e8babf5608514fb9"",
    affiliations = ""Google Brain Team, United States"",
    abstract = ""Deep neural networks have proved to be a very e ective way to perform classification tasks. They excel when the input data is high dimensional, the relationship between the input and the output is complicated, and the number of labeled training examples is large [Szegedy et al., 2015, Wu et al., 2016, Jozefowicz et al., 2016, Graves et al., 2013]. But it is hard to explain why a learned network makes a particular classification decision on a particular test case. This is due to their reliance on distributed hierarchical representations. If we could take the knowledge acquired by the neural net and express the same knowledge in a model that relies on hierarchical decisions instead, explaining a particular decision would be much easier. We describe a way of using a trained neural net to create a type of soft decision tree that generalizes better than one learned directly from the training data. Copyright (c) 2018 for this paper by its authors. Copying permitted for private and academic purposes."",
    keywords = ""Decision trees; Deep neural networks; Trees (mathematics); Classification decision; Classification tasks; Hierarchical decisions; Hierarchical representation; High-dimensional; Soft decision; Training data; Training example; Neural networks"",
    publisher = ""CEUR-WS"",
    issn = ""16130073"",
    language = ""English"",
    abbrev_source_title = ""CEUR Workshop Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 19; Conference name: 1st International Workshop on Comprehensibility and Explanation in AI and ML, CEX 2017; Conference date: 16 November 2017 through 17 November 2017; Conference code: 135275""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	Distilling a Neural Network Into a Soft Decision Tree	https://www.scopus.com/record/display.uri?eid=2-s2.0-85045439769&origin=resultslist&sort=plf-f&src=s&sid=7ede30158a89625a2d0e731fe899257a&sot=b&sdt=b&s=TITLE%28Distilling+a+Neural+Network+Into+a+Soft+Decision+Tree%29&sl=60&sessionSearchId=7ede30158a89625a2d0e731fe899257a&relpos=0	CEUR-WS	nan; References; Pages
56	TestNN	Exploring Strategies for Training Deep Neural Networks	Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms.		Larochelle, Hugo; Bengio, Yoshua; Louradour, J\'{e}r\^{o}me; Lamblin, Pascal	J. Mach. Learn. Res.	https://doi.org/10.5555/1577069.1577070		1-40	"""@article{10.5555/1577069.1577070,
    author = ""Larochelle, Hugo and Bengio, Yoshua and Louradour, J\'{e}r\^{o}me and Lamblin, Pascal"",
    title = ""Exploring Strategies for Training Deep Neural Networks"",
    year = ""2009"",
    issue_date = ""12/1/2009"",
    publisher = ""JMLR.org"",
    volume = ""10"",
    issn = ""1532-4435"",
    abstract = ""Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms."",
    journal = ""J. Mach. Learn. Res."",
    month = ""jun"",
    pages = ""1-40"",
    numpages = ""40""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	Scopus Signed In	2009	Exploring Strategies for Training Deep Neural Networks	https://dl.acm.org/doi/10.5555/1577069.1577070	JMLR.org	nan; Keywords; References
57	TestNN	Failing to Learn: Autonomously Identifying Perception Failures for Self-Driving Cars	One of the major open challenges in self-driving cars is the ability to detect cars and pedestrians to safely navigate in the world. Deep learning-based object detector approaches have enabled great advances in using camera imagery to detect and classify objects. But for a safety critical application, such as autonomous driving, the error rates of the current state of the art are still too high to enable safe operation. Moreover, the characterization of object detector performance is primarily limited to testing on prerecorded datasets. Errors that occur on novel data go undetected without additional human labels. In this letter, we propose an automated method to identify mistakes made by object detectors without ground truth labels. We show that inconsistencies in the object detector output between a pair of similar images can be used as hypotheses for false negatives (e.g., missed detections) and using a novel set of features for each hypothesis, an off-the-shelf binary classifier can be used to find valid errors. In particular, we study two distinct cues-temporal and stereo inconsistencies--using data that are readily available on most autonomous vehicles. Our method can be used with any camera-based object detector and we illustrate the technique on several sets of real world data. We show that a state-of-the-art detector, tracker, and our classifier trained only on synthetic data can identify valid errors on KITTI tracking dataset with an average precision of 0.94. We also release a new tracking dataset with 104 sequences totaling 80,655 labeled pairs of stereo images along with ground truth disparity from a game engine to facilitate further research.	Detectors;Cameras;Object recognition;Autonomous automobiles;Object detection;Autonomous vehicles;Testing;Computer vision for transportation;object detection;segmentation and categorization;visual learning; Detectors; Cameras; Object recognition; Autonomous automobiles; Object detection; Autonomous vehicles; Testing; Computer vision for transportation; object detection; segmentation and categorization; visual learning	Ramanagopal, Manikandasriram Srinivasan; Anderson, Cyrus; Vasudevan, Ram; Johnson-Roberson, Matthew	IEEE Robotics and Automation Letters	https://doi.org/10.1109/LRA.2018.2857402		3860-3867	"""@ARTICLE{8412512,
    author = ""Ramanagopal, Manikandasriram Srinivasan and Anderson, Cyrus and Vasudevan, Ram and Johnson-Roberson, Matthew"",
    journal = ""IEEE Robotics and Automation Letters"",
    title = ""Failing to Learn: Autonomously Identifying Perception Failures for Self-Driving Cars"",
    year = ""2018"",
    volume = ""3"",
    number = ""4"",
    pages = ""3860-3867"",
    abstract = ""One of the major open challenges in self-driving cars is the ability to detect cars and pedestrians to safely navigate in the world. Deep learning-based object detector approaches have enabled great advances in using camera imagery to detect and classify objects. But for a safety critical application, such as autonomous driving, the error rates of the current state of the art are still too high to enable safe operation. Moreover, the characterization of object detector performance is primarily limited to testing on prerecorded datasets. Errors that occur on novel data go undetected without additional human labels. In this letter, we propose an automated method to identify mistakes made by object detectors without ground truth labels. We show that inconsistencies in the object detector output between a pair of similar images can be used as hypotheses for false negatives (e.g., missed detections) and using a novel set of features for each hypothesis, an off-the-shelf binary classifier can be used to find valid errors. In particular, we study two distinct cues-temporal and stereo inconsistencies--using data that are readily available on most autonomous vehicles. Our method can be used with any camera-based object detector and we illustrate the technique on several sets of real world data. We show that a state-of-the-art detector, tracker, and our classifier trained only on synthetic data can identify valid errors on KITTI tracking dataset with an average precision of 0.94. We also release a new tracking dataset with 104 sequences totaling 80,655 labeled pairs of stereo images along with ground truth disparity from a game engine to facilitate further research."",
    keywords = ""Detectors;Cameras;Object recognition;Autonomous automobiles;Object detection;Autonomous vehicles;Testing;Computer vision for transportation;object detection;segmentation and categorization;visual learning"",
    doi = ""10.1109/LRA.2018.2857402"",
    ISSN = ""2377-3766"",
    month = ""Oct""
}
"""	Included	Included	new_screen			1	IEEE	2017	Failing to learn: autonomously identifying perception failures for self-driving cars [arXiv]	https://doi.org/10.1109/LRA.2018.2857402	IEEE	nan; References; Link
58	TestNN	Feature-Guided Black-Box Safety Testing of Deep Neural Networks	Despite the improved accuracy of deep neural networks, the discovery of adversarial examples has raised serious safety concerns. Most existing approaches for crafting adversarial examples necessitate some knowledge (architecture, parameters, etc) of the network at hand. In this paper, we focus on image classifiers and propose afeature-guidedblack-box approach to test the safety of deep neural networks that requires no such knowledge. Our algorithm employs object detection techniques such as SIFT (Scale Invariant Feature Transform) to extract features from an image. These features are converted into a mutable saliency distribution, where high probability is assigned to pixels that affect the composition of the image with respect to the human visual system. We formulate the crafting of adversarial examples as a two-player turn-based stochastic game, where the first player's objective is to minimise the distance to an adversarial example by manipulating the features, and the second player can be cooperative, adversarial, or random. We show that, theoretically, the two-player game can converge to the optimal strategy, and that the optimal strategy represents a globally minimal adversarial image. For Lipschitz networks, we also identify conditions that provide safety guarantees that no adversarial examples exist. Using Monte Carlo tree search we gradually explore the game state space to search for adversarial examples. Our experiments show that, despite the black-box setting, manipulations guided by a perception-based saliency distribution are competitive with state-of-the-art methods that rely on white-box saliency matrices or sophisticated optimization procedures. Finally, we show how our method can be used to evaluate robustness of neural networks in safety-critical applications such as traffic sign recognition in self-driving cars.	Deep Neural Networks; Adversarial Examples; Monte Carlo Tree Search (MCTS); Scale Invariant Feature Transform (SIFT); Saliency Distribution	Matthew Wicker; Xiaowei Huang; Marta Kwiatkowska	International Conference on Tools and Algorithms for the Construction and Analysis of Systems	https://doi.org/10.1007/978-3-319-89960-2_22		408-426		Included	Included	new_screen			1	Springer Link	2018	Feature-guided black-box safety testing of deep neural networks	https://doi.org/10.1007/978-3-319-89960-2_22	Springer, Cham	nan; References; Year; Bibtex; Link
59	TestNN	Formal verification of autonomous vehicle platooning	"The coordination of multiple autonomous vehicles into convoys or platoons is expected on our highways in the near future. However, before such platoons can be deployed, the behaviours of the vehicles in these platoons must be certified. This is non-trivial and goes beyond current certification requirements, for human-controlled vehicles, in that these vehicles can act autonomously. In this paper, we show how formal verification can contribute to the analysis of these new, and increasingly autonomous, systems. An appropriate overall representation for vehicle platooning is as a multi-agent system in which each agent captures the ""autonomous decisions"" carried out by each vehicle. In order to ensure that these autonomous decision-making agents in vehicle platoons never violate safety requirements, we use formal verification. However, as the formal verification technique used to verify the individual agent's code does not scale to the full system, and as the global system verification technique does not capture the essential verification of autonomous behaviour, we use a combination of the two approaches. This mixed strategy allows us to verify safety requirements not only of a model of the system, but of the actual agent code used to program the autonomous vehicles."	Vehicle platooning;  Agent programming;  Model checking; Vehicle platooning, Agent programming, Model checking	Kamali, Maryam; Dennis, Louise A.; McAree, Owen; Fisher, Michael; Veres, Sandor M.	Science of Computer Programming			88-106	"""@article{KAMALI201788,
    author = ""Kamali, Maryam and Dennis, Louise A. and McAree, Owen and Fisher, Michael and Veres, Sandor M."",
    title = ""Formal verification of autonomous vehicle platooning"",
    journal = ""Science of Computer Programming"",
    volume = ""148"",
    pages = ""88-106"",
    year = ""2017"",
    note = ""Special issue on Automated Verification of Critical Systems (AVoCS 2015)"",
    issn = ""0167-6423"",
    doi = ""https://doi.org/10.1016/j.scico.2017.05.006"",
    url = ""https://www.sciencedirect.com/science/article/pii/S0167642317301168"",
    keywords = ""Vehicle platooning, Agent programming, Model checking"",
    abstract = ""The coordination of multiple autonomous vehicles into convoys or platoons is expected on our highways in the near future. However, before such platoons can be deployed, the behaviours of the vehicles in these platoons must be certified. This is non-trivial and goes beyond current certification requirements, for human-controlled vehicles, in that these vehicles can act autonomously. In this paper, we show how formal verification can contribute to the analysis of these new, and increasingly autonomous, systems. An appropriate overall representation for vehicle platooning is as a multi-agent system in which each agent captures the ""autonomous decisions"" carried out by each vehicle. In order to ensure that these autonomous decision-making agents in vehicle platoons never violate safety requirements, we use formal verification. However, as the formal verification technique used to verify the individual agent's code does not scale to the full system, and as the global system verification technique does not capture the essential verification of autonomous behaviour, we use a combination of the two approaches. This mixed strategy allows us to verify safety requirements not only of a model of the system, but of the actual agent code used to program the autonomous vehicles.""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Science Direct	2017	Formal verification of autonomous vehicle platooning		Science Direct	nan; References; Link
60	TestNN	Game theoretic modeling of driver and vehicle interactions for verification and validation of autonomous vehicle control systems	Autonomous driving has been the subject of increased interest in recent years both in industry and in academia. Serious efforts are being pursued to address legal, technical, and logistical problems and make autonomous cars a viable option for everyday transportation. One significant challenge is the time and effort required for the verification and validation of the decision and control algorithms employed in these vehicles to ensure a safe and comfortable driving experience. Hundreds of thousands of miles of driving tests are required to achieve a well calibrated control system that is capable of operating an autonomous vehicle in an uncertain traffic environment where interactions among multiple drivers and vehicles occur simultaneously. Traffic simulators where these interactions can be modeled and represented with reasonable fidelity can help to decrease the time and effort necessary for the development of the autonomous driving control algorithms by providing a venue where acceptable initial control calibrations can be achieved quickly and safely before actual road tests. In this paper, we present a game theoretic traffic model that can be used to: 1) test and compare various autonomous vehicle decision and control systems and 2) calibrate the parameters of an existing control system. We demonstrate two example case studies, where, in the first case, we test and quantitatively compare two autonomous vehicle control systems in terms of their safety and performance, and, in the second case, we optimize the parameters of an autonomous vehicle control system, utilizing the proposed traffic model and simulation environment.	Control system synthesis; Game theory; Reinforcement learning; Vehicle actuated signals; Autonomous vehicle control; Autonomous Vehicles; Decision and control algorithms; Game-theoretic model; Logistical problems; Traffic model; Vehicle interactions; Verification-and-validation; Vehicles; Control system synthesis;  Game theory;  Reinforcement learning;  Vehicle actuated signals;  Autonomous vehicle control;  Autonomous Vehicles;  Decision and control algorithms;  Game-theoretic model;  Logistical problems;  Traffic model;  Vehicle interactions;  Verification-and-validation;  Vehicles	Li, Nan; Oyler, Dave W.; Zhang, Mengxuan; Yildiz, Yildiray; Kolmanovsky, Ilya; Girard, Anouck R.	IEEE Transactions on Control Systems Technology	https://doi.org/10.1109/TCST.2017.2723574	"1.M. Campbell, M. Egerstedt, J. P. How and R. M. Murray, ""Autonomous driving in urban environments: Approaches lessons and challenges"", Philos. Trans. Roy. Soc. London A Math. Phys. Sci., vol. 368, no. 1928, pp. 4649-4672, 2010. CrossRef  Google Scholar; 2.J. M. Anderson, K. Nidhi, K. D. Stanley, P. Sorensen, C. Samaras and O. A. Oluwatola, Autonomous Vehicle Technology: A Guide for Policymakers, Santa Monica, CA, USA:Rand Corporation, 2014. Google Scholar; 3.N. Kalra, ""With driverless cars how safe is safe enough?"", 2016,  [online]  Available: http://www.rand.org/blog/2016/02/with-driverless-cars-how-safe-is-safe-enough.html. Google Scholar; 4.T. Wongpiromsarn and R. M. Murray, ""Formal verification of an autonomous vehicle system"", Proc. Conf. Decision Control, 2008. Google Scholar; 5.T. Wongpiromsarn, S. Mitra, R. M. Murray and A. Lamperski, ""Periodically controlled hybrid systems: Verifying a controller for an autonomous vehicle"", Proc. HSCC, 2008. CrossRef  Google Scholar; 6.J. Lygeros, D. N. Godbole and S. Sastry, ""Verified hybrid controllers for automated vehicles"", IEEE Trans. Autom. Control, vol. 43, no. 4, pp. 522-539, Apr. 1998. View Article  Google Scholar; 7.M. Althoff and J. M. Dolan, ""Online verification of automated road vehicles using reachability analysis"", IEEE Trans. Robot., vol. 30, no. 4, pp. 903-918, Aug. 2014. View Article  Google Scholar; 8.A. Carvalho, S. Lefevre, G. Schildbach, J. Kong and F. Borrelli, ""Automated driving: The role of forecasts and uncertainty--A control perspective"", Eur. J. Control, vol. 24, pp. 14-32, Jul. 2015. CrossRef  Google Scholar; 9.I. Miller et al., ""Team Cornell's Skynet: Robust perception and planning in an urban environment"", J. Field Robot., vol. 25, no. 8, pp. 493-527, 2008. CrossRef  Google Scholar; 10.L. Claussman, A. Carvalho and G. Schildbach, ""A path planner for autonomous driving on highways using a human mimicry approach with binary decision diagrams"", Proc. Eur. Control Conf., pp. 2976-2982, Jul. 2015. View Article  Google Scholar; 11.S. Brechtel, T. Gindele and R. Dillmann, ""Probabilistic decision-making under uncertainty for autonomous driving using continuous POMDPs"", Proc. IEEE 17th Int. Conf. Intell. Transp. Syst. (ITSC), pp. 392-399, Oct. 2014. View Article  Google Scholar; 12.E. Galceran, A. G. Cunningham, R. M. Eustice and E. Olson, ""Multipolicy decision-making for autonomous driving via changepoint-based behavior prediction: Theory and experiment"", Robot. Sci. Syst., vol. 41, no. 6, pp. 1367-1382, 2015. CrossRef  Google Scholar; 13.P. Falcone, F. Borrelli, J. Asgari, H. E. Tseng and D. Hrovat, ""Predictive active steering control for autonomous vehicle systems"", IEEE Trans. Control Syst. Technol., vol. 15, no. 3, pp. 566-580, May 2007. View Article  Google Scholar; 14.A. Carvalho, Y. Gao, A. Gray, H. E. Tseng and F. Borrelli, ""Predictive control of an autonomous ground vehicle using an iterative linearization approach"", Proc. 16th Int. IEEE Conf. Intell. Transp. Syst. (ITSC), pp. 2335-2340, Oct. 2013. View Article  Google Scholar; 15.J. H. Yoo and R. Langari, ""Stackelberg game based model of highway driving"", Proc. ASME 5th Annu. Dyn. Syst. Control Conf. Joint JSME 11th Motion Vibrat. Conf., pp. 499-508, 2012. CrossRef  Google Scholar; 16.J. H. Yoo and R. Langari, ""A Stackelberg game theoretic driver model for merging"", Proc. ASME Dyn. Syst. Control Conf., pp. V002T30A003, 2013. CrossRef  Google Scholar; 17.S. Lefevre, Y. Gao, D. Vasquez, H. E. Tseng, R. Bajcsy and F. Borrelli, ""Lane keeping assistance with learning-based driver model and model predictive control"", Proc. 12th Int. Symp. Adv. Vehicle Control, 2014. Google Scholar; 18.S. Lefevre, A. Carvalho and F. Borrelli, ""Autonomous car following: A learning-based approach"", Proc. IEEE Intell. Vehicles Symp. (IV), pp. 920-926, Jun./Jul. 2015. View Article  Google Scholar; 19.R. Vasudevan, V. Shia, Y. Gao, R. Cervera-Navarro, R. Bajcsy and F. Borrelli, ""Safe semi-autonomous control with enhanced driver modeling"", Proc. Amer. Control Conf. (ACC), pp. 2896-2903, Jun. 2012. View Article  Google Scholar; 20.V. A. Shia et al., ""Semiautonomous vehicular control using driver modeling"", IEEE Trans. Intell. Transp. Syst., vol. 15, no. 6, pp. 2696-2709, Dec. 2014. View Article  Google Scholar; 21.D. Salvucci, E. Boer and A. Liu, ""Toward an integrated model of driver behavior in cognitive architecture"", Transp. Res. Rec. J. Transp. Res. Board, vol. 1779, pp. 9-16, 2001. CrossRef  Google Scholar; 22.P. Hidas, ""Modelling lane changing and merging in microscopic traffic simulation"", Transp. Res. C Emerg. Technol., vol. 10, no. 5, pp. 351-371, Oct./Dec. 2002. CrossRef  Google Scholar; 23.D. Sadigh, S. Sastry, S. A. Seshia and A. D. Dragan, ""Planning for autonomous cars that leverage effects on human actions"", Proc. Robot. Sci. Syst. Conf. (RSS), 2016. CrossRef  Google Scholar; 24.R. Lee and D. Wolpert, ""Game theoretic modeling of pilot behavior during mid-air encounters"" in Decision Making with Imperfect Decision Makers, Heidelberg, Germany:Springer, pp. 75-111, 2012. CrossRef  Google Scholar; 25.S. Backhaus et al., ""Cyber-physical security: A game theory model of humans interacting over control systems"", IEEE Trans. Smart Grid, vol. 4, no. 4, pp. 2320-2327, Dec. 2013. View Article  Google Scholar; 26.C. Dextreit and I. V. Kolmanovsky, ""Game theory controller for hybrid electric vehicles"", IEEE Trans. Control Syst. Technol., vol. 22, no. 2, pp. 652-663, Mar. 2014. View Article  Google Scholar; 27.Y. Yildiz, A. Agogino and G. Brat, ""Predicting pilot behavior in medium-scale scenarios using game theory and reinforcement learning"", J. Guid. Control Dyn., vol. 37, no. 4, pp. 1335-1343, 2014. CrossRef  Google Scholar; 28.N. Musavi, D. Onural, K. Gunes and Y. Yildiz, ""Unmanned aircraft systems airspace integration: A game theoretical framework for concept evaluations"", J. Guid. Control Dyn., vol. 40, no. 1, pp. 96-109, 2016. CrossRef  Google Scholar; 29.D. W. Oyler, Y. Yildiz, A. R. Girard, N. I. Li and I. V. Kolmanovsky, ""A game theoretical model of traffic with multiple interacting drivers for use in autonomous vehicle development"", Proc. IEEE Amer. Control Conf. (ACC), pp. 1705-1710, Jul. 2016. View Article  Google Scholar; 30.N. Li, D. Oyler, M. Zhang, Y. Yildiz, A. Girard and I. Kolmanovsky, ""Hierarchical reasoning game theory based approach for evaluation and testing of autonomous vehicle control systems"", Proc. IEEE 55th Conf. Decision Control (CDC), pp. 727-733, Dec. 2016. View Article  Google Scholar"	1782 - 1797	"""@ARTICLE{Li20181782,
    author = ""Li, Nan and Oyler, Dave W. and Zhang, Mengxuan and Yildiz, Yildiray and Kolmanovsky, Ilya and Girard, Anouck R."",
    title = ""Game theoretic modeling of driver and vehicle interactions for verification and validation of autonomous vehicle control systems"",
    year = ""2018"",
    journal = ""IEEE Transactions on Control Systems Technology"",
    volume = ""26"",
    number = ""5"",
    pages = ""1782 - 1797"",
    doi = ""10.1109/TCST.2017.2723574"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028916873\&doi=10.1109\%2fTCST.2017.2723574\&partnerID=40\&md5=886568f3ecc536e5329fc3b743b980a4"",
    affiliations = ""Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109, MI, United States; Department of Mechanical Engineering, Bilkent University, Ankara, 06800, Turkey"",
    abstract = ""Autonomous driving has been the subject of increased interest in recent years both in industry and in academia. Serious efforts are being pursued to address legal, technical, and logistical problems and make autonomous cars a viable option for everyday transportation. One significant challenge is the time and effort required for the verification and validation of the decision and control algorithms employed in these vehicles to ensure a safe and comfortable driving experience. Hundreds of thousands of miles of driving tests are required to achieve a well calibrated control system that is capable of operating an autonomous vehicle in an uncertain traffic environment where interactions among multiple drivers and vehicles occur simultaneously. Traffic simulators where these interactions can be modeled and represented with reasonable fidelity can help to decrease the time and effort necessary for the development of the autonomous driving control algorithms by providing a venue where acceptable initial control calibrations can be achieved quickly and safely before actual road tests. In this paper, we present a game theoretic traffic model that can be used to: 1) test and compare various autonomous vehicle decision and control systems and 2) calibrate the parameters of an existing control system. We demonstrate two example case studies, where, in the first case, we test and quantitatively compare two autonomous vehicle control systems in terms of their safety and performance, and, in the second case, we optimize the parameters of an autonomous vehicle control system, utilizing the proposed traffic model and simulation environment. (c) 1993-2012 IEEE."",
    author_keywords = ""Autonomous vehicles; game theory; reinforcement learning (RL); traffic modeling; verification and validation (V\&V)"",
    keywords = ""Control system synthesis; Game theory; Reinforcement learning; Vehicle actuated signals; Autonomous vehicle control; Autonomous Vehicles; Decision and control algorithms; Game-theoretic model; Logistical problems; Traffic model; Vehicle interactions; Verification-and-validation; Vehicles"",
    correspondence_address = ""N. Li; Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109, United States; email: nanli@umich.edu"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""10636536"",
    coden = ""IETTE"",
    language = ""English"",
    abbrev_source_title = ""IEEE Trans Control Syst Technol"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 184; All Open Access, Bronze Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2017	Game Theoretic Modeling of Driver and Vehicle Interactions for Verification and Validation of Autonomous Vehicle Control Systems	https://www.scopus.com/record/display.uri?eid=2-s2.0-85028916873&origin=resultslist&sort=plf-f&src=s&sid=2c5c7fa0c98a8e21cd4c8abbfa58fa20&sot=b&sdt=b&s=TITLE-ABS-KEY%28game+theoretic+modeling+of+driver+and+vehicle+interactions+for+verification+and+validation+of+autonomous+vehicle+control+systems%29&sl=143&sessionSearchId=2c5c7fa0c98a8e21cd4c8abbfa58fa20&relpos=0	Institute of Electrical and Electronics Engineers Inc	
61	TestNN	Measurement of autonomous operation	"While robotic systems and the field of Artificial Intelligence (AI) have been funded through the Department Of Defense (DoD) and Industry for decades, it was not until recent years that the combination of these two technologies has made truly significant advances in the area of Autonomous Operation (AO) systems. Through the efforts of the Defense Advanced Research Project Agency (DARPA) challenges in 2004--2007 timeframe, the academic and industrial communities came together to overcome some significant hurdles for the development of AO ground vehicles in both the rural and desert environments (DARPA Grand Challenge 2004--2005) and the urban environment (DARPA Urban Challenge 2007). Although no AO vehicle succeeded in the 2004 event, the following year four systems completed the 132 mile course within the 10 hour time limit. The winner of the 2005 event (The Stanley from Stanford University) designed an autonomous (learning system) vehicle that fused five Lidars, Radar, and an Electro Optic sensor in addition to the waypoint GPS (provided by DARPA) and an internal Inertial Measurement Unit (IMU) system to produce the situational awareness required to meet the challenge. The team took approximately one year ""training"" the perception and planning sections of the software to compensate for various types of terrain and maneuvering. It was through extensive planning, meticulous design, and thorough testing that the final goal was achieved and it will take a much greater level of effort for DoD to realize a similar capability in the air environment.In the Air domain, DoD will not have the luxury of releasing autonomous vehicles (without significant constraints) within an operationally relevant environment (like the National Air Space (NAS)) until a very high level of confidence is achieved in their ability to perform the mission while providing a level of safety commensurate with manned operation. For DoD to succeed, it is imperative that we provide the Unmanned Air System (UAS) development community the tools required to assess all of the engineering components necessary for transition of AO vehicles into the NAS and operational environments. These tools should include a model of the required environments (emulated with access to standardized hardware/software in the loop), standard set of operational test procedures (with desired metrics), and a framework through which individual components can be assessed. It is ironic that the success of AO unmanned systems will require a structured collaborative learning process within the human domain for our goals to be realized."	C4ISR;  automated decision aid (ADA);  autonomous control;  autonomous operations;  unmanned aerial system; C4ISR, automated decision aid (ADA), autonomous control, autonomous operations, unmanned aerial system	Hamel, W.	PerMIS '10: Proceedings of the 10th Performance Metrics for Intelligent Systems Workshop	https://doi.org/10.1145/2377576.2377598		112-118	"""@inproceedings{10.1145/2377576.2377598,
    author = ""Hamel, W."",
    title = ""Measurement of autonomous operation"",
    year = ""2010"",
    isbn = ""9781450302906"",
    publisher = ""Association for Computing Machinery"",
    address = ""New York, NY, USA"",
    url = ""https://doi.org/10.1145/2377576.2377598"",
    doi = ""10.1145/2377576.2377598"",
    abstract = {While robotic systems and the field of Artificial Intelligence (AI) have been funded through the Department Of Defense (DoD) and Industry for decades, it was not until recent years that the combination of these two technologies has made truly significant advances in the area of Autonomous Operation (AO) systems. Through the efforts of the Defense Advanced Research Project Agency (DARPA) challenges in 2004--2007 timeframe, the academic and industrial communities came together to overcome some significant hurdles for the development of AO ground vehicles in both the rural and desert environments (DARPA Grand Challenge 2004--2005) and the urban environment (DARPA Urban Challenge 2007). Although no AO vehicle succeeded in the 2004 event, the following year four systems completed the 132 mile course within the 10 hour time limit. The winner of the 2005 event (The Stanley from Stanford University) designed an autonomous (learning system) vehicle that fused five Lidars, Radar, and an Electro Optic sensor in addition to the waypoint GPS (provided by DARPA) and an internal Inertial Measurement Unit (IMU) system to produce the situational awareness required to meet the challenge. The team took approximately one year ""training"" the perception and planning sections of the software to compensate for various types of terrain and maneuvering. It was through extensive planning, meticulous design, and thorough testing that the final goal was achieved and it will take a much greater level of effort for DoD to realize a similar capability in the air environment.In the Air domain, DoD will not have the luxury of releasing autonomous vehicles (without significant constraints) within an operationally relevant environment (like the National Air Space (NAS)) until a very high level of confidence is achieved in their ability to perform the mission while providing a level of safety commensurate with manned operation. For DoD to succeed, it is imperative that we provide the Unmanned Air System (UAS) development community the tools required to assess all of the engineering components necessary for transition of AO vehicles into the NAS and operational environments. These tools should include a model of the required environments (emulated with access to standardized hardware/software in the loop), standard set of operational test procedures (with desired metrics), and a framework through which individual components can be assessed. It is ironic that the success of AO unmanned systems will require a structured collaborative learning process within the human domain for our goals to be realized.},
    booktitle = ""Proceedings of the 10th Performance Metrics for Intelligent Systems Workshop"",
    pages = ""112-118"",
    numpages = ""7"",
    keywords = ""C4ISR, automated decision aid (ADA), autonomous control, autonomous operations, unmanned aerial system"",
    location = ""Baltimore, Maryland"",
    series = ""PerMIS '10""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	Scopus Signed In	2010	Measurement of autonomous operation	https://dl.acm.org/doi/10.1145/2377576.2377598	Association for Computing Machinery	nan; References
62	TestNN	Micro-simulation model for assessing the risk of vehicle-pedestrian road accidents	Data on traffic accidents clearly point to road black spots, where the accident rate is always high. However, road safety research is still far from understanding why these particular places on a road are risky. The reason is the lack of sufficient knowledge on how pedestrians and drivers interact when facing a potentially dangerous traffic situation, and the lack of an integrated framework that relates the data on human behavior to real-world traffic situations. We attempt to tackle this problem by developing SAFEPED, a multi-agent microscopic three-dimensional (3D) simulation of vehicle and pedestrian dynamics at a black spot. SAFEPED is a test platform for evaluating experimentally estimated drivers and pedestrians behavioral rules, and estimating accident risks in different traffic situations. It aims to analyze the design of existing and future black spots and to assess alternative architectural and environmental solutions in order to identify maximally efficient safety countermeasures.	Behavioral research; Computational methods; Computer simulation; Motor transportation; Multi agent systems; Pedestrian safety; Risk assessment; Risk perception; Roads and streets; Agent-based model; Black spot; Integrated frameworks; Microsimulation models; Pedestrian dynamics; Safety countermeasures; Spatially explicit modeling; Three-dimensional (3-D) simulation; accident; numerical model; optimization; road transport; simulation; traffic management; transportation safety; transportation system; Highway accidents; Behavioral research;  Computational methods;  Computer simulation;  Motor transportation;  Multi agent systems;  Pedestrian safety;  Risk assessment;  Risk perception;  Roads and streets;  Agent-based model;  Black spot;  Integrated frameworks;  Microsimulation models;  Pedestrian dynamics;  Safety countermeasures;  Spatially explicit modeling;  Three-dimensional (3-D) simulation;  accident;  numerical model;  optimization;  road transport;  simulation;  traffic management;  transportation safety;  transportation system;  Highway accidents	Waizman, Gennady; Shoval, Shraga; Benenson, Itzhak	Journal of Intelligent Transportation Systems: Technology, Planning, and Operations	https://doi.org/10.1080/15472450.2013.856721		63 - 77	"""@ARTICLE{Waizman201563,
    author = ""Waizman, Gennady and Shoval, Shraga and Benenson, Itzhak"",
    title = ""Micro-simulation model for assessing the risk of vehicle-pedestrian road accidents"",
    year = ""2015"",
    journal = ""Journal of Intelligent Transportation Systems: Technology, Planning, and Operations"",
    volume = ""19"",
    number = ""1"",
    pages = ""63 - 77"",
    doi = ""10.1080/15472450.2013.856721"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924037275\&doi=10.1080\%2f15472450.2013.856721\&partnerID=40\&md5=700f408fd9b18ba78cb22fd167ae4fcd"",
    affiliations = ""Department of Geography and Human Environment, Tel Aviv University, Ramat Aviv, 69978, Tel Aviv, Israel; Department of Industrial Engineering and Management, Ariel University, Ariel, Israel"",
    abstract = ""Data on traffic accidents clearly point to road black spots, where the accident rate is always high. However, road safety research is still far from understanding why these particular places on a road are risky. The reason is the lack of sufficient knowledge on how pedestrians and drivers interact when facing a potentially dangerous traffic situation, and the lack of an integrated framework that relates the data on human behavior to real-world traffic situations. We attempt to tackle this problem by developing SAFEPED, a multi-agent microscopic three-dimensional (3D) simulation of vehicle and pedestrian dynamics at a black spot. SAFEPED is a test platform for evaluating experimentally estimated drivers and pedestrians behavioral rules, and estimating accident risks in different traffic situations. It aims to analyze the design of existing and future black spots and to assess alternative architectural and environmental solutions in order to identify maximally efficient safety countermeasures. (c) 2015 Taylor and Francis Group, LLC."",
    author_keywords = ""Agent-Based Modeling; Black Spot; Spatially Explicit Modeling; Traffic Accidents"",
    keywords = ""Behavioral research; Computational methods; Computer simulation; Motor transportation; Multi agent systems; Pedestrian safety; Risk assessment; Risk perception; Roads and streets; Agent-based model; Black spot; Integrated frameworks; Microsimulation models; Pedestrian dynamics; Safety countermeasures; Spatially explicit modeling; Three-dimensional (3-D) simulation; accident; numerical model; optimization; road transport; simulation; traffic management; transportation safety; transportation system; Highway accidents"",
    publisher = ""Taylor and Francis Inc."",
    issn = ""15472450"",
    language = ""English"",
    abbrev_source_title = ""J. Intell. Transp. Syst. Technol. Plann. Oper."",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 24""
}
"""	Excluded	Excluded	new_screen		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	2015	Micro-simulation model for assessing the risk of vehicle-pedestrian road accidents	https://www.scopus.com/record/display.uri?eid=2-s2.0-84924037275&origin=resultslist&sort=plf-f&src=s&sid=300f5faef60c32434d6012ce03ed7a0e&sot=b&sdt=b&s=TITLE-ABS-KEY%28micro+simulation+model+for+assessing+the+risk+of+vehicle+pedestrian+road+accidents%29&sl=97&sessionSearchId=300f5faef60c32434d6012ce03ed7a0e&relpos=0	Taylor and Francis Inc	nan; References
63	TestNN	Output Reachable Set Estimation and Verification for Multilayer Neural Networks	In this brief, the output reachable estimation and safety verification problems for multilayer perceptron (MLP) neural networks are addressed. First, a conception called maximum sensitivity is introduced, and for a class of MLPs whose activation functions are monotonic functions, the maximum sensitivity can be computed via solving convex optimization problems. Then, using a simulation-based method, the output reachable set estimation problem for neural networks is formulated into a chain of optimization problems. Finally, an automated safety verification is developed based on the output reachable set estimation result. An application to the safety verification for a robotic arm model with two joints is presented to show the effectiveness of the proposed approaches.	Neurons;Safety;Estimation;Neural networks;Nonhomogeneous media;Sensitivity;Contracts;Multilayer perceptron (MLP);reachable set estimation;simulation;verification; Neurons; Safety; Estimation; Neural networks; Nonhomogeneous media; Sensitivity; Contracts; Multilayer perceptron (MLP); reachable set estimation; simulation; verification	Xiang, Weiming; Tran, Hoang-Dung; Johnson, Taylor T.	IEEE Transactions on Neural Networks and Learning Systems	https://doi.org/10.1109/TNNLS.2018.2808470	"1.K. J. Hunt, D. Sbarbaro, R. Zbikowski and P. J. Gawthrop, ""Neural networks for control systems--A survey"", Automatica, vol. 28, no. 6, pp. 1083-1112, 1992. CrossRef  Google Scholar; 2.S. S. Ge, C. C. Hang and T. Zhang, ""Adaptive neural network control of nonlinear systems by state and output feedback"", IEEE Trans. Syst. Man Cybern. B Cybern., vol. 29, no. 6, pp. 818-828, Dec. 1999. View Article  Google Scholar; 3.T. Wang, H. Gao and J. Qiu, ""A combined adaptive neural network and nonlinear model predictive control for multirate networked industrial process control"", IEEE Trans. Neural Netw. Learn. Syst., vol. 27, no. 2, pp. 416-425, Feb. 2016. View Article  Google Scholar; 4.Z.-G. Wu, P. Shi, H. Su and J. Chu, ""Exponential stabilization for sampled-data neural-network-based control systems"", IEEE Trans. Neural Netw. Learn. Syst., vol. 25, no. 12, pp. 2180-2190, Dec. 2014. View Article  Google Scholar; 5.J. Schmidhuber, ""Deep learning in neural networks: An overview"", Neural Netw., vol. 61, pp. 85-117, Jan. 2015. CrossRef  Google Scholar; 6.S. Lawrence, C. L. Giles, A. C. Tsoi and A. D. Back, ""Face recognition: A convolutional neural-network approach"", IEEE Trans. Neural Netw., vol. 8, no. 1, pp. 98-113, Jan. 1997. View Article  Google Scholar; 7.D. Silver et al., ""Mastering the game of Go with deep neural networks and tree search"", Nature, vol. 529, no. 7587, pp. 484-489, 2016. CrossRef  Google Scholar; 8.M. Bojarski et al., End to end learning for self-driving cars, Apr. 2016,  [online]  Available: https://arxiv.org/abs/1604.07316. Google Scholar; 9.G. Katz, C. Barrett, D. L. Dill, K. Julian and M. J. Kochenderfer, ""Reluplex: An efficient SMT solver for verifying deep neural networks"", Proc. Int. Conf. Comput. Aided Verification, pp. 97-117, 2017. CrossRef  Google Scholar; 10.X. Huang, M. Kwiatkowska, S. Wang and M. Wu, ""Safety verification of deep neural networks"", Proc. Int. Conf. Comput. Aided Verification, pp. 3-29, 2017. Google Scholar; 11.L. Pulina and A. Tacchella, ""Challenging SMT solvers to verify neural networks"", AI Commun., vol. 25, no. 2, pp. 117-135, 2012. CrossRef  Google Scholar; 12.L. Pulina and A. Tacchella, ""An abstraction-refinement approach to verification of artificial neural networks"", Proc. Int. Conf. Comput. Aided Verification, pp. 243-257, 2010. CrossRef  Google Scholar; 13.W. Xiang, H.-D. Tran and T. T. Johnson, Reachable set computation and safety verification for neural networks with ReLU activations, Dec. 2017,  [online]  Available: https://arxiv.org/abs/1712.08163. Google Scholar; 14.Z. Xu, H. Su, P. Shi, R. Lu and Z.-G. Wu, ""Reachable set estimation for Markovian jump neural networks with time-varying delays"", IEEE Trans. Cybern., vol. 47, no. 10, pp. 3208-3217, Oct. 2017. View Article  Google Scholar; 15.Z. Zuo, Z. Wang, Y. Chen and Y. Wang, ""A non-ellipsoidal reachable set estimation for uncertain neural networks with time-varying delay"", Commun. Nonlinear Sci. Numer. Simul., vol. 19, no. 4, pp. 1097-1106, 2014. CrossRef  Google Scholar; 16.M. V. Thuan, H. M. Tran and H. Trinh, ""Reachable sets bounding for generalized neural networks with interval time-varying delay and bounded disturbances"" in Neural Computing and Applications, London, U.K.:Springer, pp. 1-12, 2016. Google Scholar; 17.W. Xiang, H.-D. Tran and T. T. Johnson, ""Robust exponential stability and disturbance attenuation for discrete-time switched systems under arbitrary switching"", IEEE Trans. Autom. Control. View Article  Google Scholar; 18.W. Xiang, ""Parameter-memorized Lyapunov functions for discrete-time systems with time-varying parametric uncertainties"", Automatica, vol. 87, pp. 450-454, Jan. 2018. CrossRef  Google Scholar; 19.W. Xiang, J. Lam and J. Shen, ""            Stability analysis and                     \$mathcal {L}_{1}\$            -gain characterization for switched positive systems under dwell-time constraint                  "", Automatica, vol. 85, pp. 1-8, Nov. 2017. CrossRef  Google Scholar; 20.W. Xiang, ""Necessary and sufficient condition for stability of switched uncertain linear systems under dwell-time constraint"", IEEE Trans. Autom. Control, vol. 61, no. 11, pp. 3619-3624, Nov. 2016. View Article  Google Scholar; 21.W. Xiang, H.-D. Tran and T. T. Johnson, ""Output reachable set estimation for switched linear systems and its application in safety verification"", IEEE Trans. Autom. Control, vol. 62, no. 10, pp. 5380-5387, Oct. 2017. View Article  Google Scholar; 22.W. Xiang, H.-D. Tran and T. T. Johnson, ""On reachable set estimation for discrete-time switched linear systems under arbitrary switching"", Proc. Amer. Control Conf. (ACC), pp. 4534-4539, May 2017. View Article  Google Scholar; 23.P. S. Duggirala, S. Mitra, M. Viswanathan and M. Potok, ""C2E2: A verification tool for stateflow models"", Proc. Int. Conf. Tools Algorithms Construction Anal. Syst., pp. 68-82, 2015. CrossRef  Google Scholar; 24.C. Fan, B. Qi, S. Mitra, M. Viswanathan and P. S. Duggirala, ""Automatic reachability analysis for nonlinear hybrid models with C2E2"", Proc. Int. Conf. Comput. Aided Verification, pp. 531-538, 2016. CrossRef  Google Scholar; 25.S. Bak and P. S. Duggirala, ""HyLAA: A tool for computing simulation-equivalent reachability for linear systems"", Proc. 20th Int. Conf. Hybrid Syst. Comput. Control, pp. 173-178, 2017. CrossRef  Google Scholar; 26.K. Hornik, M. Stinchcombe and H. White, ""Multilayer feedforward networks are universal approximators"", Neural Netw., vol. 2, no. 5, pp. 359-366, 1989. CrossRef  Google Scholar; 27.X. Zeng and D. S. Yeung, ""Sensitivity analysis of multilayer perceptron to input and weight perturbations"", IEEE Trans. Neural Netw., vol. 12, no. 6, pp. 1358-1366, Nov. 2001. View Article  Google Scholar; 28.X. Zeng and D. S. Yeung, ""A quantified sensitivity measure for multilayer perceptron to input perturbation"", Neural Comput., vol. 15, no. 1, pp. 183-212, 2003. View Article  Google Scholar; 29.X.-Z. Wang, Q.-Y. Shao, Q. Miao and J.-H. Zhai, ""Architecture selection for networks trained with extreme learning machine using localized generalization error model"", Neurocomputing, vol. 102, pp. 3-9, Feb. 2013. Google Scholar; 30.S. W. Piche, ""The selection of weight accuracies for Madalines"", IEEE Trans. Neural Netw., vol. 6, no. 2, pp. 432-445, Mar. 1995. View Article  Google Scholar"	5777-5783	"""@ARTICLE{8318388,
    author = ""Xiang, Weiming and Tran, Hoang-Dung and Johnson, Taylor T."",
    journal = ""IEEE Transactions on Neural Networks and Learning Systems"",
    title = ""Output Reachable Set Estimation and Verification for Multilayer Neural Networks"",
    year = ""2018"",
    volume = ""29"",
    number = ""11"",
    pages = ""5777-5783"",
    abstract = ""In this brief, the output reachable estimation and safety verification problems for multilayer perceptron (MLP) neural networks are addressed. First, a conception called maximum sensitivity is introduced, and for a class of MLPs whose activation functions are monotonic functions, the maximum sensitivity can be computed via solving convex optimization problems. Then, using a simulation-based method, the output reachable set estimation problem for neural networks is formulated into a chain of optimization problems. Finally, an automated safety verification is developed based on the output reachable set estimation result. An application to the safety verification for a robotic arm model with two joints is presented to show the effectiveness of the proposed approaches."",
    keywords = ""Neurons;Safety;Estimation;Neural networks;Nonhomogeneous media;Sensitivity;Contracts;Multilayer perceptron (MLP);reachable set estimation;simulation;verification"",
    doi = ""10.1109/TNNLS.2018.2808470"",
    ISSN = ""2162-2388"",
    month = ""Nov""
}
"""	Included	Included	new_screen			1	IEEE	2018	Output Reachable Set Estimation and Verification for Multilayer Neural Networks	https://ieeexplore.ieee.org/document/8318388	IEEE	
64	TestNN	Predictive threat assessment via reachability analysis and set invariance theory	We propose two model-based threat assessment methods for semi-autonomous vehicles, i.e., human-driven vehicles with autonomous driving capabilities. Based on information about the surrounding environment, we introduce a set of constraints on the vehicle states, which are satisfied under safe driving conditions. Then, we formulate the threat assessment problem as a constraint satisfaction problem. Vehicle and driver mathematical models are used to predict future constraint violation, indicating the possibility of accident or loss of vehicle control, hence, the need to assist the driver. The two proposed methods differ in the models used to predict vehicle motion within the surrounding environment. We demonstrate the proposed methods in a roadway departure application and validate them through experimental data.	Accidents; Constraint theory; Control system synthesis; Decision making; Mathematical models; Rating; Vehicles; Active safety; Invariant set theory; reachability analysis; semi-autonomous vehicles; threat assessment; Remotely operated vehicles; Accidents;  Constraint theory;  Control system synthesis;  Decision making;  Mathematical models;  Rating;  Vehicles;  Active safety;  Invariant set theory;  reachability analysis;  semi-autonomous vehicles;  threat assessment;  Remotely operated vehicles	Falcone, Paolo; Ali, Mohammad; Sjoberg, Jonas	IEEE Transactions on Intelligent Transportation Systems	https://doi.org/10.1109/TITS.2011.2158210		1352 - 1361	"""@ARTICLE{Falcone20111352,
    author = ""Falcone, Paolo and Ali, Mohammad and Sjoberg, Jonas"",
    title = ""Predictive threat assessment via reachability analysis and set invariance theory"",
    year = ""2011"",
    journal = ""IEEE Transactions on Intelligent Transportation Systems"",
    volume = ""12"",
    number = ""4"",
    pages = ""1352 - 1361"",
    doi = ""10.1109/TITS.2011.2158210"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-82455164302\&doi=10.1109\%2fTITS.2011.2158210\&partnerID=40\&md5=3e18c8bf0f28fb9d39a09e27ab08ec8f"",
    affiliations = ""Department of Signals and Systems, Chalmers University of Technology, 412 96 Goteborg, Sweden; Active Safety and Chassis Department, Volvo Car Corporation, 405 31 Goteborg, Sweden"",
    abstract = ""We propose two model-based threat assessment methods for semi-autonomous vehicles, i.e., human-driven vehicles with autonomous driving capabilities. Based on information about the surrounding environment, we introduce a set of constraints on the vehicle states, which are satisfied under safe driving conditions. Then, we formulate the threat assessment problem as a constraint satisfaction problem. Vehicle and driver mathematical models are used to predict future constraint violation, indicating the possibility of accident or loss of vehicle control, hence, the need to assist the driver. The two proposed methods differ in the models used to predict vehicle motion within the surrounding environment. We demonstrate the proposed methods in a roadway departure application and validate them through experimental data. (c) 2011 IEEE."",
    author_keywords = ""Active safety; decision making; invariant set theory; reachability analysis; semi-autonomous vehicles; threat assessment"",
    keywords = ""Accidents; Constraint theory; Control system synthesis; Decision making; Mathematical models; Rating; Vehicles; Active safety; Invariant set theory; reachability analysis; semi-autonomous vehicles; threat assessment; Remotely operated vehicles"",
    correspondence_address = ""P. Falcone; Department of Signals and Systems, Chalmers University of Technology, 412 96 Goteborg, Sweden; email: falcone@chalmers.se"",
    issn = ""15249050"",
    language = ""English"",
    abbrev_source_title = ""IEEE Trans. Intell. Transp. Syst."",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 90""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2011	Predictive threat assessment via reachability analysis and set invariance theory	https://www.scopus.com/record/display.uri?eid=2-s2.0-82455164302&origin=resultslist&sort=plf-f&src=s&sid=a03c8552d6feca37902eaa3d50520958&sot=b&sdt=b&s=TITLE-ABS-KEY%28predictive+threat+assessment+via+reachability+analysis+and+set+invariance+theory%29&sl=95&sessionSearchId=a03c8552d6feca37902eaa3d50520958&relpos=0	IEEE	nan; References
65	TestNN	Risk assessment of an AUV based on an improved SFMEA method	In considering the limitations in risk assessment of AUV (autonomous underwater vehicle) software systems by the traditional SFMEA (software failure modes and effects analysis) method, and on the basis of evaluating failure modes by fuzzy set theory, an improved SFMEA method based on grey region relationship was proposed. In this method, through calculating the grey region degree of relationship between the failure object and the ideal object, a quantitative risk assessment of intelligent planning and decision-making control systems of the AUV was gained, and the failure priority of the failure modes was given. Experimental results prove that the above methods can effectively solve problems which can only deal with a single value of O, S, and D by the existing SFMEA method, and improve the accuracy of the application of SFMEA methods in the AUV.	Autonomous underwater vehicles; Decision making; Failure modes; Fuzzy logic; Fuzzy set theory; Fuzzy sets; Rating; Safety factor; Submersibles; Underwater equipment; Water craft; AUV (autonomous underwater vehicle); Grey region relationship; Intelligent planning; Quantitative risk assessment; Single-value; Software failure; Software failure modes and effects analysis (SFMEA); Software systems; Risk assessment; Autonomous underwater vehicles;  Decision making;  Failure modes;  Fuzzy logic;  Fuzzy set theory;  Fuzzy sets;  Rating;  Safety factor;  Submersibles;  Underwater equipment;  Water craft;  AUV (autonomous underwater vehicle);  Grey region relationship;  Intelligent planning;  Quantitative risk assessment;  Single-value;  Software failure;  Software failure modes and effects analysis (SFMEA);  Software systems;  Risk assessment	Shi, Changting; Zhang, Rubo	Harbin Gongcheng Daxue Xuebao/Journal of Harbin Engineering University	https://doi.org/10.3969/j.issn.1006-7043.2011.03.014		345 - 349	"""@ARTICLE{Shi2011345,
    author = ""Shi, Changting and Zhang, Rubo"",
    title = ""Risk assessment of an AUV based on an improved SFMEA method"",
    year = ""2011"",
    journal = ""Harbin Gongcheng Daxue Xuebao/Journal of Harbin Engineering University"",
    volume = ""32"",
    number = ""3"",
    pages = ""345 - 349"",
    doi = ""10.3969/j.issn.1006-7043.2011.03.014"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955966021\&doi=10.3969\%2fj.issn.1006-7043.2011.03.014\&partnerID=40\&md5=819dbfa9f5cc81fc59b639cf035b2ea6"",
    affiliations = ""College of Computer Science and Technology, Harbin Engineering University, Harbin 150001, China"",
    abstract = ""In considering the limitations in risk assessment of AUV (autonomous underwater vehicle) software systems by the traditional SFMEA (software failure modes and effects analysis) method, and on the basis of evaluating failure modes by fuzzy set theory, an improved SFMEA method based on grey region relationship was proposed. In this method, through calculating the grey region degree of relationship between the failure object and the ideal object, a quantitative risk assessment of intelligent planning and decision-making control systems of the AUV was gained, and the failure priority of the failure modes was given. Experimental results prove that the above methods can effectively solve problems which can only deal with a single value of O, S, and D by the existing SFMEA method, and improve the accuracy of the application of SFMEA methods in the AUV."",
    author_keywords = ""Autonomous underwater vehicle (AUV); Grey region relationship; Risk assessment; Software failure modes and effects analysis (SFMEA)"",
    keywords = ""Autonomous underwater vehicles; Decision making; Failure modes; Fuzzy logic; Fuzzy set theory; Fuzzy sets; Rating; Safety factor; Submersibles; Underwater equipment; Water craft; AUV (autonomous underwater vehicle); Grey region relationship; Intelligent planning; Quantitative risk assessment; Single-value; Software failure; Software failure modes and effects analysis (SFMEA); Software systems; Risk assessment"",
    correspondence_address = ""C. Shi; College of Computer Science and Technology, Harbin Engineering University, Harbin 150001, China; email: shichangting@hrbeu.edu.cn"",
    issn = ""10067043"",
    coden = ""HGHPF"",
    language = ""Chinese"",
    abbrev_source_title = ""Harbin Gongcheng Daxue Xuebao"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 4""
}
"""	Excluded	Excluded	new_screen		Exclusion: full-text is not available/not written in English/not aiming at NN-based CPSs	1	Scopus Signed In	2011	Risk assessment of an AUV based on an improved SFMEA method	https://doi.org/10.3969/j.issn.1006-7043.2011.03.014		nan; References; Link; Publisher
66	TestNN	Safety performance monitoring of autonomous marine systems	The marine environment is vast, harsh, and challenging. Unanticipated faults and events might lead to loss of vessels, transported goods, collected scientific data, and business reputation. Hence, systems have to be in place that monitor the safety performance of operation and indicate if it drifts into an intolerable safety level. This article proposes a process for developing safety indicators for the operation of autonomous marine systems (AMS). The condition of safety barriers and resilience engineering form the basis for the development of safety indicators, synthesizing and further adjusting the dual assurance and the resilience based early warning indicator (REWI) approaches. The article locates the process for developing safety indicators in the system life cycle emphasizing a timely implementation of the safety indicators. The resulting safety indicators reflect safety in AMS operation and can assist in planning of operations, in daily operational decision-making, and identification of improvements. Operation of an autonomous underwater vehicle (AUV) exemplifies the process for developing safety indicators and their implementation. The case study shows that the proposed process leads to a comprehensive set of safety indicators. It is expected that application of the resulting safety indicators consequently will contribute to safer operation of current and future AMS.	Safety indicators;  Autonomous marine systems;  Dual assurance;  Resilience; Safety indicators, Autonomous marine systems, Dual assurance, Resilience	Thieme, Christoph A.; Utne, Ingrid B.	Reliability Engineering & System Safety			264-275	"""@article{THIEME2017264,
    author = ""Thieme, Christoph A. and Utne, Ingrid B."",
    title = ""Safety performance monitoring of autonomous marine systems"",
    journal = ""Reliability Engineering \& System Safety"",
    volume = ""159"",
    pages = ""264-275"",
    year = ""2017"",
    issn = ""0951-8320"",
    doi = ""https://doi.org/10.1016/j.ress.2016.11.024"",
    url = ""https://www.sciencedirect.com/science/article/pii/S0951832016308870"",
    keywords = ""Safety indicators, Autonomous marine systems, Dual assurance, Resilience"",
    abstract = ""The marine environment is vast, harsh, and challenging. Unanticipated faults and events might lead to loss of vessels, transported goods, collected scientific data, and business reputation. Hence, systems have to be in place that monitor the safety performance of operation and indicate if it drifts into an intolerable safety level. This article proposes a process for developing safety indicators for the operation of autonomous marine systems (AMS). The condition of safety barriers and resilience engineering form the basis for the development of safety indicators, synthesizing and further adjusting the dual assurance and the resilience based early warning indicator (REWI) approaches. The article locates the process for developing safety indicators in the system life cycle emphasizing a timely implementation of the safety indicators. The resulting safety indicators reflect safety in AMS operation and can assist in planning of operations, in daily operational decision-making, and identification of improvements. Operation of an autonomous underwater vehicle (AUV) exemplifies the process for developing safety indicators and their implementation. The case study shows that the proposed process leads to a comprehensive set of safety indicators. It is expected that application of the resulting safety indicators consequently will contribute to safer operation of current and future AMS.""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Science Direct	2017	Safety performance monitoring of autonomous marine systems		Science Direct	nan; References; Link
67	TestNN	Safety Verification of Deep Neural Networks	Deep neural networks have achieved impressive experimental results in image classification, but can surprisingly be unstable with respect to adversarial perturbations, that is, minimal changes to the input image that cause the network to misclassify it. With potential applications including perception modules and end-to-end controllers for self-driving cars, this raises concerns about their safety. We develop a novel automated verification framework for feed-forward multi-layer neural networks based on Satisfiability Modulo Theory (SMT). We focus on safety of image classification decisions with respect to image manipulations, such as scratches or changes to camera angle or lighting conditions that would result in the same class being assigned by a human, and define safety for an individual decision in terms of invariance of the classification within a small neighbourhood of the original image. We enable exhaustive search of the region by employing discretisation, and propagate the analysis layer by layer. Our method works directly with the network code and, in contrast to existing methods, can guarantee that adversarial examples, if they exist, are found for the given region and family of manipulations. If found, adversarial examples can be shown to human testers and/or used to fine-tune the network. We implement the techniques using Z3 and evaluate them on state-of-the-art networks, including regularised and deep learning networks. We also compare against existing techniques to search for adversarial examples and estimate network robustness.	Deep Neural Networks; Adversarial Examples; Adversarial Perturbations; Fast Gradient Sign Method (FGSM); German Traffic Sign Recognition Benchmark (GTSRB)	Huang, Xiaowei; Kwiatkowska, Marta; Wang, Sen; Wu, Min	International Conference on Computer Aided Verification	https://doi.org/10.1007/978-3-319-63387-9_1		3--29	"""@InProceedings{10.1007/978-3-319-63387-9_1,
    author = ""Huang, Xiaowei and Kwiatkowska, Marta and Wang, Sen and Wu, Min"",
    editor = ""Majumdar, Rupak and Kun{\v{c}}ak, Viktor"",
    title = ""Safety Verification of Deep Neural Networks"",
    booktitle = ""Computer Aided Verification"",
    year = ""2017"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""3--29"",
    abstract = ""Deep neural networks have achieved impressive experimental results in image classification, but can surprisingly be unstable with respect to adversarial perturbations, that is, minimal changes to the input image that cause the network to misclassify it. With potential applications including perception modules and end-to-end controllers for self-driving cars, this raises concerns about their safety. We develop a novel automated verification framework for feed-forward multi-layer neural networks based on Satisfiability Modulo Theory (SMT). We focus on safety of image classification decisions with respect to image manipulations, such as scratches or changes to camera angle or lighting conditions that would result in the same class being assigned by a human, and define safety for an individual decision in terms of invariance of the classification within a small neighbourhood of the original image. We enable exhaustive search of the region by employing discretisation, and propagate the analysis layer by layer. Our method works directly with the network code and, in contrast to existing methods, can guarantee that adversarial examples, if they exist, are found for the given region and family of manipulations. If found, adversarial examples can be shown to human testers and/or used to fine-tune the network. We implement the techniques using Z3 and evaluate them on state-of-the-art networks, including regularised and deep learning networks. We also compare against existing techniques to search for adversarial examples and estimate network robustness."",
    isbn = ""978-3-319-63387-9""
}
"""	Included	Included	new_screen			1	Springer Link	2017	Safety Verification of Deep Neural Networks, Pt I. R. Majumdar and V. Kuncak. 10426: 3-29.	https://doi.org/10.1007/978-3-319-63387-9_1	Springer International Publishing	nan; References; Link
68	TestNN	Testing of Intelligent Vehicles Using Virtual Environments and Staged Scenarios	This chapter focuses on procedures and tools used in the testing stages of the intelligent vehicle design process. By testing the developed intelligent vehicle algorithms and architectures in a series of environments, starting from pure simulation and ending with physical, full-scale tests, it is possible to avoid the time, safety, and logistics costs of full-blown outdoor tests for the initial stages of the development process. The described procedure, which uses both simulation environments and small-scale indoor testbeds before the outdoor tests, makes use of different levels of virtualization for sensors, agents, scenarios and environments, and has been successfully demonstrated on multiple autonomous vehicle implementation examples.	Intelligent vehicle highway systems; Safety testing; Testbeds; Development process; Full scale tests; Logistics costs; Multiple autonomous vehicles; Simulation environment; Staged scenarios; Vehicle design; Virtual sensor; Vehicles; Intelligent vehicle highway systems;  Safety testing;  Testbeds;  Development process;  Full scale tests;  Logistics costs;  Multiple autonomous vehicles;  Simulation environment;  Staged scenarios;  Vehicle design;  Virtual sensor;  Vehicles	Kurt, Arda; Vernier, Michael; Biddlestone, Scott; Redmill, Keith; Ozguner, Umit	Advances in Intelligent Vehicles	https://doi.org/10.1016/B978-0-12-397199-9.00002-1		45 - 64	"""@BOOK{Kurt201345,
    author = ""Kurt, Arda and Vernier, Michael and Biddlestone, Scott and Redmill, Keith and Ozguner, Umit"",
    title = ""Testing of Intelligent Vehicles Using Virtual Environments and Staged Scenarios"",
    year = ""2013"",
    journal = ""Advances in Intelligent Vehicles"",
    pages = ""45 - 64"",
    doi = ""10.1016/B978-0-12-397199-9.00002-1"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902064057\&doi=10.1016\%2fB978-0-12-397199-9.00002-1\&partnerID=40\&md5=6f60c873d32f91327754beefe97d1f2a"",
    affiliations = ""The Ohio State University, OH, United States"",
    abstract = ""This chapter focuses on procedures and tools used in the testing stages of the intelligent vehicle design process. By testing the developed intelligent vehicle algorithms and architectures in a series of environments, starting from pure simulation and ending with physical, full-scale tests, it is possible to avoid the time, safety, and logistics costs of full-blown outdoor tests for the initial stages of the development process. The described procedure, which uses both simulation environments and small-scale indoor testbeds before the outdoor tests, makes use of different levels of virtualization for sensors, agents, scenarios and environments, and has been successfully demonstrated on multiple autonomous vehicle implementation examples. (c) 2014 Elsevier Inc. All rights reserved."",
    author_keywords = ""Indoor testbeds; Intelligent vehicles; Simulation environments; Staged scenarios; Virtual sensors"",
    keywords = ""Intelligent vehicle highway systems; Safety testing; Testbeds; Development process; Full scale tests; Logistics costs; Multiple autonomous vehicles; Simulation environment; Staged scenarios; Vehicle design; Virtual sensor; Vehicles"",
    publisher = ""Elsevier Inc."",
    isbn = ""978-012397199-9"",
    language = ""English"",
    abbrev_source_title = ""Adv. in Intell. Veh."",
    type = ""Book chapter"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 5""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2013	Testing of Intelligent Vehicles Using Virtual Environments and Staged Scenarios	https://www.scopus.com/record/display.uri?eid=2-s2.0-84902064057&origin=resultslist&sort=plf-f&src=s&sid=4a6fd053153ce981d6520f9c37bf4ad8&sot=b&sdt=b&s=TITLE-ABS-KEY%28testing+of+intelligent+vehicles+using+virtual+environments+and+staged+scenarios%29&sl=94&sessionSearchId=4a6fd053153ce981d6520f9c37bf4ad8&relpos=0	Elsevier Inc	nan; References
69	TestNN	Toward scalable verification for safety-critical deep networks [arXiv]			Kuper, L., G. Katz, J. Gottschlich, K. Julian, C. Barrett and M. Kochenderfer	arXiv					Included	Included	new_screen			1		2018				
70	TestNN	A Flight Simulator for Unmanned Aerial Vehicle Flights Over Construction Job Sites	In 2015, the construction had the highest rate of fatalities among all industries in the United States. Unsafe operation of construction equipment is one of the main causes of fatal incidents. Operation, management and interactions between construction equipment and construction crews should be thoroughly regulated to minimize the risk of fatal incidents on job sites. While use of most traditional construction equipment is regulated, the construction industry has struggled with regulating new, innovative and smart equipment such as Unmanned Aerial Vehicles (UAVs) that have recently been introduced to construction job sites. In this paper, collision avoidance and spatial safety theories in construction are discussed. The bases of these theories are extended to UAV operation in order to establish the first known theory on safe use and operation of UAVs in construction. Also, basic principles of UAV flights are discussed. By applying the basic principles of UAV flights and construction spatial safety theories, a UAV flight simulator in construction environments has been developed in Unity game engine. The flight simulator is designed for UAV pilots, construction managers and safety managers, and enables users to fly a UAV within a simulated environment extracted from a BIM model. This UAV flight simulator is tested in a case study of a building currently under construction. This simulator can be used to assess UAV pilots' capabilities, test the risks of UAV flights in any construction environment, and UAV safe flight path planning.	Flight simulator; Unmanned aerial vehicle; UAV; Flight simulation	Izadi Moud, Hashem; Razkenari, Mohamad A.; Flood, Ian; Kibert, Charles	Advances in Informatics and Computing in Civil and Construction Engineering	https://doi.org/10.1007/978-3-030-00220-6_73		609--616	"""@InProceedings{10.1007/978-3-030-00220-6_73,
    author = ""Izadi Moud, Hashem and Razkenari, Mohamad A. and Flood, Ian and Kibert, Charles"",
    editor = ""Mutis, Ivan and Hartmann, Timo"",
    title = ""A Flight Simulator for Unmanned Aerial Vehicle Flights Over Construction Job Sites"",
    booktitle = ""Advances in Informatics and Computing in Civil and Construction Engineering"",
    year = ""2019"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""609--616"",
    abstract = ""In 2015, the construction had the highest rate of fatalities among all industries in the United States. Unsafe operation of construction equipment is one of the main causes of fatal incidents. Operation, management and interactions between construction equipment and construction crews should be thoroughly regulated to minimize the risk of fatal incidents on job sites. While use of most traditional construction equipment is regulated, the construction industry has struggled with regulating new, innovative and smart equipment such as Unmanned Aerial Vehicles (UAVs) that have recently been introduced to construction job sites. In this paper, collision avoidance and spatial safety theories in construction are discussed. The bases of these theories are extended to UAV operation in order to establish the first known theory on safe use and operation of UAVs in construction. Also, basic principles of UAV flights are discussed. By applying the basic principles of UAV flights and construction spatial safety theories, a UAV flight simulator in construction environments has been developed in Unity game engine. The flight simulator is designed for UAV pilots, construction managers and safety managers, and enables users to fly a UAV within a simulated environment extracted from a BIM model. This UAV flight simulator is tested in a case study of a building currently under construction. This simulator can be used to assess UAV pilots' capabilities, test the risks of UAV flights in any construction environment, and UAV safe flight path planning."",
    isbn = ""978-3-030-00220-6""
}
"""	Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	Springer Link	2019	A Flight Simulator for Unmanned Aerial Vehicle Flights Over Construction Job Sites	https://doi.org/10.1007/978-3-030-00220-6_73	Springer International Publishing	nan; References; Link
71	TestNN	A formal approach for identifying assurance deficits in unmanned aerial vehicle software	While formal methods have proved to be unfeasible for large scale systems, argument-based safety cases offer a plausible alternative basis for certification of critical software. Our proposed method for increasing safety combines formal methods with argumentation-based reasoning. In a first step, we provide a formal representation of the the argumentative-based Goal Structuring Notation (GSN) standard used in industry. In a second step, our solution exploits reasoning in description logic to identify assurance deficits in the GSN model. The identified flaws are given to a hybrid logic-based model checker to be validated against a Kripke model. The method is illustrated for an unmanned aerial vehicle software, with reasoning performed in RacerPro engine and the HLMC model checker based on hybrid logic.	Case based reasoning; Data description; Formal languages; Model checking; Systems engineering; Unmanned aerial vehicles (UAV); argumentation; Assurance deficits; Description logic; Formal representations; Goal structuring notation; Hybrid logic; Logic-based modeling; Safety case; Formal methods; Case based reasoning;  Data description;  Formal languages;  Model checking;  Systems engineering;  Unmanned aerial vehicles (UAV);  argumentation;  Assurance deficits;  Description logic;  Formal representations;  Goal structuring notation;  Hybrid logic;  Logic-based modeling;  Safety case;  Formal methods	Groza, Adrian; Letia, Ioan Alfred; Goron, Anca; Zaporojan, Sergiu	Advances in Intelligent Systems and Computing	https://doi.org/10.1007/978-3-319-08422-0_35		233 - 239	"""@ARTICLE{Groza2015233,
    author = ""Groza, Adrian and Letia, Ioan Alfred and Goron, Anca and Zaporojan, Sergiu"",
    title = ""A formal approach for identifying assurance deficits in unmanned aerial vehicle software"",
    year = ""2015"",
    journal = ""Advances in Intelligent Systems and Computing"",
    volume = ""1089"",
    pages = ""233 - 239"",
    doi = ""10.1007/978-3-319-08422-0\_35"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906542893\&doi=10.1007\%2f978-3-319-08422-0\_35\&partnerID=40\&md5=70d4bedad213041dcd56678943d96b2d"",
    affiliations = ""Department of Computer Science, Technical University of ClujNapoca, Cluj-Napoca, Romania; Department of Computer Science, Technical University of Moldova, Chisinau, Moldova"",
    abstract = ""While formal methods have proved to be unfeasible for large scale systems, argument-based safety cases offer a plausible alternative basis for certification of critical software. Our proposed method for increasing safety combines formal methods with argumentation-based reasoning. In a first step, we provide a formal representation of the the argumentative-based Goal Structuring Notation (GSN) standard used in industry. In a second step, our solution exploits reasoning in description logic to identify assurance deficits in the GSN model. The identified flaws are given to a hybrid logic-based model checker to be validated against a Kripke model. The method is illustrated for an unmanned aerial vehicle software, with reasoning performed in RacerPro engine and the HLMC model checker based on hybrid logic. (c) Springer International Publishing Switzerland 2015."",
    author_keywords = ""argumentation; description logic; hybrid logic; safety cases"",
    keywords = ""Case based reasoning; Data description; Formal languages; Model checking; Systems engineering; Unmanned aerial vehicles (UAV); argumentation; Assurance deficits; Description logic; Formal representations; Goal structuring notation; Hybrid logic; Logic-based modeling; Safety case; Formal methods"",
    correspondence_address = ""A. Groza; Department of Computer Science, Technical University of ClujNapoca, Cluj-Napoca, Romania; email: Adrian.Groza@mail.utm.md"",
    publisher = ""Springer Verlag"",
    issn = ""21945357"",
    isbn = ""978-331908421-3"",
    language = ""English"",
    abbrev_source_title = ""Adv. Intell. Sys. Comput."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 10; Conference name: 23rd International Conference on Systems Engineering, ICSEng 2014; Conference date: 19 August 2014 through 21 August 2014; Conference code: 107141""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2015	A formal approach for identifying assurance deficits in unmanned aerial vehicle software	https://www.scopus.com/record/display.uri?eid=2-s2.0-84906542893&origin=resultslist&sort=plf-f&src=s&sid=2bc5cae4e24283204295b78858cae725&sot=b&sdt=b&s=TITLE-ABS-KEY%28a+formal+approach+for+identifying+assurance+deficits+in+unmanned+aerial+vehicle+software%29&sl=103&sessionSearchId=2bc5cae4e24283204295b78858cae725&relpos=0	Springer Verlag	nan; References
72	TestNN	A Formal Approach to Autonomous Vehicle Coordination	Increasing demands on safety and energy efficiency will require higher levels of automation in transportation systems. This involves dealing with safety-critical distributed coordination. In this paper we demonstrate how a Satisfiability Modulo Theories (SMT) solver can be used to prove correctness of a vehicular coordination problem. We formalise a recent distributed coordination protocol and validate our approach using an intersection collision avoidance (ICA) case study. The system model captures continuous time and space, and an unbounded number of vehicles and messages. The safety of the case study is automatically verified using the Z3 theorem prover.	Collision Avoidance; Formal Approach; Reachable State; Target Speed; Hybrid Automaton	Asplund, Mikael; Manzoor, Atif; Bouroche, M{\'e}lanie; Clarke, Siobh{\`a}n; Cahill, Vinny	International Symposium on Formal Methods	https://doi.org/10.1007/978-3-642-32759-9_8		52--67	"""@InProceedings{10.1007/978-3-642-32759-9_8,
    author = ""Asplund, Mikael and Manzoor, Atif and Bouroche, M{\'e}lanie and Clarke, Siobh{\`a}n and Cahill, Vinny"",
    editor = ""Giannakopoulou, Dimitra and M{\'e}ry, Dominique"",
    title = ""A Formal Approach to Autonomous Vehicle Coordination"",
    booktitle = ""FM 2012: Formal Methods"",
    year = ""2012"",
    publisher = ""Springer Berlin Heidelberg"",
    address = ""Berlin, Heidelberg"",
    pages = ""52--67"",
    abstract = ""Increasing demands on safety and energy efficiency will require higher levels of automation in transportation systems. This involves dealing with safety-critical distributed coordination. In this paper we demonstrate how a Satisfiability Modulo Theories (SMT) solver can be used to prove correctness of a vehicular coordination problem. We formalise a recent distributed coordination protocol and validate our approach using an intersection collision avoidance (ICA) case study. The system model captures continuous time and space, and an unbounded number of vehicles and messages. The safety of the case study is automatically verified using the Z3 theorem prover."",
    isbn = ""978-3-642-32759-9""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Springer Link	2012	A Formal Approach to Autonomous Vehicle Coordination	https://doi.org/10.1007/978-3-642-32759-9_8	Springer Berlin Heidelberg	nan; References; Link
73	TestNN	A Formally Verified Motion Planner for Autonomous Vehicles	Autonomous vehicles are safety-critical cyber-physical systems. To ensure their correctness, we use a proof assistant to prove safety properties deductively. This paper presents a formally verified motion planner based on manoeuvre automata in Isabelle/HOL. Two general properties which we ensure are numerical soundness (the absence of floating-point errors) and logical correctness (satisfying a plan specified in linear temporal logic). From these two properties, we obtain a motion planner whose correctness only depends on the validity of the models of the ego vehicle and its environment.	Motion primitives; Manoeuvre automata; Motion planning; Theorem proving; Linear temporal logic; Reachability analysis; Autonomous vehicles	"Rizaldi, Albert; Immler, Fabian; Sch{\""u}rmann, Bastian; Althoff, Matthias"	International Symposium on Automated Technology for Verification and Analysis	https://doi.org/10.1007/978-3-030-01090-4_5		75--90	"""@InProceedings{10.1007/978-3-030-01090-4_5,
    author = {Rizaldi, Albert and Immler, Fabian and Sch{\""u}rmann, Bastian and Althoff, Matthias},
    editor = ""Lahiri, Shuvendu K. and Wang, Chao"",
    title = ""A Formally Verified Motion Planner for Autonomous Vehicles"",
    booktitle = ""Automated Technology for Verification and Analysis"",
    year = ""2018"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""75--90"",
    abstract = ""Autonomous vehicles are safety-critical cyber-physical systems. To ensure their correctness, we use a proof assistant to prove safety properties deductively. This paper presents a formally verified motion planner based on manoeuvre automata in Isabelle/HOL. Two general properties which we ensure are numerical soundness (the absence of floating-point errors) and logical correctness (satisfying a plan specified in linear temporal logic). From these two properties, we obtain a motion planner whose correctness only depends on the validity of the models of the ego vehicle and its environment."",
    isbn = ""978-3-030-01090-4""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Springer Link	2018	A Formally Verified Motion Planner for Autonomous Vehicles	https://doi.org/10.1007/978-3-030-01090-4_5	Springer International Publishing	nan; References; Link
74	TestNN	Automated Synthesis of Safe Autonomous Vehicle Control Under Perception Uncertainty	Autonomous vehicles have found wide-ranging adoption in aerospace, terrestrial as well as marine use. These systems often operate in uncertain environments and in the presence of noisy sensors, and use machine learning and statistical sensor fusion algorithms to form an internal model of the world that is inherently probabilistic. Autonomous vehicles need to operate using this uncertain world-model, and hence, their correctness cannot be deterministically specified. Even once probabilistic correctness is specified, proving that an autonomous vehicle will operate correctly is a challenging problem. In this paper, we address these challenges by proposing a correct-by-synthesis approach to autonomous vehicle control. We propose a probabilistic extension of temporal logic, named Chance Constrained Temporal Logic (C2TL), that can be used to specify correctness requirements in presence of uncertainty. We present a novel automated synthesis technique that compiles C2TL specification into mixed integer constraints, and uses second-order (quadratic) cone programming to synthesize optimal control of autonomous vehicles subject to the C2TL specification. We demonstrate the effectiveness of the proposed approach on a diverse set of illustrative examples.	Temporal Logic; Model Predictive Control; Probabilistic Constraint; Autonomous Vehicle; Lane Change	Jha, Susmit; Raman, Vasumathi	NASA Formal Methods Symposium	https://doi.org/10.1007/978-3-319-40648-0_10		117--132	"""@InProceedings{10.1007/978-3-319-40648-0_10,
    author = ""Jha, Susmit and Raman, Vasumathi"",
    editor = ""Rayadurgam, Sanjai and Tkachuk, Oksana"",
    title = ""Automated Synthesis of Safe Autonomous Vehicle Control Under Perception Uncertainty"",
    booktitle = ""NASA Formal Methods"",
    year = ""2016"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""117--132"",
    abstract = ""Autonomous vehicles have found wide-ranging adoption in aerospace, terrestrial as well as marine use. These systems often operate in uncertain environments and in the presence of noisy sensors, and use machine learning and statistical sensor fusion algorithms to form an internal model of the world that is inherently probabilistic. Autonomous vehicles need to operate using this uncertain world-model, and hence, their correctness cannot be deterministically specified. Even once probabilistic correctness is specified, proving that an autonomous vehicle will operate correctly is a challenging problem. In this paper, we address these challenges by proposing a correct-by-synthesis approach to autonomous vehicle control. We propose a probabilistic extension of temporal logic, named Chance Constrained Temporal Logic (C2TL), that can be used to specify correctness requirements in presence of uncertainty. We present a novel automated synthesis technique that compiles C2TL specification into mixed integer constraints, and uses second-order (quadratic) cone programming to synthesize optimal control of autonomous vehicles subject to the C2TL specification. We demonstrate the effectiveness of the proposed approach on a diverse set of illustrative examples."",
    isbn = ""978-3-319-40648-0""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Springer Link	2016	Automated Synthesis of Safe Autonomous Vehicle Control Under Perception Uncertainty	https://doi.org/10.1007/978-3-319-40648-0_10	Springer International Publishing	nan; References; Link
75	TestNN	Combination of Simulation and Model-Checking for the Analysis of Autonomous Vehicles Behaviors: A Case Study			Johan ArcileJrmy SobierajHanna KlaudelGuillaume Hutzler	Multi-Agent Systems and Agreement Technologies					Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1		2018				
76	TestNN	Compositional Falsification of Cyber-Physical Systems with Machine Learning Components	Cyber-physical systems (CPS), such as automotive systems, are starting to include sophisticated machine learning (ML) components. Their correctness, therefore, depends on properties of the inner ML modules. While learning algorithms aim to generalize from examples, they are only as good as the examples provided, and recent efforts have shown that they can produce inconsistent output under small adversarial perturbations. This raises the question: can the output from learning components lead to a failure of the entire CPS? In this work, we address this question by formulating it as a problem of falsifying signal temporal logic specifications for CPS with ML components. We propose a compositional falsification framework where a temporal logic falsifier and a machine learning analyzer cooperate with the aim of finding falsifying executions of the considered model. The efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks.	Artificial intelligence; Computer circuits; Crime; Cyber Physical System; Deep learning; Deep neural networks; Embedded systems; Learning systems; Machine components; Neural networks; Temporal logic; Automotive Systems; Autonomous driving; Component based; Cyber-Physical System (CPS); Falsification; Falsification frameworks; Sophisticated machines; Temporal logic specifications; Learning algorithms; Artificial intelligence;  Computer circuits;  Crime;  Cyber Physical System;  Deep learning;  Deep neural networks;  Embedded systems;  Learning systems;  Machine components;  Neural networks;  Temporal logic;  Automotive Systems;  Autonomous driving;  Component based;  Cyber-Physical System (CPS);  Falsification;  Falsification frameworks;  Sophisticated machines;  Temporal logic specifications;  Learning algorithms	Dreossi, Tommaso; Donze, Alexandre; Seshia, Sanjit A.	Journal of Automated Reasoning	https://doi.org/10.1007/s10817-018-09509-5		1031 - 1053	"""@ARTICLE{Dreossi20191031,
    author = ""Dreossi, Tommaso and Donze, Alexandre and Seshia, Sanjit A."",
    title = ""Compositional Falsification of Cyber-Physical Systems with Machine Learning Components"",
    year = ""2019"",
    journal = ""Journal of Automated Reasoning"",
    volume = ""63"",
    number = ""4"",
    pages = ""1031 - 1053"",
    doi = ""10.1007/s10817-018-09509-5"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060349868\&doi=10.1007\%2fs10817-018-09509-5\&partnerID=40\&md5=f87cb216796cb6bb61e71f71664c8f18"",
    affiliations = ""University of California, Berkeley, Berkeley, United States; Decyphir SAS, Moirans, France"",
    abstract = ""Cyber-physical systems (CPS), such as automotive systems, are starting to include sophisticated machine learning (ML) components. Their correctness, therefore, depends on properties of the inner ML modules. While learning algorithms aim to generalize from examples, they are only as good as the examples provided, and recent efforts have shown that they can produce inconsistent output under small adversarial perturbations. This raises the question: can the output from learning components lead to a failure of the entire CPS? In this work, we address this question by formulating it as a problem of falsifying signal temporal logic specifications for CPS with ML components. We propose a compositional falsification framework where a temporal logic falsifier and a machine learning analyzer cooperate with the aim of finding falsifying executions of the considered model. The efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks. (c) 2019, Springer Nature B.V."",
    author_keywords = ""Autonomous driving; Cyber-physical systems; Deep learning; Falsification; Machine learning; Neural networks; Temporal logic"",
    keywords = ""Artificial intelligence; Computer circuits; Crime; Cyber Physical System; Deep learning; Deep neural networks; Embedded systems; Learning systems; Machine components; Neural networks; Temporal logic; Automotive Systems; Autonomous driving; Component based; Cyber-Physical System (CPS); Falsification; Falsification frameworks; Sophisticated machines; Temporal logic specifications; Learning algorithms"",
    correspondence_address = ""T. Dreossi; University of California, Berkeley, Berkeley, United States; email: dreossi@berkeley.edu"",
    publisher = ""Springer Netherlands"",
    issn = ""01687433"",
    coden = ""JAREE"",
    language = ""English"",
    abbrev_source_title = ""J Autom Reasoning"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 97; All Open Access, Green Open Access""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	Compositional Falsification of Cyber-Physical Systems with Machine Learning Components	https://www.scopus.com/record/display.uri?eid=2-s2.0-85060349868&origin=resultslist&sort=plf-f&src=s&sid=cf0d0a232c4b4a3e7f43c569a49a2f76&sot=b&sdt=b&s=TITLE-ABS-KEY%28compositional+falsification+of+cyber+physical+systems+with+machine+learning+components%29&sl=101&sessionSearchId=cf0d0a232c4b4a3e7f43c569a49a2f76&relpos=0	Springer Netherlands	nan; References
77	TestNN	Falsification of Cyber-Physical Systems Using Deep Reinforcement Learning	A Cyber-Physical System (CPS) is a system which consists of software components and physical components. Traditional system verification techniques such as model checking or theorem proving are difficult to apply to CPS because the physical components have infinite number of states. To solve this problem, robustness guided falsification of CPS is introduced. Robustness measures how robustly the given specification is satisfied. Robustness guided falsification tries to minimize the robustness by changing inputs and parameters of the system. The input with a minimal robustness (counterexample) is a good candidate to violate the specification. Existing methods use several optimization techniques to minimize robustness. However, those methods do not use temporal structures in a system input and often require a large number of simulation runs to minimize the robustness. In this paper, we explore state-of-the-art Deep Reinforcement Learning (DRL) techniques, i.e., Asynchronous Advantage Actor-Critic (A3C) and Double Deep Q Network (DDQN), to reduce the number of simulation runs required to find such counterexamples. We theoretically show how robustness guided falsification of a safety property is formatted as a reinforcement learning problem. Then, we experimentally compare the effectiveness of our methods with three baseline methods, i.e., random sampling, cross entropy and simulated annealing, on three well known CPS systems. We thoroughly analyse the experiment results and identify two factors of CPS which make DRL based methods better than existing methods. The most important factor is the availability of the system internal dynamics to the reinforcement learning algorithm. The other factor is the existence of learnable structure in the counterexample.	Robustness;Reinforcement learning;Model checking;Software;Optimization;Robustness guided falsification;CPS;reinforcement learning; Robustness; Reinforcement learning; Model checking; Software; Optimization; Robustness guided falsification; CPS; reinforcement learning	Yamagata, Yoriyuki; Liu, Shuang; Akazaki, Takumi; Duan, Yihai; Hao, Jianye	IEEE Transactions on Software Engineering	https://doi.org/10.1109/TSE.2020.2969178	"1.H. Abbas and G. E. Fainekos, ""Convergence proofs for simulated annealing falsification of safety properties"", Proc. 50th Annu. Allerton Conf. Commun. Control Comput., pp. 1594-1601, 2012. View Article  Google Scholar; 2.H. Abbas, G. Fainekos, S. Sankaranarayanan, F. Ivancic and A. Gupta, ""Probabilistic temporal logic falsification of cyber-physical systems"", ACM Trans. Embedded Comput. Syst., vol. 12, no. 2s, pp. 95:1-95:30, May 2013. CrossRef  Google Scholar; 3.Y. Annpureddy, C. Liu, G. E. Fainekos and S. Sankaranarayanan, ""S-TaLiRo: A tool for temporal logic falsification for hybrid systems"", Proc. 17th Int. Conf. Tools Algorithms Construction Anal. Syst., pp. 254-257, 2011. CrossRef  Google Scholar; 4.R. Koymans, ""Specifying real-time properties with metric temporal logic"", Real-Time Syst., vol. 2, no. 4, pp. 255-299, 1990. CrossRef  Google Scholar; 5.O. Maler and D. Nickovic, ""Monitoring temporal properties of continuous signals"", Proc. Int. Symp. Formal Techn. Modelling Anal. Timed Fault-Tolerant Syst., pp. 152-166, 2004. CrossRef  Google Scholar; 6.S. Sankaranarayanan and G. E. Fainekos, ""Falsification of temporal properties of hybrid systems using the cross-entropy method"", Proc. 15th ACM Int. Conf. Hybrid Syst.: Comput. Control, pp. 125-134, 2012. CrossRef  Google Scholar; 7.D. Silver et, ""Mastering the game of go with deep neural networks and tree search"", Nature, vol. 529, no. 7587, 2016. CrossRef  Google Scholar; 8.V. Mnih et al., ""Human-level control through deep reinforcement learning"", Nature, vol. 518, no. 7540, pp. 529-533, 2015. CrossRef  Google Scholar; 9.H. L. S. Younes and R. G. Simmons, ""Statistical probabilistic model checking with a focus on time-bounded properties"", Inf. Comput., vol. 204, no. 9, pp. 1368-1409, Sep. 2006. CrossRef  Google Scholar; 10.E. Clarke, A. Donze and A. Legay, ""            Statistical model checking of mixed-analog circuits with an application to a third order                     \$Delta\$D            -                     \$Sigma\$S            modulator                  "", Proc. 4th Int. Haifa Verification Conf. Hardware Softw.: Verification Testing, pp. 149-163, 2009. CrossRef  Google Scholar; 11.E. M. Clarke and P. Zuliani, ""Statistical model checking for cyber-physical systems"", Proc. Int. Symp. Automated Technol. Verification Anal., pp. 1-12, 2011. CrossRef  Google Scholar; 12.P. Zuliani, A. Platzer and E. M. Clarke, ""Bayesian statistical model checking with application to simulink/stateflow verification"", Proc. 13th ACM Int. Conf. Hybrid Syst.: Comput. Control, pp. 243-252, 2010. CrossRef  Google Scholar; 13.R. Grosu and S. A. Smolka, ""Monte Carlo model checking"", Proc. Int. Conf. Tools Algorithms Construction Anal. Syst., pp. 271-286, 2005. CrossRef  Google Scholar; 14.J. Kapinski, B. H. Krogh, O. Maler and O. Stursberg, ""On systematic simulation of open continuous systems"", Proc. Int. Workshop Hybrid Syst.: Comput. Control, pp. 283-297, 2003. CrossRef  Google Scholar; 15.T. Nghiem, S. Sankaranarayanan, G. Fainekos, F. Ivancic, A. Gupta and G. J. Pappas, ""Monte-Carlo techniques for falsification of temporal properties of non-linear hybrid systems"", Proc. 13th ACM Int. Conf. Hybrid Syst.: Comput. Control, pp. 211-220, 2010. CrossRef  Google Scholar; 16.O. Maler and D. Nickovic, ""Monitoring temporal properties of continuous signals"", Proc. Joint Int. Conf. Formal Modelling Anal. Timed Syst. Formal Techn. Real-Time Fault-Tolerant Syst., pp. 152-166, 2004. CrossRef  Google Scholar; 17.A. Donze and O. Maler, ""Robust satisfaction of temporal logic over real-valued signals"", Proc. 8th Int. Conf. Formal Model. Anal. Timed Syst., pp. 92-106, 2010. CrossRef  Google Scholar; 18.Y. Annpureddy, C. Liu, G. Fainekos and S. Sankaranarayanan, ""S-TaLiRo: A tool for temporal logic falsification for hybrid systems"", Proc. Int. Conf. Tools Algorithms Construction Anal. Syst., pp. 254-257, 2011. CrossRef  Google Scholar; 19.G. E. Fainekos, S. Sankaranarayanan, K. Ueda and H. Yazarel, ""Verification of automotive control applications using S-TaLiRo"", Proc. Amer. Control Conf., pp. 3567-3572, 2012. View Article  Google Scholar; 20.Y. S. R. Annapureddy and G. E. Fainekos, ""Ant colonies for temporal logic falsification of hybrid systems"", Proc. 36th Annu. Conf. IEEE Ind. Electron. Soc., pp. 91-96, 2010. View Article  Google Scholar; 21.J. V. Deshmukh, X. Jin, J. Kapinski and O. Maler, ""Stochastic local search for falsification of hybrid systems"", Proc. 13th Int. Symp. Automated Technol. Verification Anal., pp. 500-517, 2015. CrossRef  Google Scholar; 22.S. Yaghoubi and G. Fainekos, ""Falsification of temporal logic requirements using gradient based local search in space and time"", Proc. 6th IFAC Conf. Anal. Des. Hybrid Syst., pp. 103-108, 2018. CrossRef  Google Scholar; 23.A. Donze, ""Breach A toolbox for verification and parameter synthesis of hybrid systems"", Proc. 22nd Int. Conf. Comput. Aided Verification, pp. 167-170, 2010. CrossRef  Google Scholar; 24.T. Akazaki, ""Falsification of conditional safety properties for cyber-physical systems with Gaussian process regression"", Proc. 16th Int. Conf. Runtime Verification, pp. 439-446, 2016. CrossRef  Google Scholar; 25.N. Polikarpova and S. Schneider, An Active Learning Approach to the Falsification of Black Box Cyber-Physical Systems, Berlin, Germany:Springer, 2017. Google Scholar; 26.S. Silvetti, A. Policriti and L. Bortolussi, ""An active learning approach to the falsification of black box cyber-physical systems"", CoRR, vol. abs/1705.01879, 2017. CrossRef  Google Scholar; 27.J. V. Deshmukh, M. Horvat, X. Jin, R. Majumdar and V. S. Prabhu, ""Testing cyber-physical systems through Bayesian optimization"", ACM Trans. Embedded Comput. Syst., vol. 16, no. 5, pp. 170:1-170:18, 2017. CrossRef  Google Scholar; 28.E. Plaku, L. E. Kavraki and M. Y. Vardi, ""Falsification of LTL safety properties in hybrid systems"", Proc. Int. Conf. Tools Algorithms Construction Anal. Syst., pp. 368-382, 2009. CrossRef  Google Scholar; 29.T. Dreossi, T. Dang, A. Donze, J. Kapinski, X. Jin and J. V. Deshmukh, ""Efficient guiding strategies for testing of temporal properties of hybrid systems"", Proc. 7th Int. Symp. NASA Formal Methods, pp. 127-142, 2015. CrossRef  Google Scholar; 30.T. Akazaki, S. Liu, Y. Yamagata, Y. Duan and J. Hao, ""Falsification of cyber-physical systems using deep reinforcement learning"", Proc. 22nd Int. Symp. Formal Methods, pp. 456-465, 2018. CrossRef  Google Scholar"	2823-2840	"""@ARTICLE{8967146,
    author = ""Yamagata, Yoriyuki and Liu, Shuang and Akazaki, Takumi and Duan, Yihai and Hao, Jianye"",
    journal = ""IEEE Transactions on Software Engineering"",
    title = ""Falsification of Cyber-Physical Systems Using Deep Reinforcement Learning"",
    year = ""2021"",
    volume = ""47"",
    number = ""12"",
    pages = ""2823-2840"",
    abstract = ""A Cyber-Physical System (CPS) is a system which consists of software components and physical components. Traditional system verification techniques such as model checking or theorem proving are difficult to apply to CPS because the physical components have infinite number of states. To solve this problem, robustness guided falsification of CPS is introduced. Robustness measures how robustly the given specification is satisfied. Robustness guided falsification tries to minimize the robustness by changing inputs and parameters of the system. The input with a minimal robustness (counterexample) is a good candidate to violate the specification. Existing methods use several optimization techniques to minimize robustness. However, those methods do not use temporal structures in a system input and often require a large number of simulation runs to minimize the robustness. In this paper, we explore state-of-the-art Deep Reinforcement Learning (DRL) techniques, i.e., Asynchronous Advantage Actor-Critic (A3C) and Double Deep Q Network (DDQN), to reduce the number of simulation runs required to find such counterexamples. We theoretically show how robustness guided falsification of a safety property is formatted as a reinforcement learning problem. Then, we experimentally compare the effectiveness of our methods with three baseline methods, i.e., random sampling, cross entropy and simulated annealing, on three well known CPS systems. We thoroughly analyse the experiment results and identify two factors of CPS which make DRL based methods better than existing methods. The most important factor is the availability of the system internal dynamics to the reinforcement learning algorithm. The other factor is the existence of learnable structure in the counterexample."",
    keywords = ""Robustness;Reinforcement learning;Model checking;Software;Optimization;Robustness guided falsification;CPS;reinforcement learning"",
    doi = ""10.1109/TSE.2020.2969178"",
    ISSN = ""1939-3520"",
    month = ""Dec""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2018	Falsification of Cyber-Physical Systems Using Deep Reinforcement Learning	https://ieeexplore.ieee.org/document/8967146	IEEE	
78	TestNN	Learning-Based testing of cyber-physical systems-of-systems: A platooning study	Learning-based testing (LBT) is a paradigm for fully automated requirements testing that combines machine learning with model-checking techniques. LBT has been shown to be effective for unit and integration testing of safety critical components in cyber-physical systems, e.g. automotive ECU software. We consider the challenges faced, and some initial results obtained in an effort to scale up LBT to testing co-operative open cyber-physical systems-of-systems (CO-CPS). For this we focus on a case study of testing safety and performance properties of multi-vehicle platoons.	Artificial intelligence; Cyber Physical System; Embedded systems; Learning systems; Model checking; Safety engineering; Safety testing; Software testing; System of systems; Systems engineering; Automotive ecus; Cyber physical systems (CPSs); Fully automated; Model based testing; Model-checking techniques; Performance properties; Platooning; Safety critical components; Integration testing; Artificial intelligence;  Cyber Physical System;  Embedded systems;  Learning systems;  Model checking;  Safety engineering;  Safety testing;  Software testing;  System of systems;  Systems engineering;  Automotive ecus;  Cyber physical systems (CPSs);  Fully automated;  Model based testing;  Model-checking techniques;  Performance properties;  Platooning;  Safety critical components;  Integration testing	Meinke, Karl	Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)	https://doi.org/10.1007/978-3-319-66583-2_9		135 - 151	"""@ARTICLE{Meinke2017135,
    author = ""Meinke, Karl"",
    editor = ""P., Reinecke and A., Di Marco"",
    title = ""Learning-Based testing of cyber-physical systems-of-systems: A platooning study"",
    year = ""2017"",
    journal = ""Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"",
    volume = ""10497 LNCS"",
    pages = ""135 - 151"",
    doi = ""10.1007/978-3-319-66583-2\_9"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029453120\&doi=10.1007\%2f978-3-319-66583-2\_9\&partnerID=40\&md5=39d69257e318318ee286f16ef5af0256"",
    affiliations = ""School of Computer Science and Communication, KTH Royal Institute of Technology, Stockholm, 100 44, Sweden"",
    abstract = ""Learning-based testing (LBT) is a paradigm for fully automated requirements testing that combines machine learning with model-checking techniques. LBT has been shown to be effective for unit and integration testing of safety critical components in cyber-physical systems, e.g. automotive ECU software. We consider the challenges faced, and some initial results obtained in an effort to scale up LBT to testing co-operative open cyber-physical systems-of-systems (CO-CPS). For this we focus on a case study of testing safety and performance properties of multi-vehicle platoons. (c) Springer International Publishing AG 2017."",
    author_keywords = ""Cyber-physical system; Learning-based testing; Machine learning; Model-based testing; Platooning; Requirements testing; System-of-systems"",
    keywords = ""Artificial intelligence; Cyber Physical System; Embedded systems; Learning systems; Model checking; Safety engineering; Safety testing; Software testing; System of systems; Systems engineering; Automotive ecus; Cyber physical systems (CPSs); Fully automated; Model based testing; Model-checking techniques; Performance properties; Platooning; Safety critical components; Integration testing"",
    correspondence_address = ""K. Meinke; School of Computer Science and Communication, KTH Royal Institute of Technology, Stockholm, 100 44, Sweden; email: karlm@kth.se"",
    publisher = ""Springer Verlag"",
    issn = ""03029743"",
    isbn = ""978-331966582-5"",
    language = ""English"",
    abbrev_source_title = ""Lect. Notes Comput. Sci."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 25; Conference name: 14th European Workshop on Computer Performance Engineering, EPEW 2017; Conference date: 7 September 2017 through 8 September 2017; Conference code: 197319; All Open Access, Green Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2017	Learning-Based Testing of Cyber-Physical Systems-of-Systems: A Platooning Study	https://www.scopus.com/record/display.uri?eid=2-s2.0-85029453120&origin=resultslist&sort=plf-f&src=s&sid=738a333a99ccd6166d65008695cfa889&sot=b&sdt=b&s=TITLE-ABS-KEY%28learning+based+testing+of+cyber+physical+systems+of+systems+a+platooning+study%29&sl=93&sessionSearchId=738a333a99ccd6166d65008695cfa889&relpos=0	Springer Verlag	nan; References
79	TestNN	Chapter 19 - Model-Based Testing of Cyber-Physical Systems	Cyber-physical systems (CPSs) are the result of the integration of connected computer systems with the physical world. They feature complex interactions that go beyond traditional communication schemes and protocols in computer systems. One distinguished feature of such complex interactions is the tight coupling between discrete and continuous interactions, captured by hybrid system models. Due to the complexity of CPSs, providing rigorous and model-based analysis methods and tools for verifying correctness of such systems is of the utmost importance. Model-based testing (MBT) is one such verification technique that can be used for checking the conformance of an implementation of a system to its specification (model). In this chapter, we first review the main concepts and techniques in MBT. Subsequently, we review the most common modeling formalisms for CPSs, with focus on hybrid system models. Subsequently, we provide a brief overview of conformance relations and conformance testing techniques for CPSs.	Cyber-physical systems;  V-model;  Model-based testing;  Conformance;  Test-case generation;  Test coverage; Cyber-physical systems, V-model, Model-based testing, Conformance, Test-case generation, Test coverage	Aerts, A.; Reniers, M.; Mousavi, M.R.	Cyber-Physical Systems			287-304	"""@incollection{AERTS2017287,
    editor = ""Song, Houbing and Rawat, Danda B. and Jeschke, Sabina and Brecher, Christian"",
    author = ""Aerts, A. and Reniers, M. and Mousavi, M.R."",
    title = ""Chapter 19 - Model-Based Testing of Cyber-Physical Systems"",
    booktitle = ""Cyber-Physical Systems"",
    publisher = ""Academic Press"",
    address = ""Boston"",
    pages = ""287-304"",
    year = ""2017"",
    series = ""Intelligent Data-Centric Systems"",
    isbn = ""978-0-12-803801-7"",
    doi = ""https://doi.org/10.1016/B978-0-12-803801-7.00019-5"",
    url = ""https://www.sciencedirect.com/science/article/pii/B9780128038017000195"",
    keywords = ""Cyber-physical systems, V-model, Model-based testing, Conformance, Test-case generation, Test coverage"",
    abstract = ""Cyber-physical systems (CPSs) are the result of the integration of connected computer systems with the physical world. They feature complex interactions that go beyond traditional communication schemes and protocols in computer systems. One distinguished feature of such complex interactions is the tight coupling between discrete and continuous interactions, captured by hybrid system models. Due to the complexity of CPSs, providing rigorous and model-based analysis methods and tools for verifying correctness of such systems is of the utmost importance. Model-based testing (MBT) is one such verification technique that can be used for checking the conformance of an implementation of a system to its specification (model). In this chapter, we first review the main concepts and techniques in MBT. Subsequently, we review the most common modeling formalisms for CPSs, with focus on hybrid system models. Subsequently, we provide a brief overview of conformance relations and conformance testing techniques for CPSs.""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Science Direct	2018	Model Based Testing of Cyber-Physical Systems		Academic Press	nan; References; Link
80	TestNN	ModelPlex: verified runtime validation of verified cyber-physical system models	Formal verification and validation play a crucial role in making cyber-physical systems (CPS) safe. Formal methods make strong guarantees about the system behavior if accurate models of the system can be obtained, including models of the controller and of the physical dynamics. In CPS, models are essential; but any model we could possibly build necessarily deviates from the real world. If the real system fits to the model, its behavior is guaranteed to satisfy the correctness properties verified with respect to the model. Otherwise, all bets are off. This article introduces ModelPlex, a method ensuring that verification results about models apply to CPS implementations. ModelPlex provides correctness guarantees for CPS executions at runtime: it combines offline verification of CPS models with runtime validation of system executions for compliance with the model. ModelPlex ensures in a provably correct way that the verification results obtained for the model apply to the actual system runs by monitoring the behavior of the world for compliance with the model. If, at some point, the observed behavior no longer complies with the model so that offline verification results no longer apply, ModelPlex initiates provably safe fallback actions, assuming the system dynamics deviation is bounded. This article, furthermore, develops a systematic technique to synthesize provably correct monitors automatically from CPS proofs in differential dynamic logic by a correct-by-construction approach, leading to verifiably correct runtime model validation. Overall, ModelPlex generates provably correct monitor conditions that, if checked to hold at runtime, are provably guaranteed to imply that the offline safety verification results about the CPS model apply to the present run of the actual CPS implementation.	Compliance control; Computer circuits; Dynamics; Embedded systems; Formal methods; Hybrid systems; Reconfigurable hardware; Correct-by-construction; Correctness properties; Cyber physical systems (CPSs); Cyber-physical systems (CPS); Differential dynamic logic; Run-time verification; Static verification; Verification-and-validation; Formal verification; Compliance control;  Computer circuits;  Dynamics;  Embedded systems;  Formal methods;  Hybrid systems;  Reconfigurable hardware;  Correct-by-construction;  Correctness properties;  Cyber physical systems (CPSs);  Cyber-physical systems (CPS);  Differential dynamic logic;  Run-time verification;  Static verification;  Verification-and-validation;  Formal verification	Mitsch, Stefan; Platzer, Andre	Formal Methods in System Design	https://doi.org/10.1007/s10703-016-0241-z		33 - 74	"""@ARTICLE{Mitsch201633,
    author = ""Mitsch, Stefan and Platzer, Andre"",
    title = ""ModelPlex: verified runtime validation of verified cyber-physical system models"",
    year = ""2016"",
    journal = ""Formal Methods in System Design"",
    volume = ""49"",
    number = ""1-2"",
    pages = ""33 - 74"",
    doi = ""10.1007/s10703-016-0241-z"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994027707\&doi=10.1007\%2fs10703-016-0241-z\&partnerID=40\&md5=09d944ed9de3ca1ac892b04787dcd16a"",
    affiliations = ""Computer Science Department, Carnegie Mellon University, Pittsburgh, United States; Department of Cooperative Information Systems, Johannes Kepler University, Linz, Austria"",
    abstract = ""Formal verification and validation play a crucial role in making cyber-physical systems (CPS) safe. Formal methods make strong guarantees about the system behavior if accurate models of the system can be obtained, including models of the controller and of the physical dynamics. In CPS, models are essential; but any model we could possibly build necessarily deviates from the real world. If the real system fits to the model, its behavior is guaranteed to satisfy the correctness properties verified with respect to the model. Otherwise, all bets are off. This article introduces ModelPlex, a method ensuring that verification results about models apply to CPS implementations. ModelPlex provides correctness guarantees for CPS executions at runtime: it combines offline verification of CPS models with runtime validation of system executions for compliance with the model. ModelPlex ensures in a provably correct way that the verification results obtained for the model apply to the actual system runs by monitoring the behavior of the world for compliance with the model. If, at some point, the observed behavior no longer complies with the model so that offline verification results no longer apply, ModelPlex initiates provably safe fallback actions, assuming the system dynamics deviation is bounded. This article, furthermore, develops a systematic technique to synthesize provably correct monitors automatically from CPS proofs in differential dynamic logic by a correct-by-construction approach, leading to verifiably correct runtime model validation. Overall, ModelPlex generates provably correct monitor conditions that, if checked to hold at runtime, are provably guaranteed to imply that the offline safety verification results about the CPS model apply to the present run of the actual CPS implementation. (c) 2016, The Author(s)."",
    author_keywords = ""Cyber-physical systems; Differential dynamic logic; Hybrid systems; Runtime verification; Static verification"",
    keywords = ""Compliance control; Computer circuits; Dynamics; Embedded systems; Formal methods; Hybrid systems; Reconfigurable hardware; Correct-by-construction; Correctness properties; Cyber physical systems (CPSs); Cyber-physical systems (CPS); Differential dynamic logic; Run-time verification; Static verification; Verification-and-validation; Formal verification"",
    correspondence_address = ""S. Mitsch; Computer Science Department, Carnegie Mellon University, Pittsburgh, United States; email: smitsch@cs.cmu.edu"",
    publisher = ""Springer New York LLC"",
    issn = ""09259856"",
    coden = ""FMSDE"",
    language = ""English"",
    abbrev_source_title = ""Formal Methods Syst Des"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 80; All Open Access, Hybrid Gold Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2014	ModelPlex: Verified Runtime Validation of Verified Cyber-Physical System Models	https://www.scopus.com/record/display.uri?eid=2-s2.0-84994027707&origin=resultslist&sort=plf-f&src=s&sid=7db872463442b4bd04adb797fc33e62a&sot=b&sdt=b&s=TITLE-ABS-KEY%28modelplex+verified+runtime+validation+of+verified+cyber+physical+system+models%29&sl=93&sessionSearchId=7db872463442b4bd04adb797fc33e62a&relpos=0	Springer New York LLC	nan; References
81	TestNN	MoDeS3: Model-Based Demonstrator for Smart and Safe Cyber-Physical Systems	We present MoDeS3, a complex research demonstrator illustrating the combined use of model-driven development, formal verification, safety engineering and IoT technologies for smart and safe cyber-physical systems. MoDeS3 represents a smart transportation system-of-systems composed of a model railway and a crane which may automatically load and unload cargo from trains where both subsystems need to fulfill functional and safety requirements. The demonstrator is built by using the model-based software engineering principle, while the system level safety is ensured by the combined use of design-time and runtime verification and validation techniques.	Smart cyber-physical systems; Model-driven engineering; Formal methods; Education; Demonstrator	"V{\""o}r{\""o}s, Andr{\'a}s; B{\'u}r, M{\'a}rton; R{\'a}th, Istv{\'a}n; Horv{\'a}th, {\'A}kos; Micskei, Zolt{\'a}n; Balogh, L{\'a}szl{\'o}; Hegyi, B{\'a}lint; Horv{\'a}th, Benedek; M{\'a}zl{\'o}, Zsolt; Varr{\'o}, D{\'a}niel"	NASA Formal Methods Symposium	https://doi.org/10.1007/978-3-319-77935-5_31		460--467	"""@InProceedings{10.1007/978-3-319-77935-5_31,
    author = {V{\""o}r{\""o}s, Andr{\'a}s and B{\'u}r, M{\'a}rton and R{\'a}th, Istv{\'a}n and Horv{\'a}th, {\'A}kos and Micskei, Zolt{\'a}n and Balogh, L{\'a}szl{\'o} and Hegyi, B{\'a}lint and Horv{\'a}th, Benedek and M{\'a}zl{\'o}, Zsolt and Varr{\'o}, D{\'a}niel},
    editor = ""Dutle, Aaron and Mu{\\textasciitilde {n}}oz, C{\'e}sar and Narkawicz, Anthony"",
    title = ""MoDeS3: Model-Based Demonstrator for Smart and Safe Cyber-Physical Systems"",
    booktitle = ""NASA Formal Methods"",
    year = ""2018"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""460--467"",
    abstract = ""We present MoDeS3, a complex research demonstrator illustrating the combined use of model-driven development, formal verification, safety engineering and IoT technologies for smart and safe cyber-physical systems. MoDeS3 represents a smart transportation system-of-systems composed of a model railway and a crane which may automatically load and unload cargo from trains where both subsystems need to fulfill functional and safety requirements. The demonstrator is built by using the model-based software engineering principle, while the system level safety is ensured by the combined use of design-time and runtime verification and validation techniques."",
    isbn = ""978-3-319-77935-5""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Springer Link	2018	MoDeS3: Model-Based Demonstrator for Smart and Safe Cyber-Physical Systems	https://doi.org/10.1007/978-3-319-77935-5_31	Springer International Publishing	nan; References; Link
82	TestNN	Safety Assurance Strategies for Autonomous Vehicles	Assuring safety of autonomous vehicles requires that the vehicle control system can perceive the situation in the environment and react to actions of other entities. One approach to vehicle safety assurance is based on the assumption that hazardous sequences of events should be identified during hazard analysis and then some means of hazard avoidance and mitigation, like barriers, should be designed and implemented. Another approach is to design a system which is able to dynamically examine the risk associated with possible actions and then select the safest action to carry it out. Dynamic risk assessment requires maintaining the situation awareness and prediction of possible future situations. We analyse how these two approaches can be applied for autonomous vehicles and what strategies can be used for safety argumentation.	Risk Level; Hazard Analysis; Situation Awareness; System Safety; Autonomous Vehicle	Wardzi{\'{n}}ski, Andrzej	International Conference on Computer Safety, Reliability, and Security	https://doi.org/10.1007/978-3-540-87698-4_24		277--290	"""@InProceedings{10.1007/978-3-540-87698-4_24,
    author = ""Wardzi{\'{n}}ski, Andrzej"",
    editor = ""Harrison, Michael D. and Sujan, Mark-Alexander"",
    title = ""Safety Assurance Strategies for Autonomous Vehicles"",
    booktitle = ""Computer Safety, Reliability, and Security"",
    year = ""2008"",
    publisher = ""Springer Berlin Heidelberg"",
    address = ""Berlin, Heidelberg"",
    pages = ""277--290"",
    abstract = ""Assuring safety of autonomous vehicles requires that the vehicle control system can perceive the situation in the environment and react to actions of other entities. One approach to vehicle safety assurance is based on the assumption that hazardous sequences of events should be identified during hazard analysis and then some means of hazard avoidance and mitigation, like barriers, should be designed and implemented. Another approach is to design a system which is able to dynamically examine the risk associated with possible actions and then select the safest action to carry it out. Dynamic risk assessment requires maintaining the situation awareness and prediction of possible future situations. We analyse how these two approaches can be applied for autonomous vehicles and what strategies can be used for safety argumentation."",
    isbn = ""978-3-540-87698-4""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Springer Link	2008	Safety Assurance Strategies for Autonomous Vehicles	https://doi.org/10.1007/978-3-540-87698-4_24	Springer Berlin Heidelberg	nan; References; Link
83	TestNN	Towards Learning and Verifying Invariants of Cyber-Physical Systems by Code Mutation	Cyber-physical systems (CPS), which integrate algorithmic control with physical processes, often consist of physically distributed components communicating over a network. A malfunctioning or compromised component in such a CPS can lead to costly consequences, especially in the context of public infrastructure. In this short paper, we argue for the importance of constructing invariants (or models) of the physical behaviour exhibited by CPS, motivated by their applications to the control, monitoring, and attestation of components. To achieve this despite the inherent complexity of CPS, we propose a new technique for learning invariants that combines machine learning with ideas from mutation testing. We present a preliminary study on a water treatment system that suggests the efficacy of this approach, propose strategies for establishing confidence in the correctness of invariants, then summarise some research questions and the steps we are taking to investigate them.	Support Vector Machine; Sensor Data; Water Treatment Plant; Mutation Testing; Programmable Logic Controller	Chen, Yuqi; Poskitt, Christopher M.; Sun, Jun	International Symposium on Formal Methods	https://doi.org/10.1007/978-3-319-48989-6_10		155--163	"""@InProceedings{10.1007/978-3-319-48989-6_10,
    author = ""Chen, Yuqi and Poskitt, Christopher M. and Sun, Jun"",
    editor = ""Fitzgerald, John and Heitmeyer, Constance and Gnesi, Stefania and Philippou, Anna"",
    title = ""Towards Learning and Verifying Invariants of Cyber-Physical Systems by Code Mutation"",
    booktitle = ""FM 2016: Formal Methods"",
    year = ""2016"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""155--163"",
    abstract = ""Cyber-physical systems (CPS), which integrate algorithmic control with physical processes, often consist of physically distributed components communicating over a network. A malfunctioning or compromised component in such a CPS can lead to costly consequences, especially in the context of public infrastructure. In this short paper, we argue for the importance of constructing invariants (or models) of the physical behaviour exhibited by CPS, motivated by their applications to the control, monitoring, and attestation of components. To achieve this despite the inherent complexity of CPS, we propose a new technique for learning invariants that combines machine learning with ideas from mutation testing. We present a preliminary study on a water treatment system that suggests the efficacy of this approach, propose strategies for establishing confidence in the correctness of invariants, then summarise some research questions and the steps we are taking to investigate them."",
    isbn = ""978-3-319-48989-6""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Springer Link	2016	Towards Learning and Verifying Invariants of Cyber-Physical Systems by Code Mutation	https://doi.org/10.1007/978-3-319-48989-6_10	Springer International Publishing	nan; References; Link
84	TestNN	Virtual Environment for Training Autonomous Vehicles	Driver assistance and semi-autonomous features are regularly added to commercial vehicles with two key stakes: collecting data for training self-driving algorithms, and using these vehicles as testbeds for these algorithms. Due to the nature of algorithms used in autonomous vehicles, their behavior in unknown situation is not fully predictable. This calls for extensive testing. In this paper, we propose to use a virtual environment for both testing algorithms for autonomous vehicles and acquiring simulated data for their training. The benefit of this environment is to able to train algorithms with realistic simulated sensor data before their deployment in real life. To this end, the proposed virtual environment has the capacity to generate similar data than real sensors (e.g. cameras, LiDar, ...). After reviewing state-of-the-art techniques and datasets available for the automotive industry, we identify that dynamic data generated on-demand is needed to improve the current results in training autonomous vehicles. Our proposition describes the benefits a virtual environment brings in improving the development, quality and confidence in the algorithms.	Virtual reality; Simulators; Sensor data synthesis; Game physics engine; Machine vision; Neural networks; Datasets	"Leudet, Jerome; Mikkonen, Tommi; Christophe, Fran{\c{c}}ois; M{\""a}nnist{\""o}, Tomi"	Annual Conference Towards Autonomous Robotic Systems	https://doi.org/10.1007/978-3-319-96728-8_14		159--169	"""@InProceedings{10.1007/978-3-319-96728-8_14,
    author = {Leudet, Jerome and Mikkonen, Tommi and Christophe, Fran{\c{c}}ois and M{\""a}nnist{\""o}, Tomi},
    editor = ""Giuliani, Manuel and Assaf, Tareq and Giannaccini, Maria Elena"",
    title = ""Virtual Environment for Training Autonomous Vehicles"",
    booktitle = ""Towards Autonomous Robotic Systems"",
    year = ""2018"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""159--169"",
    abstract = ""Driver assistance and semi-autonomous features are regularly added to commercial vehicles with two key stakes: collecting data for training self-driving algorithms, and using these vehicles as testbeds for these algorithms. Due to the nature of algorithms used in autonomous vehicles, their behavior in unknown situation is not fully predictable. This calls for extensive testing. In this paper, we propose to use a virtual environment for both testing algorithms for autonomous vehicles and acquiring simulated data for their training. The benefit of this environment is to able to train algorithms with realistic simulated sensor data before their deployment in real life. To this end, the proposed virtual environment has the capacity to generate similar data than real sensors (e.g. cameras, LiDar, ...). After reviewing state-of-the-art techniques and datasets available for the automotive industry, we identify that dynamic data generated on-demand is needed to improve the current results in training autonomous vehicles. Our proposition describes the benefits a virtual environment brings in improving the development, quality and confidence in the algorithms."",
    isbn = ""978-3-319-96728-8""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	Springer Link	2018	Virtual Environment for Training Autonomous Vehicles	https://doi.org/10.1007/978-3-319-96728-8_14	Springer International Publishing	nan; References; Link
85	TestNN	Virtualization: System-Level Fault Simulation of SRAM Errors in Automotive Electronic Control Systems	In the coming age of self-driving cars, system-level testing of electronic control will become much more important to ensure dependable operation of automated functions. Modern VLSI devices are not always totally reliable. They can fail due to aging, electromagnetic excitation and many other reasons as described in the other chapters in this book. Therefore, dependable electronic systems must be tested against possible VLSI device failures. This may not be a common practice for meeting the ISO 26262 functional safety standard today, but deemed necessary for full-fledged self-driving cars in future. In this chapter, we demonstrate system-level simulation of SRAM errors and their impact on the design of electronic control. Automotive engine control is chosen as a test bed for this study. Model-based development techniques for automotive control systems are described first as the background and virtual electronic control units are introduced. A dependable SRAM architecture is proposed, and to test it in a practical use, a multilayer simulation modeling of an electromechanical system, its control software, and the SRAM design built-in microcontroller are discussed. To run a fault injection analysis in the SRAM chip at a large scale, a public cloud computing is used. The virtual computer machines in the cloud computing carry out the virtual engine control system simulation in which an instruction set simulator for the microcontroller executes the control software code step by step. The simulation system traces the outcome of the engine control system behavior upon a fault injection into SRAM to evaluate the dependable SRAM design. The large-scale fault analysis proposed here allows us to evaluate quantitatively the impact of the quality design of components on the entire system failure rate.	Electronic control unit (ECU); Model-based development (MBD); Functional safety; Fault injection; Cloud computing	Oho, Shigeru; Ito, Yasuhiro; Sugure, Yasuo; Nakata, Yohei; Kawaguchi, Hiroshi; Yoshimoto, Masahiko	VLSI Design and Test for Systems Dependability	https://doi.org/10.1007/978-4-431-56594-9_15		539--551	"""@Inbook{Oho2019,
    author = ""Oho, Shigeru and Ito, Yasuhiro and Sugure, Yasuo and Nakata, Yohei and Kawaguchi, Hiroshi and Yoshimoto, Masahiko"",
    editor = ""Asai, Shojiro"",
    title = ""Virtualization: System-Level Fault Simulation of SRAM Errors in Automotive Electronic Control Systems"",
    bookTitle = ""VLSI Design and Test for Systems Dependability"",
    year = ""2019"",
    publisher = ""Springer Japan"",
    address = ""Tokyo"",
    pages = ""539--551"",
    abstract = ""In the coming age of self-driving cars, system-level testing of electronic control will become much more important to ensure dependable operation of automated functions. Modern VLSI devices are not always totally reliable. They can fail due to aging, electromagnetic excitation and many other reasons as described in the other chapters in this book. Therefore, dependable electronic systems must be tested against possible VLSI device failures. This may not be a common practice for meeting the ISO 26262 functional safety standard today, but deemed necessary for full-fledged self-driving cars in future. In this chapter, we demonstrate system-level simulation of SRAM errors and their impact on the design of electronic control. Automotive engine control is chosen as a test bed for this study. Model-based development techniques for automotive control systems are described first as the background and virtual electronic control units are introduced. A dependable SRAM architecture is proposed, and to test it in a practical use, a multilayer simulation modeling of an electromechanical system, its control software, and the SRAM design built-in microcontroller are discussed. To run a fault injection analysis in the SRAM chip at a large scale, a public cloud computing is used. The virtual computer machines in the cloud computing carry out the virtual engine control system simulation in which an instruction set simulator for the microcontroller executes the control software code step by step. The simulation system traces the outcome of the engine control system behavior upon a fault injection into SRAM to evaluate the dependable SRAM design. The large-scale fault analysis proposed here allows us to evaluate quantitatively the impact of the quality design of components on the entire system failure rate."",
    isbn = ""978-4-431-56594-9"",
    doi = ""10.1007/978-4-431-56594-9\_15"",
    url = ""https://doi.org/10.1007/978-4-431-56594-9\_15""
}
"""	Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	Springer Link	2019	Virtualization: System-Level Fault Simulation of SRAM Errors in Automotive Electronic Control Systems	https://doi.org/10.1007/978-4-431-56594-9_15	Springer Japan	nan; References; Link
86	TestNN	Autonomous vehicle simulation model to assess potential collisions to reduce severity of impacts	Autonomous vehicle safety has received much attention in recent years. Autonomous vehicles will improve road safety by eliminating human errors. However, not all automotive collisions can be avoided. A strategy needs to be developed in the event when an autonomous vehicle encounters an unavoidable collision. Furthermore, the vehicle will need to take responsibility for the safety of its occupants, as well as any other individuals, who may be affected by the vehicle's behaviour. This paper proposes a control system to assist an autonomous vehicle to make a decision to reduce the risks to occupants potentially involved in highway motorway collisions. Before any decision can be made, the potential collisions need to be assessed for their effects. A quick and numerical method for evaluation of impact of potential collisions was developed. Assessing the Kinetic Energy of the vehicles before and after collisions is proposed as a method to assess the severity of collisions. A simulation model developed calculates the kinetic energy values and recommends an autonomous vehicle the motorway lane to drive into to cause the least severe collision impact. Different scenarios are defined and used to test the simulation model. The results obtained are promising and in line with the decision made by the subject expert.	Intelligent systems; Intelligent vehicle highway systems; Kinetic energy; Kinetics; Man machine systems; Motor transportation; Numerical methods; Traffic control; Human errors; Road safety; Simulation model; Vehicle simulation; Autonomous vehicles; Intelligent systems;  Intelligent vehicle highway systems;  Kinetic energy;  Kinetics;  Man machine systems;  Motor transportation;  Numerical methods;  Traffic control;  Human errors;  Road safety;  Simulation model;  Vehicle simulation;  Autonomous vehicles	Gilbert, Alex; Petrovic, Dobrila; Warwick, Kevin; Serghi, Vasilis	VEHITS 2018 - Proceedings of the 4th International Conference on Vehicle Technology and Intelligent Transport Systems	https://doi.org/10.5220/0006663102430250		243 - 250	"""@CONFERENCE{Gilbert2018243,
    author = ""Gilbert, Alex and Petrovic, Dobrila and Warwick, Kevin and Serghi, Vasilis"",
    editor = ""M., Helfert and O., Gusikhin"",
    title = ""Autonomous vehicle simulation model to assess potential collisions to reduce severity of impacts"",
    year = ""2018"",
    journal = ""VEHITS 2018 - Proceedings of the 4th International Conference on Vehicle Technology and Intelligent Transport Systems"",
    volume = ""2018-March"",
    pages = ""243 - 250"",
    doi = ""10.5220/0006663102430250"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051927193\&doi=10.5220\%2f0006663102430250\&partnerID=40\&md5=5e43f0b59e89612ef598398306ee60c1"",
    affiliations = ""Coventry University, Faculty of Engineering, Environment and Computing, United Kingdom; Jaguar Land Rover, Autonomous Vehicle Control, United Kingdom"",
    abstract = ""Autonomous vehicle safety has received much attention in recent years. Autonomous vehicles will improve road safety by eliminating human errors. However, not all automotive collisions can be avoided. A strategy needs to be developed in the event when an autonomous vehicle encounters an unavoidable collision. Furthermore, the vehicle will need to take responsibility for the safety of its occupants, as well as any other individuals, who may be affected by the vehicle's behaviour. This paper proposes a control system to assist an autonomous vehicle to make a decision to reduce the risks to occupants potentially involved in highway motorway collisions. Before any decision can be made, the potential collisions need to be assessed for their effects. A quick and numerical method for evaluation of impact of potential collisions was developed. Assessing the Kinetic Energy of the vehicles before and after collisions is proposed as a method to assess the severity of collisions. A simulation model developed calculates the kinetic energy values and recommends an autonomous vehicle the motorway lane to drive into to cause the least severe collision impact. Different scenarios are defined and used to test the simulation model. The results obtained are promising and in line with the decision made by the subject expert. Copyright (c) 2018 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved"",
    author_keywords = ""Autonomous Vehicles; Collision Avoidance/Mitigation; Lane-Change Manoeuvre; Simulation Model"",
    keywords = ""Intelligent systems; Intelligent vehicle highway systems; Kinetic energy; Kinetics; Man machine systems; Motor transportation; Numerical methods; Traffic control; Human errors; Road safety; Simulation model; Vehicle simulation; Autonomous vehicles"",
    publisher = ""SciTePress"",
    isbn = ""978-989758293-6"",
    language = ""English"",
    abbrev_source_title = ""VEHITS - Proc. Int. Conf. Veh. Technol. Intell. Transport Syst."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: 4th International Conference on Vehicle Technology and Intelligent Transport Systems, VEHITS 2018; Conference date: 16 March 2018 through 18 March 2018; Conference code: 135924; All Open Access, Green Open Access, Hybrid Gold Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	Scopus Signed In	2018	Autonomous vehicle simulation model to assess potential collisions to reduce severity of impacts	https://www.scopus.com/record/display.uri?eid=2-s2.0-85051927193&origin=resultslist&sort=plf-f&src=s&sid=a05ba63e1bd09d6edcb1060eaa25a107&sot=b&sdt=b&s=TITLE-ABS-KEY%28autonomous+vehicle+simulation+model+to+assess+potential+collisions+to+reduce+severity+of+impacts%29&sl=111&sessionSearchId=a05ba63e1bd09d6edcb1060eaa25a107&relpos=0	SciTePress	nan; References
87	TestNN	Considerations of Artificial Intelligence Safety Engineering for Unmanned Aircraft	Unmanned aircraft systems promise to be useful for a multitude of applications such as cargo transport and disaster recovery. The research on increased autonomous decision-making capabilities is therefore rapidly growing and advancing. However, the safe use, certification, and airspace integration for unmanned aircraft in a broad fashion is still unclear. Standards for development and verification of manned aircraft are either only partially applicable or resulting safety and verification efforts are unrealistic in practice due to the higher level of autonomy required by unmanned aircraft. Machine learning techniques are hard to interpret for a human and their outcome is strongly dependent on the training data. This work presents the current certification practices in unmanned aviation in the context of autonomy and artificial intelligence. Specifically, the recently introduced categories of unmanned aircraft systems and the specific operation risk assessment are described, which provide means for flight permission not solely focusing on the aircraft but also incorporating the target operation. Exemplary, we show how the specific operation risk assessment might be used as an enabler for hard-to-certify techniques by taking the operation into account during system design.	Aerospace; Certification; AI-based system; Unmanned aircraft systems; Verification and validation	Schirmer, Sebastian; Torens, Christoph; Nikodem, Florian; Dauer, Johann	International Conference on Computer Safety, Reliability, and Security	https://doi.org/10.1007/978-3-319-99229-7_40		465--472	"""@InProceedings{10.1007/978-3-319-99229-7_40,
    author = ""Schirmer, Sebastian and Torens, Christoph and Nikodem, Florian and Dauer, Johann"",
    editor = ""Gallina, Barbara and Skavhaug, Amund and Schoitsch, Erwin and Bitsch, Friedemann"",
    title = ""Considerations of Artificial Intelligence Safety Engineering for Unmanned Aircraft"",
    booktitle = ""Computer Safety, Reliability, and Security"",
    year = ""2018"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""465--472"",
    abstract = ""Unmanned aircraft systems promise to be useful for a multitude of applications such as cargo transport and disaster recovery. The research on increased autonomous decision-making capabilities is therefore rapidly growing and advancing. However, the safe use, certification, and airspace integration for unmanned aircraft in a broad fashion is still unclear. Standards for development and verification of manned aircraft are either only partially applicable or resulting safety and verification efforts are unrealistic in practice due to the higher level of autonomy required by unmanned aircraft. Machine learning techniques are hard to interpret for a human and their outcome is strongly dependent on the training data. This work presents the current certification practices in unmanned aviation in the context of autonomy and artificial intelligence. Specifically, the recently introduced categories of unmanned aircraft systems and the specific operation risk assessment are described, which provide means for flight permission not solely focusing on the aircraft but also incorporating the target operation. Exemplary, we show how the specific operation risk assessment might be used as an enabler for hard-to-certify techniques by taking the operation into account during system design."",
    isbn = ""978-3-319-99229-7""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	Springer Link	2018	Considerations of artificial intelligence safety engineering for unmanned aircraft.	https://doi.org/10.1007/978-3-319-99229-7_40	Springer International Publishing	nan; References; Link
88	TestNN	DeepGauge: multi-granularity testing criteria for deep learning systems	Deep learning (DL) defines a new data-driven programming paradigm that constructs the internal system logic of a crafted neuron network through a set of training data. We have seen wide adoption of DL in many safety-critical scenarios. However, a plethora of studies have shown that the state-of-the-art DL systems suffer from various vulnerabilities which can lead to severe consequences when applied to real-world applications. Currently, the testing adequacy of a DL system is usually measured by the accuracy of test data. Considering the limitation of accessible high quality test data, good accuracy performance on test data can hardly provide confidence to the testing adequacy and generality of DL systems. Unlike traditional software systems that have clear and controllable logic and functionality, the lack of interpretability in a DL system makes system analysis and defect detection difficult, which could potentially hinder its real-world deployment. In this paper, we propose DeepGauge, a set of multi-granularity testing criteria for DL systems, which aims at rendering a multi-faceted portrayal of the testbed. The in-depth evaluation of our proposed testing criteria is demonstrated on two well-known datasets, five DL systems, and with four state-of-the-art adversarial attack techniques against DL. The potential usefulness of DeepGauge sheds light on the construction of more generic and robust DL systems.	Deep learning;  Deep neural networks;  Software testing;  Testing criteria; Deep learning, Deep neural networks, Software testing, Testing criteria	Ma, Lei; Juefei-Xu, Felix; Zhang, Fuyuan; Sun, Jiyuan; Xue, Minhui; Li, Bo; Chen, Chunyang; Su, Ting; Li, Li; Liu, Yang; Zhao, Jianjun; Wang, Yadong	ASE '18: Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering	https://doi.org/10.1145/3238147.3238202		120-131	"""@inproceedings{10.1145/3238147.3238202,
    author = ""Ma, Lei and Juefei-Xu, Felix and Zhang, Fuyuan and Sun, Jiyuan and Xue, Minhui and Li, Bo and Chen, Chunyang and Su, Ting and Li, Li and Liu, Yang and Zhao, Jianjun and Wang, Yadong"",
    title = ""DeepGauge: multi-granularity testing criteria for deep learning systems"",
    year = ""2018"",
    isbn = ""9781450359375"",
    publisher = ""Association for Computing Machinery"",
    address = ""New York, NY, USA"",
    url = ""https://doi.org/10.1145/3238147.3238202"",
    doi = ""10.1145/3238147.3238202"",
    abstract = ""Deep learning (DL) defines a new data-driven programming paradigm that constructs the internal system logic of a crafted neuron network through a set of training data. We have seen wide adoption of DL in many safety-critical scenarios. However, a plethora of studies have shown that the state-of-the-art DL systems suffer from various vulnerabilities which can lead to severe consequences when applied to real-world applications. Currently, the testing adequacy of a DL system is usually measured by the accuracy of test data. Considering the limitation of accessible high quality test data, good accuracy performance on test data can hardly provide confidence to the testing adequacy and generality of DL systems. Unlike traditional software systems that have clear and controllable logic and functionality, the lack of interpretability in a DL system makes system analysis and defect detection difficult, which could potentially hinder its real-world deployment. In this paper, we propose DeepGauge, a set of multi-granularity testing criteria for DL systems, which aims at rendering a multi-faceted portrayal of the testbed. The in-depth evaluation of our proposed testing criteria is demonstrated on two well-known datasets, five DL systems, and with four state-of-the-art adversarial attack techniques against DL. The potential usefulness of DeepGauge sheds light on the construction of more generic and robust DL systems."",
    booktitle = ""Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering"",
    pages = ""120-131"",
    numpages = ""12"",
    keywords = ""Deep learning, Deep neural networks, Software testing, Testing criteria"",
    location = ""Montpellier, France"",
    series = ""ASE '18""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2018	DeepGauge: multi-granularity testing criteria for deep learning systems	https://dl.acm.org/doi/10.1145/3238147.3238202	Association for Computing Machinery	nan; References
89	TestNN	Deeproad: GaN-based metamorphic testing and input validation framework for autonomous driving systems	While Deep Neural Networks (DNNs) have established the fundamentals of image-based autonomous driving systems, they may exhibit erroneous behaviors and cause fatal accidents. To address the safety issues in autonomous driving systems, a recent set of testing techniques have been designed to automatically generate artificial driving scenes to enrich test suite, e.g., generating new input images transformed from the original ones. However, these techniques are insufficient due to two limitations: first, many such synthetic images often lack diversity of driving scenes, and hence compromise the resulting efficacy and reliability. Second, for machine-learning-based systems, a mismatch between training and application domain can dramatically degrade system accuracy, such that it is necessary to validate inputs for improving system robustness. In this paper, we propose DeepRoad, an unsupervised DNN-based framework for automatically testing the consistency of DNN-based autonomous driving systems and online validation. First, DeepRoad automatically synthesizes large amounts of diverse driving scenes without using image transformation rules (e.g. scale, shear and rotation). In particular, DeepRoad is able to produce driving scenes with various weather conditions (including those with rather extreme conditions) by applying Generative Adversarial Networks (GANs) along with the corresponding real-world weather scenes. Second, DeepRoad utilizes metamorphic testing techniques to check the consistency of such systems using synthetic images. Third, DeepRoad validates input images for DNN-based systems by measuring the distance of the input and training images using their VGGNet features. We implement DeepRoad to test three well-recognized DNN-based autonomous driving systems in Udacity self-driving car challenge. The experimental results demonstrate that DeepRoad can detect thousands of inconsistent behaviors for these systems, and effectively validate input images to potentially enhance the system robustness as well.	Automatic test pattern generation; Deep neural networks; Gallium nitride; III-V semiconductors; Online systems; Safety testing; Software testing; Adversarial networks; Autonomous driving; Extreme conditions; Image transformations; Improving systems; Input validation; Metamorphic testing; Test generations; Image enhancement; Automatic test pattern generation;  Deep neural networks;  Gallium nitride;  III-V semiconductors;  Online systems;  Safety testing;  Software testing;  Adversarial networks;  Autonomous driving;  Extreme conditions;  Image transformations;  Improving systems;  Input validation;  Metamorphic testing;  Test generations;  Image enhancement	Zhang, Mengshi; Zhang, Yuqun; Zhang, Lingming; Liu, Cong; Khurshid, Sarfraz	ASE 2018 - Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering	https://doi.org/10.1145/3238147.3238187		132 - 142	"""@CONFERENCE{Zhang2018132,
    author = ""Zhang, Mengshi and Zhang, Yuqun and Zhang, Lingming and Liu, Cong and Khurshid, Sarfraz"",
    editor = ""C., Kastner and M., Huchard and G., Fraser"",
    title = ""Deeproad: GaN-based metamorphic testing and input validation framework for autonomous driving systems"",
    year = ""2018"",
    journal = ""ASE 2018 - Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering"",
    pages = ""132 - 142"",
    doi = ""10.1145/3238147.3238187"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056509092\&doi=10.1145\%2f3238147.3238187\&partnerID=40\&md5=1d01dd8945cf7323da3424fc0a43a6ff"",
    affiliations = ""University of Texas, Austin, United States; Shenzhen Key Laboratory of Computational Intelligence, Department of Computer Science and Engineering, Southern University of Science and Technology, China; University of Texas, Dallas, United States"",
    abstract = ""While Deep Neural Networks (DNNs) have established the fundamentals of image-based autonomous driving systems, they may exhibit erroneous behaviors and cause fatal accidents. To address the safety issues in autonomous driving systems, a recent set of testing techniques have been designed to automatically generate artificial driving scenes to enrich test suite, e.g., generating new input images transformed from the original ones. However, these techniques are insufficient due to two limitations: first, many such synthetic images often lack diversity of driving scenes, and hence compromise the resulting efficacy and reliability. Second, for machine-learning-based systems, a mismatch between training and application domain can dramatically degrade system accuracy, such that it is necessary to validate inputs for improving system robustness. In this paper, we propose DeepRoad, an unsupervised DNN-based framework for automatically testing the consistency of DNN-based autonomous driving systems and online validation. First, DeepRoad automatically synthesizes large amounts of diverse driving scenes without using image transformation rules (e.g. scale, shear and rotation). In particular, DeepRoad is able to produce driving scenes with various weather conditions (including those with rather extreme conditions) by applying Generative Adversarial Networks (GANs) along with the corresponding real-world weather scenes. Second, DeepRoad utilizes metamorphic testing techniques to check the consistency of such systems using synthetic images. Third, DeepRoad validates input images for DNN-based systems by measuring the distance of the input and training images using their VGGNet features. We implement DeepRoad to test three well-recognized DNN-based autonomous driving systems in Udacity self-driving car challenge. The experimental results demonstrate that DeepRoad can detect thousands of inconsistent behaviors for these systems, and effectively validate input images to potentially enhance the system robustness as well. (c) 2018 Association for Computing Machinery."",
    author_keywords = ""Deep neural networks; Input validation; Software testing; Test generation"",
    keywords = ""Automatic test pattern generation; Deep neural networks; Gallium nitride; III-V semiconductors; Online systems; Safety testing; Software testing; Adversarial networks; Autonomous driving; Extreme conditions; Image transformations; Improving systems; Input validation; Metamorphic testing; Test generations; Image enhancement"",
    correspondence_address = ""Y. Zhang; Shenzhen Key Laboratory of Computational Intelligence, Department of Computer Science and Engineering, Southern University of Science and Technology, China; email: zhangyq@sustc.edu.cn"",
    publisher = ""Association for Computing Machinery, Inc"",
    isbn = ""978-145035937-5"",
    language = ""English"",
    abbrev_source_title = ""ASE - Proc. ACM/IEEE Int. Conf. Autom. Soft. Eng."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 416; Conference name: 33rd IEEE/ACM International Conference on Automated Software Engineering, ASE 2018; Conference date: 3 September 2018 through 7 September 2018; Conference code: 140337; All Open Access, Bronze Open Access""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2018	DeepRoad: GAN-based metamorphic testing and input validation framework for autonomous driving systems.	https://www.scopus.com/record/display.uri?eid=2-s2.0-85056509092&origin=resultslist&sort=plf-f&src=s&sid=14c47b23b7b8c6b7d2f0ac0a4294e8a5&sot=b&sdt=b&s=TITLE-ABS-KEY%28deeproad+gan+based+metamorphic+testing+and+input+validation+framework+for+autonomous+driving+systems%29&sl=115&sessionSearchId=14c47b23b7b8c6b7d2f0ac0a4294e8a5&relpos=0	Association for Computing Machinery, Inc	nan; References
90	TestNN	DLFuzz: Differential fuzzing testing of deep learning systems	Deep learning (DL) systems are increasingly applied to safetycritical domains such as autonomous driving cars. It is of significant importance to ensure the reliability and robustness of DL systems. Existing testing methodologies always fail to include rare inputs in the testing dataset and exhibit low neuron coverage. In this paper, we propose DLFuzz, the first differential fuzzing testing framework to guide DL systems exposing incorrect behaviors. DLFuzz keeps minutely mutating the input to maximize the neuron coverage and the prediction difference between the original input and the mutated input, without manual labeling effort or cross-referencing oracles from other DL systems with the same functionality.We present empirical evaluations on two well-known datasets to demonstrate its efficiency. Compared with DeepXplore, the state-of-the-art DL whitebox testing framework, DLFuzz does not require extra efforts to find similar functional DL systems for cross-referencing check, but could generate 338.59% more adversarial inputs with 89.82% smaller perturbations, averagely obtain 2.86% higher neuron coverage, and save 20.11% time consumption.	Neurons; Powertrains; Software engineering; Statistical tests; Autonomous driving; Empirical evaluations; Reliability and robustness; Safety-critical domain; Testing framework; Testing methodology; Time consumption; White-box testing; Deep learning; Neurons;  Powertrains;  Software engineering;  Statistical tests;  Autonomous driving;  Empirical evaluations;  Reliability and robustness;  Safety-critical domain;  Testing framework;  Testing methodology;  Time consumption;  White-box testing;  Deep learning	Guo, Jianmin; Jiang, Yu; Zhao, Yue; Chen, Quan; Sun, Jiaguang	ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering	https://doi.org/10.1145/3236024.3264835		739 - 743	"""@CONFERENCE{Guo2018739,
    author = ""Guo, Jianmin and Jiang, Yu and Zhao, Yue and Chen, Quan and Sun, Jiaguang"",
    editor = ""A., Garci and C.S., Pasareanu and G.T., Leavens"",
    title = ""DLFuzz: Differential fuzzing testing of deep learning systems"",
    year = ""2018"",
    journal = ""ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering"",
    pages = ""739 - 743"",
    doi = ""10.1145/3236024.3264835"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058304120\&doi=10.1145\%2f3236024.3264835\&partnerID=40\&md5=ce34bac0d915f65df8a0af97678ad7c6"",
    affiliations = ""School of Software, Tsinghua University, Beijing, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China"",
    abstract = ""Deep learning (DL) systems are increasingly applied to safetycritical domains such as autonomous driving cars. It is of significant importance to ensure the reliability and robustness of DL systems. Existing testing methodologies always fail to include rare inputs in the testing dataset and exhibit low neuron coverage. In this paper, we propose DLFuzz, the first differential fuzzing testing framework to guide DL systems exposing incorrect behaviors. DLFuzz keeps minutely mutating the input to maximize the neuron coverage and the prediction difference between the original input and the mutated input, without manual labeling effort or cross-referencing oracles from other DL systems with the same functionality.We present empirical evaluations on two well-known datasets to demonstrate its efficiency. Compared with DeepXplore, the state-of-the-art DL whitebox testing framework, DLFuzz does not require extra efforts to find similar functional DL systems for cross-referencing check, but could generate 338.59\% more adversarial inputs with 89.82\% smaller perturbations, averagely obtain 2.86\% higher neuron coverage, and save 20.11\% time consumption. (c) 2018 Association for Computing Machinery."",
    author_keywords = ""Deep Learning; Fuzzing Testing; Neuron Coverage"",
    keywords = ""Neurons; Powertrains; Software engineering; Statistical tests; Autonomous driving; Empirical evaluations; Reliability and robustness; Safety-critical domain; Testing framework; Testing methodology; Time consumption; White-box testing; Deep learning"",
    correspondence_address = ""J. Guo; School of Software, Tsinghua University, Beijing, China; email: guojm17@mails.tsinghua.edu.cn"",
    publisher = ""Association for Computing Machinery, Inc"",
    isbn = ""978-145035573-5"",
    language = ""English"",
    abbrev_source_title = ""ESEC/FSE - Proc. ACM Jt. Meet. Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 190; Conference name: 26th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2018; Conference date: 4 November 2018 through 9 November 2018; Conference code: 142072; All Open Access, Green Open Access""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2018	DLFuzz: differential fuzzing testing of deep learning systems	https://www.scopus.com/record/display.uri?eid=2-s2.0-85058304120&origin=resultslist&sort=plf-f&src=s&sid=83ba9a0d214c40781d3af98bd2286eac&sot=b&sdt=b&s=TITLE-ABS-KEY%28dlfuzz+differential+fuzzing+testing+of+deep+learning+systems%29&sl=75&sessionSearchId=83ba9a0d214c40781d3af98bd2286eac&relpos=0	Association for Computing Machinery, Inc	nan; References
91	TestNN	Experimental Resilience Assessment of an Open-Source Driving Agent	Autonomous vehicles (AV) depend on the sensors like RADAR and camera for the perception of the environment, path planning, and control. With the increasing autonomy and interactions with the complex environment, there have been growing concerns regarding the safety and reliability of AVs. This paper presents a Systems-Theoretic Process Analysis (STPA) based fault injection framework to assess the resilience of an open-source driving agent, called openpilot, under different environmental conditions and faults affecting sensor data. To increase the coverage of unsafe scenarios during testing, we use a strategic software fault-injection approach where the triggers for injecting the faults are derived from the unsafe scenarios identified during the high-level hazard analysis of the system. The experimental results show that the proposed strategic fault injection approach increases the hazard coverage compared to random fault injection and, thus, can help with more effective simulation of safety-critical faults and testing of AVs. In addition, the paper provides insights on the performance of openpilot safety mechanisms and its ability in timely detection and recovery from faulty inputs.	Hazards; Radar; Sensors; Software; Roads; Automobiles; Environmental Conditions; Autonomous Vehicles; Path Planning; Hazard Analysis; Strategic Approach; Safety Mechanism; Learning Algorithms; Control Software; Gaussian Blur; Effect Of Defects; Radar Data; System Fault; Defect Model; Autonomic Control; Machine Learning Systems; Radar Sensor; Human Drivers; Steering Angle; Histogram Of Oriented Gradients; Lane Markings; Lead Vehicle; Control Of Autonomous Vehicles; Occurrence Of Hazards; Hazard Scenarios; Lane Center; Fault Tree Analysis; System Resilience; Safety Hazards; Constant Speed; Gene Defects; resilience; safety; STPA; fault injection; autonomous vehicle; autonomous driving; self-driving; openpilot; ACC; LKAS	Abu Hasnat Mohammad Rubaiyat; Yongming Qin; Homa Alemzadeh	2018 IEEE 23rd Pacific Rim International Symposium on Dependable Computing (PRDC)	https://doi.org/10.1109/PRDC.2018.00016				Included	Included	new_screen			1	IEEE	2018	Experimental Resilience Assessment of An Open-Source Driving Agent	https://doi.org/10.1109/PRDC.2018.00016	IEEE	nan; References; Pages; Year; Bibtex; Link
92	TestNN	Fault Tolerant Deep Neural Networks for Detection of Unrecognizable Situations	Deep Neural Networks are achieving great success in various fields. However, their use remains limited to non critical applications because their behavior is unpredictable and unsafe. In this paper we propose some fault tolerant approaches based on diversifying learning in order to improve DNNs dependability and particularly safety. Our main goal is to increase trust in the outcome of deep learning mechanisms by recognizing the unlearned inputs and preventing misclassification.	Accident prevention; Artificial intelligence; Autonomous vehicles; Deep learning; Deep neural networks; Fault tolerance; Critical applications; Fault-tolerant; Learning mechanism; Misclassifications; Neural networks; Accident prevention;  Artificial intelligence;  Autonomous vehicles;  Deep learning;  Deep neural networks;  Fault tolerance;  Critical applications;  Fault-tolerant;  Learning mechanism;  Misclassifications;  Neural networks	Rhazali, Kaoutar; Lussier, Benjamin; Schon, Walter; Geronimi, Stephane	IFAC-PapersOnLine	https://doi.org/10.1016/j.ifacol.2018.09.525		31 - 37	"""@CONFERENCE{Rhazali201831,
    author = ""Rhazali, Kaoutar and Lussier, Benjamin and Schon, Walter and Geronimi, Stephane"",
    title = ""Fault Tolerant Deep Neural Networks for Detection of Unrecognizable Situations"",
    year = ""2018"",
    volume = ""51"",
    number = ""24"",
    pages = ""31 - 37"",
    doi = ""10.1016/j.ifacol.2018.09.525"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054570837\&doi=10.1016\%2fj.ifacol.2018.09.525\&partnerID=40\&md5=b86125e80c2cb769e4948714e3b3e43a"",
    affiliations = ""Sorbonne Universites, Universite de Technologie de Compiegne, CNRS, UMR 7253, Heudiasyc CS 60 319, Compiegne, 60203, France; Groupe PSA, Direction de la recherche et de l'innovation automobile, Route de Gisy, Velizy Villacoublay, 78943, Cedex, France"",
    abstract = ""Deep Neural Networks are achieving great success in various fields. However, their use remains limited to non critical applications because their behavior is unpredictable and unsafe. In this paper we propose some fault tolerant approaches based on diversifying learning in order to improve DNNs dependability and particularly safety. Our main goal is to increase trust in the outcome of deep learning mechanisms by recognizing the unlearned inputs and preventing misclassification. (c) 2018"",
    author_keywords = ""Artificial Intelligence; Autonomous Vehicles; Fault Tolerance; Neural Networks; Safety"",
    keywords = ""Accident prevention; Artificial intelligence; Autonomous vehicles; Deep learning; Deep neural networks; Fault tolerance; Critical applications; Fault-tolerant; Learning mechanism; Misclassifications; Neural networks"",
    publisher = ""Elsevier B.V."",
    issn = ""24058963"",
    language = ""English"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 7; All Open Access, Gold Open Access""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2018	Fault Tolerant Deep Neural Networks for Detection of Unrecognizable Situations	https://www.scopus.com/record/display.uri?eid=2-s2.0-85054570837&origin=resultslist&sort=plf-f&src=s&sid=298a836f5db1c644c320042c1374f336&sot=b&sdt=b&s=TITLE-ABS-KEY%28fault+tolerant+deep+neural+networks+for+detection+of+unrecognizable+situations%29&sl=93&sessionSearchId=298a836f5db1c644c320042c1374f336&relpos=0	Elsevier B.V	nan; Venue; References
93	TestNN	Game theoretic modeling of driver and vehicle interactions for verification and validation of autonomous vehicle control systems	Autonomous driving has been the subject of increased interest in recent years both in industry and in academia. Serious efforts are being pursued to address legal, technical, and logistical problems and make autonomous cars a viable option for everyday transportation. One significant challenge is the time and effort required for the verification and validation of the decision and control algorithms employed in these vehicles to ensure a safe and comfortable driving experience. Hundreds of thousands of miles of driving tests are required to achieve a well calibrated control system that is capable of operating an autonomous vehicle in an uncertain traffic environment where interactions among multiple drivers and vehicles occur simultaneously. Traffic simulators where these interactions can be modeled and represented with reasonable fidelity can help to decrease the time and effort necessary for the development of the autonomous driving control algorithms by providing a venue where acceptable initial control calibrations can be achieved quickly and safely before actual road tests. In this paper, we present a game theoretic traffic model that can be used to: 1) test and compare various autonomous vehicle decision and control systems and 2) calibrate the parameters of an existing control system. We demonstrate two example case studies, where, in the first case, we test and quantitatively compare two autonomous vehicle control systems in terms of their safety and performance, and, in the second case, we optimize the parameters of an autonomous vehicle control system, utilizing the proposed traffic model and simulation environment.	Control system synthesis; Game theory; Reinforcement learning; Vehicle actuated signals; Autonomous vehicle control; Autonomous Vehicles; Decision and control algorithms; Game-theoretic model; Logistical problems; Traffic model; Vehicle interactions; Verification-and-validation; Vehicles; Control system synthesis;  Game theory;  Reinforcement learning;  Vehicle actuated signals;  Autonomous vehicle control;  Autonomous Vehicles;  Decision and control algorithms;  Game-theoretic model;  Logistical problems;  Traffic model;  Vehicle interactions;  Verification-and-validation;  Vehicles	Li, Nan; Oyler, Dave W.; Zhang, Mengxuan; Yildiz, Yildiray; Kolmanovsky, Ilya; Girard, Anouck R.	IEEE Transactions on Control Systems Technology	https://doi.org/10.1109/TCST.2017.2723574		1782 - 1797	"""@ARTICLE{Li20181782,
    author = ""Li, Nan and Oyler, Dave W. and Zhang, Mengxuan and Yildiz, Yildiray and Kolmanovsky, Ilya and Girard, Anouck R."",
    title = ""Game theoretic modeling of driver and vehicle interactions for verification and validation of autonomous vehicle control systems"",
    year = ""2018"",
    journal = ""IEEE Transactions on Control Systems Technology"",
    volume = ""26"",
    number = ""5"",
    pages = ""1782 - 1797"",
    doi = ""10.1109/TCST.2017.2723574"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028916873\&doi=10.1109\%2fTCST.2017.2723574\&partnerID=40\&md5=886568f3ecc536e5329fc3b743b980a4"",
    affiliations = ""Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109, MI, United States; Department of Mechanical Engineering, Bilkent University, Ankara, 06800, Turkey"",
    abstract = ""Autonomous driving has been the subject of increased interest in recent years both in industry and in academia. Serious efforts are being pursued to address legal, technical, and logistical problems and make autonomous cars a viable option for everyday transportation. One significant challenge is the time and effort required for the verification and validation of the decision and control algorithms employed in these vehicles to ensure a safe and comfortable driving experience. Hundreds of thousands of miles of driving tests are required to achieve a well calibrated control system that is capable of operating an autonomous vehicle in an uncertain traffic environment where interactions among multiple drivers and vehicles occur simultaneously. Traffic simulators where these interactions can be modeled and represented with reasonable fidelity can help to decrease the time and effort necessary for the development of the autonomous driving control algorithms by providing a venue where acceptable initial control calibrations can be achieved quickly and safely before actual road tests. In this paper, we present a game theoretic traffic model that can be used to: 1) test and compare various autonomous vehicle decision and control systems and 2) calibrate the parameters of an existing control system. We demonstrate two example case studies, where, in the first case, we test and quantitatively compare two autonomous vehicle control systems in terms of their safety and performance, and, in the second case, we optimize the parameters of an autonomous vehicle control system, utilizing the proposed traffic model and simulation environment. (c) 1993-2012 IEEE."",
    author_keywords = ""Autonomous vehicles; game theory; reinforcement learning (RL); traffic modeling; verification and validation (V\&V)"",
    keywords = ""Control system synthesis; Game theory; Reinforcement learning; Vehicle actuated signals; Autonomous vehicle control; Autonomous Vehicles; Decision and control algorithms; Game-theoretic model; Logistical problems; Traffic model; Vehicle interactions; Verification-and-validation; Vehicles"",
    correspondence_address = ""N. Li; Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109, United States; email: nanli@umich.edu"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""10636536"",
    coden = ""IETTE"",
    language = ""English"",
    abbrev_source_title = ""IEEE Trans Control Syst Technol"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 184; All Open Access, Bronze Open Access""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2018	Game theoretic modeling of driver and vehicle interactions for verification and validation of autonomous vehicle control systems	https://www.scopus.com/record/display.uri?eid=2-s2.0-85028916873&origin=resultslist&sort=plf-f&src=s&sid=b14c79a6e305e5ca1b4b741fb68c8702&sot=b&sdt=b&s=TITLE-ABS-KEY%28game+theoretic+modeling+of+driver+and+vehicle+interactions+for+verification+and+validation+of+autonomous+vehicle+control+systems%29&sl=143&sessionSearchId=b14c79a6e305e5ca1b4b741fb68c8702&relpos=0	Institute of Electrical and Electronics Engineers Inc	nan; References
94	TestNN	Eclipse plugin for automatic detection of code smells in source codes; [Kaynak kodlardaki kotu kokularin otomatik tespiti icin eclipse eklenti onerisi]	Code smells in source codes are code fragments; that do not prevent the functionality of the developed application, but which reduce code quality, make code maintenance and understandability difficult and require refactoring. Those types of smells could be found in a class as a whole or in a specific method of a class. Detecting those code smells by manual reviewing is a process that could increase the probability of unintentional omission in terms of the requirement of time, budget, and manpower as the project grows. Code smells can be caused by errors in the design phase as well as by the developer's preferences in the design to code conversion phase. In this article, we will introduce an Eclipse plugin that enables automatic detection of code smells in Java source code and presents the detected code smells to developers and maintainers. In this way, the software developers and maintainers can continuously evaluate the quality of the software with realistic values, recognize and refactor the modules that could cause a bug. This provides better quality, eas! ier maintainability and effective testability in software. The developed plugin is tested on the data sets used in fault estimation, and statistical correlation between software fault and code smells is presented. Accord! ing to results, existence of code smells is unrelated with the software faults. However, existing faults are statistically related with code smells.	Budget control; Computer software selection and evaluation; Java programming language; Odors; Software testing; Code smell; Detection tools; Java; Software metrics; Software Quality; Codes (symbols); Budget control;  Computer software selection and evaluation;  Java programming language;  Odors;  Software testing;  Code smell;  Detection tools;  Java;  Software metrics;  Software Quality;  Codes (symbols)	Altintas, Melih; Sezer, Ebru Akcapmar	CEUR Workshop Proceedings	https://doi.org/10.1109/ITSC.2017.8317868	"1.S. Singh, Critical reasons for crashes investigated in the National Motor Vehicle Crash Causation Survey. (Traffic Safety Facts Crash Stats. Report No. DOT HS 812 115), 2015. Google Scholar; 2.J. Carbaugh, D. N. Godbole and R. Sengupta, ""Safety and capacity analysis of automated and manual highway systems"", Transp. Res. Part C Emerg. Technol., vol. 6, no. 1-2, pp. 69-99, 1998. CrossRef  Google Scholar; 3.R. Johansson and J. Nilsson, ""The Need for an Environment Perception Block to Address all ASIL Levels Simultaneously"", Proc. of the IEEE Intelligent Vehicles Symposium (IV), 2016. CrossRef  Google Scholar; 4.S. Khastgir, S. Birrell, G. Dhadyalla and P. Jennings, ""Identifying a Gap in Existing Validation Methodologies for Intelligent Automotive Systems: Introducing the 3xD Simulator"", Proc. of the IEEE Intelligent Vehicles Symposium (IV), pp. 648-653, 2015. CrossRef  Google Scholar; 5.J. A. Michon, ""A critical view of driver behavior models: what do we know what should we do?"" in Human behavior and traffic safety, Plenum Press, pp. 485-520, 1985. CrossRef  Google Scholar; 6.V. Villa, N. Paltrinieri, F. Khan and V. Cozzani, ""Towards dynamic risk analysis: A review of the risk assessment approach and its limitations in the chemical process industry"", Saf. Sci., vol. 89, pp. 77-93, 2016. CrossRef  Google Scholar; 7.The Buncefield Incident 11 December 2005: The final report of the Major Incident Investigation Board, 2008. Google Scholar; 8.H. Pasman and G. Reniers, ""Past present and future of Quantitative Risk Assessment (QRA) and the incentive it obtained from Land-Use Planning (LUP)"", J. Loss Prev. Process Ind., vol. 28, pp. 2-9, 2014. CrossRef  Google Scholar; 9.E. Fadier and C. De La Garza, ""Safety design: Towards a new philosophy"", Saf. Sci., vol. 44, no. 1, pp. 55-73, 2006. CrossRef  Google Scholar; 10.N. Paltrinieri, F. Khan and V. Cozzani, ""Coupling of advanced techniques for dynamic risk management"", J. Risk Res., vol. 18, no. 7, pp. 910-930, 2015. CrossRef  Google Scholar; 11.G. D. Creedy, ""Quantitative risk assessment: How realistic are those frequency assumptions?"", J. Loss Prev. Process Ind., vol. 24, no. 3, pp. 203-207, 2011. CrossRef  Google Scholar; 12.M. Kalantamia, F. Khan and K. Hawboldt, ""Dynamic risk assessment using failure assessment and Bayesian theory"", J. Loss Prev. Process Ind., vol. 22, no. 5, pp. 600-606, 2009. CrossRef  Google Scholar; 13.A. Falck, E. Skramstad and M. Berg, ""Use of QRA for decision support in the design of an offshore oil production installation"", J. Hazard. Mater., vol. 71, no. 1-3, pp. 179-192, 2000. CrossRef  Google Scholar; 14.M. Yang, F. Khan and P. Amyotte, ""Operational risk assessment: A case of the Bhopal disaster"", Process Saf. Environ. Prot., vol. 97, pp. 70-79, 2015. CrossRef  Google Scholar; 15.M. Kalantamia, F. Khan and K. Hawboldt, ""Modelling of BP Texas City refinery accident using dynamic risk assessment approach"", Process Saf. Environ. Prot., vol. 88, no. 3, pp. 191-199, 2010. CrossRef  Google Scholar; 16.N. Paltrinieri and G. Scarponi, ""Addressing Dynamic Risk in the Petroleum Industry by Means of Innovative Analysis Solutions"", Chem. Eng. Trans., vol. 36, pp. 451-456, 2014. Google Scholar; 17.N. Khakzad, F. Khan and P. Amyotte, ""Dynamic risk analysis using bow-tie approach"", Reliab. Eng. Syst. Saf., vol. 104, pp. 36-44, 2012. CrossRef  Google Scholar; 18.N. Paltrinieri, A. Tugnoli, J. Buston, M. Wardman and V. Cozzani, ""Dynamic Procedure for Atypical Scenarios Identification (DyPASI): A new systematic HAZID tool"", J. Loss Prev. Process Ind., vol. 26, no. 4, pp. 683-695, 2013. CrossRef  Google Scholar; 19.Road vehicles - Functional safety (ISO 26262), 2011. Google Scholar; 20.P. E. Labeau, C. Smidts and S. Swaminathan, ""Dynamic reliability: Towards an integrated platform for probabilistic risk assessment"", Reliab. Eng. Syst. Saf., vol. 68, no. 3, pp. 219-254, 2000. CrossRef  Google Scholar; 21.S. Swaminathan, ""The Event Sequence Diagram framework for dynamic Probabilistic Risk Assessment"", Reliab. Eng. Syst. Saf., vol. 63, no. 1, pp. 73-90, 1999. CrossRef  Google Scholar; 22.H. Boudali and J. B. Dugan, ""A discrete-time Bayesian network reliability modeling and analysis framework"", Reliab. Eng. Syst. Saf., vol. 87, no. 3, pp. 337-349, 2005. CrossRef  Google Scholar; 23.R. Ferdous, F. Khan, R. Sadiq, P. Amyotte and B. Veitch, ""Analyzing system safety and risks under uncertainty using a bow-tie diagram: An innovative approach"", Process Saf. Environ. Prot., vol. 91, no. 1-2, pp. 1-18, 2013. CrossRef  Google Scholar; 24.M. Abimbola, F. Khan and N. Khakzad, ""Dynamic safety risk analysis of offshore drilling"", J. Loss Prev. process Ind., vol. 30, no. 1, pp. 74-85, 2014. CrossRef  Google Scholar; 25.S. Rathnayaka, F. Khan and P. Amayotte, ""Accident modeling and risk assessment framework for safety critical decision-making: application to deepwater drilling operation"", J. Risk Reliab., vol. 227, no. 1, pp. 86-105, 2013. CrossRef  Google Scholar; 26.F. Khan, S. J. Hashemi, N. Paltrinieri, P. Amyotte, V. Cozzani and G. Reniers, ""Dynamic risk management: a contemporary approach to process safety management"", Curr. Opin. Chem. Eng., vol. 14, pp. 9-17, 2016. CrossRef  Google Scholar; 27.N. Paltrinieri, F. Khan, P. Amyotte and V. Cozzani, ""Dynamic approach to risk management: Application to the Hoeganaes metal dust accidents"", Process Saf. Environ. Prot., vol. 92, no. 6, pp. 669-679, 2013. CrossRef  Google Scholar; 28.S. Khastgir, S. Birrell, G. Dhadyalla, H. Sivencrona and P. Jennings, ""Towards increased reliability by objectification of Hazard Analysis and Risk Assessment (HARA) of automated automotive systems"", Saf. Sci., 2017. CrossRef  Google Scholar; 29.H. Yu, C.- W. Lin and B. Kim, ""Automotive Software Certification: Current Status and Challenges"", SAE Int. J. Passeng. Cars - Electron. Electr. Syst., vol. 9, no. 1, pp. 2016-01-0050, 2016. CrossRef  Google Scholar; 30.R. Johansson and J. Nilsson, ""Disarming the Trolley Problem - Why Self-driving Cars do not Need to Choose Whom to Kill"", Proc. of the Workshop Critical Automotive applications: Robustness & Safety, 2016. Google Scholar"	1 - 6	"""@CONFERENCE{Altintas2018,
    author = ""Altintas, Melih and Sezer, Ebru Akcapmar"",
    editor = ""M., Erten and A., Tarhan"",
    title = ""Eclipse plugin for automatic detection of code smells in source codes; [Kaynak kodlardaki kotu kokularin otomatik tespiti icin eclipse eklenti onerisi]"",
    year = ""2018"",
    journal = ""CEUR Workshop Proceedings"",
    volume = ""2201"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053705671\&partnerID=40\&md5=7441cd7166dfcac91bd1592d6df71d1c"",
    affiliations = ""Bilgisayar Muhendisligi Bolumu, Hacettepe Universitesi, Ankara, Turkey; Yazilim Muhendisligi Mudurlugu, UGES, Aselsan, Ankara, Turkey"",
    abstract = ""Code smells in source codes are code fragments; that do not prevent the functionality of the developed application, but which reduce code quality, make code maintenance and understandability difficult and require refactoring. Those types of smells could be found in a class as a whole or in a specific method of a class. Detecting those code smells by manual reviewing is a process that could increase the probability of unintentional omission in terms of the requirement of time, budget, and manpower as the project grows. Code smells can be caused by errors in the design phase as well as by the developer's preferences in the design to code conversion phase. In this article, we will introduce an Eclipse plugin that enables automatic detection of code smells in Java source code and presents the detected code smells to developers and maintainers. In this way, the software developers and maintainers can continuously evaluate the quality of the software with realistic values, recognize and refactor the modules that could cause a bug. This provides better quality, eas! ier maintainability and effective testability in software. The developed plugin is tested on the data sets used in fault estimation, and statistical correlation between software fault and code smells is presented. Accord! ing to results, existence of code smells is unrelated with the software faults. However, existing faults are statistically related with code smells."",
    author_keywords = ""Code smell detection tool; Code smells; Java; Software metrics; Software quality"",
    keywords = ""Budget control; Computer software selection and evaluation; Java programming language; Odors; Software testing; Code smell; Detection tools; Java; Software metrics; Software Quality; Codes (symbols)"",
    publisher = ""CEUR-WS"",
    issn = ""16130073"",
    language = ""Turkish"",
    abbrev_source_title = ""CEUR Workshop Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 0; Conference name: 12th Turkish National Software Engineering Symposium, UYMS 2018; Conference date: 10 September 2018 through 12 September 2018; Conference code: 139255""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	IEEE	2018	Introducing ASIL inspired dynamic tactical safety decision framework for automated vehicles 2	https://doi.org/10.1109/ITSC.2017.8317868	CEUR-WS	nan; Link
95	TestNN	Keeping intelligence under control	Modern software systems, such as smart systems, are based on a continuous interaction with the dynamic and partially unknown environment in which they are deployed. Classical development techniques, based on a complete description of how the system must behave in different environmental conditions, are no longer effective. On the contrary, modern techniques should be able to produce systems that autonomously learn how to behave in different environmental conditions.Machine learning techniques allow creating systems that learn how to execute a set of actions to achieve a desired goal. When a change occurs, the system can autonomously learn new policies and strategies for actions execution. This flexibility comes at a cost: the developer has no longer full control on the system behaviour. Thus, there is no way to guarantee that the system will not violate important properties, such as safety-critical properties.To overcome this issue, we believe that machine learning techniques should be combined with suitable reasoning mechanisms aimed at assuring that the decisions taken by the machine learning algorithm do not violate safety-critical requirements. This paper proposes an approach that combines machine learning with runtime monitoring to detect violations of system invariants in the actions execution policies.	safety-critical;  run-time verification;  reinforcement learning;  machine learning;  autonomous systems; safety-critical, run-time verification, reinforcement learning, machine learning, autonomous systems	Mallozzi, Piergiuseppe; Pelliccione, Patrizio; Menghi, Claudio	SE4COG '18: Proceedings of the 1st International Workshop on Software Engineering for Cognitive Services	https://doi.org/10.1145/3195555.3195558		37-40	"""@inproceedings{10.1145/3195555.3195558,
    author = ""Mallozzi, Piergiuseppe and Pelliccione, Patrizio and Menghi, Claudio"",
    title = ""Keeping intelligence under control"",
    year = ""2018"",
    isbn = ""9781450357401"",
    publisher = ""Association for Computing Machinery"",
    address = ""New York, NY, USA"",
    url = ""https://doi.org/10.1145/3195555.3195558"",
    doi = ""10.1145/3195555.3195558"",
    abstract = ""Modern software systems, such as smart systems, are based on a continuous interaction with the dynamic and partially unknown environment in which they are deployed. Classical development techniques, based on a complete description of how the system must behave in different environmental conditions, are no longer effective. On the contrary, modern techniques should be able to produce systems that autonomously learn how to behave in different environmental conditions.Machine learning techniques allow creating systems that learn how to execute a set of actions to achieve a desired goal. When a change occurs, the system can autonomously learn new policies and strategies for actions execution. This flexibility comes at a cost: the developer has no longer full control on the system behaviour. Thus, there is no way to guarantee that the system will not violate important properties, such as safety-critical properties.To overcome this issue, we believe that machine learning techniques should be combined with suitable reasoning mechanisms aimed at assuring that the decisions taken by the machine learning algorithm do not violate safety-critical requirements. This paper proposes an approach that combines machine learning with runtime monitoring to detect violations of system invariants in the actions execution policies."",
    booktitle = ""Proceedings of the 1st International Workshop on Software Engineering for Cognitive Services"",
    pages = ""37-40"",
    numpages = ""4"",
    keywords = ""safety-critical, run-time verification, reinforcement learning, machine learning, autonomous systems"",
    location = ""Gothenburg, Sweden"",
    series = ""SE4COG '18""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2018	Keeping intelligence under control.	https://dl.acm.org/doi/10.1145/3195555.3195558	Association for Computing Machinery	nan; References
96	TestNN	LEMNA: Explaining Deep Learning based Security Applications	While deep learning has shown a great potential in various domains, the lack of transparency has limited its application in security or safety-critical areas. Existing research has attempted to develop explanation techniques to provide interpretable explanations for each classification decision. Unfortunately, current methods are optimized for non-security tasks ( e.g., image analysis). Their key assumptions are often violated in security applications, leading to a poor explanation fidelity. In this paper, we propose LEMNA, a high-fidelity explanation method dedicated for security applications. Given an input data sample, LEMNA generates a small set of interpretable features to explain how the input sample is classified. The core idea is to approximate a local area of the complex deep learning decision boundary using a simple interpretable model. The local interpretable model is specially designed to (1) handle feature dependency to better work with security applications ( e.g., binary code analysis); and (2) handle nonlinear local boundaries to boost explanation fidelity. We evaluate our system using two popular deep learning applications in security (a malware classifier, and a function start detector for binary reverse-engineering). Extensive evaluations show that LEMNA's explanation has a much higher fidelity level compared to existing methods. In addition, we demonstrate practical use cases of LEMNA to help machine learning developers to validate model behavior, troubleshoot classification errors, and automatically patch the errors of the target models.	binary analysis;  deep recurrent neural networks;  explainable AI; binary analysis, deep recurrent neural networks, explainable AI	Guo, Wenbo; Mu, Dongliang; Xu, Jun; Su, Purui; Wang, Gang; Xing, Xinyu	CCS '18: Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security	https://doi.org/10.1145/3243734.3243792		364-379	"""@inproceedings{10.1145/3243734.3243792,
    author = ""Guo, Wenbo and Mu, Dongliang and Xu, Jun and Su, Purui and Wang, Gang and Xing, Xinyu"",
    title = ""LEMNA: Explaining Deep Learning based Security Applications"",
    year = ""2018"",
    isbn = ""9781450356930"",
    publisher = ""Association for Computing Machinery"",
    address = ""New York, NY, USA"",
    url = ""https://doi.org/10.1145/3243734.3243792"",
    doi = ""10.1145/3243734.3243792"",
    abstract = ""While deep learning has shown a great potential in various domains, the lack of transparency has limited its application in security or safety-critical areas. Existing research has attempted to develop explanation techniques to provide interpretable explanations for each classification decision. Unfortunately, current methods are optimized for non-security tasks ( e.g., image analysis). Their key assumptions are often violated in security applications, leading to a poor explanation fidelity. In this paper, we propose LEMNA, a high-fidelity explanation method dedicated for security applications. Given an input data sample, LEMNA generates a small set of interpretable features to explain how the input sample is classified. The core idea is to approximate a local area of the complex deep learning decision boundary using a simple interpretable model. The local interpretable model is specially designed to (1) handle feature dependency to better work with security applications ( e.g., binary code analysis); and (2) handle nonlinear local boundaries to boost explanation fidelity. We evaluate our system using two popular deep learning applications in security (a malware classifier, and a function start detector for binary reverse-engineering). Extensive evaluations show that LEMNA's explanation has a much higher fidelity level compared to existing methods. In addition, we demonstrate practical use cases of LEMNA to help machine learning developers to validate model behavior, troubleshoot classification errors, and automatically patch the errors of the target models."",
    booktitle = ""Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security"",
    pages = ""364-379"",
    numpages = ""16"",
    keywords = ""binary analysis, deep recurrent neural networks, explainable AI"",
    location = ""Toronto, Canada"",
    series = ""CCS '18""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2018	LEMNA: Explaining Deep Learning based Security Applications	https://dl.acm.org/doi/10.1145/3243734.3243792	Association for Computing Machinery	nan; References
97	TestNN	MTL Robustness for Path Planning with A*	Maintaining the safety of an autonomous drone while it executes a mission is a primary concern in presence of fixed and mobile enemies. Path planning using A* fails to deliver a feasible, safe plan when a drone has resource limitations in such environments. Enhancing A* with constraint optimization techniques may improve outcomes, but significantly increases path determination time. We define Robust A* (RA*) that introduces the use of a safety margin to maximize the robustness of the drone to meet mission requirements while managing resource restrictions. We rely on a theory of robustness based on Metric Temporal Logic (MTL) as applied to offline verification and online control of hybrid systems. By satisfying the predefined MTL constraints, RA* dynamically defines a safety margin between the drone and an enemy, while constraining the margin size given the drone's resources. The safety margin creates a robust neighborhood around the dynamically generated path. The robust neighborhood holds all valid trajectories within the current world state. When the world state changes, RA* first examines the robust neighborhood to find a valid trajectory before initiating the path re-planning. We evaluate RA* using the Rassim simulator. The results show that the algorithm generates faster and safer paths than the classical A* in the presence of moving enemies..	a*;  metric temporal logic;  path planning;  robustness; a*, metric temporal logic, path planning, robustness	Alqahtani, Sarra; Riley, Ian; Taylor, Samuel; Gamble, Rose; Mailler, Roger	AAMAS '18: Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems	https://doi.org/10.5555/3237383.3237425		247-255	"""@inproceedings{10.5555/3237383.3237425,
    author = ""Alqahtani, Sarra and Riley, Ian and Taylor, Samuel and Gamble, Rose and Mailler, Roger"",
    title = ""MTL Robustness for Path Planning with A*"",
    year = ""2018"",
    publisher = ""International Foundation for Autonomous Agents and Multiagent Systems"",
    address = ""Richland, SC"",
    abstract = ""Maintaining the safety of an autonomous drone while it executes a mission is a primary concern in presence of fixed and mobile enemies. Path planning using A* fails to deliver a feasible, safe plan when a drone has resource limitations in such environments. Enhancing A* with constraint optimization techniques may improve outcomes, but significantly increases path determination time. We define Robust A* (RA*) that introduces the use of a safety margin to maximize the robustness of the drone to meet mission requirements while managing resource restrictions. We rely on a theory of robustness based on Metric Temporal Logic (MTL) as applied to offline verification and online control of hybrid systems. By satisfying the predefined MTL constraints, RA* dynamically defines a safety margin between the drone and an enemy, while constraining the margin size given the drone's resources. The safety margin creates a robust neighborhood around the dynamically generated path. The robust neighborhood holds all valid trajectories within the current world state. When the world state changes, RA* first examines the robust neighborhood to find a valid trajectory before initiating the path re-planning. We evaluate RA* using the Rassim simulator. The results show that the algorithm generates faster and safer paths than the classical A* in the presence of moving enemies.."",
    booktitle = ""Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems"",
    pages = ""247-255"",
    numpages = ""9"",
    keywords = ""a*, metric temporal logic, path planning, robustness"",
    location = ""Stockholm, Sweden"",
    series = ""AAMAS '18""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2018	MTL Robustness for Path Planning with A* for Autonomous Agents and Multiagent Systems	https://dl.acm.org/doi/10.5555/3237383.3237425	International Foundation for Autonomous Agents and Multiagent Systems	nan; References
98	TestNN	Safety reinforced driving	"Safety must be a major focus of any Autonomous Vehicle development. Given that Humans drive about 108 miles between fatal crashes, learning methods must be capable of error rates as low as 10-9, at least 6 orders of magnitude better than mainstream ML. Clearly, not all errors lead to an accident; there is a need to determine which are fatal. This paper focuses on quantifying safety, demonstrating that instead of using ""error"" one should define competence using full distribution and test statistics of composable metrics, which include well established safety components. A Reinforcement Learning (RL) formulation is introduced which composes such metrics into a reward, whereby safety and competence are defined in terms of the test statistics of that reward. A scalable multi-agent RL algorithm is presented, which is capable of achieving high 1% percentile of such metrics. Co-existence of a certified baseline non-AI with an AI driver is achieved using apprenticeship training. Results show that it is practical to achieve competence on episodes with hundreds of steps such that the worst 1% percentile of the safety metrics remains very high. Interesting quantized reward distributions during failure are presented."	Errors; Multi agent systems; Reinforcement learning; Statistical tests; Statistics; Autonomous Vehicles; Co-existence; Fatal crashes; Learning methods; Orders of magnitude; Safety component; Safety metrics; Test statistics; Error statistics; Errors;  Multi agent systems;  Reinforcement learning;  Statistical tests;  Statistics;  Autonomous Vehicles;  Co-existence;  Fatal crashes;  Learning methods;  Orders of magnitude;  Safety component;  Safety metrics;  Test statistics;  Error statistics	Schwalb, Edward; Taslimi, Farzaneh; Kuecuekyan, Horen	AUVSI XPONENTIAL 2018		Kaelbling, L.P.,Littman, M.L.,Cassandra, A.R.; Ng, A.Y.,Russel, S.Algorithms for Inverse Reinforcement Learning, ICML 2000.Cited 2283 times.; (2003)Surrogate Safety Measures from Traffic Simulation Models, FHWA-RD-03-050.Cited 223 times.; Task Analysis of Intersection Driving Scenarios: Information Processing BottlenecksFHWA-HRT-06-033; Abbeel, P.,Coates, A.,Quigley, M.,Ng, A.Y.; Bengio, Y.,Louradour, J.,Collobert, R.,Weston, J.; Geiger, A.,Lenz, P.,Stiller, C.,Urtasun, R.; Chen, C.,Seff, A.,Kornhauser, A.,Xiao, J.; Mnih, V.,Kavukcuoglu, K.,Silver, D.,Rusu, A.A.,Veness, J.,Bellemare, M.G.,Graves, A.,(...),Hassabis, D.; Mnih, V.,Badia, A.P.,Mirza, L.,Graves, A.,Harley, T.,Lillicrap, T.P.,Silver, D.,(...),Kavukcuoglu, K.; Xu, H.,Gao, Y.,Yu, F.,Darrell, T.End-to-end Learning of Driving Models from Large-scale Video Datasets.Cited 7 times.arXiv:1612.01079, 2016; Shalev-Shwartz, S.,Shammah, S.,Shashua, A.Reinforcement learning for autonomous drivingICRI-CI 2017; Hessel, M.,Modayil, J.,Van Hasselt, H.,Schaul, T.,Ostrovski, G.,Dabney, W.,Horgan, D.,(...),Silver, D.Rainbow: Combining Improvements in Deep Reinforcement Learning.Cited 283 times.arXiv:1710.02298v1; Shimosaka, M.,Sato, J.,Takenaka, K.,Hitomi, K.; Kalra, N.Challenges and approaches to realizing autonomous vehicle safety, self-Driving cars: Road to deployment, subcommittee on digital commerce and consumer protection, committee on energy and commerce, United States house of representatives(2017)115thCongress, First SessionFeb.; Florensa, C.,Held, D.,Wulfmeier, M.,Zhang, M.,Abbeel, P.Reverse curriculum generation for reinforcement learning(2017)CoRL.Cited 280 times.; El Sallab, A.,Abdou, M.,Perot, E.,Yogamani, S.; Dosovitskiy, A.,Ros, G.,Codevilla, F.,Lopez, A.,Koltun, V.CARLA: An open urban driving simulator(2017)CoRL.Cited 4136 times.; Narvekar, S.,Sinapov, J.,Stone, P.; Van Seijen, H.,Fatemi, M.,Romoff, J.,Laroche, R.(2017)Separation of Concerns in Reinforcement Learning.Cited 8 times.arXiv:1612.05159v2 Mar; Foerster, J.N.,Chen, R.Y.,Al-Shedivat, M.,Whiteson, S.,Abbeel, P.,Mordatch, I.Learning with Opponent-learning Awareness.Cited 103 times.arXiv:1709.04326v2; Yang, Z.,Merrick, K.,Abbass, H.,Jin, L.; Laroche, R.,Trichelair, P.(2018)Safe Policy Improvement with Baseline Bootstrapping.Cited 21 times.arXiv:1712.06924v3 18 Jan; A Toolkit for Developing and Comparing Reinforcementlearning Algorithms.Cited 13 times.https://gym.openai.com		"""@CONFERENCE{Schwalb2018,
    author = ""Schwalb, Edward and Taslimi, Farzaneh and Kuecuekyan, Horen"",
    title = ""Safety reinforced driving"",
    year = ""2018"",
    journal = ""AUVSI XPONENTIAL 2018"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054632219\&partnerID=40\&md5=f75033a31a4264f6adf7a516b5305b20"",
    affiliations = ""Machine Learning Group, MSC Software, United States"",
    abstract = {Safety must be a major focus of any Autonomous Vehicle development. Given that Humans drive about 108 miles between fatal crashes, learning methods must be capable of error rates as low as 10-9, at least 6 orders of magnitude better than mainstream ML. Clearly, not all errors lead to an accident; there is a need to determine which are fatal. This paper focuses on quantifying safety, demonstrating that instead of using ""error"" one should define competence using full distribution and test statistics of composable metrics, which include well established safety components. A Reinforcement Learning (RL) formulation is introduced which composes such metrics into a reward, whereby safety and competence are defined in terms of the test statistics of that reward. A scalable multi-agent RL algorithm is presented, which is capable of achieving high 1\% percentile of such metrics. Co-existence of a certified baseline non-AI with an AI driver is achieved using apprenticeship training. Results show that it is practical to achieve competence on episodes with hundreds of steps such that the worst 1\% percentile of the safety metrics remains very high. Interesting quantized reward distributions during failure are presented. (c) 2018 IQPC. All rights reserved.},
    keywords = ""Errors; Multi agent systems; Reinforcement learning; Statistical tests; Statistics; Autonomous Vehicles; Co-existence; Fatal crashes; Learning methods; Orders of magnitude; Safety component; Safety metrics; Test statistics; Error statistics"",
    publisher = ""Association for Unmanned Vehicle Systems International"",
    language = ""English"",
    abbrev_source_title = ""AUVSI XPONENTIAL"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 0; Conference name: AUVSI XPONENTIAL 2018; Conference date: 1 May 2018 through 3 May 2018; Conference code: 139451""
}
"""	Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	Scopus Signed In	2018	Safety reinforced driving		Association for Unmanned Vehicle Systems International	nan; Pages; DOI; Link
99	TestNN	Serious gaming for building a basis of certification via trust and trustworthiness of autonomous systems	"Autonomous systems governed by a variety of adaptive and nondeterministic algorithms are being planned for inclusion into safety-critical environments, such as unmanned aircraft and space systems in both civilian and military applications. However, until autonomous systems are proven and perceived to be capable and resilient in the face of unanticipated conditions, humans will be reluctant or unable to delegate authority, remaining in control aided by machine-based information and decision support. Proving capability, or trustworthiness, is a necessary component of certification. Perceived capability is a component of trust. Trustworthiness is an attribute of a cyber-physical system that requires context-driven metrics to prove and certify. Trust is an attribute of the agents participating in the system and is gained over time and multiple interactions through trustworthy behavior and transparency. Historically, artificial intelligence and machine learning systems provide answers without explanation - without a rationale or insight into the machine ""thinking"". In order to function as trusted teammates, machines must be able to explain their decisions and actions. This transparency is a product of both content and communication. NASA's Autonomy Teaming & TRAjectories for Complex Trusted Operational Reliability (ATTRACTOR) project seeks to build a basis for certification of autonomous systems via establishing metrics for trustworthiness and trust in multi-agent team interactions, using AI explainability and persistent modeling and simulation, in the context of mission planning and execution, with analyzable trajectories. Inspired by Massively Multiplayer Online Role Playing Games (MMORPG) and Serious Gaming, the proposed ATTRACTOR modeling and simulation environment is similar to online gaming environments in which player (aka agent) participants interact with each other, affect their environment, and expect the simulation to persist and change regardless of any individual agent's active participation. This persistent simulation environment will accommodate individual agents, groups of self-organizing agents, and large-scale infrastructure behavior. The effects of the emerging adaptation and co-evolution can be observed and measured to building a basis of measurable trustworthiness and trust, toward certification of safety-critical autonomous systems."	Decision support systems; Embedded systems; Intelligent agents; Learning systems; Military applications; Multi agent systems; NASA; Safety engineering; Serious games; Social networking (online); Transparency; Large scale infrastructures; Massively multiplayer online role-playing games; Nondeterministic algorithms; Operational reliability; Perceived capabilities; Self organizing agents; Simulation environment; Trust and trustworthiness; Autonomous agents; Decision support systems;  Embedded systems;  Intelligent agents;  Learning systems;  Military applications;  Multi agent systems;  NASA;  Safety engineering;  Serious games;  Social networking (online);  Transparency;  Large scale infrastructures;  Massively multiplayer online role-playing games;  Nondeterministic algorithms;  Operational reliability;  Perceived capabilities;  Self organizing agents;  Simulation environment;  Trust and trustworthiness;  Autonomous agents	Allen, Bonnie D.	2018 Aviation Technology, Integration, and Operations Conference	https://doi.org/10.2514/6.2018-3844			"""@CONFERENCE{Allen2018,
    author = ""Allen, Bonnie D."",
    title = ""Serious gaming for building a basis of certification via trust and trustworthiness of autonomous systems"",
    year = ""2018"",
    journal = ""2018 Aviation Technology, Integration, and Operations Conference"",
    doi = ""10.2514/6.2018-3844"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051647799\&doi=10.2514\%2f6.2018-3844\&partnerID=40\&md5=847a402844d0db04809ec3d1c4a07c28"",
    affiliations = ""NASA Senior Technologist for Intelligent Flight Systems, NASA Langley Research Center, MS 492, Hampton, 23681, VA, United States"",
    abstract = ""Autonomous systems governed by a variety of adaptive and nondeterministic algorithms are being planned for inclusion into safety-critical environments, such as unmanned aircraft and space systems in both civilian and military applications. However, until autonomous systems are proven and perceived to be capable and resilient in the face of unanticipated conditions, humans will be reluctant or unable to delegate authority, remaining in control aided by machine-based information and decision support. Proving capability, or trustworthiness, is a necessary component of certification. Perceived capability is a component of trust. Trustworthiness is an attribute of a cyber-physical system that requires context-driven metrics to prove and certify. Trust is an attribute of the agents participating in the system and is gained over time and multiple interactions through trustworthy behavior and transparency. Historically, artificial intelligence and machine learning systems provide answers without explanation - without a rationale or insight into the machine ""thinking"". In order to function as trusted teammates, machines must be able to explain their decisions and actions. This transparency is a product of both content and communication. NASA's Autonomy Teaming \& TRAjectories for Complex Trusted Operational Reliability (ATTRACTOR) project seeks to build a basis for certification of autonomous systems via establishing metrics for trustworthiness and trust in multi-agent team interactions, using AI explainability and persistent modeling and simulation, in the context of mission planning and execution, with analyzable trajectories. Inspired by Massively Multiplayer Online Role Playing Games (MMORPG) and Serious Gaming, the proposed ATTRACTOR modeling and simulation environment is similar to online gaming environments in which player (aka agent) participants interact with each other, affect their environment, and expect the simulation to persist and change regardless of any individual agent's active participation. This persistent simulation environment will accommodate individual agents, groups of self-organizing agents, and large-scale infrastructure behavior. The effects of the emerging adaptation and co-evolution can be observed and measured to building a basis of measurable trustworthiness and trust, toward certification of safety-critical autonomous systems. (c) 2018, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved."",
    keywords = ""Decision support systems; Embedded systems; Intelligent agents; Learning systems; Military applications; Multi agent systems; NASA; Safety engineering; Serious games; Social networking (online); Transparency; Large scale infrastructures; Massively multiplayer online role-playing games; Nondeterministic algorithms; Operational reliability; Perceived capabilities; Self organizing agents; Simulation environment; Trust and trustworthiness; Autonomous agents"",
    correspondence_address = ""B.D. Allen; NASA Senior Technologist for Intelligent Flight Systems, NASA Langley Research Center, Hampton, MS 492, 23681, United States; email: danette.allen@nasa.gov"",
    publisher = ""American Institute of Aeronautics and Astronautics Inc, AIAA"",
    isbn = ""978-162410556-2"",
    language = ""English"",
    abbrev_source_title = ""Aviat. Technol., Integr., Op. Conf."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 2; Conference name: 18th AIAA Aviation Technology, Integration, and Operations Conference, 2018; Conference date: 25 June 2018 through 29 June 2018; Conference code: 215129""
}
"""	Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	Scopus Signed In	2018	Serious gaming for building a basis of certification via trust and trustworthiness of autonomous systems	https://www.scopus.com/record/display.uri?eid=2-s2.0-85051647799&origin=resultslist&sort=plf-f&src=s&sid=42d3e1518bdd403914c897c828a7ba98&sot=b&sdt=b&s=TITLE-ABS-KEY%28serious+gaming+for+building+a+basis+of+certification+via+trust+and+trustworthiness+of+autonomous+systems%29&sl=119&sessionSearchId=42d3e1518bdd403914c897c828a7ba98&relpos=0	American Institute of Aeronautics and Astronautics Inc, AIAA	nan; References; Pages
100	TestNN	Tactical Safety Reasoning - A Case for Autonomous Vehicles	Self driving cars have recently attracted academia and industry interest. As planning algorithms become responsible for critical decisions, many questions concerning traffic safety arise. An increased automation level demands proportional impact on safety requirements, currently governed by the ISO 26262 standard. However, ISO 26262 sees safety as a functional property of a system and fails to cover emergent concerns related to autonomous decisions. In order to fill this gap we propose the field of tactical safety, which extends safety analysis to planning and execution of driving maneuvers, response to traffic events or autonomous system failures. It is meant to complement, not to replace functional safety properties of a system and allows the analysis of autonomous agents from a safe behavior point of view. We draw the requirements for tactical safety from an automotive standard which defines functional elements for advanced driving automation systems.	Safety;Automation;Vehicles;Vehicle crash testing;ISO Standards;Planning; Safety; Automation; Vehicles; Vehicle crash testing; ISO Standards; Planning	Serban, Alexandru Constantin; Poll, Erik; Visser, Joost	2018 IEEE 87th Vehicular Technology Conference (VTC Spring)	https://doi.org/10.1109/VTCSpring.2018.8417887	"1.S. Behere and M. Torngren, ""A functional reference architecture for autonomous driving"", Information and Software Technology, vol. 73, pp. 136-150, 2016. CrossRef  Google Scholar; 2.M. Broy, ""Challenges in automotive software engineering"", Proceedings of the 28th international conference on Software engineering, pp. 33-42, 2006. CrossRef  Google Scholar; 3.""Society of automotive engineers taxonomy and definitions for terms related to on-road motor vehicle automated driving systems"", SAE Standard J3016, 2014. Google Scholar; 4.M. Staron, ""Software complexity metrics in general and in the context of iso 26262 software verification requirements"", Scandinavian Conference on Systems Safety, 2016. Google Scholar; 5.""Iso 26262:2011 road vehicles - functional safety"", ISO, 2011. Google Scholar; 6.J.-F. Bonnefon, A. Shariff and I. Rahwan, ""The social dilemma of autonomous vehicles"", Science, vol. 352, no. 6293, pp. 1573-1576, 2016. CrossRef  Google Scholar; 7.G. E. Marchant and R. A. Lindor, ""The coming collision between autonomous vehicles and the liability system"", Santa Clara L. Rev., vol. 52, pp. 1321, 2012. Google Scholar; 8.F. M. Favaro, N. Nader, S. O. Eurich, M. Tripp and N. Varadaraju, ""Examining accident reports involving autonomous vehicles in california"", PLoS one, vol. 12, no. 9, pp. e0184952, 2017. CrossRef  Google Scholar; 9.W. Wu and T. Kelly, ""Safety tactics for software architecture design"", Computer Software and Applications Conference 2004. COMPSAC 2004. Proceedings of the 28th Annual International, pp. 368-375, 2004. View Article  Google Scholar; 10.G. F. Kinney, ""Practical risk analysis for safety management"" in tech. rep., China Lake, CA:Naval Weapons Center, 1976. Google Scholar; 11.L. Bainbridge, ""Ironies of automation"", Automatica, vol. 19, no. 6, pp. 775-779, 1983. CrossRef  Google Scholar; 12.S. Thorpe, D. Fize, C. Marlot et al., ""Speed of processing in the human visual system"", nature, vol. 381, no. 6582, pp. 520-522, 1996. CrossRef  Google Scholar; 13.C. Zhang, S. Bengio, M. Hardt, B. Recht and O. Vinyals, Understanding deep learning requires rethinking generalization, 2016. Google Scholar; 14.I. J. Goodfellow, J. Shlens and C. Szegedy, Explaining and harnessing adversarial examples, 2014. Google Scholar; 15.N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik and A. Swami, Practical black-box attacks against deep learning systems using adversarial examples, 2016. Google Scholar; 16.A. Kurakin, I. Goodfellow and S. Bengio, Adversarial examples in the physical world, 2016. Google Scholar; 17.R. Rana, M. Staron, C. Berger, J. Hansson, M. Nilsson and F. Tornr, ""Early verification and validation according to iso 26262 by combining fault injection and mutation testing"", International Conference on Software Technologies, pp. 164-179, 2013. Google Scholar; 18.M. Conrad, P. Munier and F. Rauch, ""Qualifying software tools according to iso 26262"", MBEES, pp. 117-128, 2010. Google Scholar; 19.P. Rempel, P. Mader, T. Kuschke and J. Cleland-Huang, ""Mind the gap: assessing the conformance of software traceability to relevant guidelines"", Proceedings of the 36th International Conference on Software Engineering, pp. 943-954, 2014. CrossRef  Google Scholar; 20.W. Llc, On the road to fully self-driving, 2017,  [online]  Available: https://waymo.com/safetyreport/. Google Scholar; 21.Carla open-source simulator for autonomous driving research,  [online]  Available: https://carla.org. Google Scholar; 22.Apolo.,  [online]  Available: http://apollo.auto. Google Scholar; 23.Cognata deep learning autonomous simulator,  [online]  Available: http://www.cognata.com. Google Scholar; 24.D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman and D. Mane, Concrete problems in ai safety, 2016. Google Scholar; 25.J. Leike, M. Martic, V. Krakovna, P. A. Ortega, T. Everitt, A. Lefrancq, et al., Ai safety gridworlds, 2017. Google Scholar; 26.S. Shalev-Shwartz, S. Shammah and A. Shashua, On a formal model of safe and scalable self-driving cars, 2017. Google Scholar; 27.S. Shalev-Shwartz, S. Shammah and A. Shashua, Safe multiagent reinforcement learning for autonomous driving, 2016. Google Scholar; 28.S. A. Seshia, D. Sadigh and S. S. Sastry, Towards verified artificial intelligence, 2016. Google Scholar; 29.X. Huang, M. Kwiatkowska, S. Wang and M. Wu, ""Safety verification of deep neural networks"", International Conference on Computer Aided Verification, pp. 3-29, 2017. CrossRef  Google Scholar; 30.G. Katz, C. Barrett, D. L. Dill, K. Julian and M. J. Kochenderfer, ""Reluplex: An efficient smt solver for verifying deep neural networks"", International Conference on Computer Aided Verification, pp. 97-117, 2017. CrossRef  Google Scholar"	1-5	"""@INPROCEEDINGS{8417887,
    author = ""Serban, Alexandru Constantin and Poll, Erik and Visser, Joost"",
    booktitle = ""2018 IEEE 87th Vehicular Technology Conference (VTC Spring)"",
    title = ""Tactical Safety Reasoning - A Case for Autonomous Vehicles"",
    year = ""2018"",
    volume = """",
    number = """",
    pages = ""1-5"",
    abstract = ""Self driving cars have recently attracted academia and industry interest. As planning algorithms become responsible for critical decisions, many questions concerning traffic safety arise. An increased automation level demands proportional impact on safety requirements, currently governed by the ISO 26262 standard. However, ISO 26262 sees safety as a functional property of a system and fails to cover emergent concerns related to autonomous decisions. In order to fill this gap we propose the field of tactical safety, which extends safety analysis to planning and execution of driving maneuvers, response to traffic events or autonomous system failures. It is meant to complement, not to replace functional safety properties of a system and allows the analysis of autonomous agents from a safe behavior point of view. We draw the requirements for tactical safety from an automotive standard which defines functional elements for advanced driving automation systems."",
    keywords = ""Safety;Automation;Vehicles;Vehicle crash testing;ISO Standards;Planning"",
    doi = ""10.1109/VTCSpring.2018.8417887"",
    ISSN = ""2577-2465"",
    month = ""June""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	IEEE	2018	Tactical safety reasoning. A case for autonomous vehicles	https://ieeexplore.ieee.org/document/8417887	IEEE	
101	TestNN	Validation and verification flight tests of fixed-wing collaborative UASs with high speeds and high inertias	The research objective for this work is to validate and verify guidance, navigation, and control algorithms that are designed for fixed-wing collaborative unmanned aerial systems (UASs) in unstructured environments. A biologically-inspired swarm control theory provides a framework to distribute sensor payloads between several smaller and less complex agents that have local interactions. Controller design and flight testing of large UASs with high speeds and high inertias holding a formation in a dynamically changing environment and in the presence of external disturbances is complex and requires advanced planning and safety measures. Verification and validation flight tests were conducted using a fixed-wing unmanned aerial system with 4 meter wingspans to investigate the robustness of the guidance, navigation, and control algorithms and also test the embedded morphing potential field collision avoidance logic.	Air navigation; Antennas; Controllers; Flight dynamics; Safety testing; Biologically inspired swarm controls; Changing environment; External disturbances; Guidance ;  navigation ;  and controls; Unmanned aerial systems; Unstructured environments; Validation and verification; Verification-and-validation; Fixed wings; Air navigation;  Antennas;  Controllers;  Flight dynamics;  Safety testing;  Biologically inspired swarm controls;  Changing environment;  External disturbances;  Guidance , navigation , and controls;  Unmanned aerial systems;  Unstructured environments;  Validation and verification;  Verification-and-validation;  Fixed wings	Blevins, Aaron T.; Kim, A. Ram; Shukla, Daksh; Keshmiri, Shawn S.; Huang, Weizhang	2018 Flight Testing Conference	https://doi.org/10.2514/6.2018-4280			"""@CONFERENCE{Blevins2018,
    author = ""Blevins, Aaron T. and Kim, A. Ram and Shukla, Daksh and Keshmiri, Shawn S. and Huang, Weizhang"",
    title = ""Validation and verification flight tests of fixed-wing collaborative UASs with high speeds and high inertias"",
    year = ""2018"",
    journal = ""2018 Flight Testing Conference"",
    doi = ""10.2514/6.2018-4280"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051656104\&doi=10.2514\%2f6.2018-4280\&partnerID=40\&md5=c890a0b3855ba6801664c40bbb93328d"",
    affiliations = ""Department of Aerospace Engineering, University of Kansas, Lawrence, 66045, KS, United States"",
    abstract = ""The research objective for this work is to validate and verify guidance, navigation, and control algorithms that are designed for fixed-wing collaborative unmanned aerial systems (UASs) in unstructured environments. A biologically-inspired swarm control theory provides a framework to distribute sensor payloads between several smaller and less complex agents that have local interactions. Controller design and flight testing of large UASs with high speeds and high inertias holding a formation in a dynamically changing environment and in the presence of external disturbances is complex and requires advanced planning and safety measures. Verification and validation flight tests were conducted using a fixed-wing unmanned aerial system with 4 meter wingspans to investigate the robustness of the guidance, navigation, and control algorithms and also test the embedded morphing potential field collision avoidance logic. (c) 2018, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved."",
    keywords = ""Air navigation; Antennas; Controllers; Flight dynamics; Safety testing; Biologically inspired swarm controls; Changing environment; External disturbances; Guidance , navigation , and controls; Unmanned aerial systems; Unstructured environments; Validation and verification; Verification-and-validation; Fixed wings"",
    publisher = ""American Institute of Aeronautics and Astronautics Inc, AIAA"",
    isbn = ""978-162410555-5"",
    language = ""English"",
    abbrev_source_title = ""Flight Test. Conf."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 4; Conference name: AIAA Flight Testing Conference, 2018; Conference date: 25 June 2018 through 29 June 2018; Conference code: 215029""
}
"""	Excluded	Excluded	new_screen		Exclusion: full-text is not available	1	Scopus Signed In	2018	Validation and Verification Flight Tests of Fixed-Wing Collaborative UASs With High Speeds and High Inertias	https://www.scopus.com/record/display.uri?eid=2-s2.0-85051656104&origin=resultslist&sort=plf-f&src=s&sid=215fab81094eb1c4eeaea4a7795de11e&sot=b&sdt=b&s=TITLE-ABS-KEY%28validation+and+verification+flight+tests+of+fixed+wing+collaborative+uass+with+high+speeds+and+high+inertias%29&sl=123&sessionSearchId=215fab81094eb1c4eeaea4a7795de11e&relpos=0	American Institute of Aeronautics and Astronautics Inc, AIAA	nan; References; Pages
102	TestNN	AILiveSim: An extensible virtual environment for training autonomous vehicles	Virtualization technologies have become common-place both in software development as well as engineering in a more general sense. Using virtualization offers other benefits than simulation and testing as a virtual environment can often be more liberally configured than the corresponding physical environment. This, in turn, introduces new possibilities for education and training, including both for humans and artificial intelligence (AI). To this end, we are developing a simulation platform AILiveSim. The platform is built on top of the Unreal Engine (www.unrealengine.com) game development system, and it is dedicated to training and testing autonomous systems, their sensors and their algorithms in a simulated environment. In this paper, we describe the elements that we have built on top of the engine to realize a Virtual Environment (VE) useful for the design, implementation, application and analysis of autonomous systems. We present the architecture that we have put in place to transform our simulation platform from automotive specific to be domain agnostic and support two new domains of applications: autonomous ships and autonomous mining machines. We describe the important specificity of each domain in regard to simulation.In addition, we also report the challenges encountered when simulating those applications, and the decisions taken to overcome these challenges.	Application programs; Autonomous vehicles; E-learning; Engines; Personnel training; Simulation platform; Software design; Virtualization; Autonomous systems; Education and training; Physical environments; Simulated environment; Simulation; Simulation and testing; Validation; Virtualization technologies; Virtual reality; Application programs;  Autonomous vehicles;  E-learning;  Engines;  Personnel training;  Simulation platform;  Software design;  Virtualization;  Autonomous systems;  Education and training;  Physical environments;  Simulated environment;  Simulation;  Simulation and testing;  Validation;  Virtualization technologies;  Virtual reality	Leudet, Jerome; Christophe, Francois; Mikkonen, Tommi; Mannisto, Tomi	Proceedings - International Computer Software and Applications Conference	https://doi.org/10.1109/COMPSAC.2019.00074	Abram, Gregory D.,Whitted, Turner; Austin, M.Google built an entire fake city to test the AI of its driverless cars(2017)Digital Trends,27.Aughttps://www.digitaltrends.com/cars/google-fake-city/; Behere, S.(2016)Reference Architectures for Highly Automated Driving.Cited 7 times.PhD thesis, KTH Royal Institute of Technology; Berntorp, K.,Hoang, T.,Quirynen, R.,Di Cairano, S.; Bojarski, M.,Del Testa, D.,Dworakowski, D.,Firner, B.,Flepp, B.,Goyal, P.,Jackel, L.D.,(...),Zhang, J.(2016)End to End Learning for Self-driving Cars.Cited 2970 times.arXiv preprint arXiv:1604.07316; Dosovitskiy, A.,Ros, G.,Codevilla, F.,Lopez, A.,Koltun, V.(2017)Carla: An Open Urban Driving Simulator.Cited 4136 times.arXiv preprint arXiv:1711.03938; Games, E.(2007)Unreal Engine.Cited 407 times.https://www.unrealengine.com; Fitzgerald, B.,Stol, K.-J.; Geiger, A.,Lenz, P.,Stiller, C.,Urtasun, R.; Gorgorin, C.,Gradinescu, V.,Diaconescu, R.,Cristea, V.,Iftode, L.; Gutwin, C.; Hoyhtya, M.,Huusko, J.,Kiviranta, M.,Solberg, K.,Rokka, J.; Huang, X.,Wang, P.,Cheng, X.,Zhou, D.,Geng, Q.,Yang, R.(2018)The Apolloscape Open Dataset for Autonomous Driving and Its Application.Cited 32 times.; Huntsberger, T.,Aghazarian, H.,Howard, A.,Trotz, D.C.; (1980)IETF RFC 768. User Datagram Protocol; (1981)IETF RFC 793. Transmission Control Protocol; (2011)ISO26262. Road Vehicles-Functional Safety. International Standard ISO/FDIS, 26262; Leudet, J.,Mikkonen, T.,Christophe, F.,Mannisto, T.; Li, L.Iterative em planning: A flexible motion planning platform for autonomous driving on urban roads(2018)2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC),pp. 374-379.Cited 2 times.; Lind, M.,Brodje, A.,Watson, R.,Haraldson, S.,Holmberg, P.E.,Hagg, M.Digital infrastructures for enabling sea traffic management(2014)The 10th International Symposium ISIS.Cited 2 times.; Lind, M.,Hagg, M.,Siwe, U.,Haraldson, S.; Martensson, T.,Stahl, D.,Bosch, J.; Shah, S.,Dey, D.,Lovett, C.,Kapoor, A.; Statheros, T.,Howells, G.,McDonald-Maier, K.; Tu, E.,Zhang, G.,Rachmawati, L.,Rajabally, E.,Huang, G.-B.; (2011)International Regulations for Prevention of Collisions at Sea, 1972 (72 Colregs)UCG Commandant International Standard ISO/FDIS, 26262; Wang, S.,Zhu, H.; Yang, Z.,Zhang, Y.,Yu, J.,Cai, J.,Luo, J.(2018)End-to-end Multi-modal Multi-task Vehicle Control for Self-driving Cars with Visual Perception.Cited 20 times.; Yu, F.,Xian, W.,Chen, Y.,Liu, F.,Liao, M.,Madhavan, V.,Darrell, T.(2018)Bdd100k: A Diverse Driving Video Database with Scalable Annotation Tooling.Cited 574 times.	479 - 488	"""@CONFERENCE{Leudet2019479,
    author = ""Leudet, Jerome and Christophe, Francois and Mikkonen, Tommi and Mannisto, Tomi"",
    editor = ""V., Getov and J.-L., Gaudiot and N., Yamai and S., Cimato and M., Chang and Y., Teranishi and J.-J., Yang and H.V., Leong and H., Shahriar and M., Takemoto and D., Towey and H., Takakura and A., Elci and S., Takeuchi and S., Puri"",
    title = ""AILiveSim: An extensible virtual environment for training autonomous vehicles"",
    year = ""2019"",
    journal = ""Proceedings - International Computer Software and Applications Conference"",
    volume = ""1"",
    pages = ""479 - 488"",
    doi = ""10.1109/COMPSAC.2019.00074"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072702030\&doi=10.1109\%2fCOMPSAC.2019.00074\&partnerID=40\&md5=c6d3fe53c72c4ce8653efdb038231ac5"",
    affiliations = ""AILiveSim Oy, Helsinki, Finland; Department of Computer Science, University of Helsinki, Helsinki, Finland"",
    abstract = ""Virtualization technologies have become common-place both in software development as well as engineering in a more general sense. Using virtualization offers other benefits than simulation and testing as a virtual environment can often be more liberally configured than the corresponding physical environment. This, in turn, introduces new possibilities for education and training, including both for humans and artificial intelligence (AI). To this end, we are developing a simulation platform AILiveSim. The platform is built on top of the Unreal Engine (www.unrealengine.com) game development system, and it is dedicated to training and testing autonomous systems, their sensors and their algorithms in a simulated environment. In this paper, we describe the elements that we have built on top of the engine to realize a Virtual Environment (VE) useful for the design, implementation, application and analysis of autonomous systems. We present the architecture that we have put in place to transform our simulation platform from automotive specific to be domain agnostic and support two new domains of applications: autonomous ships and autonomous mining machines. We describe the important specificity of each domain in regard to simulation.In addition, we also report the challenges encountered when simulating those applications, and the decisions taken to overcome these challenges. (c) 2019 IEEE."",
    author_keywords = ""Autonomous Systems; Autonomous Vehicles; Simulation; Training; Validation; Virtual Environment"",
    keywords = ""Application programs; Autonomous vehicles; E-learning; Engines; Personnel training; Simulation platform; Software design; Virtualization; Autonomous systems; Education and training; Physical environments; Simulated environment; Simulation; Simulation and testing; Validation; Virtualization technologies; Virtual reality"",
    publisher = ""IEEE Computer Society"",
    issn = ""07303157"",
    isbn = ""978-172812607-4"",
    coden = ""PSICD"",
    language = ""English"",
    abbrev_source_title = ""Proc Int Comput Software Appl Conf"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 11; Conference name: 43rd IEEE Annual Computer Software and Applications Conference, COMPSAC 2019; Conference date: 15 July 2019 through 19 July 2019; Conference code: 151742""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at testing/verification approach	1	Scopus Signed In	2018	Virtual Environment for Training Autonomous Vehicles 2	https://doi.org/10.1109/COMPSAC.2019.00074	IEEE Computer Society	nan; Link
103	TestNN	Compositional Falsification of Cyber-Physical Systems with Machine Learning Components	Cyber-physical systems (CPS), such as automotive systems, are starting to include sophisticated machine learning (ML) components. Their correctness, therefore, depends on properties of the inner ML modules. While learning algorithms aim to generalize from examples, they are only as good as the examples provided, and recent efforts have shown that they can produce inconsistent output under small adversarial perturbations. This raises the question: can the output from learning components lead to a failure of the entire CPS? In this work, we address this question by formulating it as a problem of falsifying signal temporal logic specifications for CPS with ML components. We propose a compositional falsification framework where a temporal logic falsifier and a machine learning analyzer cooperate with the aim of finding falsifying executions of the considered model. The efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks.	Artificial intelligence; Computer circuits; Crime; Cyber Physical System; Deep learning; Deep neural networks; Embedded systems; Learning systems; Machine components; Neural networks; Temporal logic; Automotive Systems; Autonomous driving; Component based; Cyber-Physical System (CPS); Falsification; Falsification frameworks; Sophisticated machines; Temporal logic specifications; Learning algorithms; Artificial intelligence;  Computer circuits;  Crime;  Cyber Physical System;  Deep learning;  Deep neural networks;  Embedded systems;  Learning systems;  Machine components;  Neural networks;  Temporal logic;  Automotive Systems;  Autonomous driving;  Component based;  Cyber-Physical System (CPS);  Falsification;  Falsification frameworks;  Sophisticated machines;  Temporal logic specifications;  Learning algorithms	Dreossi, Tommaso; Donze, Alexandre; Seshia, Sanjit A.	Journal of Automated Reasoning	https://doi.org/10.1007/s10817-018-09509-5	"Imagenet. 
                    http://image-net.org/; Udacity self-driving car simulator built with unity. 
                    https://github.com/udacity/self-driving-car-sim; Abadi, M. et al.: TensorFlow: Large-scale machine learning on heterogeneous systems (2015). Software available from tensorflow.org; citation_title=S-TaLiRo: A Tool for Temporal Logic Falsification for Hybrid Systems; citation_inbook_title=Tools and Algorithms for the Construction and Analysis of Systems; citation_publication_date=2011; citation_pages=254-257; citation_id=CR4; citation_author=Yashwanth Annpureddy; citation_author=Che Liu; citation_author=Georgios Fainekos; citation_author=Sriram Sankaranarayanan; citation_publisher=Springer Berlin Heidelberg; citation_journal_title=Artif. Intell.; citation_title=Selection of relevant features and examples in machine learning; citation_author=AL Blum, P Langley; citation_volume=97; citation_issue=1; citation_publication_date=1997; citation_pages=245-271; citation_doi=10.1016/S0004-3702(97)00063-5; citation_id=CR5; Bojarski, M., DelTesta, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., Monfort, M., Muller, U., Zhang, J., etal.: End to end learning for self-driving cars (2016). arXiv preprint 
                    arXiv:1604.07316; Branicky, M.S., LaValle, S.M., Olson, K., Yang, L.: Quasi-randomized path planning. In: IEEE International Conference on Robotics and Automation, 2001. Proceedings 2001 ICRA, vol.2, pp. 1481-1487. IEEE (2001); Carlini, N., Wagner, D.: Towards evaluating the robustness of neural networks. In: 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57 (2017); citation_title=Breach, A Toolbox for Verification and Parameter Synthesis of Hybrid Systems; citation_inbook_title=Computer Aided Verification; citation_publication_date=2010; citation_pages=167-170; citation_id=CR9; citation_author=Alexandre Donze; citation_publisher=Springer Berlin Heidelberg; citation_title=Efficient Robust Monitoring for STL; citation_inbook_title=Computer Aided Verification; citation_publication_date=2013; citation_pages=264-279; citation_id=CR10; citation_author=Alexandre Donze; citation_author=Thomas Ferrere; citation_author=Oded Maler; citation_publisher=Springer Berlin Heidelberg; citation_title=Efficient Guiding Strategies for Testing of Temporal Properties of Hybrid Systems; citation_inbook_title=Lecture Notes in Computer Science; citation_publication_date=2015; citation_pages=127-142; citation_id=CR11; citation_author=Tommaso Dreossi; citation_author=Thao Dang; citation_author=Alexandre Donze; citation_author=James Kapinski; citation_author=Xiaoqing Jin; citation_author=Jyotirmoy V. Deshmukh; citation_publisher=Springer International Publishing; Dreossi, T., Donze, A., Seshia, S.A.: Compositional falsification of cyber-physical systems with machine learning components. In: NASA Formal Methods Conference (NFM) (2017); Dreossi, T., Ghosh, S., Sangiovanni-Vincentelli, A.L., Seshia, S.A.: Systematic testing of convolutional neural networks for autonomous driving. In: ICML Workshop on Reliable Machine Learning in the Wild (RMLW) (2017). 
                    arXiv:1708.03309; citation_title=Semantic Adversarial Deep Learning; citation_inbook_title=Computer Aided Verification; citation_publication_date=2018; citation_pages=3-26; citation_id=CR14; citation_author=Tommaso Dreossi; citation_author=Somesh Jha; citation_author=Sanjit A. Seshia; citation_publisher=Springer International Publishing; citation_title=C2E2: A Verification Tool for Stateflow Models; citation_inbook_title=Tools and Algorithms for the Construction and Analysis of Systems; citation_publication_date=2015; citation_pages=68-82; citation_id=CR15; citation_author=Parasara Sridhar Duggirala; citation_author=Sayan Mitra; citation_author=Mahesh Viswanathan; citation_author=Matthew Potok; citation_publisher=Springer Berlin Heidelberg; Fawzi, A., Fawzi, O., Frossard, P.: Analysis of classifiers' robustness to adversarial perturbations (2015). arXiv preprint 
                    arXiv:1502.02590; citation_journal_title=CVGIP Graph. Models Image Process.; citation_title=Resolution-first scanning of multidimensional spaces; citation_author=B Hannaford; citation_volume=55; citation_issue=5; citation_publication_date=1993; citation_pages=359-369; citation_doi=10.1006/cgip.1993.1027; citation_id=CR17; citation_journal_title=IEEE Signal Process. Mag.; citation_title=Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups; citation_author=G Hinton; citation_volume=29; citation_issue=6; citation_publication_date=2012; citation_pages=82-97; citation_doi=10.1109/MSP.2012.2205597; citation_id=CR18; Huang, X., Kwiatkowska, M., Wang, S., Wu, M.: Safety verification of deep neural networks (2016). CoRR 
                    arXiv:1610.06940; Iandola, F.N., Han, S., Moskewicz, M.W., Ashraf, K., Dally, W.J., Keutzer, K.: Squeezenet: Alexnet-level accuracy with 50x fewer parameters and 
                    
                      
                    
                    $$<$$
                    
                      
                        
                      
                    
                   0.5 mb model size (2016). arXiv preprint 
                    arXiv:1602.07360; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T.: Caffe: convolutional architecture for fast feature embedding. In: ACM Multimedia Conference, ACMMM, pp. 675-678 (2014); citation_journal_title=IEEE Trans. Comput.-Aided Des. Circuits Syst.; citation_title=Mining requirements from closed-loop control models; citation_author=X Jin, A Donze, J Deshmukh, SA Seshia; citation_volume=34; citation_issue=11; citation_publication_date=2015; citation_pages=1704-1717; citation_doi=10.1109/TCAD.2015.2421907; citation_id=CR22; Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in Neural Information Processing Systems, pp. 1097-1105 (2012); citation_title=Monitoring Temporal Properties of Continuous Signals; citation_inbook_title=Formal Techniques, Modelling and Analysis of Timed and Fault-Tolerant Systems; citation_publication_date=2004; citation_pages=152-166; citation_id=CR24; citation_author=Oded Maler; citation_author=Dejan Nickovic; citation_publisher=Springer Berlin Heidelberg; citation_title=Geometric Discrepancy: An Illustrated Guide; citation_publication_date=2009; citation_id=CR25; citation_author=J Matousek; citation_publisher=Springer; citation_title=Machine Learning: An Artificial Intelligence Approach; citation_publication_date=2013; citation_id=CR26; citation_author=RS Michalski; citation_author=JG Carbonell; citation_author=TM Mitchell; citation_publisher=Springer; Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P.: DeepFool: a simple and accurate method to fool deep neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582 (2016); citation_journal_title=SIAM J. Sci. Comput.; citation_title=Quasi-random sequences and their discrepancies; citation_author=WJ Morokoff, RE Caflisch; citation_volume=15; citation_issue=6; citation_publication_date=1994; citation_pages=1251-1279; citation_doi=10.1137/0915077; citation_id=CR28; Nguyen, A., Yosinski, J., Clune, J.: Deep neural networks are easily fooled: high confidence predictions for unrecognizable images. In: Computer Vision and Pattern Recognition, CVPR, pp. 427-436. IEEE (2015); citation_journal_title=J. Number Theory; citation_title=Low-discrepancy and low-dispersion sequences; citation_author=H Niederreiter; citation_volume=30; citation_issue=1; citation_publication_date=1988; citation_pages=51-70; citation_doi=10.1016/0022-314X(88)90025-X; citation_id=CR30; citation_title=Random Number Generation and Quasi-Monte Carlo Methods; citation_publication_date=1992; citation_id=CR31; citation_author=H Niederreiter; citation_publisher=SIAM; Pei, K., Cao, Y., Yang, J., Jana, S.: DeepXplore: automated whitebox testing of deep learning systems. In: Proceedings of the 26th Symposium on Operating Systems Principles (SOSP), pp. 1-18 (2017); Rosenblatt, J., Wierdl, M.: Pointwise ergodic theorems via harmonic analysis. In: Conference on Ergodic Theory, No. 205, pp. 3-151 (1995); citation_title=Formal Specification for Deep Neural Networks; citation_inbook_title=Automated Technology for Verification and Analysis; citation_publication_date=2018; citation_pages=20-34; citation_id=CR34; citation_author=Sanjit A. Seshia; citation_author=Ankush Desai; citation_author=Tommaso Dreossi; citation_author=Daniel J. Fremont; citation_author=Shromona Ghosh; citation_author=Edward Kim; citation_author=Sumukh Shivakumar; citation_author=Marcell Vazquez-Chanlatte; citation_author=Xiangyu Yue; citation_publisher=Springer International Publishing; Seshia, S.A., Sadigh, D., Sastry, S.S.: Towards verified artificial intelligence (2016). CoRR 
                    arXiv:1606.08514; Shirley, P. etal.: Discrepancy as a quality measure for sample distributions. In: Proceedings of Eurographics, vol.91, pp. 183-194 (1991); citation_title=Lattice Methods for Multiple Integration; citation_publication_date=1994; citation_id=CR37; citation_author=IH Sloan; citation_author=S Joe; citation_publisher=Oxford University Press; Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R.: Intriguing properties of neural networks (2013). 
                    arXiv:1312.6199; Taeyoung, L., Kyongsu, Y., Jangseop, K., Jaewan, L.: Development and evaluations of advanced emergency braking system algorithm for the commercial vehicle. In: Enhanced Safety of Vehicles Conference, ESV, pp. 11-0290 (2011); Trandafir, Aurel., Weisstein, Eric, W.: Quasirandom sequence. From MathWorld--A Wolfram Web Resource; Vapnik, V.: Principles of risk minimization for learning theory. In: NIPS, pp. 831-838 (1991); citation_title=Logical Clustering and Learning for Time-Series Data; citation_inbook_title=Computer Aided Verification; citation_publication_date=2017; citation_pages=305-325; citation_id=CR42; citation_author=Marcell Vazquez-Chanlatte; citation_author=Jyotirmoy V. Deshmukh; citation_author=Xiaoqing Jin; citation_author=Sanjit A. Seshia; citation_publisher=Springer International Publishing; citation_journal_title=Math. Ann.; citation_title=Uber die gleichverteilung von zahlen mod. eins; citation_author=H Weyl; citation_volume=77; citation_issue=3; citation_publication_date=1916; citation_pages=313-352; citation_doi=10.1007/BF01475864; citation_id=CR43; Yamaguchi, T., Kaga, T., Donze, A., Seshia, S.A.: Combining requirement mining, software model checking, and simulation-based verification for industrial automotive systems. In: Proceedings of the IEEE International Conference on Formal Methods in Computer-Aided Design (FMCAD) (2016)"	1031 - 1053	"""@ARTICLE{Dreossi20191031,
    author = ""Dreossi, Tommaso and Donze, Alexandre and Seshia, Sanjit A."",
    title = ""Compositional Falsification of Cyber-Physical Systems with Machine Learning Components"",
    year = ""2019"",
    journal = ""Journal of Automated Reasoning"",
    volume = ""63"",
    number = ""4"",
    pages = ""1031 - 1053"",
    doi = ""10.1007/s10817-018-09509-5"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060349868\&doi=10.1007\%2fs10817-018-09509-5\&partnerID=40\&md5=f87cb216796cb6bb61e71f71664c8f18"",
    affiliations = ""University of California, Berkeley, Berkeley, United States; Decyphir SAS, Moirans, France"",
    abstract = ""Cyber-physical systems (CPS), such as automotive systems, are starting to include sophisticated machine learning (ML) components. Their correctness, therefore, depends on properties of the inner ML modules. While learning algorithms aim to generalize from examples, they are only as good as the examples provided, and recent efforts have shown that they can produce inconsistent output under small adversarial perturbations. This raises the question: can the output from learning components lead to a failure of the entire CPS? In this work, we address this question by formulating it as a problem of falsifying signal temporal logic specifications for CPS with ML components. We propose a compositional falsification framework where a temporal logic falsifier and a machine learning analyzer cooperate with the aim of finding falsifying executions of the considered model. The efficacy of the proposed technique is shown on an automatic emergency braking system model with a perception component based on deep neural networks. (c) 2019, Springer Nature B.V."",
    author_keywords = ""Autonomous driving; Cyber-physical systems; Deep learning; Falsification; Machine learning; Neural networks; Temporal logic"",
    keywords = ""Artificial intelligence; Computer circuits; Crime; Cyber Physical System; Deep learning; Deep neural networks; Embedded systems; Learning systems; Machine components; Neural networks; Temporal logic; Automotive Systems; Autonomous driving; Component based; Cyber-Physical System (CPS); Falsification; Falsification frameworks; Sophisticated machines; Temporal logic specifications; Learning algorithms"",
    correspondence_address = ""T. Dreossi; University of California, Berkeley, Berkeley, United States; email: dreossi@berkeley.edu"",
    publisher = ""Springer Netherlands"",
    issn = ""01687433"",
    coden = ""JAREE"",
    language = ""English"",
    abbrev_source_title = ""J Autom Reasoning"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 104; All Open Access, Green Open Access""
}
"""	Included	Included	new_screen			1	Scopus Signed In	2017	Compositional Falsification of Cyber-Physical Systems with Machine Learning Components 2	https://doi.org/10.1007/s10817-018-09509-5	Springer Netherlands	nan; Link
104	TestNN	Safety assurance strategies for autonomous vehicles	Assuring safety of autonomous vehicles requires that the vehicle control system can perceive the situation in the environment and react to actions of other entities. One approach to vehicle safety assurance is based on the assumption that hazardous sequences of events should be identified during hazard analysis and then some means of hazard avoidance and mitigation, like barriers, should be designed and implemented. Another approach is to design a system which is able to dynamically examine the risk associated with possible actions and then select the safest action to carry it out. Dynamic risk assessment requires maintaining the situation awareness and prediction of possible future situations. We analyse how these two approaches can be applied for autonomous vehicles and what strategies can be used for safety argumentation.	Control system synthesis; Control systems; Control theory; Reliability; Risk management; Risk perception; Vehicles; Autonomous Vehicles; Hazard analyses; Hazard avoidances; Possible futures; Safety assurances; Situation awarenesses; Vehicle control systems; Vehicle safeties; Risk assessment; Control system synthesis;  Control systems;  Control theory;  Reliability;  Risk management;  Risk perception;  Vehicles;  Autonomous Vehicles;  Hazard analyses;  Hazard avoidances;  Possible futures;  Safety assurances;  Situation awarenesses;  Vehicle control systems;  Vehicle safeties;  Risk assessment	Wardzinski, Andrzej	Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)	https://doi.org/10.1007/978-3-540-87698-4_24	Lohmann, R.H.C.About Group Rapid Transit and Dual-Mode Applications(2007)APM 2007, 1 1th International Conference on Automated People MoversVienna; (2006)Urban Challenge Rules.Cited 6 times.DARPA; Robertson, S.W.H.; Clough, B.T.How The Heck Do You Determine A UAV's Autonomy Anyway?(2002)PerMIS Conference Proceedings, Gaithersburg,pp. 1-7.Cited 99 times.Metrics, Schmetrics; Sholes, E.; Hollnagel, E.Accidents and Barriers(1999)Proceedings of Lex Valenciennes, Presses Universitaires de Valenciennes,28,pp. 175-182.Cited 47 times.Hoc, J.-M, et al, eds; Springs, J.Motion Safety for an Autonomous Vehicle Race in an Urban Environment(2003)Currect Issues in Safety-critical Systems - Proceeding of the Eleventh Safety-critical Systems Symposium.Cited 2 times.Redmill, F, Anderson, T, eds, Springer, London; Bishop, P.G.,Bloomfield, R.,Guerra, S.The future of goal-based assurance cases(2004)Proceedings of Workshop on Assurance Cases. Supplemental Volume of the 2004 International Conference on Dependable Systems and Networks,pp. 390-395.Cited 46 times.; Kelly, T.P.(1998)Arguing Safety - A Systematic Approach to Managing Safety Cases.Cited 457 times.PhD thesis, University of York; Wardzinski, A.; Wardzinski, A.Dynamic Risk Assessment in Movement Planning for Autonomous Vehicles(2008)International IEEE Conference on Information Technology, IT,pp. 127-130.Gdansk (Poland, May 18-21, ) 2008; Hollnagel, E.,Woods, D.D.,Leveson, N.(2006)Resilience Engineering.Cited 111 times.Ashgate	277 - 290	"""@ARTICLE{Wardzinski2008277,
    author = ""Wardzinski, Andrzej"",
    title = ""Safety assurance strategies for autonomous vehicles"",
    year = ""2008"",
    journal = ""Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"",
    volume = ""5219 LNCS"",
    pages = ""277 - 290"",
    doi = ""10.1007/978-3-540-87698-4\_24"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-56449103279\&doi=10.1007\%2f978-3-540-87698-4\_24\&partnerID=40\&md5=8dae59cedeafb3edb409de96be615918"",
    affiliations = ""Department of Software Engineering, Gdansk University of Technology, Gdansk 80-952, Narutowicza 11/12, Poland"",
    abstract = ""Assuring safety of autonomous vehicles requires that the vehicle control system can perceive the situation in the environment and react to actions of other entities. One approach to vehicle safety assurance is based on the assumption that hazardous sequences of events should be identified during hazard analysis and then some means of hazard avoidance and mitigation, like barriers, should be designed and implemented. Another approach is to design a system which is able to dynamically examine the risk associated with possible actions and then select the safest action to carry it out. Dynamic risk assessment requires maintaining the situation awareness and prediction of possible future situations. We analyse how these two approaches can be applied for autonomous vehicles and what strategies can be used for safety argumentation. (c) 2008 Springer-Verlag Berlin Heidelberg."",
    keywords = ""Control system synthesis; Control systems; Control theory; Reliability; Risk management; Risk perception; Vehicles; Autonomous Vehicles; Hazard analyses; Hazard avoidances; Possible futures; Safety assurances; Situation awarenesses; Vehicle control systems; Vehicle safeties; Risk assessment"",
    correspondence_address = ""A. Wardzinski; Department of Software Engineering, Gdansk University of Technology, Gdansk 80-952, Narutowicza 11/12, Poland; email: andrzej.wardzinski@eti.pg.gda.pl"",
    issn = ""16113349"",
    isbn = ""3540876979; 978-354087697-7"",
    language = ""English"",
    abbrev_source_title = ""Lect. Notes Comput. Sci."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 29; Conference name: 27th International Conference on Computer Safety, Reliability, and Security, SAFECOMP 2008; Conference date: 22 September 2008 through 25 September 2008; Conference code: 74263""
}
"""	Excluded	Excluded	new_screen		Exclusion: not aiming at modern NN-based CPSs	1	Scopus Signed In	2008	Safety Assurance Strategies for Autonomous Vehicles 2	https://doi.org/10.1007/978-3-540-87698-4_24		nan; Link; Publisher
105	TestNN	Outline safety case for the use of autonomous UAVs in unsegregated airspace	Uninhibited air vehicles (UAVs) are routinely deployed in segregated airspace, however, due to organisational difficulty they are only partially integrated with normal air traffic in exceptional circumstances. This presentation examines the correct operation of UAV's software and the formal analysis of the SOAR agent programming language as contributions to the safe deployment of future military UAVs in unsegregated airspace.		Pygott, C.	2005 The IEE Forum on Autonomous Systems (Ref. No. 2005/11271)	https://doi.org/10.1049/ic:20050475		13 pp.-	"""@INPROCEEDINGS{1574597,
    author = ""Pygott, C."",
    booktitle = ""2005 The IEE Forum on Autonomous Systems (Ref. No. 2005/11271)"",
    title = ""Outline safety case for the use of autonomous UAVs in unsegregated airspace"",
    year = ""2005"",
    volume = """",
    number = """",
    pages = ""13 pp.-"",
    abstract = ""Uninhibited air vehicles (UAVs) are routinely deployed in segregated airspace, however, due to organisational difficulty they are only partially integrated with normal air traffic in exceptional circumstances. This presentation examines the correct operation of UAV's software and the formal analysis of the SOAR agent programming language as contributions to the safe deployment of future military UAVs in unsegregated airspace."",
    keywords = """",
    doi = ""10.1049/ic:20050475"",
    ISSN = ""0537-9989"",
    month = ""Nov""
}
"""	Excluded	Excluded	snowballing		Exclusion: full-text is not available, not peer-reviewed, only have slides	1	Scopus Signed In	2005	Outline safety case for the use of autonomous UAVs in unsegregated airspace	https://ieeexplore.ieee.org/document/1574597	IET	nan; Keywords; References
106	TestNN	Adaptive verification for an on-line learning neural-based flight control system	This paper presents a complex adaptive systems approach for the verification of an adaptive, online learning, sigma-pi neural network that is used for the Intelligent Flight Control System (IFCS) that has the potential of commercial aviation application. This paper reports on the partial completion of my doctoral dissertation proposal at Nova Southeastern University, in the Graduate School of Computer and Information Sciences. The most significant shortcoming of the prior and current approaches to verifying adaptive neural networks is the application of linear approaches to a non-linear problem. The project will use a MatLab simulation of the sigma-pi adaptive neural network and an aircraft simulation to fly a series of simulated flight tests. As a result of the flight simulations, a statistical analysis of the neural network weights is performed as input to both a complexity analysis and a neural network rule extraction analysis. Complex adaptive methods are a novel approach to overcome previous linear analysis limitations. Future work will be required to analyze emergent behavior of the neural network weights to show stability and convergence characteristics. Advances in computational power and neural network techniques for estimating aerodynamic stability and control derivatives provide opportunity for real-time adaptive control. New verification techniques are needed that substantially increases trustworthiness in the use of these neural network systems in life critical systems. Verification of neural-based IFCS is currently an urgent and significant research and engineering topic since these systems are being looked upon as a new approach for aircraft survivability, for both commercial and military.	Adaptive systems; Aerodynamics; Air traffic control; Computer simulation; Flight dynamics; Learning systems; Neural networks; Online systems; Statistical methods; Intelligent Flight Control System (IFCS); MatLab simulation; Non-linear problem; Rule extraction analysis; Civil aviation; Adaptive systems;  Aerodynamics;  Air traffic control;  Computer simulation;  Flight dynamics;  Learning systems;  Neural networks;  Online systems;  Statistical methods;  Intelligent Flight Control System (IFCS);  MatLab simulation;  Non-linear problem;  Rule extraction analysis;  Civil aviation	Broderick, Ronald L.	AIAA/IEEE Digital Avionics Systems Conference - Proceedings	https://doi.org/10.1109/DASC.2005.1563392			"""@CONFERENCE{Broderick2005,
    author = ""Broderick, Ronald L."",
    title = ""Adaptive verification for an on-line learning neural-based flight control system"",
    year = ""2005"",
    journal = ""AIAA/IEEE Digital Avionics Systems Conference - Proceedings"",
    volume = ""1"",
    doi = ""10.1109/DASC.2005.1563392"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746281095\&doi=10.1109\%2fDASC.2005.1563392\&partnerID=40\&md5=db62d823d4caaea803d8a361046397c2"",
    affiliations = ""Graduate School of Computer and Information Science, Nova Southeastern University, Ft. Lauderdale, FL, United States"",
    abstract = ""This paper presents a complex adaptive systems approach for the verification of an adaptive, online learning, sigma-pi neural network that is used for the Intelligent Flight Control System (IFCS) that has the potential of commercial aviation application. This paper reports on the partial completion of my doctoral dissertation proposal at Nova Southeastern University, in the Graduate School of Computer and Information Sciences. The most significant shortcoming of the prior and current approaches to verifying adaptive neural networks is the application of linear approaches to a non-linear problem. The project will use a MatLab simulation of the sigma-pi adaptive neural network and an aircraft simulation to fly a series of simulated flight tests. As a result of the flight simulations, a statistical analysis of the neural network weights is performed as input to both a complexity analysis and a neural network rule extraction analysis. Complex adaptive methods are a novel approach to overcome previous linear analysis limitations. Future work will be required to analyze emergent behavior of the neural network weights to show stability and convergence characteristics. Advances in computational power and neural network techniques for estimating aerodynamic stability and control derivatives provide opportunity for real-time adaptive control. New verification techniques are needed that substantially increases trustworthiness in the use of these neural network systems in life critical systems. Verification of neural-based IFCS is currently an urgent and significant research and engineering topic since these systems are being looked upon as a new approach for aircraft survivability, for both commercial and military."",
    keywords = ""Adaptive systems; Aerodynamics; Air traffic control; Computer simulation; Flight dynamics; Learning systems; Neural networks; Online systems; Statistical methods; Intelligent Flight Control System (IFCS); MatLab simulation; Non-linear problem; Rule extraction analysis; Civil aviation"",
    isbn = ""0780393074; 978-078039307-3"",
    coden = ""ADACF"",
    language = ""English"",
    abbrev_source_title = ""AIAA IEEE Dig Avionics Syst Conf Proc"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 2; Conference name: 24th DASC: 24th Digital Avionics Systems Conference; Conference date: 30 October 2005 through 3 November 2005; Conference code: 66374""
}
"""	Excluded	Excluded	snowballing		Exclusion: not aimed at testing/verification approach	1	Scopus Signed In	2005	Adaptive verification for an on-line learning neural-based flight control system	https://www.scopus.com/record/display.uri?eid=2-s2.0-33746281095&origin=resultslist&sort=plf-f&src=s&sid=f39e21d3e423d705aa4154ba07b89b59&sot=b&sdt=b&s=TITLE-ABS-KEY%28adaptive+verification+for+an+on+line+learning+neural+based+flight+control+system%29&sl=95&sessionSearchId=f39e21d3e423d705aa4154ba07b89b59&relpos=0	IEEE	nan; References; Pages
107	TestNN	An Abstraction-Refinement Approach to Verification of Artificial Neural Networks	A key problem in the adoption of artificial neural networks in safety-related applications is that misbehaviors can be hardly ruled out with traditional analytical or probabilistic techniques. In this paper we focus on specific networks known as Multi-Layer Perceptrons (MLPs), and we propose a solution to verify their safety using abstractions to Boolean combinations of linear arithmetic constraints. We show that our abstractions are consistent, i.e., whenever the abstract MLP is declared to be safe, the same holds for the concrete one. Spurious counterexamples, on the other hand, trigger refinements and can be leveraged to automate the correction of misbehaviors. We describe an implementation of our approach based on theHySATsolver, detailing the abstraction-refinement process and the automated correction strategy. Finally, we present experimental results confirming the feasibility of our approach on a realistic case study.	Root Mean Square Error; Hide Layer; Input Vector; Generalization Error; Abstract Domain	Luca Pulina; Armando Tacchella	International Conference on Computer Aided Verification	https://doi.org/10.1007/978-3-642-14295-6_24		243-257		Excluded	Excluded	snowballing		Exclusion: previous verison of [91]	1	Springer Link	2010	An abstraction-refinement approach to verification of artificial neural networks	https://doi.org/10.1007/978-3-642-14295-6_24	Springer, Berlin, Heidelberg	nan; References; Year; Bibtex; Link
108	TestNN	NeVer: a tool for artificial neural networks verification	The adoption of Artificial Neural Networks (ANNs) in safety-related applications is often avoided because it is difficult to rule out possible misbehaviors with traditional analytical or probabilistic techniques. In this paper we present NeVer, our tool for checking safety of ANNs. NeVerencodes the problem of verifying safety of ANNs into the problem of satisfying corresponding Boolean combinations of linear arithmetic constraints. We describe the main verification algorithm and the structure of NeVer. We present also empirical results confirming the effectiveness of NeVeron realistic case studies.	Artificial Intelligence; Formal methods for adaptive systems; Abstraction techniques; Algorithms and tools for verification; 68Q60; 68Q45	Luca Pulina; Armando Tacchella	Annals of Mathematics and Artificial Intelligence	https://doi.org/10.1007/s10472-011-9243-0	"citation_journal_title=IEEE Trans. Syst. Man Cybern., Part C Appl. Rev.; citation_title=Neural networks for classification: a survey; citation_author=GP Zhang; citation_volume=30; citation_issue=4; citation_publication_date=2000; citation_pages=451-462; citation_doi=10.1109/5326.897072; citation_id=CR1; Smith, D.J., Simpson, K.G.L.: Functional Safety - A Straightforward Guide to Applying IEC 61505 and Related Standards (2nd edn.). Elsevier (2004); Schumann, J., Gupta, P., Nelson, S.: On verification & validation of neural network based controllers. In: Proc. of International Conf. on Engineering Applications of Neural Networks (EANN'03) (2003); citation_journal_title=Neural Comput. Appl.; citation_title=Developing artificial neural networks for safety critical systems; citation_author=Z Kurd, T Kelly, J Austin; citation_volume=16; citation_issue=1; citation_publication_date=2007; citation_pages=11-19; citation_id=CR4; citation_journal_title=ACM Trans. Program. Lang. Syst. (TOPLAS); citation_title=Automatic verification of finite-state concurrent systems using temporal logic specifications; citation_author=EM Clarke, EA Emerson, AP Sistla; citation_volume=8; citation_issue=2; citation_publication_date=1986; citation_pages=263; citation_doi=10.1145/5397.5399; citation_id=CR5; Queille, J., Sifakis, J.: Specification and verification of concurrent systems in CESAR. In: International Symposium on Programming, pp. 337-351. Springer (1982); Schubert, T.: High level formal verification of next-generation microprocessors. In: Proceedings of the 40th annual Design Automation Conference. ACM (2003); Ball, T., Cook, B., Levin, V., Rajamani, S.K.: SLAM and static driver verifier: Technology transfer of formal methods inside Microsoft. In: Integrated Formal Methods, pp. 1-20. Springer (2004); Armando, A., Carbone, R., Compagna, L.: LTL model checking for security protocols. In: 20th IEEE Computer Security Foundations Symposium, pp. 385-396 (2007); Alur, R., Henzinger, T.A., Ho, P.: Automatic symbolic verification of embedded systems. In: IEEE Real-Time Systems Symposium, pp. 2-11 (1993); Clarke, E.M., Grumberg, O., Peled, D.A.: Model Checking. Springer (1999); citation_journal_title=Neural Netw; citation_title=Multilayer feedforward networks are universal approximators; citation_author=K Hornik, M Stinchcombe, H White; citation_volume=2; citation_issue=5; citation_publication_date=1989; citation_pages=359-366; citation_doi=10.1016/0893-6080(89)90020-8; citation_id=CR12; Pulina, L., Tacchella, A.: An abstraction-refinement approach to verification of artificial neural networks. In: 22nd International Conference on Computer Aided Verification (CAV 2010). Lecture Notes in Computer Science, vol. 6174, pp. 243-257. Springer (2010); Solar-Lezama, A., Jones, C.G., Bodik, R.: Sketching concurrent data structures. In: 2008 ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 136-148. ACM (2008); Vechev, M., Yahav, E., Yorsh, G.G.: Abstraction-guided synthesis of synchronization. In: 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pp. 327-338. ACM (2010); citation_journal_title=J. Mach. Learn. Res.; citation_title=Shark; citation_author=C Igel, T Glasmachers, V Heidrich-Meisner; citation_volume=9; citation_publication_date=2008; citation_pages=993-996; citation_id=CR16; citation_journal_title=JSAT, Boolean Modeling and Computation; citation_title=Efficient solving of large non-linear arithmetic constraint systems with complex boolean structure; citation_author=M Franzle, C Herde, T Teige, S Ratschan, T Schubert; citation_volume=1; citation_publication_date=2007; citation_pages=209-236; citation_id=CR17; citation_journal_title=Cem. Concr. Res.; citation_title=Modeling of strength of high-performance concrete using artificial neural networks; citation_author=IC Yeh; citation_volume=28; citation_issue=12; citation_publication_date=1998; citation_pages=1797-1808; citation_doi=10.1016/S0008-8846(98)00165-3; citation_id=CR18; Haykin, S.: Neural Networks: a Comprehensive Foundation. Prentice Hall (2008); citation_journal_title=Artif. Intell.; citation_title=Consistency in networks of relations; citation_author=AK Mackworth; citation_volume=8; citation_issue=1; citation_publication_date=1977; citation_pages=99-118; citation_doi=10.1016/0004-3702(77)90007-8; citation_id=CR20; Van Hentenryck, P.: Numerica: a modeling language for global optimization. In: Fifteenth International Joint Conference on Artificial Intelligence (IJCAI), pp. 1642-1650 (1997); Rossi, F., Van Beek, P., Walsh, T.: Handbook of Constraint Programming. Elsevier Science Ltd (2006); Barichard, V., Hao, J.K.: A population and interval constraint propagation algorithm. In: Evolutionary Multi-Criterion Optimization, Second International Conference (EMO 2003), pp. 88-101. Springer (2003); citation_title=Conflict-driven Clause Learning SAT Solvers. Handbook of Satisfiability; citation_publication_date=2009; citation_id=CR24; citation_author=J Marques-Silva; citation_author=I Lynce; citation_author=S Malik; citation_publisher=IOS Press; citation_title=Satisfiability Modulo Theories. Handbook of Satisfiability; citation_publication_date=2009; citation_id=CR25; citation_author=C Barrett; citation_author=R Sebastiani; citation_author=SA Seshia; citation_author=C Tinelli; citation_publisher=IOS Press; Jermann, C., Sam-Haroud, D., Trombettoni, G. (eds.): CP Workshop on Interval Analysis, Constraint Propagation, Applications (IntCP 2009) (2009); Cousot, P., Cousot, R.: Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints. In: 4th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, pp. 238-252 (1977); citation_journal_title=J. ACM (JACM); citation_title=Counterexample-guided abstraction refinement for symbolic model checking; citation_author=E Clarke, O Grumberg, S Jha, Y Lu, H Veith; citation_volume=50; citation_issue=5; citation_publication_date=2003; citation_pages=794; citation_doi=10.1145/876638.876643; citation_id=CR28; citation_title=Yale: rapid prototyping for complex data mining tasks; citation_inbook_title=12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'06); citation_publication_date=2006; citation_pages=935-940; citation_id=CR29; citation_author=I Mierswa; citation_author=M Wurst; citation_author=R Klinkenberg; citation_author=M Scholz; citation_author=T Euler; citation_publisher=ACM; Gordeau, R.: Roboop - a robotics object oriented package in C++. 
                    http://www.cours.polymtl.ca/roboop
                    
                   (2005); Rabunal, J.R., Dorrado, J.: Artificial Neural Networks in Real-life Applications. Idea Group Pub (2006); Witten, I.H., Frank, E.: Data Mining (2nd edn.). Morgan Kaufmann (2005); citation_journal_title=J. Artif. Intell. Res.; citation_title=Asimovian adaptive agents; citation_author=DF Gordon; citation_volume=13; citation_issue=1; citation_publication_date=2000; citation_pages=95-153; citation_id=CR33; Pappas, G., Kress-Gazit, H. (eds.): ICRA Workshop on Formal Methods in Robotics and Automation (2009)"			Included	Included	snowballing			1	Springer Link	2011	NeVer: a tool for artificial neural networks verification	https://doi.org/10.1007/s10472-011-9243-0	Springer Link	nan; Pages; Year; Bibtex; Link
109	TestNN	Challenging SMT solvers to verify neural networks	In recent years, Satisfiability Modulo Theory (SMT) solvers are becoming increasingly popular in the Computer Aided Verification and Reasoning community. Used natively or as back-engines, they are accumulating a record of success stories and, as witnessed by the annual SMT competition, their performances and capacity are also increasing steadily. Introduced in previous contributions of ours, a new application domain providing an outstanding challenge for SMT solvers is represented by verification of Multi-Layer Perceptrons (MLPs) a widely-adopted kind of artificial neural network. In this paper we present an extensive evaluation of the current state-of-the-art SMT solvers and assess their potential in the promising domain of MLP verification.	Empirical evaluation of SMT solvers; applications of automated reasoning; formal methods for adaptive systems	Luca Pulina; Armando Tacchella	AI Communications	https://doi.org/10.5555/2350156.2350160		117-135		Included	Included	snowballing			1	ACM	2012	Challenging SMT solvers to verify neural networks	https://doi.org/10.5555/2350156.2350160	IOS Press	nan; References; Year; Bibtex; Link
110	TestNN	Intriguing properties of neural networks			Szegedy, C., W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow and R. Fergus						Included	Included	snowballing			1		2013				
111	TestNN	Toward guaranteed illumination models for non-convex objects	Illumination variation remains a central challenge in object detection and recognition. Existing analyses of illumination variation typically pertain to convex, Lambert Ian objects, and guarantee quality of approximation in an average case sense. We show that it is possible to build models for the set of images across illumination variation with worst-case performance guarantees, for nonconvex Lambertian objects. Namely, a natural verification test based on the distance to the model guarantees to accept any image which can be sufficiently well-approximated by an image of the object under some admissible lighting condition, and guarantees to reject any image that does not have a sufficiently good approximation. These models are generated by sampling illumination directions with sufficient density, which follows from a new perturbation bound for directional illuminated images in the Lambertian model. As the number of such images required for guaranteed verification may be large, we introduce a new formulation for cone preserving dimensionality reduction, which leverages tools from sparse and low-rank decomposition to reduce the complexity, while controlling the approximation error with respect to the original model.	Face recognition; Dimensionality reduction; Illumination cone; Illumination variation; Lambertian surfaces; Low-rank decomposition; Nonconvex; Object detection and recognition; Worst-case performance; Acceptance tests; Face recognition;  Dimensionality reduction;  Illumination cone;  Illumination variation;  Lambertian surfaces;  Low-rank decomposition;  Nonconvex;  Object detection and recognition;  Worst-case performance;  Acceptance tests	Zhang, Yuqian; Mu, Cun; Kuo, Han-Wen; Wright, John	Proceedings of the IEEE International Conference on Computer Vision	https://doi.org/10.1109/ICCV.2013.120		937 - 944	"""@CONFERENCE{Zhang2013937,
    author = ""Zhang, Yuqian and Mu, Cun and Kuo, Han-Wen and Wright, John"",
    title = ""Toward guaranteed illumination models for non-convex objects"",
    year = ""2013"",
    journal = ""Proceedings of the IEEE International Conference on Computer Vision"",
    pages = ""937 - 944"",
    doi = ""10.1109/ICCV.2013.120"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898771090\&doi=10.1109\%2fICCV.2013.120\&partnerID=40\&md5=a5c21cb9ee32e20ccc344f0cc326b4f9"",
    affiliations = ""Columbia University, New York City, NY, United States"",
    abstract = ""Illumination variation remains a central challenge in object detection and recognition. Existing analyses of illumination variation typically pertain to convex, Lambert Ian objects, and guarantee quality of approximation in an average case sense. We show that it is possible to build models for the set of images across illumination variation with worst-case performance guarantees, for nonconvex Lambertian objects. Namely, a natural verification test based on the distance to the model guarantees to accept any image which can be sufficiently well-approximated by an image of the object under some admissible lighting condition, and guarantees to reject any image that does not have a sufficiently good approximation. These models are generated by sampling illumination directions with sufficient density, which follows from a new perturbation bound for directional illuminated images in the Lambertian model. As the number of such images required for guaranteed verification may be large, we introduce a new formulation for cone preserving dimensionality reduction, which leverages tools from sparse and low-rank decomposition to reduce the complexity, while controlling the approximation error with respect to the original model. (c) 2013 IEEE."",
    author_keywords = ""Illumination cone model; Lambertian surface; Nonconvex object; Object instance verification"",
    keywords = ""Face recognition; Dimensionality reduction; Illumination cone; Illumination variation; Lambertian surfaces; Low-rank decomposition; Nonconvex; Object detection and recognition; Worst-case performance; Acceptance tests"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-147992839-2"",
    coden = ""PICVE"",
    language = ""English"",
    abbrev_source_title = ""Proc IEEE Int Conf Comput Vision"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 9; Conference name: 2013 14th IEEE International Conference on Computer Vision, ICCV 2013; Conference date: 1 December 2013 through 8 December 2013; Conference code: 104551; All Open Access, Green Open Access""
}
"""	Excluded	Excluded	snowballing		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	2013	Toward guaranteed illumination models for non-convex objects	https://www.scopus.com/record/display.uri?eid=2-s2.0-84898771090&origin=resultslist&sort=plf-f&src=s&sid=9576e10e7a6007c4964b53b61ae81228&sot=b&sdt=b&s=TITLE-ABS-KEY%28toward+guaranteed+illumination+models+for+non+convex+objects%29&sl=75&sessionSearchId=9576e10e7a6007c4964b53b61ae81228&relpos=0	Institute of Electrical and Electronics Engineers Inc	nan; References
112	TestNN	Deep inside convolutional networks: Visualising image classification models and saliency maps	This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [5], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [13].	Convolution; Image segmentation; Visualization; Classification models; Convnet; Convolutional networks; Gradient based; Input image; Object segmentation; Saliency map; Image classification; Convolution;  Image segmentation;  Visualization;  Classification models;  Convnet;  Convolutional networks;  Gradient based;  Input image;  Object segmentation;  Saliency map;  Image classification	Simonyan, Karen; Vedaldi, Andrea; Zisserman, Andrew	2nd International Conference on Learning Representations, ICLR 2014 - Workshop Track Proceedings	https://www.scopus.com/record/display.uri?eid=2-s2.0-85083953896&origin=resultslist&sort=plf-f&src=s&sid=8a6e3dd0d29930166e213c4017796d28&sot=b&sdt=b&s=TITLE-ABS-KEY%28deep+inside+convolutional+networks+visualising+image+classification+models+and+saliency+maps%29&sl=107&sessionSearchId=8a6e3dd0d29930166e213c4017796d28&relpos=0			"""@CONFERENCE{Simonyan2014,
    author = ""Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew"",
    title = ""Deep inside convolutional networks: Visualising image classification models and saliency maps"",
    year = ""2014"",
    journal = ""2nd International Conference on Learning Representations, ICLR 2014 - Workshop Track Proceedings"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953896\&partnerID=40\&md5=5897b0590b10086cbf0bd356292a0908"",
    affiliations = ""Visual Geometry Group, University of Oxford, United Kingdom"",
    abstract = ""This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [5], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [13]. (c) 2014 International Conference on Learning Representations, ICLR. All rights reserved."",
    keywords = ""Convolution; Image segmentation; Visualization; Classification models; Convnet; Convolutional networks; Gradient based; Input image; Object segmentation; Saliency map; Image classification"",
    publisher = ""International Conference on Learning Representations, ICLR"",
    language = ""English"",
    abbrev_source_title = ""Int. Conf. Learn. Represent., ICLR - Workshop Track Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1754; Conference name: 2nd International Conference on Learning Representations, ICLR 2014; Conference date: 14 April 2014 through 16 April 2014; Conference code: 149800""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2013	Deep inside convolutional networks: Visualising image classification models and saliency maps	https://www.scopus.com/record/display.uri?eid=2-s2.0-85083953896&origin=resultslist&sort=plf-f&src=s&sid=8a6e3dd0d29930166e213c4017796d28&sot=b&sdt=b&s=TITLE-ABS-KEY%28deep+inside+convolutional+networks+visualising+image+classification+models+and+saliency+maps%29&sl=107&sessionSearchId=8a6e3dd0d29930166e213c4017796d28&relpos=0	International Conference on Learning Representations, ICLR	nan; References; Pages
113	TestNN	AxNN: Energy-efficient neuromorphic systems using approximate computing	Neuromorphic algorithms, which are comprised of highly complex, large-scale networks of artificial neurons, are increasingly used for a variety of recognition, classification, search and vision tasks. However, their computational and energy requirements can be quite high, and hence their energy-efficient implementation is of great interest. We propose a new approach to design energy-efficient hardware implementations of large-scale neural networks (NNs) using approximate computing. Our work is motivated by the observations that (i) NNs are used in applications where less-than-perfect results are acceptable, and often inevitable, and (ii) they are highly resilient to inexactness in many (but not all) of their constituent computations. We make two key contributions. First, we propose a method to transform any given NN into an Approximate Neural Network (AxNN). This is performed by (i) adapting the backpropagation technique, which is commonly used to train these networks, to quantify the impact of approximating each neuron to the overall network quality (e.g., classification accuracy), and (ii) selectively approximating those neurons that impact network quality the least. Further, we make the key observation that training is a naturally error-healing process that can be used to mitigate the impact of approximations to neurons. Therefore, we incrementally retrain the network with the approximations in-place, reclaiming a significant portion of the quality ceded by approximations. As a second contribution, we propose a programmable and quality-configurable neuromorphic processing engine (qcNPE), which utilizes arrays of specialized processing elements that execute neuron computations with dynamically configurable accuracies and can be used to execute AxNNs from diverse applications. We evaluated the proposed approach by constructing AXNNs for 6 recognition applications (ranging in complexity from 12-47,818 neurons and 160-3,155,968 connections) and executing them on two different platforms-qcNPE implementation containing 272 processing elements in 45nm technology and a commodity Intel Xeon server. Our results demonstrate 1.14X-1.92X energy benefits for virtually no loss (< 0.5%) in output quality, and even higher improvements (upto 2.3X) when some loss (upto 7.5%) in output quality is acceptable.	Algorithms; Complex networks; Hardware; Low power electronics; Neural networks; Neurons; Power electronics; Approximate Computing; Backpropagation techniques; Classification accuracy; Diverse applications; Hardware implementations; Large-scale network; Neural networks (NNS); Neuromorphic systems; Energy efficiency; Algorithms;  Complex networks;  Hardware;  Low power electronics;  Neural networks;  Neurons;  Power electronics;  Approximate Computing;  Backpropagation techniques;  Classification accuracy;  Diverse applications;  Hardware implementations;  Large-scale network;  Neural networks (NNS);  Neuromorphic systems;  Energy efficiency	Venkataramani, Swagath; Ranjan, Ashish; Roy, Kaushik; Raghunathan, Anand	Proceedings of the International Symposium on Low Power Electronics and Design	https://doi.org/10.1145/2627369.2627613		27 - 32	"""@CONFERENCE{Venkataramani201527,
    author = ""Venkataramani, Swagath and Ranjan, Ashish and Roy, Kaushik and Raghunathan, Anand"",
    title = ""AxNN: Energy-efficient neuromorphic systems using approximate computing"",
    year = ""2015"",
    journal = ""Proceedings of the International Symposium on Low Power Electronics and Design"",
    volume = ""2015-October"",
    pages = ""27 - 32"",
    doi = ""10.1145/2627369.2627613"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953384046\&doi=10.1145\%2f2627369.2627613\&partnerID=40\&md5=e552bd33a9fe0ddb6cafc554fd61aaf9"",
    affiliations = ""School of Electrical and Computer Engineering, Purdue University, 475 Northwestern Ave, West Lafayette, 47907, IN, United States"",
    abstract = ""Neuromorphic algorithms, which are comprised of highly complex, large-scale networks of artificial neurons, are increasingly used for a variety of recognition, classification, search and vision tasks. However, their computational and energy requirements can be quite high, and hence their energy-efficient implementation is of great interest. We propose a new approach to design energy-efficient hardware implementations of large-scale neural networks (NNs) using approximate computing. Our work is motivated by the observations that (i) NNs are used in applications where less-than-perfect results are acceptable, and often inevitable, and (ii) they are highly resilient to inexactness in many (but not all) of their constituent computations. We make two key contributions. First, we propose a method to transform any given NN into an Approximate Neural Network (AxNN). This is performed by (i) adapting the backpropagation technique, which is commonly used to train these networks, to quantify the impact of approximating each neuron to the overall network quality (e.g., classification accuracy), and (ii) selectively approximating those neurons that impact network quality the least. Further, we make the key observation that training is a naturally error-healing process that can be used to mitigate the impact of approximations to neurons. Therefore, we incrementally retrain the network with the approximations in-place, reclaiming a significant portion of the quality ceded by approximations. As a second contribution, we propose a programmable and quality-configurable neuromorphic processing engine (qcNPE), which utilizes arrays of specialized processing elements that execute neuron computations with dynamically configurable accuracies and can be used to execute AxNNs from diverse applications. We evaluated the proposed approach by constructing AXNNs for 6 recognition applications (ranging in complexity from 12-47,818 neurons and 160-3,155,968 connections) and executing them on two different platforms-qcNPE implementation containing 272 processing elements in 45nm technology and a commodity Intel Xeon server. Our results demonstrate 1.14X-1.92X energy benefits for virtually no loss (< 0.5\%) in output quality, and even higher improvements (upto 2.3X) when some loss (upto 7.5\%) in output quality is acceptable. (c) 2014 ACM."",
    author_keywords = ""Approximate Computing; Energy Efficiency; Large-scale Neural Networks; Neuromorphic Systems"",
    keywords = ""Algorithms; Complex networks; Hardware; Low power electronics; Neural networks; Neurons; Power electronics; Approximate Computing; Backpropagation techniques; Classification accuracy; Diverse applications; Hardware implementations; Large-scale network; Neural networks (NNS); Neuromorphic systems; Energy efficiency"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""15334678"",
    isbn = ""978-145032975-0"",
    language = ""English"",
    abbrev_source_title = ""Proc. Int. Symp. Low Power Electron. Des."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 18; Conference name: ACM/IEEE International Symposium on Low Power Electronics and Design, ISLPED 2014; Conference date: 11 August 2014 through 13 August 2014; Conference code: 117254""
}
"""	Excluded	Excluded	snowballing		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	Scopus Signed In	2014	AxNN: energy-efficient neuromorphic systems using approximate computing	https://www.scopus.com/record/display.uri?eid=2-s2.0-84953384046&origin=resultslist&sort=plf-f&src=s&sid=02fcab0f83d8840408f8552cdabfff13&sot=b&sdt=b&s=TITLE-ABS-KEY%28axnn+energy+efficient+neuromorphic+systems+using+approximate+computing%29&sl=85&sessionSearchId=02fcab0f83d8840408f8552cdabfff13&relpos=0	Institute of Electrical and Electronics Engineers Inc	nan; References
114	TestNN	Explaining and Harnessing Adversarial Examples			Goodfellow, I. J., J. Shlens and C. Szegedy						Included	Included	snowballing			1		2014				
115	TestNN	Towards deep neural network architectures robust to adversarial examples	Recent work has shown deep neural networks (DNNs) to be highly susceptible to well-designed, small perturbations at the input layer, or so-called adversarial examples. Taking images as an example, such distortions are often imperceptible, but can result in 100% mis-classification for a state of the art DNN. We study the structure of adversarial examples and explore network topology, pre-processing and training strategies to improve the robustness of DNNs. We perform various experiments to assess the removability of adversarial examples by corrupting with additional noise and pre-processing with denoising autoencoders (DAEs). We find that DAEs can remove substantial amounts of the adversarial noise. However, when stacking the DAE with the original DNN, the resulting network can again be attacked by new adversarial examples with even smaller distortion. As a solution, we propose Deep Contractive Network, a model with a new end-to-end training procedure that includes a smoothness penalty inspired by the contractive autoencoder (CAE). This increases the network robustness to adversarial examples, without a significant performance penalty.	Differential equations; Multilayer neural networks; Network architecture; Network robustness; Network topology; Performance penalties; Pre-processing; Small perturbations; State of the art; Training procedures; Training strategy; Deep neural networks; Differential equations;  Multilayer neural networks;  Network architecture;  Network robustness;  Network topology;  Performance penalties;  Pre-processing;  Small perturbations;  State of the art;  Training procedures;  Training strategy;  Deep neural networks	Gu, Shixiang; Rigazio, Luca	3rd International Conference on Learning Representations, ICLR 2015 - Workshop Track Proceedings	https://doi.org/10.48550/arXiv.1412.5068	Alain, G.,Bengio, Y.(2012)What Regularized Auto-Encoders Learn from the Data Generating Distribution.Cited 21 times.arXiv preprint; Bengio, Y.; Chen, M.,Weinberger, K.,Sha, F.,Bengio, Y.Marginalized denoising autoencoders for nonlinear representations(2014)JMLR,32(1),pp. 1476-1484.Cited 86 times.; Dahl, G.E.,Yu, D.,Deng, L.,Acero, A.; Douglas, R.J.,Koch, C.,Mahowald, M.,Martin, K.A.C.,Suarez, H.H.; Duvenand, D.,Rippel, O.,Adams, R.P.,Ghahramani, Z.(2014)Avoiding Pathologies in Very Deep Networks.Cited 9 times.arXiv preprint; Felleman, D.J.,Van Essen, D.C.; Hinton, G.E.,Krizhevsky, A.,Wang, S.D.; Krizhevsky, A.,Hinton, G.(2009)Learning Multiple Layers of Features from Tiny Images.Cited 25257 times.Computer Science Department, University of Toronto, Tech. Rep; Krizhevsky, A.,Sutskever, I.,Hinton, G.E.Imagenet classification with deep convolutional neural networks(2012)NIPS,1,p. 4.Cited 5655 times.; LeCun, Y.,Cortes, C.(1998)The Mnist Database of Handwritten Digits.Cited 5057 times.; Mnih, V.(2009)Cudamat: A Cuda-Based Matrix Class for Python.Cited 56 times.Department of Computer Science, University of Toronto, Tech. Rep. UTML TR, 4; Mnih, V.,Heess, N.,Graves, A.,Kavukcuoglu, K.Recurrent models of visual attention(2014)CoRR.Cited 455 times.http://arxiv.org/abs/1406.6247; Rifai, S.,Mesnil, G.,Vincent, P.,Muller, X.,Bengio, Y.,Dauphin, Y.,Glorot, X.; Rifai, S.,Vincent, P.,Muller, X.,Glorot, X.,Bengio, Y.; Stollenga, M.F.,Masci, J.,Gomez, F.,Schmidhuber, J.; Szegedy, C.,Liu, W.,Jia, Y.,Sermanet, P.,Reed, S.,Anguelov, D.,Erhan, D.,(...),Rabinovich, A.(2014)Going Deeper with Convolutions.Cited 3088 times.arXiv preprint; Szegedy, C.,Zaremba, W.,Sutskever, I.,Bruna, J.,Erhan, D.,Goodfellow, I.,Fergus, R.; Taigman, Y.,Yang, M.,Ranzato, M.,Wolf, L.; Tang, Y.(2013)Deep Learning Using Support Vector Machines.Cited 818 times.arXiv preprint; Vinyals, O.,Jia, Y.,Deng, L.,Darrell, T.; Zhang, N.,Paluri, M.,Ranzato, M.A.,Darrell, T.,Bourdev, L.(2013)Panda: Pose Aligned Networks for Deep Attribute Modeling.Cited 25 times.arXiv preprint		"""@CONFERENCE{Gu2015,
    author = ""Gu, Shixiang and Rigazio, Luca"",
    title = ""Towards deep neural network architectures robust to adversarial examples"",
    year = ""2015"",
    journal = ""3rd International Conference on Learning Representations, ICLR 2015 - Workshop Track Proceedings"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953152\&partnerID=40\&md5=593e582a9b597a8415144da7a56be189"",
    affiliations = ""Panasonic Silicon Valley Laboratory, Panasonic R and D Company of America, United States"",
    abstract = ""Recent work has shown deep neural networks (DNNs) to be highly susceptible to well-designed, small perturbations at the input layer, or so-called adversarial examples. Taking images as an example, such distortions are often imperceptible, but can result in 100\% mis-classification for a state of the art DNN. We study the structure of adversarial examples and explore network topology, pre-processing and training strategies to improve the robustness of DNNs. We perform various experiments to assess the removability of adversarial examples by corrupting with additional noise and pre-processing with denoising autoencoders (DAEs). We find that DAEs can remove substantial amounts of the adversarial noise. However, when stacking the DAE with the original DNN, the resulting network can again be attacked by new adversarial examples with even smaller distortion. As a solution, we propose Deep Contractive Network, a model with a new end-to-end training procedure that includes a smoothness penalty inspired by the contractive autoencoder (CAE). This increases the network robustness to adversarial examples, without a significant performance penalty. (c) 2015 International Conference on Learning Representations, ICLR. All rights reserved."",
    keywords = ""Differential equations; Multilayer neural networks; Network architecture; Network robustness; Network topology; Performance penalties; Pre-processing; Small perturbations; State of the art; Training procedures; Training strategy; Deep neural networks"",
    publisher = ""International Conference on Learning Representations, ICLR"",
    language = ""English"",
    abbrev_source_title = ""Int. Conf. Learn. Represent., ICLR - Workshop Track Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 134; Conference name: 3rd International Conference on Learning Representations, ICLR 2015; Conference date: 7 May 2015 through 9 May 2015; Conference code: 149802""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2014	Towards deep neural network architectures robust to adversarial examples	https://doi.org/10.48550/arXiv.1412.5068	International Conference on Learning Representations, ICLR	nan; Pages; Link
116	TestNN	Visualizing and Understanding Convolutional Networks	Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevskyet al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevskyet alon the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.	Input Image; Training Image; Convolutional Neural Network; Stochastic Gradient Descent; Pixel Space	Matthew D. Zeiler; Rob Fergus	European Conference on Computer Vision	https://doi.org/10.1007/978-3-319-10590-1_53		818-833		Included	Included	snowballing			1	Springer Link	2014	Visualizing and understanding convolutional networks	https://doi.org/10.1007/978-3-319-10590-1_53	Springer, Cham	nan; References; Year; Bibtex; Link
117	TestNN	Visualizing and Understanding Convolutional Networks	Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.	Input Image; Training Image; Convolutional Neural Network; Stochastic Gradient Descent; Pixel Space	Zeiler, Matthew D.; Fergus, Rob	European Conference on Computer Vision	https://doi.org/10.1007/978-3-319-10590-1_53		818--833	"""@InProceedings{10.1007/978-3-319-10590-1_53,
    author = ""Zeiler, Matthew D. and Fergus, Rob"",
    editor = ""Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne"",
    title = ""Visualizing and Understanding Convolutional Networks"",
    booktitle = ""Computer Vision -- ECCV 2014"",
    year = ""2014"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""818--833"",
    abstract = ""Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets."",
    isbn = ""978-3-319-10590-1""
}
"""	Included	Included	snowballing			1	Springer Link	2014	Visualizing and understanding convolutional networks 2	https://doi.org/10.1007/978-3-319-10590-1_53	Springer International Publishing	nan; References; Link
118	TestNN	ApproxANN: An approximate computing framework for artificial neural network	Artificial Neural networks (ANNs) are one of the most well-established machine learning techniques and have a wide range of applications, such as Recognition, Mining and Synthesis (RMS). As many of these applications are inherently error-tolerant, in this work, we propose a novel approximate computing framework for ANN, namely ApproxANN. When compared to existing solutions, ApproxANN considers approximation for both computation and memory accesses, thereby achieving more energy savings. To be specific, ApproxANN characterizes the impact of neurons on the output quality in an effective and efficient manner, and judiciously determine how to approximate the computation and memory accesses of certain less critical neurons to achieve the maximum energy efficiency gain under a given quality constraint. Experimental results on various ANN applications with different datasets demonstrate the efficacy of the proposed solution.	Energy efficiency; Learning systems; ANN application; Computing frameworks; Critical neurons; Error tolerant; Machine learning techniques; Memory access; Output quality; Quality constraints; Neural networks; Energy efficiency;  Learning systems;  ANN application;  Computing frameworks;  Critical neurons;  Error tolerant;  Machine learning techniques;  Memory access;  Output quality;  Quality constraints;  Neural networks	Zhang, Qian; Wang, Ting; Tian, Ye; Yuan, Feng; Xu, Qiang	Proceedings -Design, Automation and Test in Europe, DATE	https://doi.org/10.7873/date.2015.0618		701 - 706	"""@CONFERENCE{Zhang2015701,
    author = ""Zhang, Qian and Wang, Ting and Tian, Ye and Yuan, Feng and Xu, Qiang"",
    title = ""ApproxANN: An approximate computing framework for artificial neural network"",
    year = ""2015"",
    journal = ""Proceedings -Design, Automation and Test in Europe, DATE"",
    volume = ""2015-April"",
    pages = ""701 - 706"",
    doi = ""10.7873/date.2015.0618"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945911897\&doi=10.7873\%2fdate.2015.0618\&partnerID=40\&md5=66e4f192e10d57febce67fd81ab26d83"",
    affiliations = ""CUhk REliable Computing Laboratory (CURE), Department of Computer Science and Engineering, Chinese University of Hong Kong, Shatin, N.T., Hong Kong"",
    abstract = ""Artificial Neural networks (ANNs) are one of the most well-established machine learning techniques and have a wide range of applications, such as Recognition, Mining and Synthesis (RMS). As many of these applications are inherently error-tolerant, in this work, we propose a novel approximate computing framework for ANN, namely ApproxANN. When compared to existing solutions, ApproxANN considers approximation for both computation and memory accesses, thereby achieving more energy savings. To be specific, ApproxANN characterizes the impact of neurons on the output quality in an effective and efficient manner, and judiciously determine how to approximate the computation and memory accesses of certain less critical neurons to achieve the maximum energy efficiency gain under a given quality constraint. Experimental results on various ANN applications with different datasets demonstrate the efficacy of the proposed solution. (c) 2015 EDAA."",
    keywords = ""Energy efficiency; Learning systems; ANN application; Computing frameworks; Critical neurons; Error tolerant; Machine learning techniques; Memory access; Output quality; Quality constraints; Neural networks"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    issn = ""15301591"",
    isbn = ""978-398153704-8"",
    language = ""English"",
    abbrev_source_title = ""Proc. Des. Autom. Test Eur. DATE"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 191; Conference name: 2015 Design, Automation and Test in Europe Conference and Exhibition, DATE 2015; Conference date: 9 March 2015 through 13 March 2015; Conference code: 115713""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2015	ApproxANN: an approximate computing framework for artificial neural network	https://www.scopus.com/record/display.uri?eid=2-s2.0-84945911897&origin=resultslist&sort=plf-f&src=s&sid=bd4afaff65c29077921ccf56046f3a21&sot=b&sdt=b&s=TITLE-ABS-KEY%28approxann+an+approximate+computing+framework+for+artificial+neural+network%29&sl=89&sessionSearchId=bd4afaff65c29077921ccf56046f3a21&relpos=0	Institute of Electrical and Electronics Engineers Inc	nan; References
119	TestNN	Deep neural networks are easily fooled: High confidence predictions for unrecognizable images	"Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call ""fooling images"" (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision."	Biomedical imaging;Keyboards;Volcanoes; Biomedical imaging; Keyboards; Volcanoes	Nguyen, Anh; Yosinski, Jason; Clune, Jeff	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2015.7298640		427-436	"""@INPROCEEDINGS{7298640,
    author = ""Nguyen, Anh and Yosinski, Jason and Clune, Jeff"",
    booktitle = ""2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"",
    title = ""Deep neural networks are easily fooled: High confidence predictions for unrecognizable images"",
    year = ""2015"",
    volume = """",
    number = """",
    pages = ""427-436"",
    abstract = ""Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99\% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call ""fooling images"" (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision."",
    keywords = ""Biomedical imaging;Keyboards;Volcanoes"",
    doi = ""10.1109/CVPR.2015.7298640"",
    ISSN = ""1063-6919"",
    month = ""June""
}
"""	Included	Included	snowballing			1	IEEE	2015	Deep neural networks are easily fooled: High confidence predictions for unrecognizable images	https://doi.org/10.1109/CVPR.2015.7298640	IEEE	nan; References; Link
120	TestNN	Towards Verification of Artificial Neural Networks			Scheibler, K., L. Winterer, R. Wimmer and B. Becker						Included	Included	snowballing			1		2015				
121	TestNN	Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization	We propose a general framework for increasing local stability of Artificial Neural Nets (ANNs) using Robust Optimization (RO). We achieve this through an alternating minimization-maximization procedure, in which the loss of the network is minimized over perturbed examples that are generated at each parameter update. We show that adversarial training of ANNs is in fact robustification of the network optimization, and that our proposed framework generalizes previous approaches for increasing local stability of ANNs. Experimental results reveal that our approach increases the robustness of the network to existing adversarial examples, while making it harder to generate new ones. Furthermore, our algorithm improves the accuracy of the network also on the original test data.		Uri Shaham; Yutaro Yamada; Sahand Negahban	arXiv	https://doi.org/10.48550/arXiv.1511.05432				Included	Included	snowballing			1	arXiv	2015	Understanding adversarial training: Increasing local stability of neural nets through robust optimization	https://doi.org/10.48550/arXiv.1511.05432	arXiv	nan; Keywords; References; Pages; Year; Bibtex; Link
122	TestNN	Understanding deep image representations by inverting them	Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system. Nevertheless, our understanding of them remains limited. In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself? To answer this question we contribute a general framework to invert representations. We show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. We then use this technique to study the inverse of recent state-of-the-art CNN image representations for the first time. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.	Image reconstruction;Image representation;Visualization;Standards;TV;Neural networks;Noise; Image reconstruction; Image representation; Visualization; Standards; TV; Neural networks; Noise	Mahendran, Aravindh; Vedaldi, Andrea	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2015.7299155		5188-5196	"""@INPROCEEDINGS{7299155,
    author = ""Mahendran, Aravindh and Vedaldi, Andrea"",
    booktitle = ""2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"",
    title = ""Understanding deep image representations by inverting them"",
    year = ""2015"",
    volume = """",
    number = """",
    pages = ""5188-5196"",
    abstract = ""Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system. Nevertheless, our understanding of them remains limited. In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself? To answer this question we contribute a general framework to invert representations. We show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. We then use this technique to study the inverse of recent state-of-the-art CNN image representations for the first time. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance."",
    keywords = ""Image reconstruction;Image representation;Visualization;Standards;TV;Neural networks;Noise"",
    doi = ""10.1109/CVPR.2015.7299155"",
    ISSN = ""1063-6919"",
    month = ""June""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2015	Understanding deep image representations by inverting them	https://ieeexplore.ieee.org/document/7299155	IEEE	nan; References
123	TestNN	Distilling Knowledge from Deep Networks with Applications to Healthcare Domain	Exponential growth in Electronic Healthcare Records (EHR) has resulted in new opportunities and urgent needs for discovery of meaningful data-driven representations and patterns of diseases in Computational Phenotyping research. Deep Learning models have shown superior performance for robust prediction in computational phenotyping tasks, but suffer from the issue of model interpretability which is crucial for clinicians involved in decision-making. In this paper, we introduce a novel knowledge-distillation approach called Interpretable Mimic Learning, to learn interpretable phenotype features for making robust prediction while mimicking the performance of deep learning models. Our framework uses Gradient Boosting Trees to learn interpretable features from deep learning models such as Stacked Denoising Autoencoder and Long Short-Term Memory. Exhaustive experiments on a real-world clinical time-series dataset show that our method obtains similar or better performance than the deep learning models, and it provides interpretable phenotypes for clinical decision making.		Zhengping Che; Sanjay Purushotham; Robinder Khemani; Yan Liu	arXiv	https://doi.org/10.48550/arXiv.1512.03542				Included	Included	snowballing			1	arXiv	2015	Distilling knowledge from deep networks with applications to healthcare domain	https://doi.org/10.48550/arXiv.1512.03542	arXiv	nan; Keywords; References; Pages; Year; Bibtex; Link
124	TestNN	Distilling the Knowledge in a Neural Network	A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.		Geoffrey Hinton; Oriol Vinyals; Jeff Dean	arXiv	https://doi.org/10.48550/arXiv.1503.02531				Included	Included	snowballing			1	arXiv	2015	Distilling the knowledge in a neural network	https://doi.org/10.48550/arXiv.1503.02531	arXiv	nan; Keywords; References; Pages; Year; Bibtex; Link
125	TestNN	On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation	Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest.We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.	Algorithms; Artificial Intelligence; Humans; Image Processing;  Computer-Assisted; Pattern Recognition;  Automated; Article; artificial neural network; Bag of Words model; classification; classifier; controlled study; image analysis; kernel method; layer wise relevance propagation; machine learning; nonlinear system; prediction; algorithm; artificial intelligence; automated pattern recognition; human; image processing; procedures; Algorithms;  Artificial Intelligence;  Humans;  Image Processing, Computer-Assisted;  Pattern Recognition, Automated;  Article;  artificial neural network;  Bag of Words model;  classification;  classifier;  controlled study;  image analysis;  kernel method;  layer wise relevance propagation;  machine learning;  nonlinear system;  prediction;  algorithm;  artificial intelligence;  automated pattern recognition;  human;  image processing;  procedures	Bach, Sebastian; Binder, Alexander; Montavon, Gregoire; Klauschen, Frederick; Muller, Klaus-Robert; Samek, Wojciech	PLoS ONE	https://doi.org/10.1371/journal.pone.0130140			"""@ARTICLE{Bach2015,
    author = ""Bach, Sebastian and Binder, Alexander and Montavon, Gregoire and Klauschen, Frederick and Muller, Klaus-Robert and Samek, Wojciech"",
    title = ""On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation"",
    year = ""2015"",
    journal = ""PLoS ONE"",
    volume = ""10"",
    number = ""7"",
    doi = ""10.1371/journal.pone.0130140"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940560152\&doi=10.1371\%2fjournal.pone.0130140\&partnerID=40\&md5=7de7149c6d217b8865b973d5df616d90"",
    affiliations = ""Machine Learning Group, Fraunhofer Heinrich Hertz Institute, Berlin, Germany; Machine Learning Group, Technische Universitat Berlin, Berlin, Germany; Charite University Hospital, Berlin, Germany; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; ISTD Pillar, Singapore University of Technology and Design (SUTD), Singapore, Singapore"",
    abstract = ""Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest.We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package. (c) 2015 Bach et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited."",
    keywords = ""Algorithms; Artificial Intelligence; Humans; Image Processing, Computer-Assisted; Pattern Recognition, Automated; Article; artificial neural network; Bag of Words model; classification; classifier; controlled study; image analysis; kernel method; layer wise relevance propagation; machine learning; nonlinear system; prediction; algorithm; artificial intelligence; automated pattern recognition; human; image processing; procedures"",
    publisher = ""Public Library of Science"",
    issn = ""19326203"",
    coden = ""POLNC"",
    pmid = ""26161953"",
    language = ""English"",
    abbrev_source_title = ""PLoS ONE"",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 2794; All Open Access, Gold Open Access, Green Open Access""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2015	On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation	https://www.scopus.com/record/display.uri?eid=2-s2.0-84940560152&origin=resultslist&sort=plf-f&src=s&sid=dee5e8c1063d18b0602c287c7f234c36&sot=b&sdt=b&s=TITLE-ABS-KEY%28on+pixel+wise+explanations+for+non+linear+classifier+decisions+by+layer+wise+relevance+propagation%29&sl=113&sessionSearchId=dee5e8c1063d18b0602c287c7f234c36&relpos=0	Public Library of Science	nan; References; Pages
126	TestNN	Understanding deep image representations by inverting them	Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system. Nevertheless, our understanding of them remains limited. In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself? To answer this question we contribute a general framework to invert representations. We show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. We then use this technique to study the inverse of recent state-of-the-art CNN image representations for the first time. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.	Image understanding; Neural networks; Bag-of-visual words; Convolutional neural network; Direct analysis; Image representations; Image understanding systems; Photometric invariance; Recent state; Visual information; Computer vision; Image understanding;  Neural networks;  Bag-of-visual words;  Convolutional neural network;  Direct analysis;  Image representations;  Image understanding systems;  Photometric invariance;  Recent state;  Visual information;  Computer vision	Mahendran, Aravindh; Vedaldi, Andrea	Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition	https://doi.org/10.1109/CVPR.2015.7299155	Bishop, C.M.(1995)Neural Networks for Pattern Recognition.Cited 20066 times.Clarendon Press, Oxford; Chen, Y.,Ranftl, R.,Pock, T.A bi-level view of inpainting-based image compression(2014)Proc of Computer Vision Winter Workshop.Cited 35 times.; Csurka, G.,Dance, C.R.,Dan, L.,Willamowski, J.,Bray, C.Visual categorization with bags of keypoints(2004)Proc. ECCV Workshop on Stat. Learn. in Comp. Vision.Cited 3698 times.; Dalal, N.,Triggs, B.; D'Angelo, E.,Alahi, A.,Vandergheynst, P.; Erhan, D.,Bengio, Y.,Courville, A.,Vincent, P.(2009)Visualizing Higher-layer Features of A Deep Network.Cited 972 times.Technical Report 1341, University of Montreal; Felzenszwalb, P.F.,Girshick, R.B.,McAllester, D.,Ramanan, D.; Girshick, R.B.,Felzenszwalb, P.F.,McAllester, D.Discriminatively Trained Deformable Part Models, Release 5.Cited 302 times.http://people.cs.uchicago.edu/rbg/latent-release5/; Hinton, G.E.,Salakhutdinov, R.R.; Jegou, H.,Douze, M.,Schmid, C.,Perez, P.; Jensen, C.A.,Reed, R.D.,Marks II, R.J.,El-Sharkawi, M.A.,Jung, J.-B.,Miyamoto, R.T.,Anderson, G.M.,(...),Eggen, C.J.; Jia, Y.(2013)Caffe: An Open Source Convolutional Architecture for Fast Feature Embedding.Cited 333 times.http://caffe.berkeleyvision.org/; Kato, H.,Harada, T.; Krishnan, D.,Fergus, R.; Krizhevsky, A.,Sutskever, I.,Hinton, G.E.; Lee, S.,Kil, R.M.; Leung, T.,Malik, J.; Linden, A.,Kindermann, J.; Lowe, David G.; Lowe, D.G.; Lu, B.-L.,Kita, H.,Nishikawa, Y.; Nowak, E.,Jurie, F.,Triggs, B.Sampling strategies for bag-offeatures image classification(2006)ECCV.Cited 212 times.; Perronnin, F.,Dance, C.Fisher kernels on visual vocabularies for image categorizaton(2006)CVPR.Cited 18 times.; Russakovsky, O.,Deng, J.,Su, H.,Krause, J.,Satheesh, S.,Ma, S.,Huang, Z.,(...),Fei-Fei, L.(2014)Imagenet Large Scale Visual Recognition Challenge.Cited 1360 times.CoRR, abs/1409. 0575; Sermanet, P.,Eigen, D.,Zhang, X.,Mathieu, M.,Fergus, R.,LeCun, Y.; Simonyan, K.,Vedaldi, A.,Zisserman, A.; Sivic, J.,Zisserman, A.; Szegedy, C.,Zaremba, W.,Sutskever, I.,Bruna, J.,Erhan, D.,Goodfellow, I.J.,Fergus, R.(2013)Intriguing Properties of Neural Networks.Cited 6247 times.CoRR, abs/1312. 6199; Tatu, A.,Lauze, F.,Nielsen, M.,Kimia, B.; Varkonyi-Koczy, A.R.,Rovid, A.; Vedaldi, A.(2007)An Open Implementation of the SIFT Detector and Descriptor.Cited 85 times.Technical Report 070012, UCLA CSD; Vedaldi, A.,Lenc, K.(2014)MatConvNet: CNNs for MATLAB.Cited 233 times.http://www.vlfeat.org/matconvnet/; Vondrick, C.,Khosla, A.,Malisiewicz, T.,Torralba, A.; Wang, J.,Yang, J.,Yu, K.,Lv, F.,Huang, T.,Gong, Y.; Weinzaepfel, P.,Jegou, H.,Perez, P.; Williams, R.J.Inverting a connectionist network mapping by backpropagation of error(1986)Proc. CogSci.Cited 30 times.; Yang, J.,Yu, K.,Huang, T.; Zeiler, M.D.,Fergus, R.Visualizing and understanding convolutional networks(2014)ECCV.Cited 2301 times.; Zhou, B.,Lapedriza, A.,Xiao, J.,Torralba, A.,Oliva, A.; Zhou, X.,Yu, K.,Zhang, T.,Huang, T.S.Image classification using super-vector coding of local image descriptors(2010)ECCV.Cited 152 times.	5188 - 5196	"""@CONFERENCE{Mahendran20155188,
    author = ""Mahendran, Aravindh and Vedaldi, Andrea"",
    title = ""Understanding deep image representations by inverting them"",
    year = ""2015"",
    journal = ""Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition"",
    volume = ""07-12-June-2015"",
    pages = ""5188 - 5196"",
    doi = ""10.1109/CVPR.2015.7299155"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959213675\&doi=10.1109\%2fCVPR.2015.7299155\&partnerID=40\&md5=3d22af9121de7d8060af21c7f898ffaf"",
    affiliations = ""University of Oxford, United Kingdom"",
    abstract = ""Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system. Nevertheless, our understanding of them remains limited. In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself? To answer this question we contribute a general framework to invert representations. We show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. We then use this technique to study the inverse of recent state-of-the-art CNN image representations for the first time. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance. (c) 2015 IEEE."",
    keywords = ""Image understanding; Neural networks; Bag-of-visual words; Convolutional neural network; Direct analysis; Image representations; Image understanding systems; Photometric invariance; Recent state; Visual information; Computer vision"",
    publisher = ""IEEE Computer Society"",
    issn = ""10636919"",
    isbn = ""978-146736964-0"",
    coden = ""PIVRE"",
    language = ""English"",
    abbrev_source_title = ""Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1345; Conference name: IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015; Conference date: 7 June 2015 through 12 June 2015; Conference code: 117255; All Open Access, Green Open Access""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2015	Understanding deep image representations by inverting them 2	https://doi.org/10.1109/CVPR.2015.7299155	IEEE Computer Society	nan; Link
127	TestNN	Attentive Explanations: Justifying Decisions and Pointing to the Evidence	Deep models are the defacto standard in visual decision models due to their impressive performance on a wide array of visual tasks. However, they are frequently seen as opaque and are unable to explain their decisions. In contrast, humans can justify their decisions with natural language and point to the evidence in the visual world which led to their decisions. We postulate that deep models can do this as well and propose our Pointing and Justification (PJ-X) model which can justify its decision with a sentence and point to the evidence by introspecting its decision and explanation process using an attention mechanism. Unfortunately there is no dataset available with reference explanations for visual decision making. We thus collect two datasets in two domains where it is interesting and challenging to explain decisions. First, we extend the visual question answering task to not only provide an answer but also a natural language explanation for the answer. Second, we focus on explaining human activities which is traditionally more challenging than object classification. We extensively evaluate our PJ-X model, both on the justification and pointing tasks, by comparing it to prior models and ablations using both automatic and human evaluations.		Dong Huk Park; Lisa Anne Hendricks; Zeynep Akata; Bernt Schiele; Trevor Darrell; Marcus Rohrbach	arXiv	https://doi.org/10.48550/arXiv.1612.04757				Excluded	Excluded	snowballing		Exclusion: irrelevance (more than one inclusion criteria are not satisfied)	1	arXiv	2016	Attentive explanations: Justifying decisions and pointing to the evidence	https://doi.org/10.48550/arXiv.1612.04757	arXiv	nan; Keywords; References; Pages; Year; Bibtex; Link
128	TestNN	Concrete Problems in AI Safety	"Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (""avoiding side effects"" and ""avoiding reward hacking""), an objective function that is too expensive to evaluate frequently (""scalable supervision""), or undesirable behavior during the learning process (""safe exploration"" and ""distributional shift""). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI."		Dario Amodei; Chris Olah; Jacob Steinhardt; Paul Christiano; John Schulman; Dan Mane	arXiv	https://doi.org/10.48550/arXiv.1606.06565				Excluded	Excluded	snowballing		Exclusion: review paper	1	arXiv	2016	Concrete problems in AI safety	https://doi.org/10.48550/arXiv.1606.06565	arXiv	nan; Keywords; References; Pages; Year; Bibtex; Link
129	TestNN	Distillation as a Defense to Adversarial Perturbations Against Deep Neural Networks	Deep learning algorithms have been shown to perform extremely well on many classical machine learning problems. However, recent studies have shown that deep learning, like other machine learning techniques, is vulnerable to adversarial samples: inputs crafted to force a deep neural network (DNN) to provide adversary-selected outputs. Such attacks can seriously undermine the security of the system supported by the DNN, sometimes with devastating consequences. For example, autonomous vehicles can be crashed, illicit or illegal content can bypass content filters, or biometric authentication systems can be manipulated to allow improper access. In this work, we introduce a defensive mechanism called defensive distillation to reduce the effectiveness of adversarial samples on DNNs. We analytically investigate the generalizability and robustness properties granted by the use of defensive distillation when training DNNs. We also empirically study the effectiveness of our defense mechanisms on two DNNs placed in adversarial settings. The study shows that defensive distillation can reduce effectiveness of sample creation from 95% to less than 0.5% on a studied DNN. Such dramatic gains can be explained by the fact that distillation leads gradients used in adversarial sample creation to be reduced by a factor of 1030. We also find that distillation increases the average minimum number of features that need to be modified to create adversarial samples by about 800% on one of the DNNs we tested.	Training; Computer architecture; Machine learning; Security; Automobiles; Computational modeling; Neural networks; Neural Network; Deep Neural Network; Adversarial Perturbations; Machine Learning; Deep Learning; Defense Mechanisms; High Temperature; Training Dataset; Classification Accuracy; Max-pooling Layer; Deep Neural Network Model; Input Dimension; Softmax Layer; Probability Vector; Deep Neural Network Architecture; Saliency Map; MNIST Dataset; Soft Labels; Adversarial Examples; Fast Gradient Sign Method; Source Class; Indicator Vector; Robust Definition; Malware; Deep Neural Network Classifier; Knowledge Extraction; Minimal Perturbation	Nicolas Papernot; Patrick McDaniel; Xi Wu; Somesh Jha; Ananthram Swami	2016 IEEE Symposium on Security and Privacy (SP)	https://doi.org/10.1109/SP.2016.41				Included	Included	snowballing			1	IEEE	2016	Distillation as a defense to adversarial perturbations against deep neural networks	https://doi.org/10.1109/SP.2016.41	IEEE	nan; References; Pages; Year; Bibtex; Link
130	TestNN	Improving the Robustness of Deep Neural Networks via Stability Training	In this paper we address the issue of output instability of deep neural networks: small perturbations in the visual input can significantly distort the feature embeddings and output of a neural network. Such instability affects many deep architectures with state-of-the-art performance on a wide range of computer vision tasks. We present a general stability training method to stabilize deep networks against small input distortions that result from various types of common image processing, such as compression, rescaling, and cropping. We validate our method by stabilizing the state of-the-art Inception architecture [11] against these types of distortions. In addition, we demonstrate that our stabilized model gives robust state-of-the-art performance on largescale near-duplicate detection, similar-image ranking, and classification on noisy datasets.	Training; Stability analysis; Robustness; Neural networks; Visualization; Feature extraction; Data models; Neural Network; Deep Network; Deep Neural Network; Perturbation Theory; Network Output; Visual Input; Wide Range Of Tasks; Distortion Types; Convolutional Neural Network; Gaussian Noise; Feature Space; Data Augmentation; Class Labels; Duplicate Samples; Noisy Data; Positive Image; Evaluation Dataset; Training Objective; Original Objective; Feature Distance; Adversarial Examples; JPEG Compression; Visual Similarity; Performance Ranking; Ranking Task; Query Image; Stable Output; Inception Network; Image Pairs; Image Retrieval	Stephan Zheng; Yang Song; Thomas Leung; Ian Goodfellow	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2016.485				Included	Included	snowballing			1	IEEE	2016	Improving the robustness of deep neural networks via stability training	https://doi.org/10.1109/CVPR.2016.485	IEEE	nan; References; Pages; Year; Bibtex; Link
131	TestNN	Measuring neural net robustness with constraints	"Despite having high accuracy, neural nets have been shown to be susceptible to adversarial examples, where a small perturbation to an input can cause it to become mislabeled. We propose metrics for measuring the robustness of a neural net and devise a novel algorithm for approximating these metrics based on an encoding of robustness as a linear program. We show how our metrics can be used to evaluate the robustness of deep neural nets with experiments on the MNIST and CIFAR-10 datasets. Our algorithm generates more informative estimates of robustness metrics compared to estimates based on existing algorithms. Furthermore, we show how existing approaches to improving robustness ""overfit"" to adversarial examples generated using a specific algorithm. Finally, we show that our techniques can be used to additionally improve neural net robustness both according to the metrics that we propose, but also according to previously proposed metrics."		Osbert Bastani; Yani Ioannou; Leonidas Lampropoulos; Dimitrios Vytiniotis; Aditya V. Nori; Antonio Criminisi	NIPS'16: Proceedings of the 30th International Conference on Neural Information Processing Systems	https://doi.org/10.5555/3157382.3157391		2621-2629		Included	Included	snowballing			1	ACM	2016	Measuring neural net robustness with constraints	https://doi.org/10.5555/3157382.3157391	Curran Associates Inc	nan; Keywords; References; Year; Bibtex; Link
132	TestNN	Policy compression for aircraft collision avoidance systems	One approach to designing the decision making logic for an aircraft collision avoidance system is to frame the problem as Markov decision process and optimize the system using dynamic programming. The resulting strategy can be represented as a numeric table. This methodology has been used in the development of the ACAS X family of collision avoidance systems for manned and unmanned aircraft. However, due to the high dimensionality of the state space, discretizing the state variables can lead to very large tables. To improve storage efficiency, we propose two approaches for compressing the lookup table. The first approach exploits redundancy in the table. The table is decomposed into a set of lower-dimensional tables, some of which can be represented by single tables in areas where the lower-dimensional tables are identical or nearly identical with respect to a similarity metric. The second approach uses a deep neural network to learn a complex non-linear function approximation of the table. With the use of an asymmetric loss function and a gradient descent algorithm, the parameters for this network can be trained to provide very accurate estimates of values while preserving the relative preferences of the possible advisories for each state. As a result, the table can be approximately represented by only the parameters of the network, which reduces the required storage space by a factor of 1000. Simulation studies show that system performance is very similar using either compressed table representation in place of the original table. Even though the neural network was trained directly on the original table, the network surpasses the original table on the performance metrics and encounter sets evaluated here.	Neural networks;Measurement;Aircraft;Collision avoidance;Dynamic programming;Function approximation;Redundancy; Neural networks; Measurement; Aircraft; Collision avoidance; Dynamic programming; Function approximation; Redundancy	Julian, Kyle D.; Lopez, Jessica; Brush, Jeffrey S.; Owen, Michael P.; Kochenderfer, Mykel J.	2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC)	https://doi.org/10.1109/DASC.2016.7778091	"1.J. K. Kuchar and L. C. Yang, ""A review of conflict detection and resolution modeling methods"", IEEE Transactions on Intelligent Transportation Systems, vol. 1, no. 4, pp. 179-189, 2000. View Article  Google Scholar; 2.M. J. Kochenderfer, ""Optimized airborne collision avoidance"", Decision Making under Uncertainty: Theory and Application MIT Press, 2015. CrossRef  Google Scholar; 3.M. J. Kochenderfer, J. E. Holland and J. P. Chryssanthacopoulos, ""Next generation airborne collision avoidance system"", Lincoln Laboratory Journal, vol. 19, no. 1, pp. 17-33, 2012. Google Scholar; 4.M. J. Kochenderfer and J. P. Chryssanthacopoulos, ""Robust airborne collision avoidance through dynamic programming"", Massachusetts Institute of Technology Lincoln Laboratory Report ATC-371, 2011,  [online]  Available: http://www.11.mit.edu/mission/aviation/publications/publication-files/atc-reports/Kochenderfer_2011_ATC-371_WW-21458.pdf. Google Scholar; 5.M. Marston and G. Baca, ""ACAS-Xu initial self-separation flight tests"", Tech. Rep. DFRC-E-DAA-TN22968, 2015,  [online]  Available: http://hdl.handle.net/2060/20150008347. Google Scholar; 6.Y. Engel, S. Mannor and R. Meir, ""Reinforcement learning with Gaussian processes"", International Conference on Machine Learning (ICML), 2005. CrossRef  Google Scholar; 7.R. Munos and A. Moore, ""Variable resolution discretization in optimal control"", Machine Learning, vol. 49, no. 2, pp. 291-323, 2002. Google Scholar; 8.M. J. Kochenderfer and N. Monath, ""Compression of optimal value functions for Markov decision processes"", Data Compression Conference, 2013. View Article  Google Scholar; 9.J. P. Chryssanthacopoulos and M. J. Kochenderfer, ""Accounting for state uncertainty in collision avoidance"", AIAA Journal on Guidance Control and Dynamics, vol. 34, no. 4, pp. 951-960, 2011. CrossRef  Google Scholar; 10.S. Julier and J. Uhlmann, ""Unscented filtering and nonlinear estimation"", Proceedings of the IEEE, vol. 92, no. 3, pp. 401-422, 2004. View Article  Google Scholar; 11.A. Krizhevsky, I. Sutskever and G. E. Hinton, ""Imagenet classification with deep convolutional neural networks"", Advances in Neural Information Processing Systems (NIPS), 2012. CrossRef  Google Scholar; 12.G. E. Dahl, T. N. Sainath and G. E. Hinton, ""Improving deep neural networks for lvcsr using rectified linear units and dropout"", International Conference on Acoustics Speech and Signal Processing (ICASSP), 2013. View Article  Google Scholar; 13.T. Tieleman and G. Hinton, ""Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude"", COURSERA: Neural Networks for Machine Learning, vol. 4, pp. 2, 2012. Google Scholar; 14.J. Duchi, E. Hazan and Y. Singer, ""Adaptive sub-gradient methods for online learning and stochastic optimization"", Journal of Machine Learning, vol. 12, pp. 2121-2159, 2011. Google Scholar; 15.M. D. Zeiler, ""ADADELTA: an adaptive learning rate method"", arXiv: 1212.5701, 2012. Google Scholar; 16.D. Kingma and J. Ba, ""Adam: A method for stochastic optimization"", arXiv: 1412.6980, 2014. Google Scholar; 17.G. P. Zhang, ""Neural networks for classification: A survey"", IEEE Transactions on Systems Man and Cybernetics Part C: Applications and Reviews, vol. 30, no. 4, pp. 451-462, 2000. View Article  Google Scholar; 18.S. F. Crone, ""Training artificial neural networks for time series prediction using asymmetric cost functions"", International Conference on Neural Information Processing (ICONIP), vol. 5, 2002. View Article  Google Scholar; 19.F. Chollet, ""Keras: Deep learning library for Theano and TensorFlow"", 2016,  [online]  Available: keras.io. Google Scholar; 20.""Theano Development Team"", Theano: A Python framework for fast computation of mathematical expressions. arXiv: 1605.02688, 2016. Google Scholar; 21.Y. A. LeCun, L. Bottou, G. B. Orr and K.-R. Muller, ""Efficient backprop"" in Neural Networks: Tricks of the Trade, Berlin: Springer, pp. 9-48, 2012. Google Scholar; 22.M. J. Kochenderfer, M. W. M. Edwards, L. P. Espindle, J. K. Kuchar and J. D. Griffith, ""Airspace encounter models for estimating collision risk"", AIAA Journal on Guidance Control and Dynamics, vol. 33, no. 2, pp. 487-499, 2010. CrossRef  Google Scholar; 23.R. W. Gardner and J. S. Brush, ""Enabling real-time execution: Runtime-efficiency improvements for the next generation airborne collision avoidance algorithms"", Digital Avionics Systems Conference (DASC), 2016. View Article  Google Scholar; 24.H. Y. Ong and M. J. Kochenderfer, ""Short-term conflict resolution for unmanned aircraft traffic management"", Digital Avionics Systems Conference (DASC), 2015. View Article  Google Scholar"	1-10	"""@INPROCEEDINGS{7778091,
    author = ""Julian, Kyle D. and Lopez, Jessica and Brush, Jeffrey S. and Owen, Michael P. and Kochenderfer, Mykel J."",
    booktitle = ""2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC)"",
    title = ""Policy compression for aircraft collision avoidance systems"",
    year = ""2016"",
    volume = """",
    number = """",
    pages = ""1-10"",
    abstract = ""One approach to designing the decision making logic for an aircraft collision avoidance system is to frame the problem as Markov decision process and optimize the system using dynamic programming. The resulting strategy can be represented as a numeric table. This methodology has been used in the development of the ACAS X family of collision avoidance systems for manned and unmanned aircraft. However, due to the high dimensionality of the state space, discretizing the state variables can lead to very large tables. To improve storage efficiency, we propose two approaches for compressing the lookup table. The first approach exploits redundancy in the table. The table is decomposed into a set of lower-dimensional tables, some of which can be represented by single tables in areas where the lower-dimensional tables are identical or nearly identical with respect to a similarity metric. The second approach uses a deep neural network to learn a complex non-linear function approximation of the table. With the use of an asymmetric loss function and a gradient descent algorithm, the parameters for this network can be trained to provide very accurate estimates of values while preserving the relative preferences of the possible advisories for each state. As a result, the table can be approximately represented by only the parameters of the network, which reduces the required storage space by a factor of 1000. Simulation studies show that system performance is very similar using either compressed table representation in place of the original table. Even though the neural network was trained directly on the original table, the network surpasses the original table on the performance metrics and encounter sets evaluated here."",
    keywords = ""Neural networks;Measurement;Aircraft;Collision avoidance;Dynamic programming;Function approximation;Redundancy"",
    doi = ""10.1109/DASC.2016.7778091"",
    ISSN = ""2155-7209"",
    month = ""Sep.""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2016	Policy compression for aircraft collision avoidance systems	https://ieeexplore.ieee.org/document/7778091	IEEE	
133	TestNN	Toward verified artificial intelligence	Making AI more trustworthy with a formal methods-based approach to AI system verification and validation.		Sanjit A. Seshia; Dorsa Sadigh; S. Shankar Sastry	Communications of the ACM	https://doi.org/10.1145/3503914		46-55		Excluded	Excluded	snowballing		Exclusion: review paper	1	ACM	2016	Towards verified artificial intelligence	https://doi.org/10.1145/3503914	Association for Computing Machinery	nan; Keywords; References; Year; Bibtex; Link
134	TestNN	Understanding Error Propagation in GPGPU Applications	GPUs have emerged as general-purpose accelerators in high-performance computing (HPC) and scientific applications. However, the reliability characteristics of GPU applications have not been investigated in depth. While error propagation has been extensively investigated for non-GPU applications, GPU applications have a very different programming model which can have a significant effect on error propagation in them. We perform an empirical study to understand and characterize error propagation in GPU applications. We build a compilerbased fault-injection tool for GPU applications to track error propagation, and define metrics to characterize propagation in GPU applications. We find GPU applications exhibit significant error propagation for some kinds of errors, but not others, and the behaviour is highly application specific. We observe the GPUCPU interaction boundary naturally limits error propagation in these applications compared to traditional non-GPU applications. We also formulate various guidelines for the design of faulttolerance mechanisms in GPU applications based on our results.	Program processors; Software testing; CUDA; Error propagation; Error resilience; Fault injection; GPGPU; Errors; Program processors;  Software testing;  CUDA;  Error propagation;  Error resilience;  Fault injection;  GPGPU;  Errors	Li, Guanpeng; Pattabiraman, Karthik; Cher, Chen-Yang; Bose, Pradip	International Conference for High Performance Computing, Networking, Storage and Analysis, SC	https://doi.org/10.1109/SC.2016.20		240 - 251	"""@CONFERENCE{Li2016240,
    author = ""Li, Guanpeng and Pattabiraman, Karthik and Cher, Chen-Yang and Bose, Pradip"",
    title = ""Understanding Error Propagation in GPGPU Applications"",
    year = ""2016"",
    journal = ""International Conference for High Performance Computing, Networking, Storage and Analysis, SC"",
    volume = ""0"",
    pages = ""240 - 251"",
    doi = ""10.1109/SC.2016.20"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017275616\&doi=10.1109\%2fSC.2016.20\&partnerID=40\&md5=6d5c28cfc6276448a447f6d585e58890"",
    affiliations = ""University of British Columbia, Vancouver, BC, Canada; IBM T.J. Watson Research Center, New York, United States"",
    abstract = ""GPUs have emerged as general-purpose accelerators in high-performance computing (HPC) and scientific applications. However, the reliability characteristics of GPU applications have not been investigated in depth. While error propagation has been extensively investigated for non-GPU applications, GPU applications have a very different programming model which can have a significant effect on error propagation in them. We perform an empirical study to understand and characterize error propagation in GPU applications. We build a compilerbased fault-injection tool for GPU applications to track error propagation, and define metrics to characterize propagation in GPU applications. We find GPU applications exhibit significant error propagation for some kinds of errors, but not others, and the behaviour is highly application specific. We observe the GPUCPU interaction boundary naturally limits error propagation in these applications compared to traditional non-GPU applications. We also formulate various guidelines for the design of faulttolerance mechanisms in GPU applications based on our results. (c) 2016 IEEE."",
    author_keywords = ""CUDA; Error Propagation; Error Resilience; Fault Injection; GPGPU"",
    keywords = ""Program processors; Software testing; CUDA; Error propagation; Error resilience; Fault injection; GPGPU; Errors"",
    publisher = ""IEEE Computer Society"",
    issn = ""21674329"",
    isbn = ""978-146738815-3"",
    language = ""English"",
    abbrev_source_title = ""Int. Conf. High Perfor. Comput., Networking, Storage Analysis, SC"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 84; Conference name: 2016 International Conference for High Performance Computing, Networking, Storage and Analysis, SC 2016; Conference date: 13 November 2016 through 18 November 2016; Conference code: 126860""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2016	Understanding error propagation in GPGPU applications	https://www.scopus.com/record/display.uri?eid=2-s2.0-85017275616&origin=resultslist&sort=plf-f&src=s&sid=3b513594309fba7f50de337a13593544&sot=b&sdt=b&s=TITLE-ABS-KEY%28understanding+error+propagation+in+gpgpu+applications%29&sl=68&sessionSearchId=3b513594309fba7f50de337a13593544&relpos=0	IEEE Computer Society	nan; References
135	TestNN	"Documenting Evidence of a Reuse of '""Why Should i Trust You?"": Explaining the Predictions of Any Classifier'"	"We report here the following example of reuse. LIME is a local instance-based explanation generation framework that was originally proposed by Ribeiro et al. in their paper ""'Why Should I Trust You?': Explaining the Predictions of Any Classifier"". The framework was reused by Peng et al. in their paper ""Defect Reduction Planning (using TimeLIME)"". The paper used the original implementation of LIME as one of the core components in the proposed framework."	Computer software reusability; Actionable analyse; Core components; Defect reduction; Reuse; Software analytic; Lime; Computer software reusability;  Actionable analyse;  Core components;  Defect reduction;  Reuse;  Software analytic;  Lime	Peng, Kewen; Menzies, Tim	ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering	https://doi.org/10.1145/3468264.3477217		1600	"""@CONFERENCE{Peng20211600,
    author = ""Peng, Kewen and Menzies, Tim"",
    editor = ""D., Spinellis"",
    title = {Documenting Evidence of a Reuse of '""Why Should i Trust You?"": Explaining the Predictions of Any Classifier'},
    year = ""2021"",
    journal = ""ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering"",
    pages = ""1600"",
    doi = ""10.1145/3468264.3477217"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116297955\&doi=10.1145\%2f3468264.3477217\&partnerID=40\&md5=aaecd31b049fb6a13ac14670b15f5a0f"",
    affiliations = ""North Carolina State University, United States"",
    abstract = {We report here the following example of reuse. LIME is a local instance-based explanation generation framework that was originally proposed by Ribeiro et al. in their paper ""'Why Should I Trust You?': Explaining the Predictions of Any Classifier"". The framework was reused by Peng et al. in their paper ""Defect Reduction Planning (using TimeLIME)"". The paper used the original implementation of LIME as one of the core components in the proposed framework. (c) 2021 ACM.},
    author_keywords = ""Actionable analysis; Software analytics"",
    keywords = ""Computer software reusability; Actionable analyse; Core components; Defect reduction; Reuse; Software analytic; Lime"",
    publisher = ""Association for Computing Machinery, Inc"",
    isbn = ""978-145038562-6"",
    language = ""English"",
    abbrev_source_title = ""ESEC/FSE - Proc. ACM Jt. Meet. Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 4; Conference name: 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2021; Conference date: 23 August 2021 through 28 August 2021; Conference code: 171831""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2016	Why should i trust you?: Explaining the predictions of any classifier	https://www.scopus.com/record/display.uri?eid=2-s2.0-85116297955&origin=resultslist&sort=plf-f&src=s&sid=c18177716c6a1db1a3b23c2f37594a67&sot=b&sdt=b&s=TITLE-ABS-KEY%28why+should+i+trust+you+explaining+the+predictions+of+any+classifier%29&sl=82&sessionSearchId=c18177716c6a1db1a3b23c2f37594a67&relpos=0	Association for Computing Machinery, Inc	nan; References
136	TestNN	Controlling explanatory heatmap resolution and semantics via decomposition depth	We present an application of the Layer-wise Relevance Propagation (LRP) algorithm to state of the art deep convolutional neural networks and Fisher Vector classifiers to compare the image perception and prediction strategies of both classifiers with the use of visualized heatmaps. Layer-wise Relevance Propagation (LRP) is a method to compute scores for individual components of an input image, denoting their contribution to the prediction of the classifier for one particular test point. We demonstrate the impact of different choices of decomposition cut-off points during the LRP-process, controlling the resolution and semantics of the heatmap on test images from the PASCAL VOC 2007 test data set.	Neural networks; Semantics; Statistical tests; Convolutional neural network; Decomposition depths; Fisher vectors; Heatmapping; Image perception; Individual components; Input image; State of the art; Image processing; Neural networks;  Semantics;  Statistical tests;  Convolutional neural network;  Decomposition depths;  Fisher vectors;  Heatmapping;  Image perception;  Individual components;  Input image;  State of the art;  Image processing	Bach, Sebastian; Binder, Alexander; Muller, Klaus-Robert; Samek, Wojciech	Proceedings - International Conference on Image Processing, ICIP	https://doi.org/10.1109/ICIP.2016.7532763		2271 - 2275	"""@CONFERENCE{Bach20162271,
    author = ""Bach, Sebastian and Binder, Alexander and Muller, Klaus-Robert and Samek, Wojciech"",
    title = ""Controlling explanatory heatmap resolution and semantics via decomposition depth"",
    year = ""2016"",
    journal = ""Proceedings - International Conference on Image Processing, ICIP"",
    volume = ""2016-August"",
    pages = ""2271 - 2275"",
    doi = ""10.1109/ICIP.2016.7532763"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006759512\&doi=10.1109\%2fICIP.2016.7532763\&partnerID=40\&md5=bfff85e7003cbef621dd49dd11c8e4e7"",
    affiliations = ""Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, Berlin, 10587, Germany; Singapore University of Technology (SUTD), 8 Soapah Road, Singapore, 487372, Singapore; Berlin Institute of Technology (TU Berlin), Strasse des 17. Juni 135, Berlin, 10623, Germany; Korea University, 145 Anam-ro, Seongbuk-gu, Seoul, 02841, South Korea"",
    abstract = ""We present an application of the Layer-wise Relevance Propagation (LRP) algorithm to state of the art deep convolutional neural networks and Fisher Vector classifiers to compare the image perception and prediction strategies of both classifiers with the use of visualized heatmaps. Layer-wise Relevance Propagation (LRP) is a method to compute scores for individual components of an input image, denoting their contribution to the prediction of the classifier for one particular test point. We demonstrate the impact of different choices of decomposition cut-off points during the LRP-process, controlling the resolution and semantics of the heatmap on test images from the PASCAL VOC 2007 test data set. (c) 2016 IEEE."",
    author_keywords = ""Explaining Classifiers; Heatmapping"",
    keywords = ""Neural networks; Semantics; Statistical tests; Convolutional neural network; Decomposition depths; Fisher vectors; Heatmapping; Image perception; Individual components; Input image; State of the art; Image processing"",
    publisher = ""IEEE Computer Society"",
    issn = ""15224880"",
    isbn = ""978-146739961-6"",
    language = ""English"",
    abbrev_source_title = ""Proc. Int. Conf. Image Process. ICIP"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 17; Conference name: 23rd IEEE International Conference on Image Processing, ICIP 2016; Conference date: 25 September 2016 through 28 September 2016; Conference code: 125190; All Open Access, Green Open Access""
}
"""	Excluded	Excluded	snowballing		Inclusion:	1	Scopus Signed In	2016	Controlling explanatory heatmap resolution and semantics via decomposition depth	https://www.scopus.com/record/display.uri?eid=2-s2.0-85006759512&origin=resultslist&sort=plf-f&src=s&sid=e3c048f169d76c1fd10076a0fca4aa69&sot=b&sdt=b&s=TITLE-ABS-KEY%28controlling+explanatory+heatmap+resolution+and+semantics+via+decomposition+depth%29&sl=95&sessionSearchId=e3c048f169d76c1fd10076a0fca4aa69&relpos=0	IEEE Computer Society	nan; References
137	TestNN	Learning Deep Features for Discriminative Localization	In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on imagelevel labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation. We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classification task1.	Visualization; Neural networks; Training; Object recognition; Computer vision; Detectors; Spatial resolution; Deep Features; Convolutional Neural Network; Image Regions; Bounding Box; Object Location; Average Pooling; Remarkable Ability; Global Average Pooling; Local Ability; Global Average Pooling Layer; Bounding Box Annotations; Image-level Labels; General Characteristics; Validation Set; Classification Performance; Convolutional Layers; Localization Accuracy; Final Output; Intersection Over Union; Max-pooling; Class Activation Maps; Fully-connected Layer; Global Max Pooling; Global Pooling; Scene Classification; Final Layer; Discriminative Regions; Visual Question Answering; Visual Patterns; Object Classification	Bolei Zhou; Aditya Khosla; Agata Lapedriza; Aude Oliva; Antonio Torralba	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2016.319				Included	Included	snowballing			1	IEEE	2016	Learning deep features for discriminative localization	https://doi.org/10.1109/CVPR.2016.319	IEEE	nan; References; Pages; Year; Bibtex; Link
138	TestNN	Not just a black box: Interpretable deep learning by propagating activation differences			Shrikumar, A., P. Greenside, A. Shcherbina and A. Kundaje						Included	Included	snowballing			1		2016				
139	TestNN	Synthesizing the preferred inputs for neurons in neural networks via deep generator networks	Deep neural networks (DNNs) have demonstrated state-of-the-art results on many pattern recognition tasks, especially vision classification problems. Understanding the inner workings of such computational brains is both fascinating basic science that is interesting in its own right - similar to why we study the human brain - and will enable researchers to further improve DNNs. One path to understanding how a neural network functions internally is to study what each of its neurons has learned to detect. One such method is called activation maximization (AM), which synthesizes an input (e.g. an image) that highly activates a neuron. Here we dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful, learned prior: a deep generator network (DGN). The algorithm (1) generates qualitatively state-of-the-art synthetic images that look almost real, (2) reveals the features learned by each neuron in an interpretable way, (3) generalizes well to new datasets and somewhat well to different network architectures without requiring the prior to be relearned, and (4) can be considered as a high-quality generative method (in this case, by generating novel, creative, interesting, recognizable images).	Chemical activation; Network architecture; Neural networks; Neurons; Pattern recognition; Basic science; Generative methods; High quality; Human brain; Network functions; Qualitative state; State of the art; Synthetic images; Deep neural networks; Chemical activation;  Network architecture;  Neural networks;  Neurons;  Pattern recognition;  Basic science;  Generative methods;  High quality;  Human brain;  Network functions;  Qualitative state;  State of the art;  Synthetic images;  Deep neural networks	Nguyen, Anh; Dosovitskiy, Alexey; Yosinski, Jason; Brox, Thomas; Clune, Jeff	Advances in Neural Information Processing Systems	https://www.scopus.com/record/display.uri?eid=2-s2.0-85019234593&origin=resultslist&sort=plf-f&src=s&sid=4ac83cbe1023325f34429d8685bc91ee&sot=b&sdt=b&s=TITLE-ABS-KEY%28synthesizing+the+preferred+inputs+for+neurons+in+neural+networks+via+deep+generator+networks%29&sl=107&sessionSearchId=4ac83cbe1023325f34429d8685bc91ee&relpos=0		3395 - 3403	"""@CONFERENCE{Nguyen20163395,
    author = ""Nguyen, Anh and Dosovitskiy, Alexey and Yosinski, Jason and Brox, Thomas and Clune, Jeff"",
    editor = ""R., Garnett and D.D., Lee and von Luxburg U. and I., Guyon and M., Sugiyama"",
    title = ""Synthesizing the preferred inputs for neurons in neural networks via deep generator networks"",
    year = ""2016"",
    journal = ""Advances in Neural Information Processing Systems"",
    pages = ""3395 - 3403"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019234593\&partnerID=40\&md5=9e504aace5eb4b61086588bf42290a9c"",
    abstract = ""Deep neural networks (DNNs) have demonstrated state-of-the-art results on many pattern recognition tasks, especially vision classification problems. Understanding the inner workings of such computational brains is both fascinating basic science that is interesting in its own right - similar to why we study the human brain - and will enable researchers to further improve DNNs. One path to understanding how a neural network functions internally is to study what each of its neurons has learned to detect. One such method is called activation maximization (AM), which synthesizes an input (e.g. an image) that highly activates a neuron. Here we dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful, learned prior: a deep generator network (DGN). The algorithm (1) generates qualitatively state-of-the-art synthetic images that look almost real, (2) reveals the features learned by each neuron in an interpretable way, (3) generalizes well to new datasets and somewhat well to different network architectures without requiring the prior to be relearned, and (4) can be considered as a high-quality generative method (in this case, by generating novel, creative, interesting, recognizable images). (c) 2016 NIPS Foundation - All Rights Reserved."",
    keywords = ""Chemical activation; Network architecture; Neural networks; Neurons; Pattern recognition; Basic science; Generative methods; High quality; Human brain; Network functions; Qualitative state; State of the art; Synthetic images; Deep neural networks"",
    publisher = ""Neural information processing systems foundation"",
    issn = ""10495258"",
    language = ""English"",
    abbrev_source_title = ""Adv. neural inf. proces. syst."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 445; Conference name: 30th Annual Conference on Neural Information Processing Systems, NIPS 2016; Conference date: 5 December 2016 through 10 December 2016; Conference code: 127462""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2016	Synthesizing the preferred inputs for neurons in neural networks via deep generator networks	https://www.scopus.com/record/display.uri?eid=2-s2.0-85019234593&origin=resultslist&sort=plf-f&src=s&sid=4ac83cbe1023325f34429d8685bc91ee&sot=b&sdt=b&s=TITLE-ABS-KEY%28synthesizing+the+preferred+inputs+for+neurons+in+neural+networks+via+deep+generator+networks%29&sl=107&sessionSearchId=4ac83cbe1023325f34429d8685bc91ee&relpos=0	Neural information processing systems foundation	nan; References
140	TestNN	TreeView: Peeking into Deep Neural Networks Via Feature-Space Partitioning	With the advent of highly predictive but opaque deep learning models, it has become more important than ever to understand and explain the predictions of such models. Existing approaches define interpretability as the inverse of complexity and achieve interpretability at the cost of accuracy. This introduces a risk of producing interpretable but misleading explanations. As humans, we are prone to engage in this kind of behavior \cite{mythos}. In this paper, we take a step in the direction of tackling the problem of interpretability without compromising the model accuracy. We propose to build a Treeview representation of the complex model via hierarchical partitioning of the feature space, which reveals the iterative rejection of unlikely class labels until the correct association is predicted.		Jayaraman J. Thiagarajan; Bhavya Kailkhura; Prasanna Sattigeri; Karthikeyan Natesan Ramamurthy	arXiv	https://doi.org/10.48550/arXiv.1611.07429				Included	Included	snowballing			1	arXiv	2016	TreeView: Peeking into deep neural networks via feature-space partitioning	https://doi.org/10.48550/arXiv.1611.07429	arXiv	nan; Keywords; References; Pages; Year; Bibtex; Link
141	TestNN	Verifying properties of binarized deep neural networks	Understanding properties of deep neural networks is an important challenge in deep learning. In this paper, we take a step in this direction by proposing a rigorous way of verifying properties of a popular class of neural networks, Binarized Neural Networks, using the well-developed means of Boolean satisfiability. Our main contribution is a construction that creates a representation of a binarized neural network as a Boolean formula. Our encoding is the firstexactBoolean representation of a deep neural network. Using this encoding, we leverage the power of modern SAT solvers along with a proposed counterexample-guided search procedure to verify various properties of these networks. A particular focus will be on the critical property of robustness to adversarial perturbations. For this property, our experimental results demonstrate that our approach scales to medium-size deep neural networks used in image classification tasks. To the best of our knowledge, this is the first work on verifying properties of deep neural networks using an exact Boolean encoding of the network.		Nina Narodytska; Shiva Kasiviswanathan; Leonid Ryzhyk; Mooly Sagiv; Toby Walsh	AAAI'18/IAAI'18/EAAI'18: Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence	https://doi.org/10.5555/3504035.3504845		6615-6624		Included	Included	snowballing			1	ACM	2017	Verifying properties of binarized deep neural networks	https://doi.org/10.5555/3504035.3504845	AAAI Press	nan; Keywords; References; Year; Bibtex; Link
142	TestNN	Towards proving the adversarial robustness of deep neural networks	Autonomous vehicles are highly complex systems, required to function reliably in a wide variety of situations. Manually crafting software controllers for these vehicles is difficult, but there has been some success in using deep neural networks generated usingmachine-learning. However, deep neural networks are opaque to human engineers, rendering their correctness very difficult to provemanually; and existing automated techniques, which were not designed to operate on neural networks, fail to scale to large systems. This paper focuses on proving the adversarial robustness of deep neural networks, i.e. proving that small perturbations to a correctly-classified input to the network cannot cause it to be misclassified. We describe some of our recent and ongoing work on verifying the adversarial robustness of networks, and discuss some of the open questions we have encountered and how they might be addressed.	Formal verification; Vehicles; Automated techniques; Autonomous Vehicles; Large system; Small perturbations; Software controllers; Deep neural networks; Formal verification;  Vehicles;  Automated techniques;  Autonomous Vehicles;  Large system;  Small perturbations;  Software controllers;  Deep neural networks	Katz, Guy; Barrett, Clark; Dill, David L.; Julian, Kyle; Kochenderfer, Mykel J.	Electronic Proceedings in Theoretical Computer Science, EPTCS	https://doi.org/10.4204/EPTCS.257.3		19 - 26	"""@CONFERENCE{Katz201719,
    author = ""Katz, Guy and Barrett, Clark and Dill, David L. and Julian, Kyle and Kochenderfer, Mykel J."",
    editor = ""L., Bulwahn and M., Kamali and S., Linker"",
    title = ""Towards proving the adversarial robustness of deep neural networks"",
    year = ""2017"",
    journal = ""Electronic Proceedings in Theoretical Computer Science, EPTCS"",
    volume = ""257"",
    pages = ""19 - 26"",
    doi = ""10.4204/EPTCS.257.3"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030095870\&doi=10.4204\%2fEPTCS.257.3\&partnerID=40\&md5=7c1218ee68d68aa322e5e3ba887dba5e"",
    affiliations = ""Stanford University, United States"",
    abstract = ""Autonomous vehicles are highly complex systems, required to function reliably in a wide variety of situations. Manually crafting software controllers for these vehicles is difficult, but there has been some success in using deep neural networks generated usingmachine-learning. However, deep neural networks are opaque to human engineers, rendering their correctness very difficult to provemanually; and existing automated techniques, which were not designed to operate on neural networks, fail to scale to large systems. This paper focuses on proving the adversarial robustness of deep neural networks, i.e. proving that small perturbations to a correctly-classified input to the network cannot cause it to be misclassified. We describe some of our recent and ongoing work on verifying the adversarial robustness of networks, and discuss some of the open questions we have encountered and how they might be addressed."",
    keywords = ""Formal verification; Vehicles; Automated techniques; Autonomous Vehicles; Large system; Small perturbations; Software controllers; Deep neural networks"",
    correspondence_address = ""G. Katz; Stanford University, United States; email: guyk@stanford.edu"",
    publisher = ""Open Publishing Association"",
    issn = ""20752180"",
    language = ""English"",
    abbrev_source_title = ""Electron. Proc. Theor. Comput. Sci., EPTCS"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 47; Conference name: 1st Workshop on Formal Verification of Autonomous Vehicles, FVAV 2017; Conference date: 19 September 2017; Conference code: 130650; All Open Access, Gold Open Access""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2017	Towards proving the adversarial robustness of deep neural networks	https://doi.org/10.4204/EPTCS.257.3	Open Publishing Association	nan; References; Link
143	TestNN	Output Reachable Set Estimation and Verification for Multilayer Neural Networks	In this brief, the output reachable estimation and safety verification problems for multilayer perceptron (MLP) neural networks are addressed. First, a conception called maximum sensitivity is introduced, and for a class of MLPs whose activation functions are monotonic functions, the maximum sensitivity can be computed via solving convex optimization problems. Then, using a simulation-based method, the output reachable set estimation problem for neural networks is formulated into a chain of optimization problems. Finally, an automated safety verification is developed based on the output reachable set estimation result. An application to the safety verification for a robotic arm model with two joints is presented to show the effectiveness of the proposed approaches.	Neurons;Safety;Estimation;Neural networks;Nonhomogeneous media;Sensitivity;Contracts;Multilayer perceptron (MLP);reachable set estimation;simulation;verification; Neurons; Safety; Estimation; Neural networks; Nonhomogeneous media; Sensitivity; Contracts; Multilayer perceptron (MLP); reachable set estimation; simulation; verification	Xiang, Weiming; Tran, Hoang-Dung; Johnson, Taylor T.	IEEE Transactions on Neural Networks and Learning Systems	https://doi.org/10.1109/TNNLS.2018.2808470		5777-5783	"""@ARTICLE{8318388,
    author = ""Xiang, Weiming and Tran, Hoang-Dung and Johnson, Taylor T."",
    journal = ""IEEE Transactions on Neural Networks and Learning Systems"",
    title = ""Output Reachable Set Estimation and Verification for Multilayer Neural Networks"",
    year = ""2018"",
    volume = ""29"",
    number = ""11"",
    pages = ""5777-5783"",
    abstract = ""In this brief, the output reachable estimation and safety verification problems for multilayer perceptron (MLP) neural networks are addressed. First, a conception called maximum sensitivity is introduced, and for a class of MLPs whose activation functions are monotonic functions, the maximum sensitivity can be computed via solving convex optimization problems. Then, using a simulation-based method, the output reachable set estimation problem for neural networks is formulated into a chain of optimization problems. Finally, an automated safety verification is developed based on the output reachable set estimation result. An application to the safety verification for a robotic arm model with two joints is presented to show the effectiveness of the proposed approaches."",
    keywords = ""Neurons;Safety;Estimation;Neural networks;Nonhomogeneous media;Sensitivity;Contracts;Multilayer perceptron (MLP);reachable set estimation;simulation;verification"",
    doi = ""10.1109/TNNLS.2018.2808470"",
    ISSN = ""2162-2388"",
    month = ""Nov""
}
"""	Excluded	Excluded	snowballing		Exclusion: duplicated with selected paper [95]	1	IEEE	2017	Output reachable set estimation and verification for multi-layer neural networks	https://doi.org/10.1109/TNNLS.2018.2808470	IEEE	nan; References; Link
144	TestNN	Output Range Analysis for Deep Neural Networks	"Deep neural networks (NN) are extensively used for machine learning tasks such as image classification, perception and control of autonomous systems. Increasingly, these deep NNs are also been deployed in high-assurance applications. Thus, there is a pressing need for developing techniques to verify neural networks to check whether certain user-expected properties are satisfied. In this paper, we study a specific verification problem of computing a guaranteed range for the output of a deep neural network given a set of inputs represented as a convex polyhedron. Range estimation is a key primitive for verifying deep NNs. We present an efficient range estimation algorithm that uses a combination of local search and linear programming problems to efficiently find the maximum and minimum values taken by the outputs of the NN over the given input set. In contrast to recently proposed ""monolithic"" optimization approaches, we use local gradient descent to repeatedly find and eliminate local minima of the function. The final global optimum is certified using a mixed integer programming instance. We implement our approach and compare it with Reluplex, a recently proposed solver for deep neural networks. We demonstrate the effectiveness of the proposed approach for verification of NNs used in automated control as well as those used in classification."		Souradeep Dutta; Susmit Jha; Sriram Sanakaranarayanan; Ashish Tiwari	arXiv	https://doi.org/10.48550/arXiv.1709.09130				Included	Included	snowballing			1	arXiv	2017	Output range analysis for deep neural networks	https://doi.org/10.48550/arXiv.1709.09130	arXiv	nan; Keywords; References; Pages; Year; Bibtex; Link
145	TestNN	Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks	We present an approach for the verification of feed-forward neural networks in which all nodes have a piece-wise linear activation function. Such networks are often used in deep learning and have been shown to be hard to verify for modern satisfiability modulo theory (SMT) and integer linear programming (ILP) solvers.The starting point of our approach is the addition of a global linear approximation of the overall network behavior to the verification problem that helps with SMT-like reasoning over the network behavior. We present a specialized verification algorithm that employs this approximation in a search process in which it infers additional node phases for the non-linear nodes in the network from partial node phase assignments, similar to unit propagation in classical SAT solving. We also show how to infer additional conflict clauses and safe node fixtures from the results of the analysis steps performed during the search. The resulting approach is evaluated on collision avoidance and handwritten digit recognition case studies.		Rudiger Ehlers	International Symposium on Automated Technology for Verification and Analysis	https://doi.org/10.1007/978-3-319-68167-2_19		269-286		Included	Included	snowballing			1	Springer Link	2017	Formal verification of piece-wise linear feed-forward neural networks	https://doi.org/10.1007/978-3-319-68167-2_19	Springer, Cham	nan; Keywords; References; Year; Bibtex; Link
146	TestNN	DeepSafe: A Data-Driven Approach for Assessing Robustness of Neural Networks	Deep neural networks have achieved impressive results in many complex applications, including classification tasks for image and speech recognition, pattern analysis or perception in self-driving vehicles. However, it has been observed that even highly trained networks are very vulnerable to adversarial perturbations. Adding minimal changes to inputs that are correctly classified can lead to wrong predictions, raising serious security and safety concerns. Existing techniques for checking robustness against such perturbations only consider searching locally around a few individual inputs, providing limited guarantees. We propose DeepSafe, a novel approach for automatically assessing the overall robustness of a neural network. DeepSafe applies clustering over known labeled data and leverages off-the-shelf constraint solvers to automatically identify and check safe regions in which the network is robust, i.e. all the inputs in the region are guaranteed to be classified correctly. We also introduce the concept of targeted robustness, which ensures that the neural network is guaranteed not to misclassify inputs within a region to a specific target (adversarial) label. We evaluate DeepSafe on a neural network implementation of a controller for the next-generation Airborne Collision Avoidance System for unmanned aircraft (ACAS Xu) and for the well known MNIST network. For these networks, DeepSafe identified many regions which were safe, and also found adversarial perturbations of interest.	Aircraft accidents; Speech recognition; Airborne collision avoidance systems; Classification tasks; Complex applications; Constraint solvers; Data-driven approach; Pattern analysis; Self-driving vehicles; Unmanned aircrafts; Deep neural networks; Aircraft accidents;  Speech recognition;  Airborne collision avoidance systems;  Classification tasks;  Complex applications;  Constraint solvers;  Data-driven approach;  Pattern analysis;  Self-driving vehicles;  Unmanned aircrafts;  Deep neural networks	Gopinath, Divya; Katz, Guy; Pasareanu, Corina S.; Barrett, Clark	Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)	https://doi.org/10.1007/978-3-030-01090-4_1		3 - 19	"""@ARTICLE{Gopinath20183,
    author = ""Gopinath, Divya and Katz, Guy and Pasareanu, Corina S. and Barrett, Clark"",
    editor = ""C., Wang and S.K., Lahiri"",
    title = ""DeepSafe: A Data-Driven Approach for Assessing Robustness of Neural Networks"",
    year = ""2018"",
    journal = ""Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"",
    volume = ""11138 LNCS"",
    pages = ""3 - 19"",
    doi = ""10.1007/978-3-030-01090-4\_1"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054789898\&doi=10.1007\%2f978-3-030-01090-4\_1\&partnerID=40\&md5=e6c855de182e4b98a8f43a7ab79c17f4"",
    affiliations = ""Carnegie Mellon University, Silicon Valley, Mountain View, United States; NASA Ames Research Center, Mountain View, United States; Stanford University, Stanford, United States"",
    abstract = ""Deep neural networks have achieved impressive results in many complex applications, including classification tasks for image and speech recognition, pattern analysis or perception in self-driving vehicles. However, it has been observed that even highly trained networks are very vulnerable to adversarial perturbations. Adding minimal changes to inputs that are correctly classified can lead to wrong predictions, raising serious security and safety concerns. Existing techniques for checking robustness against such perturbations only consider searching locally around a few individual inputs, providing limited guarantees. We propose DeepSafe, a novel approach for automatically assessing the overall robustness of a neural network. DeepSafe applies clustering over known labeled data and leverages off-the-shelf constraint solvers to automatically identify and check safe regions in which the network is robust, i.e. all the inputs in the region are guaranteed to be classified correctly. We also introduce the concept of targeted robustness, which ensures that the neural network is guaranteed not to misclassify inputs within a region to a specific target (adversarial) label. We evaluate DeepSafe on a neural network implementation of a controller for the next-generation Airborne Collision Avoidance System for unmanned aircraft (ACAS Xu) and for the well known MNIST network. For these networks, DeepSafe identified many regions which were safe, and also found adversarial perturbations of interest. (c) 2018, Springer Nature Switzerland AG."",
    keywords = ""Aircraft accidents; Speech recognition; Airborne collision avoidance systems; Classification tasks; Complex applications; Constraint solvers; Data-driven approach; Pattern analysis; Self-driving vehicles; Unmanned aircrafts; Deep neural networks"",
    correspondence_address = ""C.S. Pasareanu; NASA Ames Research Center, Mountain View, United States; email: corina.s.pasareanu@nasa.gov"",
    publisher = ""Springer Verlag"",
    issn = ""03029743"",
    isbn = ""978-303001089-8"",
    language = ""English"",
    abbrev_source_title = ""Lect. Notes Comput. Sci."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 61; Conference name: 16th International Symposium on Automated Technology for Verification and Analysis, ATVA 2018; Conference date: 7 October 2018 through 10 October 2018; Conference code: 218949""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2017	Deepsafe: A data-driven approach for checking adversarial robustness in neural networks	https://doi.org/10.1007/978-3-030-01090-4_1	Springer Verlag	nan; References; Link
147	TestNN	The challenge of verification and testing of machine learning	"In our second post, we gave some background explaining why attacking machine learning is often easier than defending it. We saw some of the reasons why we do not yet have completely effective defenses against adversarial examples, and we speculated about whether we can ever expect such a defense.

In this post, we explore the types of guarantees one can expect a machine learning model to possess. We argue that the limitations of existing defenses point to the lack of verification of machine learning models. Indeed, to design reliable systems, engineers typically engage in both testing and verification:

By testing, we mean evaluating the system in several conditions and observing its behavior, watching for defects.

By verification, we mean producing a compelling argument that the system will not misbehave under a very broad range of circumstances.

Orthogonal to this issue is the question of which input values should be subject to verification and testing. Do we intend to verify or test the system only for ""naturally occurring"" legitimate inputs, or do we intend to provide guarantees for its behavior on arbitrary, degenerate inputs? Many software systems such as compilers have undefined behavior for some inputs."		Goodfellow, I.; N. Papernot	Cleverhans-blog	https://www.cleverhans.io/security/privacy/ml/2017/06/14/verification.html			"""nan"""	Excluded	Excluded	snowballing		Exclusion: review paper	1	Google Scholar	2017	The challenge of verification and testing of machine learning	https://www.cleverhans.io/security/privacy/ml/2017/06/14/verification.html	Cleverhans-blog	
148	TestNN	Detecting Adversarial Samples from Artifacts			Reuben, F., R. R. Curtin, S. Saurabh and A. B. Gardner						Included	Included	snowballing			1		2017				
149	TestNN	Extending Defensive Distillation	Machine learning is vulnerable to adversarial examples: inputs carefully modified to force misclassification. Designing defenses against such inputs remains largely an open problem. In this work, we revisit defensive distillation---which is one of the mechanisms proposed to mitigate adversarial examples---to address its limitations. We view our results not only as an effective way of addressing some of the recently discovered attacks but also as reinforcing the importance of improved training techniques.		Nicolas Papernot; Patrick McDaniel	arXiv	https://doi.org/10.48550/arXiv.1705.05264				Included	Included	snowballing			1	arXiv	2017	Extending defensive distillation	https://doi.org/10.48550/arXiv.1705.05264	arXiv	nan; Keywords; References; Pages; Year; Bibtex; Link
150	TestNN	Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks	Although deep neural networks (DNNs) have achieved great success in many tasks, they can often be fooled by adversarial examples that are generated by adding small but purposeful distortions to natural examples. Previous studies to defend against adversarial examples mostly focused on refining the DNN models, but have either shown limited success or required expensive computation. We propose a new strategy, feature squeezing, that can be used to harden DNN models by detecting adversarial examples. Feature squeezing reduces the search space available to an adversary by coalescing samples that correspond to many different feature vectors in the original space into a single sample. By comparing a DNN model's prediction on the original input with that on squeezed inputs, feature squeezing detects adversarial examples with high accuracy and few false positives. This paper explores two feature squeezing methods: reducing the color bit depth of each pixel and spatial smoothing. These simple strategies are inexpensive and complementary to other defenses, and can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks.	Feature extraction; Flocculation; Neural network models; Vector spaces; Bit depth; False positive; Features vector; High-accuracy; Input features; Neural network model; Search spaces; Simple++; Single sample; Spatial smoothing; Deep neural networks; Feature extraction;  Flocculation;  Neural network models;  Vector spaces;  Bit depth;  False positive;  Features vector;  High-accuracy;  Input features;  Neural network model;  Search spaces;  Simple++;  Single sample;  Spatial smoothing;  Deep neural networks	Xu, Weilin; Evans, David; Qi, Yanjun	25th Annual Network and Distributed System Security Symposium, NDSS 2018	https://doi.org/10.14722/ndss.2018.23198	Benenson, RodrigoClassification datasets results.Cited 21 times.http://rodrigob.github.io/are_we_thereyet/build/classification_datasetsresults.html; Bhagoji, Arjun Nitin,Cullina, Daniel,Mittal, Prateek(2017)Enhancing Robustness of Machine Learning Systems via Data Transformations.Cited 13 times.arXiv preprint 1704.02654; Bishop, Christopher M(2006)Pattern Recognition and Machine Learning.Cited 39591 times.Springer; Carlini, NicholasRobust Evasion Attacks against Neural Network to Find Adversarial Examples.Cited 4 times.https://github.com/carlini/nnrobustattacks/; Carlini, N.,Mishra, P.,Vaidya, T.,Zhang, Y.,Sherr, M.,Shields, C.,Wagner, D.,(...),Zhou, W.; Carlini, Nicholas,Wagner, David(2016)Defensive Distillation is not Robust to Adversarial Examples.Cited 178 times.arXiv preprint 1607.04311; Carlini, N.,Wagner, D.; Chollet, FrancoisKeras Implementation of Inception v3https://github.com/fchollet/deep-learning-models; Feinman, Reuben,Curtin, Ryan R,Shintre, Saurabh,Gardner, Andrew B(2017)Detecting Adversarial Samples from Artifacts.Cited 575 times.arXiv preprint 1703.00410; Goodfellow, I.J.,Shlens, J.,Szegedy, C.; Grosse, Kathrin,Manoharan, Praveen,Papernot, Nicolas,Backes, Michael,McDaniel, Patrick(2017)On the (Statistical) Detection of Adversarial Examples.Cited 459 times.arXiv preprint 1702.06280; Gu, Shixiang,Rigazio, Luca(2014)Towards Deep Neural Network Architectures Robust to Adversarial Examples.Cited 366 times.arXiv preprint 1412.5068; He, W.,Wei, J.,Chen, X.,Carlini, N.,Song, D.; Hinton, Geoffrey E,Srivastava, Nitish,Krizhevsky, Alex,Sutskever, Ilya,Salakhutdinov, Ruslan R(2012)Improving Neural Networks by Preventing Co-adaptation of Feature Detectors.Cited 5261 times.arXiv preprint 1207.0580; Hosseini, Hossein,Kannan, Sreeram,Zhang, Baosen,Poovendran, Radha(2017)Deceiving Google's Perspective API Built for Detecting Toxic Comments.Cited 201 times.arXiv preprint 1702.08138; Howard, Andrew G,Zhu, Menglong,Chen, Bo,Kalenichenko, Dmitry,Wang, Weijun,Weyand, Tobias,Andreetto, Marco,(...),Adam, Hartwig(2017)Mobilenets: Efficient convolutional neural networks for mobile vision applications.Cited 17648 times.arXiv preprint 1704.04861; Huang, Gao,Liu, Zhuang,Weinberger, Kilian Q,van der Maaten, Laurens(2016)Densely connected convolutional networks.Cited 8530 times.arXiv preprint 1608.06993; Krizhevsky, A.,Sutskever, I.,Hinton, G.E.; Kurakin, A.,Goodfellow, I.J.,Bengio, S.; LeCun, Y.,Bottou, L.,Bengio, Y.,Haffner, P.; Madry, Aleksander,Makelov, Aleksandar,Schmidt, Ludwig,Tsipras, Dimitris,Vladu, Adrian(2017)Towards Deep Learning Models Resistant to Adversarial Attacks.Cited 3830 times.arXiv preprint 1706.06083; Majumdar, SomshubraDenseNet Implementation in Keras.Cited 3 times.https://github.com/titu1994/DenseNet/; Majumdar, SomshubraKeras Implementation of Mobile Networkshttps://github.com/titu1994/MobileNetworks/; Meng, D.,Chen, H.; Metzen, Jan Hendrik,Genewein, Tim,Fischer, Volker,Bischoff, Bastian(2017)On Detecting Adversarial Perturbations.Cited 105 times.arXiv preprint 1702.04267; (2015)Microsoft Malware Competition Challenge.Cited 78 times.https://www.kaggle.com/c/malware-classification; Moosavi-Dezfooli, Seyed-Mohsen,Fawzi, Alhussein,Fawzi, Omar,Frossard, PascalUniversal adversarial perturbations.Cited 482 times.https://github.com/LTS4/universal/; Moosavi-Dezfooli, S.-M.,Fawzi, A.,Frossard, P.; Nguyen, A.,Yosinski, J.,Clune, J.; (2017)OpenCV-Python Tutorials. Image Denoisinghttps://docs.opencv.org/3.2.0/d5/d69/tutorialpy_non_localmeans.html; Osadchy, Margarita,Hernandez-Castro, Julio,Gibson, Stuart,Dunkelman, Orr,Perez-Cabo, DanielNo Bot Expects the DeepCAPTCHA!(2017)IEEE Transactions on Information Forensics and Security.Cited 2 times.; Papernot, Nicolas,Goodfellow, Ian,Sheatsley, Ryan,Feinman, Reuben,McDaniel, Patrick(2016)cleverhans v1.0.0: an adversarial machine learning library.Cited 186 times.arXiv preprint 1610.00768; Papernot, Nicolas,McDaniel, Patrick,Goodfellow, Ian,Jha, Somesh,Berkay Celik, Z,Swami, AnanthramPractical Black-Box Attacks against Deep Learning Systems using Adversarial Examples(2017)ACM Asia Conference on Computer and Communications Security.Cited 348 times.; Papernot, N.,Mcdaniel, P.,Jha, S.,Fredrikson, M.,Celik, Z.B.,Swami, A.; Papernot, Nicolas,McDaniel, Patrick,Sinha, Arunesh,Wellman, MichaelSoK: Towards the Science of Security and Privacy in Machine Learning(2018)IEEE European Symposium on Security and Privacy.Cited 334 times.; Papernot, N.,McDaniel, P.,Wu, X.,Jha, S.,Swami, A.; Parkhi, Omkar M.,Vedaldi, Andrea,Zisserman, AndrewDeep Face Recognition(2015)British Machine Vision Conference.Cited 4117 times.; (2017)SciPy. Median Filter (scipy.ndimage.median_filter)https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.medianfilter.html#scipy.ndimage.median_filter; Szegedy, C.,Vanhoucke, V.,Ioffe, S.,Shlens, J.,Wojna, Z.; Szegedy, C.,Zaremba, W.,Sutskever, I.,Bruna, J.,Erhan, D.,Goodfellow, I.,Fergus, R.; Turk, Matthew A.,Pentland, Alex P.; Xu, Weilin,Evans, David,Qi, Yanjun(2017)Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks.Cited 596 times.arXiv preprint 1704.01155; Xu, Weilin,Evans, David,Qi, Yanjun(2017)Feature Squeezing Mitigates and Detects Carlini/Wagner Adversarial Examples.Cited 30 times.arXiv preprint 1705.10686		"""@CONFERENCE{Xu2018,
    author = ""Xu, Weilin and Evans, David and Qi, Yanjun"",
    title = ""Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks"",
    year = ""2018"",
    journal = ""25th Annual Network and Distributed System Security Symposium, NDSS 2018"",
    doi = ""10.14722/ndss.2018.23198"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093334791\&doi=10.14722\%2fndss.2018.23198\&partnerID=40\&md5=9ddb2f054f92a47611699393055cc0fa"",
    affiliations = ""University of Virginia, United States"",
    abstract = ""Although deep neural networks (DNNs) have achieved great success in many tasks, they can often be fooled by adversarial examples that are generated by adding small but purposeful distortions to natural examples. Previous studies to defend against adversarial examples mostly focused on refining the DNN models, but have either shown limited success or required expensive computation. We propose a new strategy, feature squeezing, that can be used to harden DNN models by detecting adversarial examples. Feature squeezing reduces the search space available to an adversary by coalescing samples that correspond to many different feature vectors in the original space into a single sample. By comparing a DNN model's prediction on the original input with that on squeezed inputs, feature squeezing detects adversarial examples with high accuracy and few false positives. This paper explores two feature squeezing methods: reducing the color bit depth of each pixel and spatial smoothing. These simple strategies are inexpensive and complementary to other defenses, and can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks. (c) 2018 25th Annual Network and Distributed System Security Symposium, NDSS 2018. All Rights Reserved."",
    keywords = ""Feature extraction; Flocculation; Neural network models; Vector spaces; Bit depth; False positive; Features vector; High-accuracy; Input features; Neural network model; Search spaces; Simple++; Single sample; Spatial smoothing; Deep neural networks"",
    publisher = ""The Internet Society"",
    isbn = ""1891562495; 978-189156249-5"",
    language = ""English"",
    abbrev_source_title = ""Annu. Netw. Distrib. Syst. Secur. Symp., NDSS"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 617; Conference name: 25th Annual Network and Distributed System Security Symposium, NDSS 2018; Conference date: 18 February 2018 through 21 February 2018; Conference code: 195211; All Open Access, Bronze Open Access, Green Open Access""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2017	Feature squeezing: Detecting adversarial examples in deep neural networks	https://doi.org/10.14722/ndss.2018.23198	The Internet Society	nan; Pages; Link
151	TestNN	On Detecting Adversarial Perturbations	"Machine learning and deep learning in particular has advanced tremendously on perceptual tasks in recent years. However, it remains vulnerable against adversarial perturbations of the input that have been crafted specifically to fool the system while being quasi-imperceptible to a human. In this work, we propose to augment deep neural networks with a small ""detector"" subnetwork which is trained on the binary classification task of distinguishing genuine data from data containing adversarial perturbations. Our method is orthogonal to prior work on addressing adversarial perturbations, which has mostly focused on making the classification network itself more robust. We show empirically that adversarial perturbations can be detected surprisingly well even though they are quasi-imperceptible to humans. Moreover, while the detectors have been trained to detect only a specific adversary, they generalize to similar and weaker adversaries. In addition, we propose an adversarial attack that fools both the classifier and the detector and a novel training procedure for the detector that counteracts this attack."		Jan Hendrik Metzen; Tim Genewein; Volker Fischer; Bastian Bischoff	arXiv	https://doi.org/10.48550/arXiv.1702.04267				Included	Included	snowballing			1	IEEE	2017	On detecting adversarial perturbations	https://doi.org/10.48550/arXiv.1702.04267	IEEE	nan; Keywords; References; Pages; Year; Bibtex; Link
152	TestNN	Parseval networks: Improving robustness to adversarial examples	We introduce Parseval networks, a form of deep neural networks in which the Lipschitz constant of linear, convolutional and aggregation layers is constrained to be smaller than 1. Parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation. The most important feature of Parseval networks is to maintain weight matrices of linear and convolutional layers to be (approximately) Parseval tight frames, which are extensions of orthogonal matrices to non-square matrices. We describe how these constraints can be maintained efficiently during SGD. We show that Parseval networks match the state-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House Numbers (SVHN), while being more robust than their vanilla counterpart against adversarial examples. Incidentally, Parseval networks also tend to train faster and make a better usage of the full capacity of the networks.	Artificial intelligence; Convolution; Deep neural networks; Important features; Lipschitz constant; Orthogonal matrix; Square matrices; State of the art; Tight frame; Weight matrices; Matrix algebra; Artificial intelligence;  Convolution;  Deep neural networks;  Important features;  Lipschitz constant;  Orthogonal matrix;  Square matrices;  State of the art;  Tight frame;  Weight matrices;  Matrix algebra	Cisse, Moustapha; Bojanowski, Piotr; Grave, Edouard; Dauphin, Yann; Usunier, Nicolas	34th International Conference on Machine Learning, ICML 2017	https://www.scopus.com/record/display.uri?eid=2-s2.0-85046998902&origin=resultslist&sort=plf-f&src=s&sid=aa717988d682fb843399a0bb1381b73b&sot=b&sdt=b&s=TITLE-ABS-KEY%28parseval+networks+improving+robustness+to+adversarial+examples%29&sl=77&sessionSearchId=aa717988d682fb843399a0bb1381b73b&relpos=0		1423 - 1432	"""@CONFERENCE{Cisse20171423,
    author = ""Cisse, Moustapha and Bojanowski, Piotr and Grave, Edouard and Dauphin, Yann and Usunier, Nicolas"",
    title = ""Parseval networks: Improving robustness to adversarial examples"",
    year = ""2017"",
    journal = ""34th International Conference on Machine Learning, ICML 2017"",
    volume = ""2"",
    pages = ""1423 - 1432"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046998902\&partnerID=40\&md5=e83a5aae0741ba575818c2526f5f294b"",
    affiliations = ""Facebook AI Research, France"",
    abstract = ""We introduce Parseval networks, a form of deep neural networks in which the Lipschitz constant of linear, convolutional and aggregation layers is constrained to be smaller than 1. Parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation. The most important feature of Parseval networks is to maintain weight matrices of linear and convolutional layers to be (approximately) Parseval tight frames, which are extensions of orthogonal matrices to non-square matrices. We describe how these constraints can be maintained efficiently during SGD. We show that Parseval networks match the state-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House Numbers (SVHN), while being more robust than their vanilla counterpart against adversarial examples. Incidentally, Parseval networks also tend to train faster and make a better usage of the full capacity of the networks. (c) 2017 by the author (s)."",
    keywords = ""Artificial intelligence; Convolution; Deep neural networks; Important features; Lipschitz constant; Orthogonal matrix; Square matrices; State of the art; Tight frame; Weight matrices; Matrix algebra"",
    correspondence_address = ""M. Cisse; Facebook AI Research, France; email: moustaphacisse@fb.com"",
    publisher = ""International Machine Learning Society (IMLS)"",
    isbn = ""978-151085514-4"",
    language = ""English"",
    abbrev_source_title = ""Int. Conf. Mach. Learn., ICML"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 281; Conference name: 34th International Conference on Machine Learning, ICML 2017; Conference date: 6 August 2017 through 11 August 2017; Conference code: 136027""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2017	Parseval networks: Improving robustness to adversarial examples	https://www.scopus.com/record/display.uri?eid=2-s2.0-85046998902&origin=resultslist&sort=plf-f&src=s&sid=aa717988d682fb843399a0bb1381b73b&sot=b&sdt=b&s=TITLE-ABS-KEY%28parseval+networks+improving+robustness+to+adversarial+examples%29&sl=77&sessionSearchId=aa717988d682fb843399a0bb1381b73b&relpos=0	International Machine Learning Society (IMLS)	nan; References
153	TestNN	Reachable Set Estimation and Safety Verification for Piecewise Linear Systems with Neural Network Controllers	In this work, the reachable set estimation and safety verification problems for a class of piecewise linear systems equipped with neural network controllers are addressed. The neural network is considered to consist of Rectified Linear Unit (ReLU) activation functions. A layer-by-layer approach is developed for the output reachable set computation of ReLU neural networks. The computation is formulated in the form of a set of manipulations for a union of polytopes. Based on the output reachable set for neural network controllers, the output reachable set for a piecewise linear feedback control system can be estimated iteratively for a given finite-time interval. With the estimated output reachable set, the safety verification for piecewise linear systems with neural network controllers can be performed by checking the existence of intersections of unsafe regions and output reach set. A numerical example is presented to illustrate the effectiveness of our approach.	Safety;Linear systems;Neurons;Estimation;Closed loop systems;Biological neural networks; Safety; Linear systems; Neurons; Estimation; Closed loop systems; Biological neural networks	Xiang, Weiming; Tran, Hoang-Dung; Rosenfeld, Joel A.; Johnson, Taylor T.	2018 Annual American Control Conference (ACC)	https://doi.org/10.23919/ACC.2018.8431048		1574-1579	"""@INPROCEEDINGS{8431048,
    author = ""Xiang, Weiming and Tran, Hoang-Dung and Rosenfeld, Joel A. and Johnson, Taylor T."",
    booktitle = ""2018 Annual American Control Conference (ACC)"",
    title = ""Reachable Set Estimation and Safety Verification for Piecewise Linear Systems with Neural Network Controllers"",
    year = ""2018"",
    volume = """",
    number = """",
    pages = ""1574-1579"",
    abstract = ""In this work, the reachable set estimation and safety verification problems for a class of piecewise linear systems equipped with neural network controllers are addressed. The neural network is considered to consist of Rectified Linear Unit (ReLU) activation functions. A layer-by-layer approach is developed for the output reachable set computation of ReLU neural networks. The computation is formulated in the form of a set of manipulations for a union of polytopes. Based on the output reachable set for neural network controllers, the output reachable set for a piecewise linear feedback control system can be estimated iteratively for a given finite-time interval. With the estimated output reachable set, the safety verification for piecewise linear systems with neural network controllers can be performed by checking the existence of intersections of unsafe regions and output reach set. A numerical example is presented to illustrate the effectiveness of our approach."",
    keywords = ""Safety;Linear systems;Neurons;Estimation;Closed loop systems;Biological neural networks"",
    doi = ""10.23919/ACC.2018.8431048"",
    ISSN = ""2378-5861"",
    month = ""June""
}
"""	Included	Included	snowballing			1	IEEE	2017	Reachable set computation and safety verification for neural networks with ReLU activations	https://doi.org/10.23919/ACC.2018.8431048	IEEE	nan; References; Link
154	TestNN	A Study of Deep Learning Robustness Against Computation Failures			Vialatte, J.-C. and F. Leduc-Primeau						Included	Included	snowballing			1		2017				
155	TestNN	Towards proving the adversarial robustness of deep neural networks	Autonomous vehicles are highly complex systems, required to function reliably in a wide variety of situations. Manually crafting software controllers for these vehicles is difficult, but there has been some success in using deep neural networks generated usingmachine-learning. However, deep neural networks are opaque to human engineers, rendering their correctness very difficult to provemanually; and existing automated techniques, which were not designed to operate on neural networks, fail to scale to large systems. This paper focuses on proving the adversarial robustness of deep neural networks, i.e. proving that small perturbations to a correctly-classified input to the network cannot cause it to be misclassified. We describe some of our recent and ongoing work on verifying the adversarial robustness of networks, and discuss some of the open questions we have encountered and how they might be addressed.	Formal verification; Vehicles; Automated techniques; Autonomous Vehicles; Large system; Small perturbations; Software controllers; Deep neural networks; Formal verification;  Vehicles;  Automated techniques;  Autonomous Vehicles;  Large system;  Small perturbations;  Software controllers;  Deep neural networks	Katz, Guy; Barrett, Clark; Dill, David L.; Julian, Kyle; Kochenderfer, Mykel J.	Electronic Proceedings in Theoretical Computer Science, EPTCS	https://doi.org/10.4204/EPTCS.257.3	Althoff, M.,Dolan, J.M.; Bastani, O.,Ioannou, Y.,Lampropoulos, L.,Vytiniotis, D.,Nori, A.V.,Criminisi, A.; Bojarski, M.,Del Testa, D.,Dworakowski, D.,Firner, B.,Flepp, B.,Goyal, P.,Jackel, L.,(...),Zieba, K.(2016)End to End Learning for Self-Driving Cars.Cited 2970 times.Technical Reporthttp://arxiv.org/abs/1604.07316; Carlini, N.,Wagner, D.; Glorot, X.,Bordes, A.,Bengio, Y.; Goodfellow, I.,Bengio, Y.,Courville, A.(2016)Deep Learning.Cited 37838 times.MIT Press; Goodfellow, I.,Shlens, J.,Szegedy, C.(2014)Explaining and Harnessing Adversarial Examples.Cited 7263 times.Technical Reporthttp://arxiv.org/abs/1412.6572; Hinton, G.,Deng, L.,Yu, D.,Dahl, G.,Mohamed, A.-R.,Jaitly, N.,Senior, A.,(...),Kingsbury, B.; Huang, X.,Kwiatkowska, M.,Wang, S.,Wu, M.(2016)Safety Verification of Deep Neural Networks.Cited 91 times.Technical Reporthttp://arxiv.org/abs/1610.06940; Jarrett, K.,Kavukcuoglu, K.,Ranzato, M.,LeCun, Y.; Jeannin, J.-B.,Ghorbal, K.,Kouskoulas, Y.,Gardner, R.,Schmidt, A.,Zawadzki, E.,Platzer, A.; Julian, K.D.,Lopez, J.,Brush, J.S.,Owen, M.P.,Kochenderfer, M.J.; Katz, G.,Barrett, C.,Dill, D.L.,Julian, K.,Kochenderfer, M.J.; Krizhevsky, A.,Sutskever, I.,Hinton, G.E.; Kurakin, A.,Goodfellow, I.,Bengio, S.(2016)Adversarial Examples in the Physical World.Cited 2181 times.Technical Reporthttp://arxiv.org/abs/1607.02533; Maas, A.,Hannun, A.,Ng, A.Rectifier nonlinearities improve neural network acoustic models(2013)Proc. 30th Int. Conf. on Machine Learning (ICML).Cited 6098 times.; Nair, V.,Hinton, G.E.; Pulina, L.,Tacchella, A.; Pulina, L.,Tacchella, A.; Silver, D.,Huang, A.,Maddison, C.J.,Guez, A.,Sifre, L.,Van Den Driessche, G.,Schrittwieser, J.,(...),Hassabis, D.; Szegedy, C.,Zaremba, W.,Sutskever, I.,Bruna, J.,Erhan, D.,Goodfellow, I.,Fergus, R.(2013)Intriguing Properties of Neural Networks.Cited 6247 times.Technical Reporthttp://arxiv.org/abs/1312.6199	19 - 26	"""@CONFERENCE{Katz201719,
    author = ""Katz, Guy and Barrett, Clark and Dill, David L. and Julian, Kyle and Kochenderfer, Mykel J."",
    editor = ""L., Bulwahn and M., Kamali and S., Linker"",
    title = ""Towards proving the adversarial robustness of deep neural networks"",
    year = ""2017"",
    journal = ""Electronic Proceedings in Theoretical Computer Science, EPTCS"",
    volume = ""257"",
    pages = ""19 - 26"",
    doi = ""10.4204/EPTCS.257.3"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030095870\&doi=10.4204\%2fEPTCS.257.3\&partnerID=40\&md5=7c1218ee68d68aa322e5e3ba887dba5e"",
    affiliations = ""Stanford University, United States"",
    abstract = ""Autonomous vehicles are highly complex systems, required to function reliably in a wide variety of situations. Manually crafting software controllers for these vehicles is difficult, but there has been some success in using deep neural networks generated usingmachine-learning. However, deep neural networks are opaque to human engineers, rendering their correctness very difficult to provemanually; and existing automated techniques, which were not designed to operate on neural networks, fail to scale to large systems. This paper focuses on proving the adversarial robustness of deep neural networks, i.e. proving that small perturbations to a correctly-classified input to the network cannot cause it to be misclassified. We describe some of our recent and ongoing work on verifying the adversarial robustness of networks, and discuss some of the open questions we have encountered and how they might be addressed."",
    keywords = ""Formal verification; Vehicles; Automated techniques; Autonomous Vehicles; Large system; Small perturbations; Software controllers; Deep neural networks"",
    correspondence_address = ""G. Katz; Stanford University, United States; email: guyk@stanford.edu"",
    publisher = ""Open Publishing Association"",
    issn = ""20752180"",
    language = ""English"",
    abbrev_source_title = ""Electron. Proc. Theor. Comput. Sci., EPTCS"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 47; Conference name: 1st Workshop on Formal Verification of Autonomous Vehicles, FVAV 2017; Conference date: 19 September 2017; Conference code: 130650; All Open Access, Gold Open Access""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2017	Towards proving the adversarial robustness of deep neural networks 2	https://doi.org/10.4204/EPTCS.257.3	Open Publishing Association	nan; Link
156	TestNN	Axiomatic attribution for deep networks	We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms--SensitivityandImplementation Invariancethat attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method calledIntegrated Gradients.Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.		Mukund Sundararajan; Ankur Taly; Qiqi Yan	ICML'17: Proceedings of the 34th International Conference on Machine Learning - Volume 70	https://doi.org/10.5555/3305890.3306024		3319-3328		Included	Included	snowballing			1	ACM	2017	Axiomatic attribution for deep networks	https://doi.org/10.5555/3305890.3306024	JMLR.org	nan; Keywords; References; Year; Bibtex; Link
157	TestNN	Explaining nonlinear classification decisions with deep Taylor decomposition	Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets.	Image recognition; Learning systems; Multilayers; Network architecture; Deep neural networks; Heatmapping; Machine learning problem; Network classification; Non-linear methods; Nonlinear classification; Nonlinear structure; Scope of application; Multilayer neural networks; Image recognition;  Learning systems;  Multilayers;  Network architecture;  Deep neural networks;  Heatmapping;  Machine learning problem;  Network classification;  Non-linear methods;  Nonlinear classification;  Nonlinear structure;  Scope of application;  Multilayer neural networks	Montavon, Gregoire; Lapuschkin, Sebastian; Binder, Alexander; Samek, Wojciech; Muller, Klaus-Robert	Pattern Recognition	https://doi.org/10.1016/j.patcog.2016.11.008		211 - 222	"""@ARTICLE{Montavon2017211,
    author = ""Montavon, Gregoire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and Muller, Klaus-Robert"",
    title = ""Explaining nonlinear classification decisions with deep Taylor decomposition"",
    year = ""2017"",
    journal = ""Pattern Recognition"",
    volume = ""65"",
    pages = ""211 - 222"",
    doi = ""10.1016/j.patcog.2016.11.008"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010676902\&doi=10.1016\%2fj.patcog.2016.11.008\&partnerID=40\&md5=fe281e0adbac8b5f621dc36cba4b43f2"",
    affiliations = ""Department of Electrical Engineering \& Computer Science, Technische Universitat Berlin, Marchstr. 23, Berlin, 10587, Germany; Department of Video Coding \& Analytics, Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, Berlin, 10587, Germany; Information Systems Technology \& Design, Singapore University of Technology and Design, 8 Somapah Road, Building 1, Level 5, 487372, Singapore; Department of Brain \& Cognitive Engineering, Korea University, Anam-dong 5ga, Seongbuk-g, Seoul, 136-713, South Korea"",
    abstract = ""Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets. (c) 2016 The Author(s)"",
    author_keywords = ""Deep neural networks; Heatmapping; Image recognition; Relevance propagation; Taylor decomposition"",
    keywords = ""Image recognition; Learning systems; Multilayers; Network architecture; Deep neural networks; Heatmapping; Machine learning problem; Network classification; Non-linear methods; Nonlinear classification; Nonlinear structure; Scope of application; Multilayer neural networks"",
    correspondence_address = ""G. Montavon; Department of Electrical Engineering \& Computer Science, Technische Universitat Berlin, Berlin, Marchstr. 23, 10587, Germany; email: gregoire.montavon@tu-berlin.de"",
    publisher = ""Elsevier Ltd"",
    issn = ""00313203"",
    coden = ""PTNRA"",
    language = ""English"",
    abbrev_source_title = ""Pattern Recogn."",
    type = ""Article"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 903; All Open Access, Green Open Access, Hybrid Gold Open Access""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2017	Explaining nonlinear classification decisions with deep Taylor decomposition	https://www.scopus.com/record/display.uri?eid=2-s2.0-85010676902&origin=resultslist&sort=plf-f&src=s&sid=4dfe3ab601c352d76ef0b4e8eb562071&sot=b&sdt=b&s=TITLE-ABS-KEY%28explaining+nonlinear+classification+decisions+with+deep+taylor+decomposition%29&sl=91&sessionSearchId=4dfe3ab601c352d76ef0b4e8eb562071&relpos=0	Elsevier Ltd	nan; References
158	TestNN	Improving Interpretability of Deep Neural Networks with Semantic Information	Interpretability of deep neural networks (DNNs) is essential since it enables users to understand the overall strengths and weaknesses of the models, conveys an understanding of how the models will behave in the future, and how to diagnose and correct potential problems. However, it is challenging to reason about what a DNN actually does due to its opaque or black-box nature. To address this issue, we propose a novel technique to improve the interpretability of DNNs by leveraging the rich semantic information embedded in human descriptions. By concentrating on the video captioning task, we first extract a set of semantically meaningful topics from the human descriptions that cover a wide range of visual concepts, and integrate them into the model with an interpretive loss. We then propose a prediction difference maximization algorithm to interpret the learned features of each neuron. Experimental results demonstrate its effectiveness in video captioning using the interpretable features, which can also be transferred to video action recognition. By clearly understanding the learned features, users can easily revise false predictions via a human-in-the-loop procedure.	Semantics; Neurons; Feature extraction; Visualization; Decoding; Computational modeling; Deep Neural Network; Semantic Information; Tencent; Interpretation Of Networks; National Basic Research Program; Interpretability Of Neural Networks; Feature Learning; Action Recognition; Interpretation Of Features; Weak Model; Video Captioning; Video Action Recognition; Validation Set; Recurrent Neural Network; Attention Mechanism; Complex Architecture; Video Analysis; Learning Procedure; Topic Modeling; Textual Descriptions; Human Users; Latent Dirichlet Allocation; Polar Bears; Representative Subject; Video Features; Latent Topics; Task-specific Features; Bidirectional Long Short-term Memory; Video Content; CNN Features	Yinpeng Dong; Hang Su; Jun Zhu; Bo Zhang	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	https://doi.org/10.1109/CVPR.2017.110	"1.S.D. Ali, ""The impact of deep learning on investments: Exploring the implications one at a time"", Predictive Analytics and Futurism, vol. 13, pp. 49-50, 2016. Google Scholar; 2.N. Ballas, L. Yao, C. Pal and A. Courville, ""Delving deeper into convolutional networks for learning video representations"", ICLR, 2016. Google Scholar; 3.Y. Bengio, A. Courville and P. Vincent, ""Representation learning: A review and new perspectives"", IEEE transactions on pattern analysis and machine intelligence, vol. 35, no. 8, pp. 1798-1828, 2013. View Article  Google Scholar; 4.D.M. Blei, A.Y. Ng and M.I. Jordan, ""Latent dirichlet allocation"", Journal of machine Learning research, vol. 3, pp. 993-1022, Jan 2003. Google Scholar; 5.M. Bojarski, D. Del Testa, D. Dworakowski, B. Firner, B. Flepp, P. Goyal, L.D. Jackel, M. Monfort, U. Muller, J. Zhang et al., End to end learning for self-driving cars, 2016. Google Scholar; 6.J.L. Boyd-Graber, D.M. Blei and X. Zhu, ""A topic model for word sense disambiguation"", EMNLP-CoNLL, 2007. Google Scholar; 7.L. Cao and L. Fei-Fei, ""Spatially coherent latent topic model for concurrent segmentation and classification of objects and scenes"", ICCV, 2007. View Article  Google Scholar; 8.D.L. Chen and W.B. Dolan, ""Collecting highly parallel data for paraphrase evaluation"", ACL, 2011. Google Scholar; 9.J. Chen, K. Li, J. Zhu and W. Chen, ""Warplda: a simple and efficient o (1) algorithm for latent dirichlet allocation"", VLDB, 2016. CrossRef  Google Scholar; 10.J. Chung, C. Gulcehre, K. Cho and Y. Bengio, ""Empirical evaluation of gated recurrent neural networks on sequence modeling"", NIPS Workshop on Deep Learning, 2014. Google Scholar; 11.M. Denkowski and A. Lavie, ""Meteor universal: Language specific translation evaluation for any target language"", ACL Workshop on Statistical Machine Translation, 2014. CrossRef  Google Scholar; 12.D. Erhan, Y. Bengio, A. Courville and P. Vincent, Visualizing higher-layer features of a deep network, University of Montreal, pp. 1341, 2009. Google Scholar; 13.L. Fei-Fei and P. Perona, ""A bayesian hierarchical model for learning natural scene categories"", CVPR, 2005. View Article  Google Scholar; 14.R. Girshick, J. Donahue, T. Darrell and J. Malik, ""Rich feature hierarchies for accurate object detection and semantic segmentation"", CVPR, 2014. View Article  Google Scholar; 15.""Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique"", IEEE Transactions on Medical Imaging, vol. 35, no. 5, pp. 1153-1159, 2016. View Article  Google Scholar; 16.B. Huval, T. Wang, S. Tandon, J. Kiske, W. Song, J. Pazhayampallil, M. Andriluka, P. Rajpurkar, T. Migimatsu, R. Cheng-Yue et al., An empirical evaluation of deep learning on highway driving, 2015. Google Scholar; 17.A. Karpathy, J. Johnson and L. Fei-Fei, ""Visualizing and understanding recurrent networks"", ICLR Workshop, 2016. Google Scholar; 18.A. Krizhevsky, I. Sutskever and G.E. Hinton, ""Imagenet classification with deep convolutional neural networks"", NIPS, 2012. Google Scholar; 19.Y. LeCun, Y. Bengio and G. Hinton, ""Deep learning"", Nature, vol. 521, no. 7553, pp. 436-444, 2015. CrossRef  Google Scholar; 20.A.-A. Liu, Y.-T. Su, W.-Z. Nie and M. Kankanhalli, ""Hierarchical clustering multi-task learning for joint human action grouping and recognition"", IEEE transactions on pattern analysis and machine intelligence, vol. 39, no. 1, pp. 102-114, 2017. View Article  Google Scholar; 21.A.-A. Liu, N. Xu, W.-Z. Nie, Y.-T. Su, Y. Wong and M. Kankanhalli, ""Benchmarking a multimodal and multiview and interactive dataset for human action recognition"", IEEE Transactions on Cybernetics, 2016. Google Scholar; 22.J. Liu, J. Luo and M. Shah, ""Recognizing realistic actions from videos in the wild"", CVPR, 2009. View Article  Google Scholar; 23.M. Liu, J. Shi, Z. Li, C. Li, J. Zhu and S. Liu, ""Towards better analysis of deep convolutional neural networks"", VAST, 2016. Google Scholar; 24.A. Nguyen, J. Yosinski and J. Clune, ""Deep neural networks are easily fooled: High confidence predictions for unrecognizable images"", CVPR, 2015. View Article  Google Scholar; 25.A. Nguyen, J. Yosinski and J. Clune, ""Multifaceted feature visualization: Uncovering the different types of features learned by each neuron in deep neural networks"", ICML Visualization Workshop, 2016. Google Scholar; 26.Y. Pan, T. Mei, T. Yao, H. Li and Y. Rui, ""Jointly modeling embedding and translation to bridge video and language"", CVPR, 2016. View Article  Google Scholar; 27.K. Papineni, S. Roukos, T. Ward and W.-J. Zhu, ""Bleu: a method for automatic evaluation of machine translation"", ACL, 2002. CrossRef  Google Scholar; 28.S. Ren, K. He, R. Girshick and J. Sun, ""Faster r-cnn: Towards real-time object detection with region proposal networks"", NIPS, 2015. Google Scholar; 29.M. Schuster and K.K. Paliwal, ""Bidirectional recurrent neural networks"", IEEE Transactions on Signal Processing, vol. 45, no. 11, pp. 2673-2681, 1997. View Article  Google Scholar; 30.C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, et al., ""Going deeper with convolutions"", CVPR, 2015. View Article  Google Scholar"			Included	Included	snowballing			1	IEEE	2017	Improving interpretability of deep neural networks with semantic information	https://doi.org/10.1109/CVPR.2017.110	IEEE	nan; Pages; Year; Bibtex; Link
159	TestNN	Interpretability via Model Extraction	The ability to interpret machine learning models has become increasingly important now that machine learning is used to inform consequential decisions. We propose an approach called model extraction for interpreting complex, blackbox models. Our approach approximates the complex model using a much more interpretable model; as long as the approximation quality is good, then statistical properties of the complex model are reflected in the interpretable model. We show how model extraction can be used to understand and debug random forests and neural nets trained on several datasets from the UCI Machine Learning Repository, as well as control policies learned for several classical reinforcement learning problems.		Osbert Bastani; Carolyn Kim; Hamsa Bastani	arXiv	https://doi.org/10.48550/arXiv.1706.09773				Included	Included	snowballing			1	arXiv	2017	Interpretability via model extraction	https://doi.org/10.48550/arXiv.1706.09773	arXiv	nan; Keywords; References; Pages; Year; Bibtex; Link
160	TestNN	Interpretable Explanations of Black Boxes by Meaningful Perturbation	"As machine learning algorithms are increasingly applied to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks ""look"" in an image for evidence for their predictions. However, these techniques are limited by their heuristic nature and architectural constraints. In this paper, we make two main contributions: First, we propose a general framework for learning different kinds of explanations for any black box algorithm. Second, we specialise the framework to find the part of an image most responsible for a classifier decision. Unlike previous works, our method is model-agnostic and testable because it is grounded in explicit and interpretable image perturbations."	Perturbation methods;Neural networks;Visualization;Machine learning algorithms;Prediction algorithms;Backpropagation;Gradient methods; Perturbation methods; Neural networks; Visualization; Machine learning algorithms; Prediction algorithms; Backpropagation; Gradient methods	Fong, Ruth C.; Vedaldi, Andrea	2017 IEEE International Conference on Computer Vision (ICCV)	https://doi.org/10.1109/ICCV.2017.371		3449-3457	"""@INPROCEEDINGS{8237633,
    author = ""Fong, Ruth C. and Vedaldi, Andrea"",
    booktitle = ""2017 IEEE International Conference on Computer Vision (ICCV)"",
    title = ""Interpretable Explanations of Black Boxes by Meaningful Perturbation"",
    year = ""2017"",
    volume = """",
    number = """",
    pages = ""3449-3457"",
    abstract = ""As machine learning algorithms are increasingly applied to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks ""look"" in an image for evidence for their predictions. However, these techniques are limited by their heuristic nature and architectural constraints. In this paper, we make two main contributions: First, we propose a general framework for learning different kinds of explanations for any black box algorithm. Second, we specialise the framework to find the part of an image most responsible for a classifier decision. Unlike previous works, our method is model-agnostic and testable because it is grounded in explicit and interpretable image perturbations."",
    keywords = ""Perturbation methods;Neural networks;Visualization;Machine learning algorithms;Prediction algorithms;Backpropagation;Gradient methods"",
    doi = ""10.1109/ICCV.2017.371"",
    ISSN = ""2380-7504"",
    month = ""Oct""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2017	Interpretable explanations of black boxes by meaningful perturbation	https://ieeexplore.ieee.org/document/8237633	IEEE	nan; References
161	TestNN	Real time image saliency for black box classifiers	In this work we develop a fast saliency detection method that can be applied to any differentiable image classifier. We train a masking model to manipulate the scores of the classifier by masking salient parts of the input image. Our model generalises well to unseen images and requires a single forward pass to perform saliency detection, therefore suitable for use in real-time systems. We test our approach on CIFAR-10 and ImageNet datasets and show that the produced saliency maps are easily interpretable, sharp, and free of artifacts. We suggest a new metric for saliency and test our method on the ImageNet object localisation task. We achieve results outperforming other weakly supervised methods.	Image classification; Image segmentation; Interactive computer systems; Black boxes; Image Classifiers; Localisation; Masking models; Real time images; Saliency detection; Saliency map; Supervised methods; Real time systems; Image classification;  Image segmentation;  Interactive computer systems;  Black boxes;  Image Classifiers;  Localisation;  Masking models;  Real time images;  Saliency detection;  Saliency map;  Supervised methods;  Real time systems	Dabkowski, Piotr; Gal, Yarin	Advances in Neural Information Processing Systems	https://www.scopus.com/record/display.uri?eid=2-s2.0-85047021939&origin=resultslist&sort=plf-f&src=s&sid=9177e9b47c3c22efd3cad2fe3ac91c88&sot=b&sdt=b&s=TITLE-ABS-KEY%28real+time+image+saliency+for+black+box+classifiers%29&sl=65&sessionSearchId=9177e9b47c3c22efd3cad2fe3ac91c88&relpos=0		6968 - 6977	"""@CONFERENCE{Dabkowski20176968,
    author = ""Dabkowski, Piotr and Gal, Yarin"",
    editor = ""I., Guyon and R., Fergus and H., Wallach and H., Wallach and I., Guyon and S.V.N., Vishwanathan and von Luxburg U. and R., Garnett and S.V.N., Vishwanathan and S., Bengio and R., Fergus"",
    title = ""Real time image saliency for black box classifiers"",
    year = ""2017"",
    journal = ""Advances in Neural Information Processing Systems"",
    volume = ""2017-December"",
    pages = ""6968 - 6977"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047021939\&partnerID=40\&md5=d7fc61dc7820b5003e899a747ead5ffa"",
    affiliations = ""University of Cambridge, United Kingdom; Alan Turing Institute, London, United Kingdom"",
    abstract = ""In this work we develop a fast saliency detection method that can be applied to any differentiable image classifier. We train a masking model to manipulate the scores of the classifier by masking salient parts of the input image. Our model generalises well to unseen images and requires a single forward pass to perform saliency detection, therefore suitable for use in real-time systems. We test our approach on CIFAR-10 and ImageNet datasets and show that the produced saliency maps are easily interpretable, sharp, and free of artifacts. We suggest a new metric for saliency and test our method on the ImageNet object localisation task. We achieve results outperforming other weakly supervised methods. (c) 2017 Neural information processing systems foundation. All rights reserved."",
    keywords = ""Image classification; Image segmentation; Interactive computer systems; Black boxes; Image Classifiers; Localisation; Masking models; Real time images; Saliency detection; Saliency map; Supervised methods; Real time systems"",
    publisher = ""Neural information processing systems foundation"",
    issn = ""10495258"",
    language = ""English"",
    abbrev_source_title = ""Adv. neural inf. proces. syst."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 336; Conference name: 31st Annual Conference on Neural Information Processing Systems, NIPS 2017; Conference date: 4 December 2017 through 9 December 2017; Conference code: 136033""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2017	Real time image saliency for black box classifiers	https://www.scopus.com/record/display.uri?eid=2-s2.0-85047021939&origin=resultslist&sort=plf-f&src=s&sid=9177e9b47c3c22efd3cad2fe3ac91c88&sot=b&sdt=b&s=TITLE-ABS-KEY%28real+time+image+saliency+for+black+box+classifiers%29&sl=65&sessionSearchId=9177e9b47c3c22efd3cad2fe3ac91c88&relpos=0	Neural information processing systems foundation	nan; References
162	TestNN	Right for the right reasons:training differentiable models by constraining their explanations	Neural networks are among the most accurate supervised learning methods in use today. However, their opacity makes them difficult to trust in critical applications, especially if conditions in training may differ from those in test. Recent work on explanations for black-box models has produced tools (e.g. LIME) to show the implicit rules behind predictions. These tools can help us identify when models are right for the wrong reasons. However, these methods do not scale to explaining entire datasets and cannot correct the problems they reveal. We introduce a method for efficiently explaining and regularizing differentiable models by examining and selectively penalizing their input gradients. We apply these penalties both based on expert annotation and in an unsupervised fashion that produces multiple classifiers with qualitatively different decision boundaries. On multiple datasets, we show our approach generates faithful explanations and models that generalize much better when conditions differ between training and test.		Andrew Slavin Ross; Michael C. Hughes; Finale Doshi-Velez	IJCAI'17: Proceedings of the 26th International Joint Conference on Artificial Intelligence	https://doi.org/10.5555/3172077.3172259		2662-2670		Included	Included	snowballing			1	ACM	2017	Right for the right reasons: Training differentiable models by constraining their explanations	https://doi.org/10.5555/3172077.3172259	AAAI Press	nan; Keywords; References; Year; Bibtex; Link
163	TestNN	A simple neural network module for relational reasoning	Relational reasoning is a central component of generally intelligent behavior, but has proven difficult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamic physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Thus, by simply augmenting convolutions, LSTMs, and MLPs with RNs, we can remove computational burden from network components that are not well-suited to handle relational reasoning, reduce overall network complexity, and gain a general ability to reason about the relations between entities and their properties.		Adam Santoro; David Raposo; David G.T. Barrett; Mateusz Malinowski; Razvan Pascanu; Peter Battaglia; Timothy Lillicrap	NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems	https://doi.org/10.5555/3295222.3295250		4974-4983		Included	Included	snowballing			1	ACM	2017	A simple neural network module for relational reasoning	https://doi.org/10.5555/3295222.3295250	Curran Associates Inc	nan; Keywords; References; Year; Bibtex; Link
164	TestNN	A unified approach to interpreting model predictions	Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension betweenaccuracyandinterpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.		Scott M. Lundberg; Su-In Lee	NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems	https://doi.org/10.5555/3295222.3295230		4768-4777		Included	Included	snowballing			1	ACM	2017	A unified approach to interpreting model predictions	https://doi.org/10.5555/3295222.3295230	Curran Associates Inc	nan; Keywords; References; Year; Bibtex; Link
165	TestNN	Verification of Binarized Neural Networks via Inter-neuron Factoring	Binarized Neural Networks (BNN) have recently been proposed as an energy-efficient alternative to more traditional learning networks. Here we study the problem of formally verifying BNNs by reducing it to a corresponding hardware verification problem. The main step in this reduction is based on factoring computations among neurons within a hidden layer of the BNN in order to make the BNN verification problem more scalable in practice. The main contributions of this paper include results on the NP-hardness and hardness of PTAS approximability of this essential optimization and factoring step, and we design polynomial-time search heuristics for generating approximate factoring solutions. With these techniques we are able to scale the verification problem to moderately-sized BNNs for embedded devices with thousands of neurons and inputs.		"Cheng, Chih-Hong; N{\""u}hrenberg, Georg; Huang, Chung-Hao; Ruess, Harald"	Working Conference on Verified Software: Theories, Tools, and Experiments	https://doi.org/10.1007/978-3-030-03592-1_16		279--290	"""@InProceedings{10.1007/978-3-030-03592-1_16,
    author = {Cheng, Chih-Hong and N{\""u}hrenberg, Georg and Huang, Chung-Hao and Ruess, Harald},
    editor = {Piskac, Ruzica and R{\""u}mmer, Philipp},
    title = ""Verification of Binarized Neural Networks via Inter-neuron Factoring"",
    booktitle = ""Verified Software. Theories, Tools, and Experiments"",
    year = ""2018"",
    publisher = ""Springer International Publishing"",
    address = ""Cham"",
    pages = ""279--290"",
    abstract = ""Binarized Neural Networks (BNN) have recently been proposed as an energy-efficient alternative to more traditional learning networks. Here we study the problem of formally verifying BNNs by reducing it to a corresponding hardware verification problem. The main step in this reduction is based on factoring computations among neurons within a hidden layer of the BNN in order to make the BNN verification problem more scalable in practice. The main contributions of this paper include results on the NP-hardness and hardness of PTAS approximability of this essential optimization and factoring step, and we design polynomial-time search heuristics for generating approximate factoring solutions. With these techniques we are able to scale the verification problem to moderately-sized BNNs for embedded devices with thousands of neurons and inputs."",
    isbn = ""978-3-030-03592-1""
}
"""	Included	Included	snowballing			1	Springer Link	2018	Verification of binarized neural networks	https://doi.org/10.1007/978-3-030-03592-1_16	Springer International Publishing	nan; Keywords; References; Link
166	TestNN	Poster abstract: Safety analysis for UAV networks	The recent trend of collaborative operations of a network of Unmanned Aerial Vehicles (UAVs) to achieve a common objective has attracted the researchers, as well as commercial vendors. It has revolutionized the means of data collection to maximize mission performances. However, the collaborative UAVs need to be safe from cyberattacks to prevent catastrophe. They need to be able to collaborate with each other to avoid potential failure of a mission. As these smart devices are always targets of adversaries, they need to maintain safe communication with each other while avoiding fuel outage and mid-air collisions, as well as reducing the possibilities of being hacked. In this work, we present the idea of a formal verification tool that takes different UAV parameters, safety requirements, and resource constraints as input and verifies the network's safety.	Aircraft accidents; Antennas; Commercial vehicle operations; Commercial vehicles; Deep learning; Disaster prevention; Image processing; Internet of things; Collaborative operations; Formal verification tools; Mid-air collisions; Mission performance; Potential failures; Resource Constraint; Safe communications; Safety requirements; Unmanned aerial vehicles (UAV); Aircraft accidents;  Antennas;  Commercial vehicle operations;  Commercial vehicles;  Deep learning;  Disaster prevention;  Image processing;  Internet of things;  Collaborative operations;  Formal verification tools;  Mid-air collisions;  Mission performance;  Potential failures;  Resource Constraint;  Safe communications;  Safety requirements;  Unmanned aerial vehicles (UAV)	Jakaria, A.H.M.; Rahman, Mohammad Ashiqur	Proceedings - ACM/IEEE International Conference on Internet of Things Design and Implementation, IoTDI 2018	https://doi.org/10.1109/IoTDI.2018.00046		294 - 295	"""@CONFERENCE{Jakaria2018294,
    author = ""Jakaria, A.H.M. and Rahman, Mohammad Ashiqur"",
    title = ""Poster abstract: Safety analysis for UAV networks"",
    year = ""2018"",
    journal = ""Proceedings - ACM/IEEE International Conference on Internet of Things Design and Implementation, IoTDI 2018"",
    pages = ""294 - 295"",
    doi = ""10.1109/IoTDI.2018.00046"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048478177\&doi=10.1109\%2fIoTDI.2018.00046\&partnerID=40\&md5=68ef198599708e97c267fb7ec1c1f831"",
    affiliations = ""Department of Computer Science, Tennessee Tech University, Cookeville, TN, United States"",
    abstract = ""The recent trend of collaborative operations of a network of Unmanned Aerial Vehicles (UAVs) to achieve a common objective has attracted the researchers, as well as commercial vendors. It has revolutionized the means of data collection to maximize mission performances. However, the collaborative UAVs need to be safe from cyberattacks to prevent catastrophe. They need to be able to collaborate with each other to avoid potential failure of a mission. As these smart devices are always targets of adversaries, they need to maintain safe communication with each other while avoiding fuel outage and mid-air collisions, as well as reducing the possibilities of being hacked. In this work, we present the idea of a formal verification tool that takes different UAV parameters, safety requirements, and resource constraints as input and verifies the network's safety. (c) 2018 IEEE."",
    author_keywords = ""BLE; Deep learning; Image processing"",
    keywords = ""Aircraft accidents; Antennas; Commercial vehicle operations; Commercial vehicles; Deep learning; Disaster prevention; Image processing; Internet of things; Collaborative operations; Formal verification tools; Mid-air collisions; Mission performance; Potential failures; Resource Constraint; Safe communications; Safety requirements; Unmanned aerial vehicles (UAV)"",
    publisher = ""Institute of Electrical and Electronics Engineers Inc."",
    isbn = ""978-153866312-7"",
    language = ""English"",
    abbrev_source_title = ""Proc. - ACM/IEEE Int. Conf. Internet Things Des. Implement., IoTDI"",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 1; Conference name: 3rd ACM/IEEE International Conference on Internet of Things Design and Implementation, IoTDI 2018; Conference date: 17 April 2018 through 20 April 2018; Conference code: 136740""
}
"""	Excluded	Excluded	snowballing		Exclusion: full-text is not available	1	Scopus Signed In	2018	Poster abstract: Safety analysis for UAV networks	https://www.scopus.com/record/display.uri?eid=2-s2.0-85048478177&origin=resultslist&sort=plf-f&src=s&sid=aea1b3f81d35915c2b05eb3279858cf4&sot=b&sdt=b&s=TITLE-ABS-KEY%28poster+abstract+safety+analysis+for+uav+networks%29&sl=63&sessionSearchId=aea1b3f81d35915c2b05eb3279858cf4&relpos=0	Institute of Electrical and Electronics Engineers Inc	nan; References
167	TestNN	A game-based approximate verification of deep neural networks with provable guarantees	Despite the improved accuracy of deep neural networks, the discovery of adversarial examples has raised serious safety concerns. In this paper, we study two variants of pointwise robustness, themaximum safe radiusproblem, which for a given input sample computes the minimum distance to an adversarial example, and thefeature robustnessproblem, which aims to quantify the robustness of individual features to adversarial perturbations. We demonstrate that, under the assumption of Lipschitz continuity, both problems can be approximated using finite optimisation by discretising the input space, and the approximation has provable guarantees, i.e., the error is bounded. We then show that the resulting optimisation problems can be reduced to the solution of two-player turn-based games, where the first player selects features and the second perturbs the image within the feature. While the second player aims to minimise the distance to an adversarial example, depending on the optimisation objective the first player can be cooperative or competitive. We employ an anytime approach to solve the games, in the sense of approximating the value of a game by monotonically improving its upper and lower bounds. The Monte Carlo tree search algorithm is applied to compute upper bounds for both games, and the Admissible A*and the Alpha-Beta Pruning algorithms are, respectively, used to compute lower bounds for the maximum safety radius and feature robustness games. When working on the upper bound of the maximum safe radius problem, our tool demonstrates competitive performance against existing adversarial example crafting algorithms. Furthermore, we show how our framework can be deployed to evaluate pointwise robustness of neural networks in safety-critical applications such as traffic sign recognition in self-driving cars.	Automated verification; Deep neural networks; Adversarial examples; Two-player game	MinWua; MatthewWickerb; WenjieRuana; XiaoweiHuangc; MartaKwiatkowskaa	Theoretical Computer Science	https://doi.org/10.1016/j.tcs.2019.05.046		298-329		Included	Included	snowballing			1	Science Direct	2018	A Game-Based Approximate Verification of Deep Neural Networks with Provable Guarantees	https://doi.org/10.1016/j.tcs.2019.05.046	Science Direct	nan; References; Year; Bibtex; Link
168	TestNN	Anchors:high-precision model-agnostic explanations	"We introduce a novel model-agnostic system that explains the behavior of complex models with high-precision rules calledanchors, representing local, ""sufficient"" conditions for predictions. We propose an algorithm to efficiently compute these explanations for any black-box model with high-probability guarantees. We demonstrate the flexibility of anchors by explaining a myriad of different models for different domains and tasks. In a user study, we show that anchors enable users to predict how a model would behave on unseen instances with less effort and higher precision, as compared to existing linear explanations or no explanations."		Marco Tulio Ribeiro; Sameer Singh; Carlos Guestrin	AAAI'18/IAAI'18/EAAI'18: Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence	https://doi.org/10.5555/3504035.3504222		1527-1535		Included	Included	snowballing			1	ACM	2018	Anchors: High-precision model-agnostic explanations	https://doi.org/10.5555/3504035.3504222	AAAI Press	nan; Keywords; References; Year; Bibtex; Link
169	TestNN	Global-and-local attention networks for visual recognition	"Most recent gains in machine vision have originated from the development of network architectures which incorporate some form of attention. While biology is sometimes mentioned as a source of inspiration, the attentional mechanisms that have been considered by the computer vision community remain limited in comparison to the richness and diversity of the processes used by our visual system. Here, we describe a biologicallymotivated ""global-and-local attention"" (GALA) module which is shown to yield state-of-the-art object recognition accuracy when embedded in a modern deep neural network. We further describe ClickMe.ai, a largescale online experiment designed for human participants to identify diagnostic image regions for visual recognition in order to co-train a GALA network. Adding humans-inthe-loop is shown to significantly improve network accuracy, while also yielding visual representations that are more interpretable and more similar to those used by human observers."	Object recognition; deep learning; biological vision; human-in-the-loop machine learning; visual features	Linsley, D., D. Scheibler, S. Eberhardt; T. Serre	Benefits, 2018	https://ccneuro.org/2018/proceedings/1113.pdf		2	"""nan"""	Included	Included	snowballing			1	Google Scholar	2018	Global-and-local attention networks for visual recognition	https://ccneuro.org/2018/proceedings/1113.pdf	CCNeuro	
170	TestNN	Interpreting Deep Classifier by Visual Distillation of Dark Knowledge			Xu, K., D. H. Park, C. Yi and C. Sutton						Included	Included	snowballing			1		2018				
171	TestNN	Learning Functional Causal Models with Generative Neural Networks	"We introduce a new approach to functional causal modeling from observational data, calledCausal Generative Neural Networks(CGNN). CGNN leverages the power of neural networks to learn a generative model of the joint distribution of the observed variables, by minimizing the Maximum Mean Discrepancy between generated and observed data. An approximate learning criterion is proposed to scale the computational cost of the approach to linear complexity in the number of observations. The performance of CGNN is studied throughout three experiments. Firstly, CGNN is applied to cause-effect inference, where the task is to identify the best causal hypothesis out of ""X-Y"" and ""Y-X"". Secondly, CGNN is applied to the problem of identifying v-structures and conditional independences. Thirdly, CGNN is applied to multivariate functional causal modeling: given a skeleton describing the direct dependences in a set of random variablesX= [X1, ...,Xd], CGNN orients the edges in the skeleton to uncover the directed acyclic causal graph describing the causal structure of the random variables. On all three tasks, CGNN is extensively assessed on both artificial and real-world data, comparing favorably to the state-of-the-art. Finally, CGNN is extended to handle the case of confounders, where latent variables are involved in the overall causal model."	Generative neural networks; Causal structure discovery; Cause-effect pair problem; Functional causal models; Structural equation models	Olivier Goudet; Diviyan Kalainathan; Philippe Caillou; Isabelle Guyon,; David Lopez-Paz; Michele Sebag	Explainable and Interpretable Models in Computer Vision and Machine Learning	https://doi.org/10.1007/978-3-319-98131-4_3		39-80		Excluded	Excluded	snowballing		Exclusion: not aiming at testing/verification approach	1	Springer Link	2018	Learning functional causal models with generative neural networks	https://doi.org/10.1007/978-3-319-98131-4_3	Springer, Cham	nan; References; Year; Bibtex; Link
172	TestNN	Learning Global Additive Explanations for Neural Nets Using Model Distillation	Interpretability has largely focused on local explanations, i.e. explaining why a model made a particular prediction for a sample. These explanations are appealing due to their simplicity and local fidelity. However, they do not provide information about the general behavior of the model. We propose to leverage model distillation to learn global additive explanations that describe the relationship between input features and model predictions. These global explanations take the form of feature shapes, which are more expressive than feature attributions. Through careful experimentation, we show qualitatively and quantitatively that global additive explanations are able to describe model behavior and yield insights about models such as neural nets. A visualization of our approach applied to a neural net as it is trained is available at https://youtu.be/ErQYwNqzEdc.		Tan, S., R. Caruana, G. Hooker, P. Koch; A. Gordo	Machine Learning for Health (ML4H) Workshop at NeurIPS 2018.	https://d1wqtxts1xzle7.cloudfront.net/84730300/1801.08640v2-libre.pdf?1650716563=&response-content-disposition=inline%3B+filename%3DDifference_in_Outcome_Following_Surgery.pdf&Expires=1724341634&Signature=P8gCJ5C4wPm0b7suGLKMK~tuR6VWQVLwNrkhvx1ckOC~~E9zgyt44vfiWdmFJA8zyZ4XM4kdnk4DFRBMiDoYycYj4jO22UJqkVahDJ18Tts2~tP5lTj3S8TSQuwB6QWYC-10Y83Sc8ywR0tOKnH0bIRMvN3MXoY4S4Xoc5RjB~mNKuZYFcx~YDXvEtoqdOpKgAaqhQ6VbGfNA4nnJfl3OZkdPv4kOcVx9yGnUsEjXd5baPfgXWUzupXUH9niK7jV~oz6V3k4PVeaPIq0wMeTLoMGGKOlXsk-QPuhPG6sIaEnF0wAg9CZx1s7nn9aHx9h0dSc9~n7WHXrzUPoVdJewQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA		13	"""nan"""	Included	Included	snowballing			1	Google Scholar	2018	Learning Global Additive Explanations for Neural Nets Using Model Distillation	https://d1wqtxts1xzle7.cloudfront.net/84730300/1801.08640v2-libre.pdf?1650716563=&response-content-disposition=inline%3B+filename%3DDifference_in_Outcome_Following_Surgery.pdf&Expires=1724341634&Signature=P8gCJ5C4wPm0b7suGLKMK~tuR6VWQVLwNrkhvx1ckOC~~E9zgyt44vfiWdmFJA8zyZ4XM4kdnk4DFRBMiDoYycYj4jO22UJqkVahDJ18Tts2~tP5lTj3S8TSQuwB6QWYC-10Y83Sc8ywR0tOKnH0bIRMvN3MXoY4S4Xoc5RjB~mNKuZYFcx~YDXvEtoqdOpKgAaqhQ6VbGfNA4nnJfl3OZkdPv4kOcVx9yGnUsEjXd5baPfgXWUzupXUH9niK7jV~oz6V3k4PVeaPIq0wMeTLoMGGKOlXsk-QPuhPG6sIaEnF0wAg9CZx1s7nn9aHx9h0dSc9~n7WHXrzUPoVdJewQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA	Microsoft Research	
173	TestNN	Learning how to explain neural networks: Patternnet and Patternattribution	DeConvNet, Guided BackProp, LRP, were invented to better understand deep neural networks. We show that these methods do not produce the theoretically correct explanation for a linear model. Yet they are used on multi-layer networks with millions of parameters. This is a cause for concern since linear models are simple neural networks. We argue that explanation methods for neural nets should work reliably in the limit of simplicity, the linear models. Based on our analysis of linear models we propose a generalization that yields two explanation techniques (PatternNet and PatternAttribution) that are theoretically sound for linear models and produce improved explanations for deep networks.	Network layers; Linear modeling; Multi-layer network; Deep neural networks; Network layers;  Linear modeling;  Multi-layer network;  Deep neural networks	Kindermans, Pieter-Jan; Schutt, Kristof T.; Alber, Maximilian; Muller, Klaus-Robert; Erhan, Dumitru; Kim, Been; Dahne, Sven	6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings	https://www.scopus.com/record/display.uri?eid=2-s2.0-85083950751&origin=resultslist&sort=plf-f&src=s&sid=75a191a30f0c62ba1fab80e682b081fd&sot=b&sdt=b&s=TITLE-ABS-KEY%28learning+how+to+explain+neural+networks+patternnet+and+patternattribution%29&sl=88&sessionSearchId=75a191a30f0c62ba1fab80e682b081fd&relpos=0			"""@CONFERENCE{Kindermans2018,
    author = ""Kindermans, Pieter-Jan and Schutt, Kristof T. and Alber, Maximilian and Muller, Klaus-Robert and Erhan, Dumitru and Kim, Been and Dahne, Sven"",
    title = ""Learning how to explain neural networks: Patternnet and Patternattribution"",
    year = ""2018"",
    journal = ""6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings"",
    url = ""https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083950751\&partnerID=40\&md5=957a69e05c08058cde74be6a4437d430"",
    affiliations = ""Google Brain, United States; TU Berlin, Germany"",
    abstract = ""DeConvNet, Guided BackProp, LRP, were invented to better understand deep neural networks. We show that these methods do not produce the theoretically correct explanation for a linear model. Yet they are used on multi-layer networks with millions of parameters. This is a cause for concern since linear models are simple neural networks. We argue that explanation methods for neural nets should work reliably in the limit of simplicity, the linear models. Based on our analysis of linear models we propose a generalization that yields two explanation techniques (PatternNet and PatternAttribution) that are theoretically sound for linear models and produce improved explanations for deep networks. (c) Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved."",
    keywords = ""Network layers; Linear modeling; Multi-layer network; Deep neural networks"",
    publisher = ""International Conference on Learning Representations, ICLR"",
    language = ""English"",
    abbrev_source_title = ""Int. Conf. Learn. Represent., ICLR - Conf. Track Proc."",
    type = ""Conference paper"",
    publication_stage = ""Final"",
    source = ""Scopus"",
    note = ""Cited by: 92; Conference name: 6th International Conference on Learning Representations, ICLR 2018; Conference date: 30 April 2018 through 3 May 2018; Conference code: 149806""
}
"""	Included	Included	snowballing			1	Scopus Signed In	2018	Learning how to explain neural networks: Patternnet and patternattribution	https://www.scopus.com/record/display.uri?eid=2-s2.0-85083950751&origin=resultslist&sort=plf-f&src=s&sid=75a191a30f0c62ba1fab80e682b081fd&sot=b&sdt=b&s=TITLE-ABS-KEY%28learning+how+to+explain+neural+networks+patternnet+and+patternattribution%29&sl=88&sessionSearchId=75a191a30f0c62ba1fab80e682b081fd&relpos=0	International Conference on Learning Representations, ICLR	nan; References; Pages
174	TestNN	Local Rule-Based Explanations of Black Box Decision Systems	The recent years have witnessed the rise of accurate but obscure decision systems which hide the logic of their internal decision processes to the users. The lack of explanations for the decisions of black box systems is a key ethical issue, and a limitation to the adoption of machine learning components in socially sensitive and safety-critical contexts. %Therefore, we need explanations that reveals the reasons why a predictor takes a certain decision. In this paper we focus on the problem of black box outcome explanation, i.e., explaining the reasons of the decision taken on a specific instance. We propose LORE, an agnostic method able to provide interpretable and faithful explanations. LORE first leans a local interpretable predictor on a synthetic neighborhood generated by a genetic algorithm. Then it derives from the logic of the local interpretable predictor a meaningful explanation consisting of: a decision rule, which explains the reasons of the decision; and a set of counterfactual rules, suggesting the changes in the instance's features that lead to a different outcome. Wide experiments show that LORE outperforms existing methods and baselines both in the quality of explanations and in the accuracy in mimicking the black box.		Riccardo Guidotti; Anna Monreale; Salvatore Ruggieri; Dino Pedreschi; Franco Turini; Fosca Giannotti	arXiv	https://doi.org/10.48550/arXiv.1805.10820				Included	Included	snowballing			1	arXiv	2018	Local rule-based explanations of black box decision systems	https://doi.org/10.48550/arXiv.1805.10820	arXiv	nan; Keywords; References; Pages; Year; Bibtex; Link
