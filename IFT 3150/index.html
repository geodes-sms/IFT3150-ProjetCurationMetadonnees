<html><head>
<title>
IFT 3150 - Guillaume Genois
</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<style>
table, th, td {
  border: 1px solid black;
   border-collapse: collapse;
}
p, ul {
  margin-top: 10px;
  margin-bottom: 10px;
  margin-right: 150px;
  margin-left: 80px;
}
h2, h3 {
  margin-top: 30px;
  margin-bottom: 20px;
  margin-right: 150px;
  margin-left: 80px;
}

th, tr, td {
  padding-top: 10px;
  padding-right: 10px;
  padding-bottom: 10px;
  padding-left: 10px;
}
</style>
</head>

<body bgcolor="#ffffff" text="#000000">
<h1 align="center">IFT 3150 - Guillaume Genois</h1>

<hr size="2">

<p>
<b>Étudiant:</b> Guillaume Genois
<br>
<b>Matricule:</b> 20248507
<br>
<b>Courriel:</b> guillaume.genois@umontreal.ca
<br>
<b>Lien GitHub du projet:</b> https://github.com/geodes-sms/IFT3150-ProjetCurationMetadonnees
<br><br>
<b>Professeur superviseur:</b> Eugene Syriani
<br>
<b>Courriel:</b> eugene.syriani@umontreal.ca
</p>

<h2>
Titre du projet
</h2>
<p>
Curation de métadonnées pour évaluer l’utilisation de l’apprentissage machine dans le cadre de revues systématiques
</p>

<h2>Énoncé du projet</h2>
<p>
Les logiciels permettant d'effectuer des revues littéraires systématiques (RLS) permettent de définir un
processus systématique à suivre et d'automatiser le plus grand nombre possible de tâches pour les chercheurs.
Avec les avancées des modèles d'apprentissage génératifs (large language models - LLM), nous explorons
comment automatiser les tâches de RLS les plus ardues, en particulier la sélection d'articles qui est la tâche la
plus longue et la source principale d'erreur et de biais. Les LLM peuvent donc aider à automatiser ou assister
les chercheurs dans cette tâche en faisant une présélection ou un tri des articles pertinents. Pour utiliser un LLM
de façon automatisée, il faut trouver la bonne requête à formuler (prompt engineering) avec la bonne structure,
formuler les bons termes et identifier si des exemples ou explications sont nécessaire pour obtenir le meilleur
résultat. Pour la sélection dans une RLS, le LLM doit décider si un article doit être inclus ou exclus de la RLS.
Ce projet vise à construire des ensembles de données fiables et annotées avec la bonne décision afin d'évaluer
l'efficacité des LLM dans la sélection d'articles. Les données proviennent de RLS déjà publiées et pour
lesquelles le processus de sélection d'articles est disponible. Nous avons déjà identifié une 20aine de
publications (30 000+ articles au total). Les données incluent les métadonnées des articles (ex. titre, résumé,
mots-clés) et l'information sur le processus décisionnel (ex. décision de chaque réviseur, décisions
conflictuelles, décision finale). Cependant, ces données sont souvent incomplètes et représentées dans des
formats différents. De plus, les informations décisionnelles doivent souvent être inférées à partir de l'article
publié et des données disponibles.<br><br>
Je ferai la collecte des métadonnées des articles ciblés, l'analyse des informations à inférer. J'effectuerai
le nettoyage, la définition et l'alignement de tous ces articles. Je développerai des algorithmes pour automatiser
cette tâche afin de réduire le risque d'erreur. En parallèle, l'étudiant M.Sc. Gauransh Kumar aura développé
l'outil pour évaluer les LLM avec cet ensemble de données. L'analyse d'articles RLS me permettra d'apprendre la méthodologie de ce genre d'étude. Avec le développement d'outil de curation dedonnées, j'appliquerai les connaissances acquises dans les cours que j'ai suivis sur des cas réels.
</p>

<h2>Description détaillée</h2>
<p>
<b>Titre:</b> Curation de métadonnées pour évaluer l’utilisation de l’apprentissage machine dans le cadre de revues systématiques
<br><br>
<b>Spécification fonctionnelle:</b> Livraison de 16 jeux de données venant répliquer les processus de sélection de leur revue systématique. Chaque jeu de données contient les informations suivantes:<br>
project, title, abstract, keywords, authors, venue, doi, references, pages, bibtex, screened_decision, final_decision, mode, inclusion_criteria, exclusion_criteria, reviewer_count, source, year, meta_title, link, publisher, metadata_missing.

<br><br>
<b>Environnement et contraintes techniques:</b> plusieurs journaux différents avec structures différentes, chaque revue systématique avec méthodologie différente, article avec métadonnées manquantes, article pas présent sur aucun principal moteur de recherche, formatage des données, sécurité des sites web des moteurs de recherche. Développement fait en Python avec comme librairies principales Pandas, Selenium et BeautifulSoup.
<br><br>
<b>Architecture logicielle:</b> <i>schéma</i>
<br><br>
<b>Modules principaux de travail:</b>
</p><ul>
<table>
	<tbody><tr>
		<td><b>Analyse de la méthodologie des revues systématiques</b></td>
		<td>Chaque revue systématique a un ou plus jeu de données avec leur propre méthodologie. Un travail d'analyse pour chaque revue systématique est donc nécessaire pour extraire les informations utiles de leurs données sources disponibles. </td>
	</tr>
	<tr>
		<td><b>Extraction des informations utiles du jeu de données fourni</b></td>
		<td>Le but est d'extraire toutes les informations nécessaire à la reproductivité du processus de sélection d'articles. En particulier, les informations sur le mode de récupération de l'article, leur critère d'exclusion et/ou d'inclusion, leur décision après les premières phases de sélection par l'abstract et leur décision finale.</td>
	</tr>
	<tr>
		<td><b>Extraction de métadonnées des HTML (parser)</b></td>
		<td>Un système d'extraction des métadonnées voulues est nécessaire. Celui-ci devra venir extraire les informations des articles présents sur les principaux moteurs de recherche tels que IEEE, ACM, Science Direct, Springer Link, Web of Science et Scopus. Ce système est indépendant des autres. Il ne demande qu'un fichier HTML en paramètre avec sa provenance afin de retourner les métadonnées.</td>
	</tr>
	<tr>
		<td><b>Recherche automatique dans les principaux moteurs de recherche</b></td>
		<td>Afin de récupérer les articles présents sur les principaux moteurs de recherche, un système automatisé vient lancer les requêtes sur les sites web des moteurs de recherche. Sur chaque requête, le système vérifie si un des articles trouvés est l'article recherché en comparant les titres. Une fois un article trouvé, le système enregistre la page HTML courante et télécharge le Bibtex offert par le moteur de recherche.</td>
	</tr>
	<tr>
		<td><b>Nettoyage et compilation des données de chaque jeu de données</b></td>
		<td>Avec les HTML et les Bibtex extraits et enregistrés, pour chaque article présent dans un jeu de données, tous les HTML et les Bibtex lui étant associés, provenants de plusieurs ou non moteurs de recherche, sont envoyés au système d'extraction de métadonnées. Les informations sont donc compilés en essayant de récupérer le maximum d'informations à travers les sources extraites.</td>
	</tr>
	<tr>
		<td><b>Intégration à ReLiS</b></td>
		<td>Détails à être confirmés vers la fin de la session si le temps le permet.</td>
	</tr>
	
</tbody></table>
</ul>
<p></p>

<h2>Plan de développement</h2>
<p>
<b>Date de début du projet:</b> Début été 2024
<br>
<b>Date de fin du projet:</b> Fin automne 2024
<br><br>
<b>Échéancier des modules principaux:</b>
</p><ul>
<table>
	<tbody><tr>
		<td><b>Analyse de la méthodologie des revues systématiques</b></td>
		<td>En continue</td>
	</tr>
	<tr>
		<td><b>Extraction des informations utiles du jeu de données fourni</b></td>
		<td>Été 2024</td>
	</tr>
	<tr>
		<td><b>Extraction de métadonnées des HTML (parser)</b></td>
		<td>Été 2024</td>
	</tr>
	<tr>
		<td><b>Recherche automatique dans les principaux moteurs de recherche</b></td>
		<td>Été 2024</td>
	</tr>
	<tr>
		<td><b>Nettoyage et compilation des données de chaque jeu de données</b></td>
		<td>En continue (le plus vite possible). 1-2 jeux de données par semaine ou en lot.</td>
	</tr>
	<tr>
		<td><b>Intégration à Bibler</b></td>
		<td>Fin AUT 2024 (si le temps le permet)</td>
	</tr>
	
</tbody></table>
</ul>
<p></p>

<hr size="2">

<h2>Rapports d'avancement</h2>
<h3>0 - Été 2024</h3>
<p>
Lors de l'été, j'ai commencé le travail pour le projet d'informatique afin de pouvoir livrer plus rapidement les jeux de données. Cela était en entente avec Prof. Eugene Syriani. J'ai donc commencé par développer le système d'extraction de métadonnées des HTML (parser). Pour le tester, j'ai développé un mini-version de l'outil de recherche automatique qui venait simplement récupérer les HTML des articles dans le jeu de données GameSE ayant un lien vers leur source. L'outil de recherche automatique a été complémenté par la suite. 7 jeux de données ont été analysés et deux jeux de données ont été complètement livrés.
<br><br>
L'objectif était de livrer plusieurs jeux de données pendant l'été. Cependant, je n'ai pas été en mesure d'atteindre cet objectif. J'ai fait plusieurs erreurs au cours de mon développement par mon inexpérience avec le "web scrapping". L'objectif pendant la session d'automne 2024 sera de livrer complètement les jeux de données restants.
</p>

<h3>1 - Semaines du 2 et 9 septembre</h3>
<ul>
<li>Mise en place du site web ci-présent en créant mon compte DIRO et en accédant à mon répertoire;</li>
<li>Complétion de l'ajout manuel des métadonnées des articles manquants dans le jeu de données de GameSE. Autour de 180 articles étaient manquants au jeu de données de plus de 3600 articles. Après les recherches manuelles, j'ai du compléter autour de 50 articles manuellement alors que les autres, j'ai pu trouver l'article dans un des journaux principaux dont l'extraction des métadonnées se fait automatiquement. Ces articles ont donc été ajoutés à la banque d'articles extraits;</li>
<li>Amélioration de la précision du système de recherche automatique en utilisant les filtres des moteurs de recherche;</li>
<li>Récupération des Bibtex des articles déjà extraits, mais dont le Bibtex manquait (fonctionnalité ajoutée plus tard);</li>
<li>Retrait des accents dans les jeux de données. Ainsi, cela règle plusieurs problèmes de formatage.</li>
</ul>
<p>
Le travail accompli est en correspondance au plan de développement. Cependant, la livraison du jeu de données GameSE tarde depuis un bon moment. Celui-ci est le premier sur lequel j'ai expérimenté les outils de recherche automatique et d'extraction des métadonnées, alors plusieurs erreurs ont été commises sur celui-ci. Beaucoup de temps a du être alloué pour réparer et récupérer les articles extraits au tout début.
</p>

<h3>2 - Semaines du 16 et 23 septembre</h3>
<ul>
<li>Quasi complétion des recherches pour les jeux de données Behave et DTCPS;</li>
<li>Ajout interopérabilité entre Linux et Windows en regroupant les variables globales des path utilisés;</li>
<li>Analyse des jeux de données ModelingAssist et ModelGuidance qui sont deux jeux de données avec des décisions comportants des conflits dans le processus de sélection;</li>
<li>Quasi complétion complète du jeu de données GameSE qui a nécessité multiples corrections et ajustements au code.</li>
</ul>
<p>
Le travail accompli est en correspondance au plan de développement. GameSE a pris plus de temps que prévu, mais maintenant qu'il est complété, les autres jeux de données seront plus rapides.
</p>

<h3>3 - Semaines du 30 septembre et 7 octobre</h3>
<ul>
<li>Complétion finale du jeu de données GameSE;</li>
<li>Re-compilation des jeux de données ESM_2 et TestNN, car ils avaient un problème d'encodage. Avec les modifications apportées dans les dernières semaines, le problème s'est réglé en recompilant simplement les jeux de données;</li>
<li>Nettoyage d'articles incorrectement enregistrés;</li>
<li>Multiples corrections et ajouts au système d'extraction des métadonnées dans les HTML;</li>
<li>Mise à jour des balises HTML pour l'extraction automatique des articles pour compléter la recherche des jeux de données Behave et DTCPS.</li>
</ul>
<p>
Le travail accompli est en correspondance au plan de développement. Avec la complétion de GameSE et l'extraction des métadonnées plus efficace, DTCPS et Behave devraient pouvoir être complété pour les semaines prochaines. ModelingAssist et ModelGuidance devraient suivre par après.
</p>

<h3>4 - Semaines du 14 et 21 octobre</h3>
<ul>
<li>Complétion du jeu de données DTCPS;</li>
<li>Ajout d'un nettoyage automatique lors de l'enregistrement des Bibtex extraits;</li>
<li>Différents ajouts encore au système d'extraction des métadonnées dans les HTML;</li>
<li>Correction d'un problème d'encodage sur les fichiers excels pour les articles ajoutés manuellement causé par l'encodage automatique utilisé sur Windows et sur Ubuntu. Une correction manuelle a été faite pour uniformiser en utf-8.</li>
</ul>
<p>
Le travail accompli est un peu en retard au plan de développement. Il faudrait que les prochaines complétions de jeux de données soient plus rapides afin de terminer dans les temps.
</p>

<h3>5 - Semaines du 28 octobre et 4 novembre</h3>
<ul>
<li>Complétion des jeux de données Behave et TrustSE. Leur complétion a demandé un ajout manuel d'environ 120 articles;</li>
<li>Ajout d'un meilleur nettoyage lors de l'extraction dans les HTML et les Bibtex des abstract, authors et keywords;</li>
<li>Ajout d'une meilleure flexibilitée en couvrant plus de cas dans les recherches sur le web pour ACM, SpringerLink et ScienceDirect.</li>
</ul>
<p>
Le travail accompli est en correspondance au plan de développement. L'extraction des articles fonctionne bien en général, tout en demandant toujours une mise à jour des balises nécessaires à la recherche en préalable. Le rythme doit être gardé pour les prochaines semaines.
</p>

<h3>6 - Semaines du 11 et 18 novembre</h3>
<ul>
<li>Débuts des recherches automatiques pour ESPLE, SecSelfAdapt, ModelGuidance, ModelingAssist, SmellReprod, CodeCompr et ArchiML;</li>
<li>Ajout d'un meilleur nettoyage des titres des articles afin de couvrir plus de cas;</li>
<li>Ajout plus grande flexibilité sur Scopus et Springer Link en récupérant plus d'articles en résultat au moteur de recherche plutôt que juste le premier;</li>
<li>Mise à jour continue des balises HTML de Scopus, Science Direct et Springer Link pour le fonctionnement de l'application.</li>
</ul>
<p>
Le travail accompli est en retard avec le plan de développement. Afin d'accélérer le processus de complétion des prochaines revues systématiques, les recherches automatiques pour plusieurs ont été tout de suite lancées afin de gagner du temps.
</p>

<h3>7 - Semaines du 25 novembre et 2 décembre</h3>
<ul>
<li>Complétion des jeux de données Behave et TrustSE. Leur complétion a demandé un ajout manuel d'environ 120 articles;</li>
<li>Complétion du document des métadonnées des projets de revues systématiques (complété pour les 15);</li>
<li>Amélioration au niveau de la robustesse pour récupérer la source par le lien ouvert par un DOI plutôt que seulement l'API de Crossref;</li>
<li>Ajout de la logique de la méthodologie pour ESPLE et SecSelfAdapt;</li>
<li>Ajout d'une dizaine d'articles manuellement pour compléter ModelGuidance.</li>
</ul>
<p>
Le travail accompli est en retard avec le plan de développement. Plusieurs revues systématiques telles que ESPLE, SmellReprod et SecSelfAdapt n'ont preque aucun article à récupérer manuellement. Il faut donc que je prenne le temps de venir les compléter manuellement. Avant l'envoi de n'importe quel jeu de données, je souhaite valider les données recueillies, mais cela retarde le projet aussi un peu.</p>

<h3>8 - Semaines du 9 et 16 décembre</h3>
<ul>
<li>Correction à l'aide de ChatGPT d'environ 700 articles dont le nom étaient mal écrits dans le fichier des données sources de ModelingAssist;</li>
<li>Ajout de la logique de la méthodologie pour CodeClone, ModelGuidance, CodeCompr et SmellReprod;</li>
<li>Ajout d'une meilleure flexibilitée en couvrant plus de cas dans les recherches sur le web pour ACM, SpringerLink et ScienceDirect;</li>
<li>Remise du rapport final.</li>
</ul>
<p>
Le travail accompli est en retard avec le plan de développement. Plusieurs revues systématiques sont complétées, 
mais il manque tout de même une validation finale avant d'être envoyée. Il manque environ 400*4 articles aux 4 derniers jeux de données, 
soient ModelingAssist, CodeClone, ArchiML et CodeCompr. Le bug se retrouve probablement dans le nettoyage pas assez complet des titres.
Ces jeux de données seront complétés lors du début de la session d'hiver.
</p>

<hr size="2">

<h2>Rapport final</h2>
<h3>Résumé</h3>
<p>
<b>Français</b>
<br>
Les revues littéraires systématiques (RLS) constituent une méthodologie clé pour synthétiser les connaissances scientifiques en suivant un processus rigoureux. Ce projet s’inscrit dans une recherche sur l'application des modèles d'apprentissage génératifs (large language models - LLM) pour automatiser des tâches critiques des RLS, notamment la sélection d'articles, souvent laborieuse et source de biais. L'objectif principal est de créer des ensembles de données annotés pour évaluer l'efficacité des LLM dans cette tâche. Les données utilisées proviennent d'une quinzaine de RLS publiées, représentant plus de 30 000 articles. Ces données incluent des métadonnées (titres, résumés, mots-clés) ainsi que des informations décisionnelles (critères d'inclusion/exclusion, décisions des réviseurs). Cependant, ces informations sont souvent incomplètes et nécessitent une normalisation pour garantir leur exploitabilité. Pour cela, plusieurs étapes ont été menées : analyse des méthodologies de RLS, extraction des métadonnées et compilation des données à partir de fichiers HTML et BibTeX issus des principaux moteurs de recherche (IEEE, ACM, Science Direct, etc.). Des algorithmes ont été développés pour automatiser la récupération, le nettoyage et l’alignement des données. Au total, 16 jeux de données standardisés ont été créés, regroupant environ 30 000 articles. Ce projet contribue au développement d’outils permettant d’assister les chercheurs dans la curation de données tout en offrant une opportunité d’apprentissage approfondi de la méthodologie des RLS et de leur application à des cas pratiques.
</p>
<p>
<b>Anglais</b>
<br>
Systematic literature reviews (SLRs) are a key methodology for synthesizing scientific knowledge through a rigorous process. This project is part of research on applying generative learning models (large language models - LLMs) to automate critical tasks in SLRs, particularly article selection, which is often laborious and prone to bias. The main objective is to create annotated datasets to evaluate the effectiveness of LLMs in this task. The data used comes from around fifteen published SLRs, representing over 30,000 articles. This data includes metadata (titles, abstracts, keywords) as well as decision-making information (inclusion/exclusion criteria, reviewer decisions). However, this information is often incomplete and requires normalization to ensure its usability. To address this, several steps were taken: analysis of SLR methodologies, extraction of metadata, and data compilation from HTML and BibTeX files obtained from major search engines (IEEE, ACM, Science Direct, etc.). Algorithms were developed to automate the retrieval, cleaning, and alignment of data. A total of 16 standardized datasets were created, encompassing about 30,000 articles. This project contributes to the development of tools to assist researchers in data curation while offering an opportunity for in-depth learning about SLR methodology and its application to practical cases.
</p>

<h3>Rapport format pdf</h3>
<p><a href="Rapport_IFT3150_GenoisGuillaume.pdf" target="_blank">Télécharger le PDF</a></p>

<hr size="2">
<p>Guillaume Genois<br>20248507<br>guillaume.genois@umontreal.ca</p>


</body></html>